2022-06-16 02:15:53,362 - Log file for this run: /home/ermanokman/repos/github/ai8x-training-detection/logs/2022.06.16-021553/2022.06.16-021553.log
2022-06-16 02:15:55,806 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2022-06-16 02:15:55,806 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0005, 'amsgrad': False}
2022-06-16 02:21:14,019 - Dataset sizes:
	training=28548
	validation=12251
	test=12251
2022-06-16 02:21:14,021 - 

2022-06-16 02:21:14,021 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:21:22,659 - Epoch: [0][  200/ 1785]    Overall Loss 10.771582    Objective Loss 10.771582                                        LR 0.001000    Time 0.043175    
2022-06-16 02:21:30,683 - Epoch: [0][  400/ 1785]    Overall Loss 10.499871    Objective Loss 10.499871                                        LR 0.001000    Time 0.041643    
2022-06-16 02:21:38,717 - Epoch: [0][  600/ 1785]    Overall Loss 10.236256    Objective Loss 10.236256                                        LR 0.001000    Time 0.041150    
2022-06-16 02:21:46,833 - Epoch: [0][  800/ 1785]    Overall Loss 9.979996    Objective Loss 9.979996                                        LR 0.001000    Time 0.041005    
2022-06-16 02:21:54,890 - Epoch: [0][ 1000/ 1785]    Overall Loss 9.747530    Objective Loss 9.747530                                        LR 0.001000    Time 0.040859    
2022-06-16 02:22:02,873 - Epoch: [0][ 1200/ 1785]    Overall Loss 9.536320    Objective Loss 9.536320                                        LR 0.001000    Time 0.040700    
2022-06-16 02:22:10,853 - Epoch: [0][ 1400/ 1785]    Overall Loss 9.344865    Objective Loss 9.344865                                        LR 0.001000    Time 0.040585    
2022-06-16 02:22:18,861 - Epoch: [0][ 1600/ 1785]    Overall Loss 9.170985    Objective Loss 9.170985                                        LR 0.001000    Time 0.040515    
2022-06-16 02:22:26,266 - Epoch: [0][ 1785/ 1785]    Overall Loss 9.019536    Objective Loss 9.019536                                        LR 0.001000    Time 0.040464    
2022-06-16 02:22:26,302 - --- validate (epoch=0)-----------
2022-06-16 02:22:26,302 - 12251 samples (16 per mini-batch)
2022-06-16 02:22:26,500 - indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)

2022-06-16 02:22:26,501 - indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)

2022-06-16 02:22:43,605 - Epoch: [0][  200/  766]    Loss 7.648111    mAP 0.747475    
2022-06-16 02:23:00,949 - Epoch: [0][  400/  766]    Loss 7.646800    mAP 0.573737    
2022-06-16 02:23:18,421 - Epoch: [0][  600/  766]    Loss 7.649039    mAP 0.440341    
2022-06-16 02:23:32,905 - Epoch: [0][  766/  766]    Loss 7.648984    mAP 0.704545    
2022-06-16 02:23:32,985 - ==> mAP: 0.70455    Loss: 7.649

2022-06-16 02:23:32,995 - ==> Best [mAP: 0.704545   vloss: 7.648984   Sparsity:0.00   Params: 335520 on epoch: 0]
2022-06-16 02:23:32,995 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:23:33,021 - 

2022-06-16 02:23:33,021 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:23:41,599 - Epoch: [1][  200/ 1785]    Overall Loss 7.518793    Objective Loss 7.518793                                        LR 0.001000    Time 0.042877    
2022-06-16 02:23:49,817 - Epoch: [1][  400/ 1785]    Overall Loss 7.421252    Objective Loss 7.421252                                        LR 0.001000    Time 0.041977    
2022-06-16 02:23:57,885 - Epoch: [1][  600/ 1785]    Overall Loss 7.328237    Objective Loss 7.328237                                        LR 0.001000    Time 0.041429    
2022-06-16 02:24:06,298 - Epoch: [1][  800/ 1785]    Overall Loss 7.235846    Objective Loss 7.235846                                        LR 0.001000    Time 0.041585    
2022-06-16 02:24:14,620 - Epoch: [1][ 1000/ 1785]    Overall Loss 7.145522    Objective Loss 7.145522                                        LR 0.001000    Time 0.041588    
2022-06-16 02:24:22,730 - Epoch: [1][ 1200/ 1785]    Overall Loss 7.061870    Objective Loss 7.061870                                        LR 0.001000    Time 0.041414    
2022-06-16 02:24:31,008 - Epoch: [1][ 1400/ 1785]    Overall Loss 6.980576    Objective Loss 6.980576                                        LR 0.001000    Time 0.041409    
2022-06-16 02:24:39,266 - Epoch: [1][ 1600/ 1785]    Overall Loss 6.899803    Objective Loss 6.899803                                        LR 0.001000    Time 0.041393    
2022-06-16 02:24:47,099 - Epoch: [1][ 1785/ 1785]    Overall Loss 6.829428    Objective Loss 6.829428                                        LR 0.001000    Time 0.041490    
2022-06-16 02:24:47,159 - --- validate (epoch=1)-----------
2022-06-16 02:24:47,159 - 12251 samples (16 per mini-batch)
2022-06-16 02:25:04,404 - Epoch: [1][  200/  766]    Loss 6.133107    mAP 0.637879    
2022-06-16 02:25:21,490 - Epoch: [1][  400/  766]    Loss 6.141204    mAP 0.840693    
2022-06-16 02:25:38,645 - Epoch: [1][  600/  766]    Loss 6.141922    mAP 0.508333    
2022-06-16 02:25:52,721 - Epoch: [1][  766/  766]    Loss 6.144713    mAP 0.666667    
2022-06-16 02:25:52,777 - ==> mAP: 0.66667    Loss: 6.145

2022-06-16 02:25:52,780 - ==> Best [mAP: 0.704545   vloss: 7.648984   Sparsity:0.00   Params: 335520 on epoch: 0]
2022-06-16 02:25:52,780 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:25:52,807 - 

2022-06-16 02:25:52,807 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:26:01,227 - Epoch: [2][  200/ 1785]    Overall Loss 6.081091    Objective Loss 6.081091                                        LR 0.001000    Time 0.042086    
2022-06-16 02:26:09,278 - Epoch: [2][  400/ 1785]    Overall Loss 6.018808    Objective Loss 6.018808                                        LR 0.001000    Time 0.041165    
2022-06-16 02:26:17,332 - Epoch: [2][  600/ 1785]    Overall Loss 5.965042    Objective Loss 5.965042                                        LR 0.001000    Time 0.040864    
2022-06-16 02:26:25,386 - Epoch: [2][  800/ 1785]    Overall Loss 5.905658    Objective Loss 5.905658                                        LR 0.001000    Time 0.040713    
2022-06-16 02:26:33,483 - Epoch: [2][ 1000/ 1785]    Overall Loss 5.858886    Objective Loss 5.858886                                        LR 0.001000    Time 0.040666    
2022-06-16 02:26:41,540 - Epoch: [2][ 1200/ 1785]    Overall Loss 5.817894    Objective Loss 5.817894                                        LR 0.001000    Time 0.040601    
2022-06-16 02:26:49,598 - Epoch: [2][ 1400/ 1785]    Overall Loss 5.786359    Objective Loss 5.786359                                        LR 0.001000    Time 0.040555    
2022-06-16 02:26:57,698 - Epoch: [2][ 1600/ 1785]    Overall Loss 5.760844    Objective Loss 5.760844                                        LR 0.001000    Time 0.040547    
2022-06-16 02:27:05,132 - Epoch: [2][ 1785/ 1785]    Overall Loss 5.737681    Objective Loss 5.737681                                        LR 0.001000    Time 0.040508    
2022-06-16 02:27:05,207 - --- validate (epoch=2)-----------
2022-06-16 02:27:05,207 - 12251 samples (16 per mini-batch)
2022-06-16 02:27:21,467 - Epoch: [2][  200/  766]    Loss 5.528664    mAP 0.746753    
2022-06-16 02:27:37,611 - Epoch: [2][  400/  766]    Loss 5.529399    mAP 0.625054    
2022-06-16 02:27:53,840 - Epoch: [2][  600/  766]    Loss 5.526292    mAP 0.839466    
2022-06-16 02:28:07,453 - Epoch: [2][  766/  766]    Loss 5.523296    mAP 0.565657    
2022-06-16 02:28:07,505 - ==> mAP: 0.56566    Loss: 5.523

2022-06-16 02:28:07,508 - ==> Best [mAP: 0.704545   vloss: 7.648984   Sparsity:0.00   Params: 335520 on epoch: 0]
2022-06-16 02:28:07,508 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:28:07,535 - 

2022-06-16 02:28:07,535 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:28:15,838 - Epoch: [3][  200/ 1785]    Overall Loss 5.496435    Objective Loss 5.496435                                        LR 0.001000    Time 0.041504    
2022-06-16 02:28:24,023 - Epoch: [3][  400/ 1785]    Overall Loss 5.486674    Objective Loss 5.486674                                        LR 0.001000    Time 0.041208    
2022-06-16 02:28:32,206 - Epoch: [3][  600/ 1785]    Overall Loss 5.479474    Objective Loss 5.479474                                        LR 0.001000    Time 0.041108    
2022-06-16 02:28:40,310 - Epoch: [3][  800/ 1785]    Overall Loss 5.465549    Objective Loss 5.465549                                        LR 0.001000    Time 0.040959    
2022-06-16 02:28:48,488 - Epoch: [3][ 1000/ 1785]    Overall Loss 5.458069    Objective Loss 5.458069                                        LR 0.001000    Time 0.040943    
2022-06-16 02:28:56,647 - Epoch: [3][ 1200/ 1785]    Overall Loss 5.448935    Objective Loss 5.448935                                        LR 0.001000    Time 0.040917    
2022-06-16 02:29:04,952 - Epoch: [3][ 1400/ 1785]    Overall Loss 5.444638    Objective Loss 5.444638                                        LR 0.001000    Time 0.041002    
2022-06-16 02:29:13,224 - Epoch: [3][ 1600/ 1785]    Overall Loss 5.438383    Objective Loss 5.438383                                        LR 0.001000    Time 0.041046    
2022-06-16 02:29:20,688 - Epoch: [3][ 1785/ 1785]    Overall Loss 5.431933    Objective Loss 5.431933                                        LR 0.001000    Time 0.040972    
2022-06-16 02:29:20,744 - --- validate (epoch=3)-----------
2022-06-16 02:29:20,744 - 12251 samples (16 per mini-batch)
2022-06-16 02:29:35,718 - Epoch: [3][  200/  766]    Loss 5.365090    mAP 0.754545    
2022-06-16 02:29:50,323 - Epoch: [3][  400/  766]    Loss 5.374977    mAP 0.796970    
2022-06-16 02:30:05,057 - Epoch: [3][  600/  766]    Loss 5.372184    mAP 0.674747    
2022-06-16 02:30:17,238 - Epoch: [3][  766/  766]    Loss 5.365688    mAP 0.875000    
2022-06-16 02:30:17,282 - ==> mAP: 0.87500    Loss: 5.366

2022-06-16 02:30:17,285 - ==> Best [mAP: 0.875000   vloss: 5.365688   Sparsity:0.00   Params: 335520 on epoch: 3]
2022-06-16 02:30:17,285 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:30:17,422 - 

2022-06-16 02:30:17,422 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:30:26,231 - Epoch: [4][  200/ 1785]    Overall Loss 5.356005    Objective Loss 5.356005                                        LR 0.001000    Time 0.044030    
2022-06-16 02:30:34,829 - Epoch: [4][  400/ 1785]    Overall Loss 5.361101    Objective Loss 5.361101                                        LR 0.001000    Time 0.043506    
2022-06-16 02:30:43,099 - Epoch: [4][  600/ 1785]    Overall Loss 5.360832    Objective Loss 5.360832                                        LR 0.001000    Time 0.042784    
2022-06-16 02:30:51,453 - Epoch: [4][  800/ 1785]    Overall Loss 5.363806    Objective Loss 5.363806                                        LR 0.001000    Time 0.042528    
2022-06-16 02:30:59,896 - Epoch: [4][ 1000/ 1785]    Overall Loss 5.360798    Objective Loss 5.360798                                        LR 0.001000    Time 0.042463    
2022-06-16 02:31:08,277 - Epoch: [4][ 1200/ 1785]    Overall Loss 5.357267    Objective Loss 5.357267                                        LR 0.001000    Time 0.042368    
2022-06-16 02:31:16,661 - Epoch: [4][ 1400/ 1785]    Overall Loss 5.358544    Objective Loss 5.358544                                        LR 0.001000    Time 0.042303    
2022-06-16 02:31:25,065 - Epoch: [4][ 1600/ 1785]    Overall Loss 5.355436    Objective Loss 5.355436                                        LR 0.001000    Time 0.042266    
2022-06-16 02:31:32,801 - Epoch: [4][ 1785/ 1785]    Overall Loss 5.354149    Objective Loss 5.354149                                        LR 0.001000    Time 0.042219    
2022-06-16 02:31:32,880 - --- validate (epoch=4)-----------
2022-06-16 02:31:32,880 - 12251 samples (16 per mini-batch)
2022-06-16 02:31:47,673 - Epoch: [4][  200/  766]    Loss 5.340721    mAP 0.631313    
2022-06-16 02:32:02,381 - Epoch: [4][  400/  766]    Loss 5.347569    mAP 0.834343    
2022-06-16 02:32:17,073 - Epoch: [4][  600/  766]    Loss 5.346416    mAP 0.769697    
2022-06-16 02:32:29,196 - Epoch: [4][  766/  766]    Loss 5.345026    mAP 0.666667    
2022-06-16 02:32:29,260 - ==> mAP: 0.66667    Loss: 5.345

2022-06-16 02:32:29,262 - ==> Best [mAP: 0.875000   vloss: 5.365688   Sparsity:0.00   Params: 335520 on epoch: 3]
2022-06-16 02:32:29,262 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:32:29,289 - 

2022-06-16 02:32:29,289 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:32:37,979 - Epoch: [5][  200/ 1785]    Overall Loss 5.306625    Objective Loss 5.306625                                        LR 0.001000    Time 0.043436    
2022-06-16 02:32:46,564 - Epoch: [5][  400/ 1785]    Overall Loss 5.317538    Objective Loss 5.317538                                        LR 0.001000    Time 0.043173    
2022-06-16 02:32:55,230 - Epoch: [5][  600/ 1785]    Overall Loss 5.325033    Objective Loss 5.325033                                        LR 0.001000    Time 0.043223    
2022-06-16 02:33:03,731 - Epoch: [5][  800/ 1785]    Overall Loss 5.326841    Objective Loss 5.326841                                        LR 0.001000    Time 0.043041    
2022-06-16 02:33:12,206 - Epoch: [5][ 1000/ 1785]    Overall Loss 5.329810    Objective Loss 5.329810                                        LR 0.001000    Time 0.042905    
2022-06-16 02:33:20,682 - Epoch: [5][ 1200/ 1785]    Overall Loss 5.329556    Objective Loss 5.329556                                        LR 0.001000    Time 0.042816    
2022-06-16 02:33:28,917 - Epoch: [5][ 1400/ 1785]    Overall Loss 5.329023    Objective Loss 5.329023                                        LR 0.001000    Time 0.042580    
2022-06-16 02:33:37,015 - Epoch: [5][ 1600/ 1785]    Overall Loss 5.328185    Objective Loss 5.328185                                        LR 0.001000    Time 0.042318    
2022-06-16 02:33:44,734 - Epoch: [5][ 1785/ 1785]    Overall Loss 5.328499    Objective Loss 5.328499                                        LR 0.001000    Time 0.042255    
2022-06-16 02:33:44,770 - --- validate (epoch=5)-----------
2022-06-16 02:33:44,770 - 12251 samples (16 per mini-batch)
2022-06-16 02:33:59,831 - Epoch: [5][  200/  766]    Loss 5.316436    mAP 0.690909    
2022-06-16 02:34:14,697 - Epoch: [5][  400/  766]    Loss 5.316938    mAP 0.821212    
2022-06-16 02:34:29,579 - Epoch: [5][  600/  766]    Loss 5.316357    mAP 0.936364    
2022-06-16 02:34:41,916 - Epoch: [5][  766/  766]    Loss 5.317741    mAP 0.935606    
2022-06-16 02:34:41,991 - ==> mAP: 0.93561    Loss: 5.318

2022-06-16 02:34:41,994 - ==> Best [mAP: 0.935606   vloss: 5.317741   Sparsity:0.00   Params: 335520 on epoch: 5]
2022-06-16 02:34:41,994 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:34:42,029 - 

2022-06-16 02:34:42,029 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:34:50,743 - Epoch: [6][  200/ 1785]    Overall Loss 5.304166    Objective Loss 5.304166                                        LR 0.001000    Time 0.043554    
2022-06-16 02:34:59,170 - Epoch: [6][  400/ 1785]    Overall Loss 5.305190    Objective Loss 5.305190                                        LR 0.001000    Time 0.042841    
2022-06-16 02:35:07,592 - Epoch: [6][  600/ 1785]    Overall Loss 5.311477    Objective Loss 5.311477                                        LR 0.001000    Time 0.042593    
2022-06-16 02:35:15,777 - Epoch: [6][  800/ 1785]    Overall Loss 5.310274    Objective Loss 5.310274                                        LR 0.001000    Time 0.042173    
2022-06-16 02:35:23,783 - Epoch: [6][ 1000/ 1785]    Overall Loss 5.307828    Objective Loss 5.307828                                        LR 0.001000    Time 0.041743    
2022-06-16 02:35:31,793 - Epoch: [6][ 1200/ 1785]    Overall Loss 5.309218    Objective Loss 5.309218                                        LR 0.001000    Time 0.041459    
2022-06-16 02:35:39,983 - Epoch: [6][ 1400/ 1785]    Overall Loss 5.310854    Objective Loss 5.310854                                        LR 0.001000    Time 0.041385    
2022-06-16 02:35:48,005 - Epoch: [6][ 1600/ 1785]    Overall Loss 5.310689    Objective Loss 5.310689                                        LR 0.001000    Time 0.041225    
2022-06-16 02:35:55,353 - Epoch: [6][ 1785/ 1785]    Overall Loss 5.311796    Objective Loss 5.311796                                        LR 0.001000    Time 0.041067    
2022-06-16 02:35:55,432 - --- validate (epoch=6)-----------
2022-06-16 02:35:55,432 - 12251 samples (16 per mini-batch)
2022-06-16 02:36:10,733 - Epoch: [6][  200/  766]    Loss 5.299386    mAP 0.670875    
2022-06-16 02:36:25,755 - Epoch: [6][  400/  766]    Loss 5.289212    mAP 0.767045    
2022-06-16 02:36:41,077 - Epoch: [6][  600/  766]    Loss 5.291243    mAP 0.628283    
2022-06-16 02:36:53,563 - Epoch: [6][  766/  766]    Loss 5.296777    mAP 0.704545    
2022-06-16 02:36:53,623 - ==> mAP: 0.70455    Loss: 5.297

2022-06-16 02:36:53,626 - ==> Best [mAP: 0.935606   vloss: 5.317741   Sparsity:0.00   Params: 335520 on epoch: 5]
2022-06-16 02:36:53,626 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:36:53,657 - 

2022-06-16 02:36:53,657 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:37:01,894 - Epoch: [7][  200/ 1785]    Overall Loss 5.306442    Objective Loss 5.306442                                        LR 0.001000    Time 0.041168    
2022-06-16 02:37:09,936 - Epoch: [7][  400/ 1785]    Overall Loss 5.299574    Objective Loss 5.299574                                        LR 0.001000    Time 0.040685    
2022-06-16 02:37:17,955 - Epoch: [7][  600/ 1785]    Overall Loss 5.292730    Objective Loss 5.292730                                        LR 0.001000    Time 0.040485    
2022-06-16 02:37:25,985 - Epoch: [7][  800/ 1785]    Overall Loss 5.296189    Objective Loss 5.296189                                        LR 0.001000    Time 0.040398    
2022-06-16 02:37:34,007 - Epoch: [7][ 1000/ 1785]    Overall Loss 5.297640    Objective Loss 5.297640                                        LR 0.001000    Time 0.040338    
2022-06-16 02:37:42,043 - Epoch: [7][ 1200/ 1785]    Overall Loss 5.298224    Objective Loss 5.298224                                        LR 0.001000    Time 0.040310    
2022-06-16 02:37:50,024 - Epoch: [7][ 1400/ 1785]    Overall Loss 5.297140    Objective Loss 5.297140                                        LR 0.001000    Time 0.040251    
2022-06-16 02:37:57,994 - Epoch: [7][ 1600/ 1785]    Overall Loss 5.298084    Objective Loss 5.298084                                        LR 0.001000    Time 0.040200    
2022-06-16 02:38:05,371 - Epoch: [7][ 1785/ 1785]    Overall Loss 5.299896    Objective Loss 5.299896                                        LR 0.001000    Time 0.040165    
2022-06-16 02:38:05,450 - --- validate (epoch=7)-----------
2022-06-16 02:38:05,450 - 12251 samples (16 per mini-batch)
2022-06-16 02:38:20,614 - Epoch: [7][  200/  766]    Loss 5.291416    mAP 0.936364    
2022-06-16 02:38:35,746 - Epoch: [7][  400/  766]    Loss 5.291241    mAP 0.722727    
2022-06-16 02:38:50,827 - Epoch: [7][  600/  766]    Loss 5.284706    mAP 0.750000    
2022-06-16 02:39:03,329 - Epoch: [7][  766/  766]    Loss 5.281965    mAP 0.867532    
2022-06-16 02:39:03,379 - ==> mAP: 0.86753    Loss: 5.282

2022-06-16 02:39:03,381 - ==> Best [mAP: 0.935606   vloss: 5.317741   Sparsity:0.00   Params: 335520 on epoch: 5]
2022-06-16 02:39:03,381 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:39:03,408 - 

2022-06-16 02:39:03,408 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:39:12,110 - Epoch: [8][  200/ 1785]    Overall Loss 5.261079    Objective Loss 5.261079                                        LR 0.001000    Time 0.043495    
2022-06-16 02:39:20,365 - Epoch: [8][  400/ 1785]    Overall Loss 5.276639    Objective Loss 5.276639                                        LR 0.001000    Time 0.042380    
2022-06-16 02:39:28,447 - Epoch: [8][  600/ 1785]    Overall Loss 5.282290    Objective Loss 5.282290                                        LR 0.001000    Time 0.041720    
2022-06-16 02:39:36,561 - Epoch: [8][  800/ 1785]    Overall Loss 5.283722    Objective Loss 5.283722                                        LR 0.001000    Time 0.041423    
2022-06-16 02:39:44,878 - Epoch: [8][ 1000/ 1785]    Overall Loss 5.283828    Objective Loss 5.283828                                        LR 0.001000    Time 0.041452    
2022-06-16 02:39:53,344 - Epoch: [8][ 1200/ 1785]    Overall Loss 5.285763    Objective Loss 5.285763                                        LR 0.001000    Time 0.041598    
2022-06-16 02:40:01,569 - Epoch: [8][ 1400/ 1785]    Overall Loss 5.285192    Objective Loss 5.285192                                        LR 0.001000    Time 0.041528    
2022-06-16 02:40:09,850 - Epoch: [8][ 1600/ 1785]    Overall Loss 5.287319    Objective Loss 5.287319                                        LR 0.001000    Time 0.041512    
2022-06-16 02:40:17,417 - Epoch: [8][ 1785/ 1785]    Overall Loss 5.288935    Objective Loss 5.288935                                        LR 0.001000    Time 0.041448    
2022-06-16 02:40:17,454 - --- validate (epoch=8)-----------
2022-06-16 02:40:17,454 - 12251 samples (16 per mini-batch)
2022-06-16 02:40:32,871 - Epoch: [8][  200/  766]    Loss 5.274275    mAP 0.664773    
2022-06-16 02:40:47,913 - Epoch: [8][  400/  766]    Loss 5.284563    mAP 0.818182    
2022-06-16 02:41:02,872 - Epoch: [8][  600/  766]    Loss 5.283539    mAP 0.893939    
2022-06-16 02:41:15,400 - Epoch: [8][  766/  766]    Loss 5.284371    mAP 0.643098    
2022-06-16 02:41:15,438 - ==> mAP: 0.64310    Loss: 5.284

2022-06-16 02:41:15,440 - ==> Best [mAP: 0.935606   vloss: 5.317741   Sparsity:0.00   Params: 335520 on epoch: 5]
2022-06-16 02:41:15,440 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:41:15,467 - 

2022-06-16 02:41:15,467 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:41:24,220 - Epoch: [9][  200/ 1785]    Overall Loss 5.274179    Objective Loss 5.274179                                        LR 0.001000    Time 0.043750    
2022-06-16 02:41:32,684 - Epoch: [9][  400/ 1785]    Overall Loss 5.277460    Objective Loss 5.277460                                        LR 0.001000    Time 0.043029    
2022-06-16 02:41:41,205 - Epoch: [9][  600/ 1785]    Overall Loss 5.276748    Objective Loss 5.276748                                        LR 0.001000    Time 0.042884    
2022-06-16 02:41:49,321 - Epoch: [9][  800/ 1785]    Overall Loss 5.280910    Objective Loss 5.280910                                        LR 0.001000    Time 0.042306    
2022-06-16 02:41:57,542 - Epoch: [9][ 1000/ 1785]    Overall Loss 5.280509    Objective Loss 5.280509                                        LR 0.001000    Time 0.042064    
2022-06-16 02:42:05,935 - Epoch: [9][ 1200/ 1785]    Overall Loss 5.280587    Objective Loss 5.280587                                        LR 0.001000    Time 0.042046    
2022-06-16 02:42:14,089 - Epoch: [9][ 1400/ 1785]    Overall Loss 5.280422    Objective Loss 5.280422                                        LR 0.001000    Time 0.041862    
2022-06-16 02:42:22,389 - Epoch: [9][ 1600/ 1785]    Overall Loss 5.281405    Objective Loss 5.281405                                        LR 0.001000    Time 0.041816    
2022-06-16 02:42:29,960 - Epoch: [9][ 1785/ 1785]    Overall Loss 5.281539    Objective Loss 5.281539                                        LR 0.001000    Time 0.041722    
2022-06-16 02:42:30,047 - --- validate (epoch=9)-----------
2022-06-16 02:42:30,047 - 12251 samples (16 per mini-batch)
2022-06-16 02:42:44,925 - Epoch: [9][  200/  766]    Loss 5.309552    mAP 0.863636    
2022-06-16 02:42:59,733 - Epoch: [9][  400/  766]    Loss 5.306089    mAP 0.790909    
2022-06-16 02:43:14,422 - Epoch: [9][  600/  766]    Loss 5.307064    mAP 0.787879    
2022-06-16 02:43:26,498 - Epoch: [9][  766/  766]    Loss 5.307610    mAP 0.767045    
2022-06-16 02:43:26,544 - ==> mAP: 0.76705    Loss: 5.308

2022-06-16 02:43:26,547 - ==> Best [mAP: 0.935606   vloss: 5.317741   Sparsity:0.00   Params: 335520 on epoch: 5]
2022-06-16 02:43:26,547 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:43:26,578 - 

2022-06-16 02:43:26,578 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:43:34,976 - Epoch: [10][  200/ 1785]    Overall Loss 5.274616    Objective Loss 5.274616                                        LR 0.001000    Time 0.041978    
2022-06-16 02:43:43,058 - Epoch: [10][  400/ 1785]    Overall Loss 5.266762    Objective Loss 5.266762                                        LR 0.001000    Time 0.041188    
2022-06-16 02:43:51,128 - Epoch: [10][  600/ 1785]    Overall Loss 5.268501    Objective Loss 5.268501                                        LR 0.001000    Time 0.040905    
2022-06-16 02:43:59,302 - Epoch: [10][  800/ 1785]    Overall Loss 5.271537    Objective Loss 5.271537                                        LR 0.001000    Time 0.040894    
2022-06-16 02:44:07,418 - Epoch: [10][ 1000/ 1785]    Overall Loss 5.274641    Objective Loss 5.274641                                        LR 0.001000    Time 0.040829    
2022-06-16 02:44:15,653 - Epoch: [10][ 1200/ 1785]    Overall Loss 5.273415    Objective Loss 5.273415                                        LR 0.001000    Time 0.040885    
2022-06-16 02:44:23,941 - Epoch: [10][ 1400/ 1785]    Overall Loss 5.272838    Objective Loss 5.272838                                        LR 0.001000    Time 0.040963    
2022-06-16 02:44:32,226 - Epoch: [10][ 1600/ 1785]    Overall Loss 5.273961    Objective Loss 5.273961                                        LR 0.001000    Time 0.041020    
2022-06-16 02:44:39,825 - Epoch: [10][ 1785/ 1785]    Overall Loss 5.276291    Objective Loss 5.276291                                        LR 0.001000    Time 0.041025    
2022-06-16 02:44:39,866 - --- validate (epoch=10)-----------
2022-06-16 02:44:39,866 - 12251 samples (16 per mini-batch)
2022-06-16 02:44:54,826 - Epoch: [10][  200/  766]    Loss 5.289231    mAP 0.818182    
2022-06-16 02:45:09,703 - Epoch: [10][  400/  766]    Loss 5.289610    mAP 0.669697    
2022-06-16 02:45:24,715 - Epoch: [10][  600/  766]    Loss 5.289428    mAP 0.779461    
2022-06-16 02:45:37,121 - Epoch: [10][  766/  766]    Loss 5.288160    mAP 1.000000    
2022-06-16 02:45:37,178 - ==> mAP: 1.00000    Loss: 5.288

2022-06-16 02:45:37,180 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 02:45:37,180 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:45:37,204 - 

2022-06-16 02:45:37,204 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:45:45,426 - Epoch: [11][  200/ 1785]    Overall Loss 5.268659    Objective Loss 5.268659                                        LR 0.001000    Time 0.041097    
2022-06-16 02:45:53,486 - Epoch: [11][  400/ 1785]    Overall Loss 5.267406    Objective Loss 5.267406                                        LR 0.001000    Time 0.040693    
2022-06-16 02:46:01,506 - Epoch: [11][  600/ 1785]    Overall Loss 5.268847    Objective Loss 5.268847                                        LR 0.001000    Time 0.040492    
2022-06-16 02:46:09,526 - Epoch: [11][  800/ 1785]    Overall Loss 5.271493    Objective Loss 5.271493                                        LR 0.001000    Time 0.040392    
2022-06-16 02:46:17,555 - Epoch: [11][ 1000/ 1785]    Overall Loss 5.269181    Objective Loss 5.269181                                        LR 0.001000    Time 0.040340    
2022-06-16 02:46:26,059 - Epoch: [11][ 1200/ 1785]    Overall Loss 5.269063    Objective Loss 5.269063                                        LR 0.001000    Time 0.040702    
2022-06-16 02:46:34,689 - Epoch: [11][ 1400/ 1785]    Overall Loss 5.270809    Objective Loss 5.270809                                        LR 0.001000    Time 0.041050    
2022-06-16 02:46:42,974 - Epoch: [11][ 1600/ 1785]    Overall Loss 5.272586    Objective Loss 5.272586                                        LR 0.001000    Time 0.041096    
2022-06-16 02:46:50,607 - Epoch: [11][ 1785/ 1785]    Overall Loss 5.273888    Objective Loss 5.273888                                        LR 0.001000    Time 0.041112    
2022-06-16 02:46:50,651 - --- validate (epoch=11)-----------
2022-06-16 02:46:50,652 - 12251 samples (16 per mini-batch)
2022-06-16 02:47:05,966 - Epoch: [11][  200/  766]    Loss 5.265032    mAP 0.806818    
2022-06-16 02:47:21,135 - Epoch: [11][  400/  766]    Loss 5.264609    mAP 0.843434    
2022-06-16 02:47:36,307 - Epoch: [11][  600/  766]    Loss 5.260349    mAP 0.845455    
2022-06-16 02:47:48,963 - Epoch: [11][  766/  766]    Loss 5.260407    mAP 0.571429    
2022-06-16 02:47:49,018 - ==> mAP: 0.57143    Loss: 5.260

2022-06-16 02:47:49,021 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 02:47:49,021 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:47:49,053 - 

2022-06-16 02:47:49,053 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:47:57,303 - Epoch: [12][  200/ 1785]    Overall Loss 5.271054    Objective Loss 5.271054                                        LR 0.001000    Time 0.041236    
2022-06-16 02:48:05,446 - Epoch: [12][  400/ 1785]    Overall Loss 5.263264    Objective Loss 5.263264                                        LR 0.001000    Time 0.040970    
2022-06-16 02:48:13,992 - Epoch: [12][  600/ 1785]    Overall Loss 5.267836    Objective Loss 5.267836                                        LR 0.001000    Time 0.041553    
2022-06-16 02:48:22,301 - Epoch: [12][  800/ 1785]    Overall Loss 5.266356    Objective Loss 5.266356                                        LR 0.001000    Time 0.041549    
2022-06-16 02:48:30,420 - Epoch: [12][ 1000/ 1785]    Overall Loss 5.266526    Objective Loss 5.266526                                        LR 0.001000    Time 0.041356    
2022-06-16 02:48:38,486 - Epoch: [12][ 1200/ 1785]    Overall Loss 5.265684    Objective Loss 5.265684                                        LR 0.001000    Time 0.041184    
2022-06-16 02:48:46,581 - Epoch: [12][ 1400/ 1785]    Overall Loss 5.265785    Objective Loss 5.265785                                        LR 0.001000    Time 0.041081    
2022-06-16 02:48:54,729 - Epoch: [12][ 1600/ 1785]    Overall Loss 5.266509    Objective Loss 5.266509                                        LR 0.001000    Time 0.041037    
2022-06-16 02:49:02,255 - Epoch: [12][ 1785/ 1785]    Overall Loss 5.268336    Objective Loss 5.268336                                        LR 0.001000    Time 0.040999    
2022-06-16 02:49:02,335 - --- validate (epoch=12)-----------
2022-06-16 02:49:02,335 - 12251 samples (16 per mini-batch)
2022-06-16 02:49:17,241 - Epoch: [12][  200/  766]    Loss 5.267690    mAP 0.705387    
2022-06-16 02:49:31,955 - Epoch: [12][  400/  766]    Loss 5.257789    mAP 0.940260    
2022-06-16 02:49:46,754 - Epoch: [12][  600/  766]    Loss 5.258309    mAP 0.757576    
2022-06-16 02:49:58,885 - Epoch: [12][  766/  766]    Loss 5.261089    mAP 0.750000    
2022-06-16 02:49:58,967 - ==> mAP: 0.75000    Loss: 5.261

2022-06-16 02:49:58,970 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 02:49:58,970 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:49:58,994 - 

2022-06-16 02:49:58,994 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:50:07,535 - Epoch: [13][  200/ 1785]    Overall Loss 5.233988    Objective Loss 5.233988                                        LR 0.001000    Time 0.042690    
2022-06-16 02:50:15,598 - Epoch: [13][  400/ 1785]    Overall Loss 5.247845    Objective Loss 5.247845                                        LR 0.001000    Time 0.041497    
2022-06-16 02:50:23,663 - Epoch: [13][  600/ 1785]    Overall Loss 5.256168    Objective Loss 5.256168                                        LR 0.001000    Time 0.041103    
2022-06-16 02:50:31,681 - Epoch: [13][  800/ 1785]    Overall Loss 5.261170    Objective Loss 5.261170                                        LR 0.001000    Time 0.040846    
2022-06-16 02:50:39,777 - Epoch: [13][ 1000/ 1785]    Overall Loss 5.261129    Objective Loss 5.261129                                        LR 0.001000    Time 0.040772    
2022-06-16 02:50:47,921 - Epoch: [13][ 1200/ 1785]    Overall Loss 5.262725    Objective Loss 5.262725                                        LR 0.001000    Time 0.040761    
2022-06-16 02:50:56,105 - Epoch: [13][ 1400/ 1785]    Overall Loss 5.263061    Objective Loss 5.263061                                        LR 0.001000    Time 0.040782    
2022-06-16 02:51:04,299 - Epoch: [13][ 1600/ 1785]    Overall Loss 5.263495    Objective Loss 5.263495                                        LR 0.001000    Time 0.040805    
2022-06-16 02:51:12,107 - Epoch: [13][ 1785/ 1785]    Overall Loss 5.264293    Objective Loss 5.264293                                        LR 0.001000    Time 0.040948    
2022-06-16 02:51:12,159 - --- validate (epoch=13)-----------
2022-06-16 02:51:12,159 - 12251 samples (16 per mini-batch)
2022-06-16 02:51:27,167 - Epoch: [13][  200/  766]    Loss 5.266412    mAP 0.929293    
2022-06-16 02:51:41,878 - Epoch: [13][  400/  766]    Loss 5.272949    mAP 0.531025    
2022-06-16 02:51:56,674 - Epoch: [13][  600/  766]    Loss 5.273546    mAP 0.697348    
2022-06-16 02:52:08,861 - Epoch: [13][  766/  766]    Loss 5.277270    mAP 0.972727    
2022-06-16 02:52:08,944 - ==> mAP: 0.97273    Loss: 5.277

2022-06-16 02:52:08,947 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 02:52:08,947 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:52:08,979 - 

2022-06-16 02:52:08,979 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:52:17,762 - Epoch: [14][  200/ 1785]    Overall Loss 5.274810    Objective Loss 5.274810                                        LR 0.001000    Time 0.043903    
2022-06-16 02:52:25,859 - Epoch: [14][  400/ 1785]    Overall Loss 5.262402    Objective Loss 5.262402                                        LR 0.001000    Time 0.042187    
2022-06-16 02:52:33,926 - Epoch: [14][  600/ 1785]    Overall Loss 5.259536    Objective Loss 5.259536                                        LR 0.001000    Time 0.041566    
2022-06-16 02:52:41,993 - Epoch: [14][  800/ 1785]    Overall Loss 5.262274    Objective Loss 5.262274                                        LR 0.001000    Time 0.041256    
2022-06-16 02:52:50,237 - Epoch: [14][ 1000/ 1785]    Overall Loss 5.262912    Objective Loss 5.262912                                        LR 0.001000    Time 0.041248    
2022-06-16 02:52:58,812 - Epoch: [14][ 1200/ 1785]    Overall Loss 5.264518    Objective Loss 5.264518                                        LR 0.001000    Time 0.041517    
2022-06-16 02:53:06,845 - Epoch: [14][ 1400/ 1785]    Overall Loss 5.263413    Objective Loss 5.263413                                        LR 0.001000    Time 0.041322    
2022-06-16 02:53:15,013 - Epoch: [14][ 1600/ 1785]    Overall Loss 5.264135    Objective Loss 5.264135                                        LR 0.001000    Time 0.041261    
2022-06-16 02:53:22,427 - Epoch: [14][ 1785/ 1785]    Overall Loss 5.265206    Objective Loss 5.265206                                        LR 0.001000    Time 0.041136    
2022-06-16 02:53:22,472 - --- validate (epoch=14)-----------
2022-06-16 02:53:22,473 - 12251 samples (16 per mini-batch)
2022-06-16 02:53:37,595 - Epoch: [14][  200/  766]    Loss 5.263519    mAP 0.954545    
2022-06-16 02:53:52,545 - Epoch: [14][  400/  766]    Loss 5.258016    mAP 0.942727    
2022-06-16 02:54:07,451 - Epoch: [14][  600/  766]    Loss 5.262722    mAP 0.745454    
2022-06-16 02:54:19,712 - Epoch: [14][  766/  766]    Loss 5.263853    mAP 0.767677    
2022-06-16 02:54:19,784 - ==> mAP: 0.76768    Loss: 5.264

2022-06-16 02:54:19,787 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 02:54:19,787 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:54:19,819 - 

2022-06-16 02:54:19,819 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:54:28,560 - Epoch: [15][  200/ 1785]    Overall Loss 5.223719    Objective Loss 5.223719                                        LR 0.001000    Time 0.043692    
2022-06-16 02:54:36,969 - Epoch: [15][  400/ 1785]    Overall Loss 5.237422    Objective Loss 5.237422                                        LR 0.001000    Time 0.042863    
2022-06-16 02:54:45,457 - Epoch: [15][  600/ 1785]    Overall Loss 5.249767    Objective Loss 5.249767                                        LR 0.001000    Time 0.042719    
2022-06-16 02:54:53,713 - Epoch: [15][  800/ 1785]    Overall Loss 5.251968    Objective Loss 5.251968                                        LR 0.001000    Time 0.042357    
2022-06-16 02:55:01,759 - Epoch: [15][ 1000/ 1785]    Overall Loss 5.256539    Objective Loss 5.256539                                        LR 0.001000    Time 0.041929    
2022-06-16 02:55:09,905 - Epoch: [15][ 1200/ 1785]    Overall Loss 5.260061    Objective Loss 5.260061                                        LR 0.001000    Time 0.041728    
2022-06-16 02:55:18,026 - Epoch: [15][ 1400/ 1785]    Overall Loss 5.260647    Objective Loss 5.260647                                        LR 0.001000    Time 0.041566    
2022-06-16 02:55:26,247 - Epoch: [15][ 1600/ 1785]    Overall Loss 5.258680    Objective Loss 5.258680                                        LR 0.001000    Time 0.041507    
2022-06-16 02:55:34,013 - Epoch: [15][ 1785/ 1785]    Overall Loss 5.259508    Objective Loss 5.259508                                        LR 0.001000    Time 0.041555    
2022-06-16 02:55:34,063 - --- validate (epoch=15)-----------
2022-06-16 02:55:34,063 - 12251 samples (16 per mini-batch)
2022-06-16 02:55:49,892 - Epoch: [15][  200/  766]    Loss 5.285412    mAP 0.717172    
2022-06-16 02:56:04,930 - Epoch: [15][  400/  766]    Loss 5.279636    mAP 0.645455    
2022-06-16 02:56:20,039 - Epoch: [15][  600/  766]    Loss 5.280821    mAP 0.746591    
2022-06-16 02:56:32,391 - Epoch: [15][  766/  766]    Loss 5.278515    mAP 0.911364    
2022-06-16 02:56:32,441 - ==> mAP: 0.91136    Loss: 5.279

2022-06-16 02:56:32,444 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 02:56:32,444 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:56:32,473 - 

2022-06-16 02:56:32,473 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:56:41,228 - Epoch: [16][  200/ 1785]    Overall Loss 5.260084    Objective Loss 5.260084                                        LR 0.001000    Time 0.043766    
2022-06-16 02:56:49,812 - Epoch: [16][  400/ 1785]    Overall Loss 5.256613    Objective Loss 5.256613                                        LR 0.001000    Time 0.043336    
2022-06-16 02:56:58,148 - Epoch: [16][  600/ 1785]    Overall Loss 5.254310    Objective Loss 5.254310                                        LR 0.001000    Time 0.042781    
2022-06-16 02:57:06,195 - Epoch: [16][  800/ 1785]    Overall Loss 5.249780    Objective Loss 5.249780                                        LR 0.001000    Time 0.042142    
2022-06-16 02:57:14,241 - Epoch: [16][ 1000/ 1785]    Overall Loss 5.251794    Objective Loss 5.251794                                        LR 0.001000    Time 0.041757    
2022-06-16 02:57:22,283 - Epoch: [16][ 1200/ 1785]    Overall Loss 5.252624    Objective Loss 5.252624                                        LR 0.001000    Time 0.041498    
2022-06-16 02:57:30,322 - Epoch: [16][ 1400/ 1785]    Overall Loss 5.255951    Objective Loss 5.255951                                        LR 0.001000    Time 0.041311    
2022-06-16 02:57:38,365 - Epoch: [16][ 1600/ 1785]    Overall Loss 5.257758    Objective Loss 5.257758                                        LR 0.001000    Time 0.041172    
2022-06-16 02:57:45,765 - Epoch: [16][ 1785/ 1785]    Overall Loss 5.258652    Objective Loss 5.258652                                        LR 0.001000    Time 0.041050    
2022-06-16 02:57:45,821 - --- validate (epoch=16)-----------
2022-06-16 02:57:45,822 - 12251 samples (16 per mini-batch)
2022-06-16 02:58:00,889 - Epoch: [16][  200/  766]    Loss 5.269396    mAP 0.754545    
2022-06-16 02:58:15,783 - Epoch: [16][  400/  766]    Loss 5.271087    mAP 0.621212    
2022-06-16 02:58:30,577 - Epoch: [16][  600/  766]    Loss 5.271455    mAP 0.650000    
2022-06-16 02:58:42,791 - Epoch: [16][  766/  766]    Loss 5.269859    mAP 0.693939    
2022-06-16 02:58:42,838 - ==> mAP: 0.69394    Loss: 5.270

2022-06-16 02:58:42,840 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 02:58:42,840 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 02:58:42,867 - 

2022-06-16 02:58:42,867 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 02:58:51,395 - Epoch: [17][  200/ 1785]    Overall Loss 5.253361    Objective Loss 5.253361                                        LR 0.001000    Time 0.042626    
2022-06-16 02:58:59,649 - Epoch: [17][  400/ 1785]    Overall Loss 5.255041    Objective Loss 5.255041                                        LR 0.001000    Time 0.041942    
2022-06-16 02:59:07,783 - Epoch: [17][  600/ 1785]    Overall Loss 5.256096    Objective Loss 5.256096                                        LR 0.001000    Time 0.041515    
2022-06-16 02:59:15,841 - Epoch: [17][  800/ 1785]    Overall Loss 5.251386    Objective Loss 5.251386                                        LR 0.001000    Time 0.041207    
2022-06-16 02:59:23,925 - Epoch: [17][ 1000/ 1785]    Overall Loss 5.253293    Objective Loss 5.253293                                        LR 0.001000    Time 0.041047    
2022-06-16 02:59:32,120 - Epoch: [17][ 1200/ 1785]    Overall Loss 5.253551    Objective Loss 5.253551                                        LR 0.001000    Time 0.041033    
2022-06-16 02:59:40,397 - Epoch: [17][ 1400/ 1785]    Overall Loss 5.254423    Objective Loss 5.254423                                        LR 0.001000    Time 0.041082    
2022-06-16 02:59:48,575 - Epoch: [17][ 1600/ 1785]    Overall Loss 5.254576    Objective Loss 5.254576                                        LR 0.001000    Time 0.041057    
2022-06-16 02:59:56,077 - Epoch: [17][ 1785/ 1785]    Overall Loss 5.255397    Objective Loss 5.255397                                        LR 0.001000    Time 0.041003    
2022-06-16 02:59:56,118 - --- validate (epoch=17)-----------
2022-06-16 02:59:56,118 - 12251 samples (16 per mini-batch)
2022-06-16 03:00:11,214 - Epoch: [17][  200/  766]    Loss 5.259142    mAP 0.787879    
2022-06-16 03:00:26,053 - Epoch: [17][  400/  766]    Loss 5.253750    mAP 0.919192    
2022-06-16 03:00:40,923 - Epoch: [17][  600/  766]    Loss 5.261592    mAP 0.723896    
2022-06-16 03:00:53,171 - Epoch: [17][  766/  766]    Loss 5.260647    mAP 0.693182    
2022-06-16 03:00:53,226 - ==> mAP: 0.69318    Loss: 5.261

2022-06-16 03:00:53,229 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 03:00:53,229 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 03:00:53,249 - 

2022-06-16 03:00:53,249 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:01:01,809 - Epoch: [18][  200/ 1785]    Overall Loss 5.221798    Objective Loss 5.221798                                        LR 0.001000    Time 0.042783    
2022-06-16 03:01:09,802 - Epoch: [18][  400/ 1785]    Overall Loss 5.228217    Objective Loss 5.228217                                        LR 0.001000    Time 0.041370    
2022-06-16 03:01:17,826 - Epoch: [18][  600/ 1785]    Overall Loss 5.238131    Objective Loss 5.238131                                        LR 0.001000    Time 0.040951    
2022-06-16 03:01:25,815 - Epoch: [18][  800/ 1785]    Overall Loss 5.242650    Objective Loss 5.242650                                        LR 0.001000    Time 0.040697    
2022-06-16 03:01:33,859 - Epoch: [18][ 1000/ 1785]    Overall Loss 5.248352    Objective Loss 5.248352                                        LR 0.001000    Time 0.040599    
2022-06-16 03:01:41,933 - Epoch: [18][ 1200/ 1785]    Overall Loss 5.247762    Objective Loss 5.247762                                        LR 0.001000    Time 0.040559    
2022-06-16 03:01:50,384 - Epoch: [18][ 1400/ 1785]    Overall Loss 5.250476    Objective Loss 5.250476                                        LR 0.001000    Time 0.040800    
2022-06-16 03:01:58,843 - Epoch: [18][ 1600/ 1785]    Overall Loss 5.252318    Objective Loss 5.252318                                        LR 0.001000    Time 0.040986    
2022-06-16 03:02:06,540 - Epoch: [18][ 1785/ 1785]    Overall Loss 5.252814    Objective Loss 5.252814                                        LR 0.001000    Time 0.041049    
2022-06-16 03:02:06,597 - --- validate (epoch=18)-----------
2022-06-16 03:02:06,597 - 12251 samples (16 per mini-batch)
2022-06-16 03:02:21,819 - Epoch: [18][  200/  766]    Loss 5.254553    mAP 0.575036    
2022-06-16 03:02:36,845 - Epoch: [18][  400/  766]    Loss 5.257473    mAP 0.559416    
2022-06-16 03:02:51,787 - Epoch: [18][  600/  766]    Loss 5.258543    mAP 0.845455    
2022-06-16 03:03:04,134 - Epoch: [18][  766/  766]    Loss 5.254118    mAP 0.519481    
2022-06-16 03:03:04,181 - ==> mAP: 0.51948    Loss: 5.254

2022-06-16 03:03:04,183 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 03:03:04,183 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 03:03:04,210 - 

2022-06-16 03:03:04,210 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:03:12,701 - Epoch: [19][  200/ 1785]    Overall Loss 5.231827    Objective Loss 5.231827                                        LR 0.001000    Time 0.042440    
2022-06-16 03:03:21,244 - Epoch: [19][  400/ 1785]    Overall Loss 5.241475    Objective Loss 5.241475                                        LR 0.001000    Time 0.042573    
2022-06-16 03:03:29,454 - Epoch: [19][  600/ 1785]    Overall Loss 5.234840    Objective Loss 5.234840                                        LR 0.001000    Time 0.042062    
2022-06-16 03:03:37,798 - Epoch: [19][  800/ 1785]    Overall Loss 5.241265    Objective Loss 5.241265                                        LR 0.001000    Time 0.041974    
2022-06-16 03:03:46,334 - Epoch: [19][ 1000/ 1785]    Overall Loss 5.245065    Objective Loss 5.245065                                        LR 0.001000    Time 0.042113    
2022-06-16 03:03:54,882 - Epoch: [19][ 1200/ 1785]    Overall Loss 5.247466    Objective Loss 5.247466                                        LR 0.001000    Time 0.042216    
2022-06-16 03:04:03,450 - Epoch: [19][ 1400/ 1785]    Overall Loss 5.249339    Objective Loss 5.249339                                        LR 0.001000    Time 0.042304    
2022-06-16 03:04:11,907 - Epoch: [19][ 1600/ 1785]    Overall Loss 5.249432    Objective Loss 5.249432                                        LR 0.001000    Time 0.042300    
2022-06-16 03:04:19,775 - Epoch: [19][ 1785/ 1785]    Overall Loss 5.249656    Objective Loss 5.249656                                        LR 0.001000    Time 0.042323    
2022-06-16 03:04:19,821 - --- validate (epoch=19)-----------
2022-06-16 03:04:19,821 - 12251 samples (16 per mini-batch)
2022-06-16 03:04:35,010 - Epoch: [19][  200/  766]    Loss 5.231502    mAP 0.761905    
2022-06-16 03:04:50,066 - Epoch: [19][  400/  766]    Loss 5.233186    mAP 0.800064    
2022-06-16 03:05:05,185 - Epoch: [19][  600/  766]    Loss 5.233877    mAP 0.854343    
2022-06-16 03:05:17,611 - Epoch: [19][  766/  766]    Loss 5.232629    mAP 0.702652    
2022-06-16 03:05:17,669 - ==> mAP: 0.70265    Loss: 5.233

2022-06-16 03:05:17,672 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 03:05:17,672 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 03:05:17,699 - 

2022-06-16 03:05:17,699 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:05:25,930 - Epoch: [20][  200/ 1785]    Overall Loss 5.228785    Objective Loss 5.228785                                        LR 0.001000    Time 0.041142    
2022-06-16 03:05:33,960 - Epoch: [20][  400/ 1785]    Overall Loss 5.237494    Objective Loss 5.237494                                        LR 0.001000    Time 0.040641    
2022-06-16 03:05:42,011 - Epoch: [20][  600/ 1785]    Overall Loss 5.237164    Objective Loss 5.237164                                        LR 0.001000    Time 0.040509    
2022-06-16 03:05:50,061 - Epoch: [20][  800/ 1785]    Overall Loss 5.243969    Objective Loss 5.243969                                        LR 0.001000    Time 0.040442    
2022-06-16 03:05:58,336 - Epoch: [20][ 1000/ 1785]    Overall Loss 5.244642    Objective Loss 5.244642                                        LR 0.001000    Time 0.040626    
2022-06-16 03:06:06,581 - Epoch: [20][ 1200/ 1785]    Overall Loss 5.244293    Objective Loss 5.244293                                        LR 0.001000    Time 0.040725    
2022-06-16 03:06:14,868 - Epoch: [20][ 1400/ 1785]    Overall Loss 5.246838    Objective Loss 5.246838                                        LR 0.001000    Time 0.040825    
2022-06-16 03:06:23,064 - Epoch: [20][ 1600/ 1785]    Overall Loss 5.247280    Objective Loss 5.247280                                        LR 0.001000    Time 0.040843    
2022-06-16 03:06:30,815 - Epoch: [20][ 1785/ 1785]    Overall Loss 5.247455    Objective Loss 5.247455                                        LR 0.001000    Time 0.040951    
2022-06-16 03:06:30,861 - --- validate (epoch=20)-----------
2022-06-16 03:06:30,861 - 12251 samples (16 per mini-batch)
2022-06-16 03:06:45,998 - Epoch: [20][  200/  766]    Loss 5.269470    mAP 0.848377    
2022-06-16 03:07:00,827 - Epoch: [20][  400/  766]    Loss 5.270382    mAP 0.508586    
2022-06-16 03:07:15,721 - Epoch: [20][  600/  766]    Loss 5.267946    mAP 0.694444    
2022-06-16 03:07:28,107 - Epoch: [20][  766/  766]    Loss 5.266870    mAP 0.927273    
2022-06-16 03:07:28,144 - ==> mAP: 0.92727    Loss: 5.267

2022-06-16 03:07:28,147 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 03:07:28,147 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 03:07:28,174 - 

2022-06-16 03:07:28,174 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:07:36,670 - Epoch: [21][  200/ 1785]    Overall Loss 5.242944    Objective Loss 5.242944                                        LR 0.001000    Time 0.042467    
2022-06-16 03:07:44,733 - Epoch: [21][  400/ 1785]    Overall Loss 5.240171    Objective Loss 5.240171                                        LR 0.001000    Time 0.041387    
2022-06-16 03:07:53,106 - Epoch: [21][  600/ 1785]    Overall Loss 5.240371    Objective Loss 5.240371                                        LR 0.001000    Time 0.041542    
2022-06-16 03:08:01,620 - Epoch: [21][  800/ 1785]    Overall Loss 5.240046    Objective Loss 5.240046                                        LR 0.001000    Time 0.041797    
2022-06-16 03:08:10,060 - Epoch: [21][ 1000/ 1785]    Overall Loss 5.237971    Objective Loss 5.237971                                        LR 0.001000    Time 0.041876    
2022-06-16 03:08:18,447 - Epoch: [21][ 1200/ 1785]    Overall Loss 5.238921    Objective Loss 5.238921                                        LR 0.001000    Time 0.041884    
2022-06-16 03:08:26,910 - Epoch: [21][ 1400/ 1785]    Overall Loss 5.242460    Objective Loss 5.242460                                        LR 0.001000    Time 0.041944    
2022-06-16 03:08:35,268 - Epoch: [21][ 1600/ 1785]    Overall Loss 5.243422    Objective Loss 5.243422                                        LR 0.001000    Time 0.041924    
2022-06-16 03:08:42,993 - Epoch: [21][ 1785/ 1785]    Overall Loss 5.245310    Objective Loss 5.245310                                        LR 0.001000    Time 0.041906    
2022-06-16 03:08:43,054 - --- validate (epoch=21)-----------
2022-06-16 03:08:43,054 - 12251 samples (16 per mini-batch)
2022-06-16 03:08:58,223 - Epoch: [21][  200/  766]    Loss 5.255221    mAP 0.757576    
2022-06-16 03:09:13,222 - Epoch: [21][  400/  766]    Loss 5.240218    mAP 0.858586    
2022-06-16 03:09:28,184 - Epoch: [21][  600/  766]    Loss 5.239566    mAP 0.833670    
2022-06-16 03:09:40,566 - Epoch: [21][  766/  766]    Loss 5.241478    mAP 0.872727    
2022-06-16 03:09:40,625 - ==> mAP: 0.87273    Loss: 5.241

2022-06-16 03:09:40,628 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 03:09:40,628 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 03:09:40,654 - 

2022-06-16 03:09:40,655 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:09:48,876 - Epoch: [22][  200/ 1785]    Overall Loss 5.231021    Objective Loss 5.231021                                        LR 0.001000    Time 0.041093    
2022-06-16 03:09:56,982 - Epoch: [22][  400/ 1785]    Overall Loss 5.238404    Objective Loss 5.238404                                        LR 0.001000    Time 0.040807    
2022-06-16 03:10:05,123 - Epoch: [22][  600/ 1785]    Overall Loss 5.241892    Objective Loss 5.241892                                        LR 0.001000    Time 0.040769    
2022-06-16 03:10:13,246 - Epoch: [22][  800/ 1785]    Overall Loss 5.238468    Objective Loss 5.238468                                        LR 0.001000    Time 0.040728    
2022-06-16 03:10:21,471 - Epoch: [22][ 1000/ 1785]    Overall Loss 5.238931    Objective Loss 5.238931                                        LR 0.001000    Time 0.040806    
2022-06-16 03:10:29,813 - Epoch: [22][ 1200/ 1785]    Overall Loss 5.240661    Objective Loss 5.240661                                        LR 0.001000    Time 0.040955    
2022-06-16 03:10:38,152 - Epoch: [22][ 1400/ 1785]    Overall Loss 5.244580    Objective Loss 5.244580                                        LR 0.001000    Time 0.041059    
2022-06-16 03:10:46,463 - Epoch: [22][ 1600/ 1785]    Overall Loss 5.244539    Objective Loss 5.244539                                        LR 0.001000    Time 0.041120    
2022-06-16 03:10:53,972 - Epoch: [22][ 1785/ 1785]    Overall Loss 5.246032    Objective Loss 5.246032                                        LR 0.001000    Time 0.041064    
2022-06-16 03:10:54,015 - --- validate (epoch=22)-----------
2022-06-16 03:10:54,015 - 12251 samples (16 per mini-batch)
2022-06-16 03:11:09,427 - Epoch: [22][  200/  766]    Loss 5.244239    mAP 0.713636    
2022-06-16 03:11:24,572 - Epoch: [22][  400/  766]    Loss 5.251204    mAP 0.954545    
2022-06-16 03:11:39,800 - Epoch: [22][  600/  766]    Loss 5.249011    mAP 0.707071    
2022-06-16 03:11:52,389 - Epoch: [22][  766/  766]    Loss 5.248290    mAP 0.803030    
2022-06-16 03:11:52,429 - ==> mAP: 0.80303    Loss: 5.248

2022-06-16 03:11:52,432 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 03:11:52,432 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 03:11:52,464 - 

2022-06-16 03:11:52,464 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:12:00,695 - Epoch: [23][  200/ 1785]    Overall Loss 5.231446    Objective Loss 5.231446                                        LR 0.001000    Time 0.041141    
2022-06-16 03:12:08,785 - Epoch: [23][  400/ 1785]    Overall Loss 5.227602    Objective Loss 5.227602                                        LR 0.001000    Time 0.040790    
2022-06-16 03:12:16,898 - Epoch: [23][  600/ 1785]    Overall Loss 5.233830    Objective Loss 5.233830                                        LR 0.001000    Time 0.040713    
2022-06-16 03:12:24,983 - Epoch: [23][  800/ 1785]    Overall Loss 5.236584    Objective Loss 5.236584                                        LR 0.001000    Time 0.040637    
2022-06-16 03:12:33,077 - Epoch: [23][ 1000/ 1785]    Overall Loss 5.238866    Objective Loss 5.238866                                        LR 0.001000    Time 0.040602    
2022-06-16 03:12:41,164 - Epoch: [23][ 1200/ 1785]    Overall Loss 5.241161    Objective Loss 5.241161                                        LR 0.001000    Time 0.040573    
2022-06-16 03:12:49,288 - Epoch: [23][ 1400/ 1785]    Overall Loss 5.243576    Objective Loss 5.243576                                        LR 0.001000    Time 0.040578    
2022-06-16 03:12:57,403 - Epoch: [23][ 1600/ 1785]    Overall Loss 5.243991    Objective Loss 5.243991                                        LR 0.001000    Time 0.040577    
2022-06-16 03:13:04,943 - Epoch: [23][ 1785/ 1785]    Overall Loss 5.244935    Objective Loss 5.244935                                        LR 0.001000    Time 0.040594    
2022-06-16 03:13:05,032 - --- validate (epoch=23)-----------
2022-06-16 03:13:05,033 - 12251 samples (16 per mini-batch)
2022-06-16 03:13:19,977 - Epoch: [23][  200/  766]    Loss 5.262349    mAP 0.691919    
2022-06-16 03:13:34,778 - Epoch: [23][  400/  766]    Loss 5.255612    mAP 0.639773    
2022-06-16 03:13:49,747 - Epoch: [23][  600/  766]    Loss 5.255622    mAP 0.842593    
2022-06-16 03:14:02,253 - Epoch: [23][  766/  766]    Loss 5.252818    mAP 0.769360    
2022-06-16 03:14:02,291 - ==> mAP: 0.76936    Loss: 5.253

2022-06-16 03:14:02,294 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 03:14:02,294 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 03:14:02,327 - 

2022-06-16 03:14:02,328 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:14:10,685 - Epoch: [24][  200/ 1785]    Overall Loss 5.240582    Objective Loss 5.240582                                        LR 0.001000    Time 0.041771    
2022-06-16 03:14:18,751 - Epoch: [24][  400/ 1785]    Overall Loss 5.237068    Objective Loss 5.237068                                        LR 0.001000    Time 0.041046    
2022-06-16 03:14:26,881 - Epoch: [24][  600/ 1785]    Overall Loss 5.234167    Objective Loss 5.234167                                        LR 0.001000    Time 0.040911    
2022-06-16 03:14:35,078 - Epoch: [24][  800/ 1785]    Overall Loss 5.232850    Objective Loss 5.232850                                        LR 0.001000    Time 0.040927    
2022-06-16 03:14:43,192 - Epoch: [24][ 1000/ 1785]    Overall Loss 5.239429    Objective Loss 5.239429                                        LR 0.001000    Time 0.040854    
2022-06-16 03:14:51,260 - Epoch: [24][ 1200/ 1785]    Overall Loss 5.242087    Objective Loss 5.242087                                        LR 0.001000    Time 0.040766    
2022-06-16 03:14:59,360 - Epoch: [24][ 1400/ 1785]    Overall Loss 5.243867    Objective Loss 5.243867                                        LR 0.001000    Time 0.040727    
2022-06-16 03:15:07,570 - Epoch: [24][ 1600/ 1785]    Overall Loss 5.245205    Objective Loss 5.245205                                        LR 0.001000    Time 0.040767    
2022-06-16 03:15:15,082 - Epoch: [24][ 1785/ 1785]    Overall Loss 5.245050    Objective Loss 5.245050                                        LR 0.001000    Time 0.040749    
2022-06-16 03:15:15,155 - --- validate (epoch=24)-----------
2022-06-16 03:15:15,155 - 12251 samples (16 per mini-batch)
2022-06-16 03:15:30,246 - Epoch: [24][  200/  766]    Loss 5.232745    mAP 0.733333    
2022-06-16 03:15:45,241 - Epoch: [24][  400/  766]    Loss 5.238655    mAP 0.649199    
2022-06-16 03:16:00,317 - Epoch: [24][  600/  766]    Loss 5.236649    mAP 0.662553    
2022-06-16 03:16:12,808 - Epoch: [24][  766/  766]    Loss 5.238345    mAP 0.888889    
2022-06-16 03:16:12,889 - ==> mAP: 0.88889    Loss: 5.238

2022-06-16 03:16:12,891 - ==> Best [mAP: 1.000000   vloss: 5.288160   Sparsity:0.00   Params: 335519 on epoch: 10]
2022-06-16 03:16:12,891 - Saving checkpoint to: logs/2022.06.16-021553/checkpoint.pth.tar
2022-06-16 03:16:12,949 - 

2022-06-16 03:16:12,949 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:16:23,131 - Epoch: [25][  200/ 1785]    Overall Loss 5.559500    Objective Loss 5.559500                                        LR 0.001000    Time 0.050895    
2022-06-16 03:16:33,198 - Epoch: [25][  400/ 1785]    Overall Loss 5.403775    Objective Loss 5.403775                                        LR 0.001000    Time 0.050611    
2022-06-16 03:16:43,140 - Epoch: [25][  600/ 1785]    Overall Loss 5.335790    Objective Loss 5.335790                                        LR 0.001000    Time 0.050307    
2022-06-16 03:16:53,318 - Epoch: [25][  800/ 1785]    Overall Loss 5.297568    Objective Loss 5.297568                                        LR 0.001000    Time 0.050450    
2022-06-16 03:17:03,867 - Epoch: [25][ 1000/ 1785]    Overall Loss 5.268256    Objective Loss 5.268256                                        LR 0.001000    Time 0.050907    
2022-06-16 03:17:14,514 - Epoch: [25][ 1200/ 1785]    Overall Loss 5.249555    Objective Loss 5.249555                                        LR 0.001000    Time 0.051294    
2022-06-16 03:17:25,193 - Epoch: [25][ 1400/ 1785]    Overall Loss 5.234394    Objective Loss 5.234394                                        LR 0.001000    Time 0.051593    
2022-06-16 03:17:35,930 - Epoch: [25][ 1600/ 1785]    Overall Loss 5.221318    Objective Loss 5.221318                                        LR 0.001000    Time 0.051853    
2022-06-16 03:17:45,713 - Epoch: [25][ 1785/ 1785]    Overall Loss 5.210413    Objective Loss 5.210413                                        LR 0.001000    Time 0.051959    
2022-06-16 03:17:45,753 - --- validate (epoch=25)-----------
2022-06-16 03:17:45,754 - 12251 samples (16 per mini-batch)
2022-06-16 03:18:01,706 - Epoch: [25][  200/  766]    Loss 5.150247    mAP 0.818182    
2022-06-16 03:18:17,585 - Epoch: [25][  400/  766]    Loss 5.151784    mAP 0.659091    
2022-06-16 03:18:33,587 - Epoch: [25][  600/  766]    Loss 5.142846    mAP 0.488636    
2022-06-16 03:18:46,891 - Epoch: [25][  766/  766]    Loss 5.141598    mAP 0.598990    
2022-06-16 03:18:46,929 - ==> mAP: 0.59899    Loss: 5.142

2022-06-16 03:18:46,932 - ==> Best [mAP: 0.598990   vloss: 5.141598   Sparsity:0.29   Params: 334541 on epoch: 25]
2022-06-16 03:18:46,932 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:18:46,950 - 

2022-06-16 03:18:46,950 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:18:57,576 - Epoch: [26][  200/ 1785]    Overall Loss 5.081275    Objective Loss 5.081275                                        LR 0.001000    Time 0.053120    
2022-06-16 03:19:08,075 - Epoch: [26][  400/ 1785]    Overall Loss 5.083817    Objective Loss 5.083817                                        LR 0.001000    Time 0.052803    
2022-06-16 03:19:18,644 - Epoch: [26][  600/ 1785]    Overall Loss 5.079009    Objective Loss 5.079009                                        LR 0.001000    Time 0.052814    
2022-06-16 03:19:29,207 - Epoch: [26][  800/ 1785]    Overall Loss 5.077109    Objective Loss 5.077109                                        LR 0.001000    Time 0.052812    
2022-06-16 03:19:39,313 - Epoch: [26][ 1000/ 1785]    Overall Loss 5.078622    Objective Loss 5.078622                                        LR 0.001000    Time 0.052353    
2022-06-16 03:19:49,404 - Epoch: [26][ 1200/ 1785]    Overall Loss 5.076619    Objective Loss 5.076619                                        LR 0.001000    Time 0.052035    
2022-06-16 03:19:59,495 - Epoch: [26][ 1400/ 1785]    Overall Loss 5.075228    Objective Loss 5.075228                                        LR 0.001000    Time 0.051808    
2022-06-16 03:20:09,592 - Epoch: [26][ 1600/ 1785]    Overall Loss 5.071093    Objective Loss 5.071093                                        LR 0.001000    Time 0.051642    
2022-06-16 03:20:18,851 - Epoch: [26][ 1785/ 1785]    Overall Loss 5.070114    Objective Loss 5.070114                                        LR 0.001000    Time 0.051475    
2022-06-16 03:20:18,891 - --- validate (epoch=26)-----------
2022-06-16 03:20:18,892 - 12251 samples (16 per mini-batch)
2022-06-16 03:20:35,393 - Epoch: [26][  200/  766]    Loss 5.101100    mAP 0.863636    
2022-06-16 03:20:51,578 - Epoch: [26][  400/  766]    Loss 5.100289    mAP 0.764773    
2022-06-16 03:21:07,837 - Epoch: [26][  600/  766]    Loss 5.100297    mAP 0.757576    
2022-06-16 03:21:21,319 - Epoch: [26][  766/  766]    Loss 5.100377    mAP 0.858586    
2022-06-16 03:21:21,375 - ==> mAP: 0.85859    Loss: 5.100

2022-06-16 03:21:21,378 - ==> Best [mAP: 0.858586   vloss: 5.100377   Sparsity:0.29   Params: 334549 on epoch: 26]
2022-06-16 03:21:21,378 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:21:21,409 - 

2022-06-16 03:21:21,409 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:21:31,509 - Epoch: [27][  200/ 1785]    Overall Loss 5.031729    Objective Loss 5.031729                                        LR 0.001000    Time 0.050486    
2022-06-16 03:21:41,577 - Epoch: [27][  400/ 1785]    Overall Loss 5.033082    Objective Loss 5.033082                                        LR 0.001000    Time 0.050409    
2022-06-16 03:21:51,541 - Epoch: [27][  600/ 1785]    Overall Loss 5.044803    Objective Loss 5.044803                                        LR 0.001000    Time 0.050208    
2022-06-16 03:22:01,777 - Epoch: [27][  800/ 1785]    Overall Loss 5.047272    Objective Loss 5.047272                                        LR 0.001000    Time 0.050450    
2022-06-16 03:22:11,767 - Epoch: [27][ 1000/ 1785]    Overall Loss 5.046674    Objective Loss 5.046674                                        LR 0.001000    Time 0.050348    
2022-06-16 03:22:21,772 - Epoch: [27][ 1200/ 1785]    Overall Loss 5.043098    Objective Loss 5.043098                                        LR 0.001000    Time 0.050292    
2022-06-16 03:22:31,914 - Epoch: [27][ 1400/ 1785]    Overall Loss 5.042609    Objective Loss 5.042609                                        LR 0.001000    Time 0.050350    
2022-06-16 03:22:42,283 - Epoch: [27][ 1600/ 1785]    Overall Loss 5.043154    Objective Loss 5.043154                                        LR 0.001000    Time 0.050536    
2022-06-16 03:22:51,853 - Epoch: [27][ 1785/ 1785]    Overall Loss 5.043747    Objective Loss 5.043747                                        LR 0.001000    Time 0.050659    
2022-06-16 03:22:51,922 - --- validate (epoch=27)-----------
2022-06-16 03:22:51,922 - 12251 samples (16 per mini-batch)
2022-06-16 03:23:08,202 - Epoch: [27][  200/  766]    Loss 5.068420    mAP 0.897273    
2022-06-16 03:23:24,167 - Epoch: [27][  400/  766]    Loss 5.067486    mAP 1.000000    
2022-06-16 03:23:40,326 - Epoch: [27][  600/  766]    Loss 5.072447    mAP 0.915909    
2022-06-16 03:23:53,628 - Epoch: [27][  766/  766]    Loss 5.078272    mAP 1.000000    
2022-06-16 03:23:53,693 - ==> mAP: 1.00000    Loss: 5.078

2022-06-16 03:23:53,695 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:23:53,695 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:23:53,718 - 

2022-06-16 03:23:53,718 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:24:04,320 - Epoch: [28][  200/ 1785]    Overall Loss 5.016697    Objective Loss 5.016697                                        LR 0.001000    Time 0.052995    
2022-06-16 03:24:14,503 - Epoch: [28][  400/ 1785]    Overall Loss 5.025988    Objective Loss 5.025988                                        LR 0.001000    Time 0.051951    
2022-06-16 03:24:24,847 - Epoch: [28][  600/ 1785]    Overall Loss 5.025057    Objective Loss 5.025057                                        LR 0.001000    Time 0.051870    
2022-06-16 03:24:34,965 - Epoch: [28][  800/ 1785]    Overall Loss 5.023501    Objective Loss 5.023501                                        LR 0.001000    Time 0.051547    
2022-06-16 03:24:45,082 - Epoch: [28][ 1000/ 1785]    Overall Loss 5.021160    Objective Loss 5.021160                                        LR 0.001000    Time 0.051352    
2022-06-16 03:24:55,590 - Epoch: [28][ 1200/ 1785]    Overall Loss 5.020835    Objective Loss 5.020835                                        LR 0.001000    Time 0.051549    
2022-06-16 03:25:05,931 - Epoch: [28][ 1400/ 1785]    Overall Loss 5.020722    Objective Loss 5.020722                                        LR 0.001000    Time 0.051570    
2022-06-16 03:25:16,099 - Epoch: [28][ 1600/ 1785]    Overall Loss 5.020295    Objective Loss 5.020295                                        LR 0.001000    Time 0.051477    
2022-06-16 03:25:25,475 - Epoch: [28][ 1785/ 1785]    Overall Loss 5.026390    Objective Loss 5.026390                                        LR 0.001000    Time 0.051394    
2022-06-16 03:25:25,534 - --- validate (epoch=28)-----------
2022-06-16 03:25:25,535 - 12251 samples (16 per mini-batch)
2022-06-16 03:25:41,828 - Epoch: [28][  200/  766]    Loss 5.081346    mAP 0.900000    
2022-06-16 03:25:57,909 - Epoch: [28][  400/  766]    Loss 5.090888    mAP 0.790909    
2022-06-16 03:26:14,167 - Epoch: [28][  600/  766]    Loss 5.086863    mAP 0.578114    
2022-06-16 03:26:27,564 - Epoch: [28][  766/  766]    Loss 5.088117    mAP 0.838384    
2022-06-16 03:26:27,611 - ==> mAP: 0.83838    Loss: 5.088

2022-06-16 03:26:27,613 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:26:27,613 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:26:27,630 - 

2022-06-16 03:26:27,631 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:26:38,043 - Epoch: [29][  200/ 1785]    Overall Loss 5.020299    Objective Loss 5.020299                                        LR 0.001000    Time 0.052049    
2022-06-16 03:26:48,393 - Epoch: [29][  400/ 1785]    Overall Loss 5.015668    Objective Loss 5.015668                                        LR 0.001000    Time 0.051895    
2022-06-16 03:26:58,792 - Epoch: [29][  600/ 1785]    Overall Loss 5.015177    Objective Loss 5.015177                                        LR 0.001000    Time 0.051925    
2022-06-16 03:27:09,023 - Epoch: [29][  800/ 1785]    Overall Loss 5.017958    Objective Loss 5.017958                                        LR 0.001000    Time 0.051731    
2022-06-16 03:27:19,137 - Epoch: [29][ 1000/ 1785]    Overall Loss 5.019274    Objective Loss 5.019274                                        LR 0.001000    Time 0.051496    
2022-06-16 03:27:29,523 - Epoch: [29][ 1200/ 1785]    Overall Loss 5.021768    Objective Loss 5.021768                                        LR 0.001000    Time 0.051567    
2022-06-16 03:27:39,976 - Epoch: [29][ 1400/ 1785]    Overall Loss 5.020443    Objective Loss 5.020443                                        LR 0.001000    Time 0.051666    
2022-06-16 03:27:50,364 - Epoch: [29][ 1600/ 1785]    Overall Loss 5.020793    Objective Loss 5.020793                                        LR 0.001000    Time 0.051699    
2022-06-16 03:27:59,699 - Epoch: [29][ 1785/ 1785]    Overall Loss 5.020779    Objective Loss 5.020779                                        LR 0.001000    Time 0.051569    
2022-06-16 03:27:59,756 - --- validate (epoch=29)-----------
2022-06-16 03:27:59,756 - 12251 samples (16 per mini-batch)
2022-06-16 03:28:16,218 - Epoch: [29][  200/  766]    Loss 5.091159    mAP 0.828283    
2022-06-16 03:28:32,238 - Epoch: [29][  400/  766]    Loss 5.089117    mAP 0.881818    
2022-06-16 03:28:48,482 - Epoch: [29][  600/  766]    Loss 5.091018    mAP 0.772727    
2022-06-16 03:29:01,883 - Epoch: [29][  766/  766]    Loss 5.091546    mAP 0.659933    
2022-06-16 03:29:01,921 - ==> mAP: 0.65993    Loss: 5.092

2022-06-16 03:29:01,923 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:29:01,923 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:29:01,940 - 

2022-06-16 03:29:01,940 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:29:12,064 - Epoch: [30][  200/ 1785]    Overall Loss 4.997934    Objective Loss 4.997934                                        LR 0.001000    Time 0.050606    
2022-06-16 03:29:21,996 - Epoch: [30][  400/ 1785]    Overall Loss 5.000836    Objective Loss 5.000836                                        LR 0.001000    Time 0.050129    
2022-06-16 03:29:31,925 - Epoch: [30][  600/ 1785]    Overall Loss 5.003960    Objective Loss 5.003960                                        LR 0.001000    Time 0.049964    
2022-06-16 03:29:41,960 - Epoch: [30][  800/ 1785]    Overall Loss 5.007618    Objective Loss 5.007618                                        LR 0.001000    Time 0.050014    
2022-06-16 03:29:51,997 - Epoch: [30][ 1000/ 1785]    Overall Loss 5.011846    Objective Loss 5.011846                                        LR 0.001000    Time 0.050046    
2022-06-16 03:30:02,146 - Epoch: [30][ 1200/ 1785]    Overall Loss 5.013355    Objective Loss 5.013355                                        LR 0.001000    Time 0.050161    
2022-06-16 03:30:12,039 - Epoch: [30][ 1400/ 1785]    Overall Loss 5.014214    Objective Loss 5.014214                                        LR 0.001000    Time 0.050060    
2022-06-16 03:30:21,993 - Epoch: [30][ 1600/ 1785]    Overall Loss 5.014951    Objective Loss 5.014951                                        LR 0.001000    Time 0.050023    
2022-06-16 03:30:31,306 - Epoch: [30][ 1785/ 1785]    Overall Loss 5.017765    Objective Loss 5.017765                                        LR 0.001000    Time 0.050055    
2022-06-16 03:30:31,358 - --- validate (epoch=30)-----------
2022-06-16 03:30:31,358 - 12251 samples (16 per mini-batch)
2022-06-16 03:30:47,500 - Epoch: [30][  200/  766]    Loss 5.066915    mAP 0.888889    
2022-06-16 03:31:03,764 - Epoch: [30][  400/  766]    Loss 5.067461    mAP 1.000000    
2022-06-16 03:31:19,955 - Epoch: [30][  600/  766]    Loss 5.065421    mAP 0.791667    
2022-06-16 03:31:33,310 - Epoch: [30][  766/  766]    Loss 5.059938    mAP 0.888889    
2022-06-16 03:31:33,360 - ==> mAP: 0.88889    Loss: 5.060

2022-06-16 03:31:33,362 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:31:33,362 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:31:33,379 - 

2022-06-16 03:31:33,379 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:31:44,082 - Epoch: [31][  200/ 1785]    Overall Loss 4.998066    Objective Loss 4.998066                                        LR 0.001000    Time 0.053504    
2022-06-16 03:31:54,686 - Epoch: [31][  400/ 1785]    Overall Loss 4.999821    Objective Loss 4.999821                                        LR 0.001000    Time 0.053257    
2022-06-16 03:32:05,375 - Epoch: [31][  600/ 1785]    Overall Loss 5.001160    Objective Loss 5.001160                                        LR 0.001000    Time 0.053317    
2022-06-16 03:32:16,053 - Epoch: [31][  800/ 1785]    Overall Loss 5.002245    Objective Loss 5.002245                                        LR 0.001000    Time 0.053333    
2022-06-16 03:32:26,448 - Epoch: [31][ 1000/ 1785]    Overall Loss 5.006942    Objective Loss 5.006942                                        LR 0.001000    Time 0.053058    
2022-06-16 03:32:36,579 - Epoch: [31][ 1200/ 1785]    Overall Loss 5.013128    Objective Loss 5.013128                                        LR 0.001000    Time 0.052657    
2022-06-16 03:32:46,735 - Epoch: [31][ 1400/ 1785]    Overall Loss 5.014392    Objective Loss 5.014392                                        LR 0.001000    Time 0.052387    
2022-06-16 03:32:56,986 - Epoch: [31][ 1600/ 1785]    Overall Loss 5.015034    Objective Loss 5.015034                                        LR 0.001000    Time 0.052244    
2022-06-16 03:33:06,442 - Epoch: [31][ 1785/ 1785]    Overall Loss 5.015987    Objective Loss 5.015987                                        LR 0.001000    Time 0.052126    
2022-06-16 03:33:06,494 - --- validate (epoch=31)-----------
2022-06-16 03:33:06,495 - 12251 samples (16 per mini-batch)
2022-06-16 03:33:22,609 - Epoch: [31][  200/  766]    Loss 5.089097    mAP 0.750000    
2022-06-16 03:33:38,619 - Epoch: [31][  400/  766]    Loss 5.097698    mAP 0.733030    
2022-06-16 03:33:54,626 - Epoch: [31][  600/  766]    Loss 5.095499    mAP 0.757576    
2022-06-16 03:34:07,825 - Epoch: [31][  766/  766]    Loss 5.094548    mAP 0.666667    
2022-06-16 03:34:07,911 - ==> mAP: 0.66667    Loss: 5.095

2022-06-16 03:34:07,914 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:34:07,914 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:34:07,941 - 

2022-06-16 03:34:07,941 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:34:18,011 - Epoch: [32][  200/ 1785]    Overall Loss 4.994700    Objective Loss 4.994700                                        LR 0.001000    Time 0.050336    
2022-06-16 03:34:27,911 - Epoch: [32][  400/ 1785]    Overall Loss 5.000591    Objective Loss 5.000591                                        LR 0.001000    Time 0.049912    
2022-06-16 03:34:37,771 - Epoch: [32][  600/ 1785]    Overall Loss 5.003108    Objective Loss 5.003108                                        LR 0.001000    Time 0.049705    
2022-06-16 03:34:47,704 - Epoch: [32][  800/ 1785]    Overall Loss 5.002961    Objective Loss 5.002961                                        LR 0.001000    Time 0.049692    
2022-06-16 03:34:57,597 - Epoch: [32][ 1000/ 1785]    Overall Loss 5.002225    Objective Loss 5.002225                                        LR 0.001000    Time 0.049645    
2022-06-16 03:35:07,641 - Epoch: [32][ 1200/ 1785]    Overall Loss 5.004663    Objective Loss 5.004663                                        LR 0.001000    Time 0.049740    
2022-06-16 03:35:17,648 - Epoch: [32][ 1400/ 1785]    Overall Loss 5.008638    Objective Loss 5.008638                                        LR 0.001000    Time 0.049780    
2022-06-16 03:35:27,634 - Epoch: [32][ 1600/ 1785]    Overall Loss 5.010673    Objective Loss 5.010673                                        LR 0.001000    Time 0.049798    
2022-06-16 03:35:37,082 - Epoch: [32][ 1785/ 1785]    Overall Loss 5.011455    Objective Loss 5.011455                                        LR 0.001000    Time 0.049928    
2022-06-16 03:35:37,175 - --- validate (epoch=32)-----------
2022-06-16 03:35:37,175 - 12251 samples (16 per mini-batch)
2022-06-16 03:35:53,347 - Epoch: [32][  200/  766]    Loss 5.092671    mAP 0.757576    
2022-06-16 03:36:09,394 - Epoch: [32][  400/  766]    Loss 5.084244    mAP 0.787879    
2022-06-16 03:36:25,531 - Epoch: [32][  600/  766]    Loss 5.083848    mAP 0.852273    
2022-06-16 03:36:38,820 - Epoch: [32][  766/  766]    Loss 5.080098    mAP 0.792857    
2022-06-16 03:36:38,883 - ==> mAP: 0.79286    Loss: 5.080

2022-06-16 03:36:38,885 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:36:38,885 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:36:38,909 - 

2022-06-16 03:36:38,909 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:36:49,374 - Epoch: [33][  200/ 1785]    Overall Loss 4.976797    Objective Loss 4.976797                                        LR 0.001000    Time 0.052312    
2022-06-16 03:36:59,609 - Epoch: [33][  400/ 1785]    Overall Loss 4.992435    Objective Loss 4.992435                                        LR 0.001000    Time 0.051737    
2022-06-16 03:37:09,651 - Epoch: [33][  600/ 1785]    Overall Loss 4.998391    Objective Loss 4.998391                                        LR 0.001000    Time 0.051226    
2022-06-16 03:37:19,671 - Epoch: [33][  800/ 1785]    Overall Loss 4.999625    Objective Loss 4.999625                                        LR 0.001000    Time 0.050941    
2022-06-16 03:37:29,694 - Epoch: [33][ 1000/ 1785]    Overall Loss 5.000750    Objective Loss 5.000750                                        LR 0.001000    Time 0.050774    
2022-06-16 03:37:39,737 - Epoch: [33][ 1200/ 1785]    Overall Loss 5.001534    Objective Loss 5.001534                                        LR 0.001000    Time 0.050679    
2022-06-16 03:37:49,778 - Epoch: [33][ 1400/ 1785]    Overall Loss 5.004525    Objective Loss 5.004525                                        LR 0.001000    Time 0.050610    
2022-06-16 03:37:59,945 - Epoch: [33][ 1600/ 1785]    Overall Loss 5.007197    Objective Loss 5.007197                                        LR 0.001000    Time 0.050637    
2022-06-16 03:38:09,178 - Epoch: [33][ 1785/ 1785]    Overall Loss 5.008396    Objective Loss 5.008396                                        LR 0.001000    Time 0.050561    
2022-06-16 03:38:09,230 - --- validate (epoch=33)-----------
2022-06-16 03:38:09,230 - 12251 samples (16 per mini-batch)
2022-06-16 03:38:25,546 - Epoch: [33][  200/  766]    Loss 5.065712    mAP 0.919192    
2022-06-16 03:38:41,698 - Epoch: [33][  400/  766]    Loss 5.057931    mAP 0.870536    
2022-06-16 03:38:57,983 - Epoch: [33][  600/  766]    Loss 5.061814    mAP 0.979798    
2022-06-16 03:39:11,368 - Epoch: [33][  766/  766]    Loss 5.060984    mAP 0.613636    
2022-06-16 03:39:11,468 - ==> mAP: 0.61364    Loss: 5.061

2022-06-16 03:39:11,471 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:39:11,471 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:39:11,487 - 

2022-06-16 03:39:11,487 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:39:22,227 - Epoch: [34][  200/ 1785]    Overall Loss 4.989908    Objective Loss 4.989908                                        LR 0.001000    Time 0.053683    
2022-06-16 03:39:32,353 - Epoch: [34][  400/ 1785]    Overall Loss 4.992015    Objective Loss 4.992015                                        LR 0.001000    Time 0.052153    
2022-06-16 03:39:42,403 - Epoch: [34][  600/ 1785]    Overall Loss 4.996301    Objective Loss 4.996301                                        LR 0.001000    Time 0.051515    
2022-06-16 03:39:52,710 - Epoch: [34][  800/ 1785]    Overall Loss 5.001656    Objective Loss 5.001656                                        LR 0.001000    Time 0.051517    
2022-06-16 03:40:03,049 - Epoch: [34][ 1000/ 1785]    Overall Loss 5.002323    Objective Loss 5.002323                                        LR 0.001000    Time 0.051551    
2022-06-16 03:40:13,014 - Epoch: [34][ 1200/ 1785]    Overall Loss 5.002720    Objective Loss 5.002720                                        LR 0.001000    Time 0.051261    
2022-06-16 03:40:23,053 - Epoch: [34][ 1400/ 1785]    Overall Loss 5.000918    Objective Loss 5.000918                                        LR 0.001000    Time 0.051108    
2022-06-16 03:40:33,051 - Epoch: [34][ 1600/ 1785]    Overall Loss 5.002910    Objective Loss 5.002910                                        LR 0.001000    Time 0.050967    
2022-06-16 03:40:42,352 - Epoch: [34][ 1785/ 1785]    Overall Loss 5.003865    Objective Loss 5.003865                                        LR 0.001000    Time 0.050894    
2022-06-16 03:40:42,407 - --- validate (epoch=34)-----------
2022-06-16 03:40:42,407 - 12251 samples (16 per mini-batch)
2022-06-16 03:40:58,824 - Epoch: [34][  200/  766]    Loss 5.080977    mAP 0.472150    
2022-06-16 03:41:15,151 - Epoch: [34][  400/  766]    Loss 5.071256    mAP 0.768182    
2022-06-16 03:41:31,353 - Epoch: [34][  600/  766]    Loss 5.071199    mAP 0.739899    
2022-06-16 03:41:44,770 - Epoch: [34][  766/  766]    Loss 5.070153    mAP 0.628030    
2022-06-16 03:41:44,830 - ==> mAP: 0.62803    Loss: 5.070

2022-06-16 03:41:44,832 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:41:44,832 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:41:44,856 - 

2022-06-16 03:41:44,856 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:41:55,017 - Epoch: [35][  200/ 1785]    Overall Loss 4.980813    Objective Loss 4.980813                                        LR 0.001000    Time 0.050794    
2022-06-16 03:42:04,919 - Epoch: [35][  400/ 1785]    Overall Loss 4.992555    Objective Loss 4.992555                                        LR 0.001000    Time 0.050145    
2022-06-16 03:42:14,893 - Epoch: [35][  600/ 1785]    Overall Loss 4.996701    Objective Loss 4.996701                                        LR 0.001000    Time 0.050050    
2022-06-16 03:42:24,820 - Epoch: [35][  800/ 1785]    Overall Loss 4.995926    Objective Loss 4.995926                                        LR 0.001000    Time 0.049944    
2022-06-16 03:42:35,264 - Epoch: [35][ 1000/ 1785]    Overall Loss 5.001206    Objective Loss 5.001206                                        LR 0.001000    Time 0.050397    
2022-06-16 03:42:45,314 - Epoch: [35][ 1200/ 1785]    Overall Loss 5.001489    Objective Loss 5.001489                                        LR 0.001000    Time 0.050371    
2022-06-16 03:42:55,640 - Epoch: [35][ 1400/ 1785]    Overall Loss 5.001695    Objective Loss 5.001695                                        LR 0.001000    Time 0.050549    
2022-06-16 03:43:05,764 - Epoch: [35][ 1600/ 1785]    Overall Loss 5.002084    Objective Loss 5.002084                                        LR 0.001000    Time 0.050557    
2022-06-16 03:43:15,101 - Epoch: [35][ 1785/ 1785]    Overall Loss 5.002273    Objective Loss 5.002273                                        LR 0.001000    Time 0.050547    
2022-06-16 03:43:15,149 - --- validate (epoch=35)-----------
2022-06-16 03:43:15,149 - 12251 samples (16 per mini-batch)
2022-06-16 03:43:31,552 - Epoch: [35][  200/  766]    Loss 5.054361    mAP 0.771515    
2022-06-16 03:43:47,904 - Epoch: [35][  400/  766]    Loss 5.049685    mAP 0.878788    
2022-06-16 03:44:04,259 - Epoch: [35][  600/  766]    Loss 5.048327    mAP 0.850000    
2022-06-16 03:44:17,751 - Epoch: [35][  766/  766]    Loss 5.050382    mAP 0.595238    
2022-06-16 03:44:17,819 - ==> mAP: 0.59524    Loss: 5.050

2022-06-16 03:44:17,821 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:44:17,821 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:44:17,845 - 

2022-06-16 03:44:17,845 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:44:28,391 - Epoch: [36][  200/ 1785]    Overall Loss 4.996166    Objective Loss 4.996166                                        LR 0.001000    Time 0.052715    
2022-06-16 03:44:38,903 - Epoch: [36][  400/ 1785]    Overall Loss 4.995409    Objective Loss 4.995409                                        LR 0.001000    Time 0.052632    
2022-06-16 03:44:49,532 - Epoch: [36][  600/ 1785]    Overall Loss 4.988808    Objective Loss 4.988808                                        LR 0.001000    Time 0.052800    
2022-06-16 03:44:59,745 - Epoch: [36][  800/ 1785]    Overall Loss 4.992076    Objective Loss 4.992076                                        LR 0.001000    Time 0.052363    
2022-06-16 03:45:09,734 - Epoch: [36][ 1000/ 1785]    Overall Loss 4.991850    Objective Loss 4.991850                                        LR 0.001000    Time 0.051877    
2022-06-16 03:45:19,708 - Epoch: [36][ 1200/ 1785]    Overall Loss 4.993732    Objective Loss 4.993732                                        LR 0.001000    Time 0.051541    
2022-06-16 03:45:29,658 - Epoch: [36][ 1400/ 1785]    Overall Loss 4.997686    Objective Loss 4.997686                                        LR 0.001000    Time 0.051284    
2022-06-16 03:45:39,626 - Epoch: [36][ 1600/ 1785]    Overall Loss 4.999852    Objective Loss 4.999852                                        LR 0.001000    Time 0.051102    
2022-06-16 03:45:48,803 - Epoch: [36][ 1785/ 1785]    Overall Loss 5.001793    Objective Loss 5.001793                                        LR 0.001000    Time 0.050946    
2022-06-16 03:45:48,887 - --- validate (epoch=36)-----------
2022-06-16 03:45:48,888 - 12251 samples (16 per mini-batch)
2022-06-16 03:46:05,194 - Epoch: [36][  200/  766]    Loss 5.041774    mAP 0.696465    
2022-06-16 03:46:21,433 - Epoch: [36][  400/  766]    Loss 5.048720    mAP 0.784091    
2022-06-16 03:46:37,677 - Epoch: [36][  600/  766]    Loss 5.054089    mAP 0.539773    
2022-06-16 03:46:51,112 - Epoch: [36][  766/  766]    Loss 5.056068    mAP 0.803340    
2022-06-16 03:46:51,221 - ==> mAP: 0.80334    Loss: 5.056

2022-06-16 03:46:51,224 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:46:51,224 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:46:51,243 - 

2022-06-16 03:46:51,243 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:47:01,405 - Epoch: [37][  200/ 1785]    Overall Loss 4.991134    Objective Loss 4.991134                                        LR 0.001000    Time 0.050795    
2022-06-16 03:47:11,258 - Epoch: [37][  400/ 1785]    Overall Loss 4.987937    Objective Loss 4.987937                                        LR 0.001000    Time 0.050025    
2022-06-16 03:47:21,198 - Epoch: [37][  600/ 1785]    Overall Loss 4.987110    Objective Loss 4.987110                                        LR 0.001000    Time 0.049912    
2022-06-16 03:47:31,145 - Epoch: [37][  800/ 1785]    Overall Loss 4.991621    Objective Loss 4.991621                                        LR 0.001000    Time 0.049866    
2022-06-16 03:47:41,106 - Epoch: [37][ 1000/ 1785]    Overall Loss 4.990908    Objective Loss 4.990908                                        LR 0.001000    Time 0.049851    
2022-06-16 03:47:51,079 - Epoch: [37][ 1200/ 1785]    Overall Loss 4.994711    Objective Loss 4.994711                                        LR 0.001000    Time 0.049852    
2022-06-16 03:48:01,032 - Epoch: [37][ 1400/ 1785]    Overall Loss 4.995233    Objective Loss 4.995233                                        LR 0.001000    Time 0.049838    
2022-06-16 03:48:10,953 - Epoch: [37][ 1600/ 1785]    Overall Loss 4.996212    Objective Loss 4.996212                                        LR 0.001000    Time 0.049808    
2022-06-16 03:48:20,120 - Epoch: [37][ 1785/ 1785]    Overall Loss 4.998716    Objective Loss 4.998716                                        LR 0.001000    Time 0.049781    
2022-06-16 03:48:20,198 - --- validate (epoch=37)-----------
2022-06-16 03:48:20,198 - 12251 samples (16 per mini-batch)
2022-06-16 03:48:36,311 - Epoch: [37][  200/  766]    Loss 5.069180    mAP 0.808081    
2022-06-16 03:48:52,335 - Epoch: [37][  400/  766]    Loss 5.068780    mAP 0.848485    
2022-06-16 03:49:08,526 - Epoch: [37][  600/  766]    Loss 5.072963    mAP 0.626263    
2022-06-16 03:49:21,703 - Epoch: [37][  766/  766]    Loss 5.071747    mAP 0.693182    
2022-06-16 03:49:21,763 - ==> mAP: 0.69318    Loss: 5.072

2022-06-16 03:49:21,766 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:49:21,766 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:49:21,793 - 

2022-06-16 03:49:21,793 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:49:31,952 - Epoch: [38][  200/ 1785]    Overall Loss 4.969880    Objective Loss 4.969880                                        LR 0.001000    Time 0.050779    
2022-06-16 03:49:41,863 - Epoch: [38][  400/ 1785]    Overall Loss 4.987642    Objective Loss 4.987642                                        LR 0.001000    Time 0.050161    
2022-06-16 03:49:51,813 - Epoch: [38][  600/ 1785]    Overall Loss 4.986872    Objective Loss 4.986872                                        LR 0.001000    Time 0.050022    
2022-06-16 03:50:01,764 - Epoch: [38][  800/ 1785]    Overall Loss 4.992158    Objective Loss 4.992158                                        LR 0.001000    Time 0.049952    
2022-06-16 03:50:11,728 - Epoch: [38][ 1000/ 1785]    Overall Loss 4.990610    Objective Loss 4.990610                                        LR 0.001000    Time 0.049924    
2022-06-16 03:50:22,298 - Epoch: [38][ 1200/ 1785]    Overall Loss 4.992908    Objective Loss 4.992908                                        LR 0.001000    Time 0.050410    
2022-06-16 03:50:32,924 - Epoch: [38][ 1400/ 1785]    Overall Loss 4.994720    Objective Loss 4.994720                                        LR 0.001000    Time 0.050797    
2022-06-16 03:50:42,883 - Epoch: [38][ 1600/ 1785]    Overall Loss 4.994426    Objective Loss 4.994426                                        LR 0.001000    Time 0.050670    
2022-06-16 03:50:52,117 - Epoch: [38][ 1785/ 1785]    Overall Loss 4.995965    Objective Loss 4.995965                                        LR 0.001000    Time 0.050591    
2022-06-16 03:50:52,169 - --- validate (epoch=38)-----------
2022-06-16 03:50:52,169 - 12251 samples (16 per mini-batch)
2022-06-16 03:51:08,280 - Epoch: [38][  200/  766]    Loss 5.077569    mAP 0.836364    
2022-06-16 03:51:24,314 - Epoch: [38][  400/  766]    Loss 5.083335    mAP 0.824675    
2022-06-16 03:51:40,347 - Epoch: [38][  600/  766]    Loss 5.080271    mAP 0.777778    
2022-06-16 03:51:53,653 - Epoch: [38][  766/  766]    Loss 5.075178    mAP 0.784091    
2022-06-16 03:51:53,742 - ==> mAP: 0.78409    Loss: 5.075

2022-06-16 03:51:53,745 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:51:53,745 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:51:53,768 - 

2022-06-16 03:51:53,768 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:52:04,380 - Epoch: [39][  200/ 1785]    Overall Loss 4.965070    Objective Loss 4.965070                                        LR 0.001000    Time 0.053047    
2022-06-16 03:52:14,548 - Epoch: [39][  400/ 1785]    Overall Loss 4.973568    Objective Loss 4.973568                                        LR 0.001000    Time 0.051938    
2022-06-16 03:52:24,664 - Epoch: [39][  600/ 1785]    Overall Loss 4.983332    Objective Loss 4.983332                                        LR 0.001000    Time 0.051481    
2022-06-16 03:52:34,744 - Epoch: [39][  800/ 1785]    Overall Loss 4.988057    Objective Loss 4.988057                                        LR 0.001000    Time 0.051208    
2022-06-16 03:52:45,004 - Epoch: [39][ 1000/ 1785]    Overall Loss 4.990657    Objective Loss 4.990657                                        LR 0.001000    Time 0.051225    
2022-06-16 03:52:55,090 - Epoch: [39][ 1200/ 1785]    Overall Loss 4.990261    Objective Loss 4.990261                                        LR 0.001000    Time 0.051091    
2022-06-16 03:53:05,188 - Epoch: [39][ 1400/ 1785]    Overall Loss 4.992289    Objective Loss 4.992289                                        LR 0.001000    Time 0.051003    
2022-06-16 03:53:15,328 - Epoch: [39][ 1600/ 1785]    Overall Loss 4.996933    Objective Loss 4.996933                                        LR 0.001000    Time 0.050964    
2022-06-16 03:53:24,588 - Epoch: [39][ 1785/ 1785]    Overall Loss 4.996632    Objective Loss 4.996632                                        LR 0.001000    Time 0.050869    
2022-06-16 03:53:24,626 - --- validate (epoch=39)-----------
2022-06-16 03:53:24,627 - 12251 samples (16 per mini-batch)
2022-06-16 03:53:40,914 - Epoch: [39][  200/  766]    Loss 5.069688    mAP 0.817273    
2022-06-16 03:53:57,096 - Epoch: [39][  400/  766]    Loss 5.073873    mAP 0.868687    
2022-06-16 03:54:13,130 - Epoch: [39][  600/  766]    Loss 5.078875    mAP 0.848485    
2022-06-16 03:54:26,402 - Epoch: [39][  766/  766]    Loss 5.077322    mAP 0.606061    
2022-06-16 03:54:26,462 - ==> mAP: 0.60606    Loss: 5.077

2022-06-16 03:54:26,464 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:54:26,464 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:54:26,488 - 

2022-06-16 03:54:26,488 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:54:37,122 - Epoch: [40][  200/ 1785]    Overall Loss 4.969381    Objective Loss 4.969381                                        LR 0.001000    Time 0.053154    
2022-06-16 03:54:47,089 - Epoch: [40][  400/ 1785]    Overall Loss 4.976077    Objective Loss 4.976077                                        LR 0.001000    Time 0.051490    
2022-06-16 03:54:57,071 - Epoch: [40][  600/ 1785]    Overall Loss 4.976147    Objective Loss 4.976147                                        LR 0.001000    Time 0.050960    
2022-06-16 03:55:07,350 - Epoch: [40][  800/ 1785]    Overall Loss 4.980661    Objective Loss 4.980661                                        LR 0.001000    Time 0.051066    
2022-06-16 03:55:17,486 - Epoch: [40][ 1000/ 1785]    Overall Loss 4.980461    Objective Loss 4.980461                                        LR 0.001000    Time 0.050987    
2022-06-16 03:55:27,556 - Epoch: [40][ 1200/ 1785]    Overall Loss 4.983053    Objective Loss 4.983053                                        LR 0.001000    Time 0.050879    
2022-06-16 03:55:37,467 - Epoch: [40][ 1400/ 1785]    Overall Loss 4.988681    Objective Loss 4.988681                                        LR 0.001000    Time 0.050689    
2022-06-16 03:55:48,005 - Epoch: [40][ 1600/ 1785]    Overall Loss 4.990575    Objective Loss 4.990575                                        LR 0.001000    Time 0.050937    
2022-06-16 03:55:57,770 - Epoch: [40][ 1785/ 1785]    Overall Loss 4.990228    Objective Loss 4.990228                                        LR 0.001000    Time 0.051127    
2022-06-16 03:55:57,826 - --- validate (epoch=40)-----------
2022-06-16 03:55:57,826 - 12251 samples (16 per mini-batch)
2022-06-16 03:56:13,861 - Epoch: [40][  200/  766]    Loss 5.066419    mAP 0.731775    
2022-06-16 03:56:29,704 - Epoch: [40][  400/  766]    Loss 5.064994    mAP 0.905606    
2022-06-16 03:56:45,727 - Epoch: [40][  600/  766]    Loss 5.068467    mAP 0.650000    
2022-06-16 03:56:59,028 - Epoch: [40][  766/  766]    Loss 5.071258    mAP 0.693182    
2022-06-16 03:56:59,078 - ==> mAP: 0.69318    Loss: 5.071

2022-06-16 03:56:59,080 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:56:59,080 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:56:59,104 - 

2022-06-16 03:56:59,104 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:57:09,212 - Epoch: [41][  200/ 1785]    Overall Loss 4.996930    Objective Loss 4.996930                                        LR 0.001000    Time 0.050528    
2022-06-16 03:57:19,213 - Epoch: [41][  400/ 1785]    Overall Loss 4.990655    Objective Loss 4.990655                                        LR 0.001000    Time 0.050261    
2022-06-16 03:57:29,237 - Epoch: [41][  600/ 1785]    Overall Loss 4.983195    Objective Loss 4.983195                                        LR 0.001000    Time 0.050210    
2022-06-16 03:57:39,246 - Epoch: [41][  800/ 1785]    Overall Loss 4.985511    Objective Loss 4.985511                                        LR 0.001000    Time 0.050166    
2022-06-16 03:57:49,199 - Epoch: [41][ 1000/ 1785]    Overall Loss 4.983845    Objective Loss 4.983845                                        LR 0.001000    Time 0.050084    
2022-06-16 03:57:59,202 - Epoch: [41][ 1200/ 1785]    Overall Loss 4.984613    Objective Loss 4.984613                                        LR 0.001000    Time 0.050071    
2022-06-16 03:58:09,210 - Epoch: [41][ 1400/ 1785]    Overall Loss 4.987169    Objective Loss 4.987169                                        LR 0.001000    Time 0.050065    
2022-06-16 03:58:19,193 - Epoch: [41][ 1600/ 1785]    Overall Loss 4.991000    Objective Loss 4.991000                                        LR 0.001000    Time 0.050045    
2022-06-16 03:58:28,495 - Epoch: [41][ 1785/ 1785]    Overall Loss 4.991291    Objective Loss 4.991291                                        LR 0.001000    Time 0.050069    
2022-06-16 03:58:28,536 - --- validate (epoch=41)-----------
2022-06-16 03:58:28,536 - 12251 samples (16 per mini-batch)
2022-06-16 03:58:44,708 - Epoch: [41][  200/  766]    Loss 5.078069    mAP 0.809091    
2022-06-16 03:59:00,911 - Epoch: [41][  400/  766]    Loss 5.076817    mAP 0.868687    
2022-06-16 03:59:16,990 - Epoch: [41][  600/  766]    Loss 5.075150    mAP 0.858701    
2022-06-16 03:59:30,289 - Epoch: [41][  766/  766]    Loss 5.076430    mAP 0.931818    
2022-06-16 03:59:30,336 - ==> mAP: 0.93182    Loss: 5.076

2022-06-16 03:59:30,339 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 03:59:30,339 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 03:59:30,366 - 

2022-06-16 03:59:30,366 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 03:59:40,414 - Epoch: [42][  200/ 1785]    Overall Loss 4.975993    Objective Loss 4.975993                                        LR 0.001000    Time 0.050223    
2022-06-16 03:59:50,379 - Epoch: [42][  400/ 1785]    Overall Loss 4.978278    Objective Loss 4.978278                                        LR 0.001000    Time 0.050019    
2022-06-16 04:00:00,260 - Epoch: [42][  600/ 1785]    Overall Loss 4.979647    Objective Loss 4.979647                                        LR 0.001000    Time 0.049811    
2022-06-16 04:00:10,403 - Epoch: [42][  800/ 1785]    Overall Loss 4.985376    Objective Loss 4.985376                                        LR 0.001000    Time 0.050035    
2022-06-16 04:00:21,013 - Epoch: [42][ 1000/ 1785]    Overall Loss 4.986915    Objective Loss 4.986915                                        LR 0.001000    Time 0.050636    
2022-06-16 04:00:31,628 - Epoch: [42][ 1200/ 1785]    Overall Loss 4.990125    Objective Loss 4.990125                                        LR 0.001000    Time 0.051040    
2022-06-16 04:00:42,240 - Epoch: [42][ 1400/ 1785]    Overall Loss 4.988675    Objective Loss 4.988675                                        LR 0.001000    Time 0.051328    
2022-06-16 04:00:52,916 - Epoch: [42][ 1600/ 1785]    Overall Loss 4.991749    Objective Loss 4.991749                                        LR 0.001000    Time 0.051583    
2022-06-16 04:01:02,760 - Epoch: [42][ 1785/ 1785]    Overall Loss 4.991915    Objective Loss 4.991915                                        LR 0.001000    Time 0.051751    
2022-06-16 04:01:02,817 - --- validate (epoch=42)-----------
2022-06-16 04:01:02,817 - 12251 samples (16 per mini-batch)
2022-06-16 04:01:18,786 - Epoch: [42][  200/  766]    Loss 5.098497    mAP 0.752020    
2022-06-16 04:01:34,684 - Epoch: [42][  400/  766]    Loss 5.086120    mAP 0.981818    
2022-06-16 04:01:50,621 - Epoch: [42][  600/  766]    Loss 5.083468    mAP 0.990909    
2022-06-16 04:02:03,836 - Epoch: [42][  766/  766]    Loss 5.080272    mAP 0.838223    
2022-06-16 04:02:03,881 - ==> mAP: 0.83822    Loss: 5.080

2022-06-16 04:02:03,883 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:02:03,883 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:02:03,907 - 

2022-06-16 04:02:03,907 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:02:14,147 - Epoch: [43][  200/ 1785]    Overall Loss 4.956548    Objective Loss 4.956548                                        LR 0.001000    Time 0.051186    
2022-06-16 04:02:24,031 - Epoch: [43][  400/ 1785]    Overall Loss 4.967578    Objective Loss 4.967578                                        LR 0.001000    Time 0.050299    
2022-06-16 04:02:33,994 - Epoch: [43][  600/ 1785]    Overall Loss 4.974772    Objective Loss 4.974772                                        LR 0.001000    Time 0.050134    
2022-06-16 04:02:44,011 - Epoch: [43][  800/ 1785]    Overall Loss 4.979185    Objective Loss 4.979185                                        LR 0.001000    Time 0.050119    
2022-06-16 04:02:54,068 - Epoch: [43][ 1000/ 1785]    Overall Loss 4.984533    Objective Loss 4.984533                                        LR 0.001000    Time 0.050151    
2022-06-16 04:03:04,126 - Epoch: [43][ 1200/ 1785]    Overall Loss 4.987297    Objective Loss 4.987297                                        LR 0.001000    Time 0.050172    
2022-06-16 04:03:14,219 - Epoch: [43][ 1400/ 1785]    Overall Loss 4.987050    Objective Loss 4.987050                                        LR 0.001000    Time 0.050213    
2022-06-16 04:03:24,456 - Epoch: [43][ 1600/ 1785]    Overall Loss 4.987058    Objective Loss 4.987058                                        LR 0.001000    Time 0.050333    
2022-06-16 04:03:33,718 - Epoch: [43][ 1785/ 1785]    Overall Loss 4.989177    Objective Loss 4.989177                                        LR 0.001000    Time 0.050304    
2022-06-16 04:03:33,764 - --- validate (epoch=43)-----------
2022-06-16 04:03:33,765 - 12251 samples (16 per mini-batch)
2022-06-16 04:03:49,990 - Epoch: [43][  200/  766]    Loss 5.064674    mAP 0.639583    
2022-06-16 04:04:06,172 - Epoch: [43][  400/  766]    Loss 5.062247    mAP 0.805455    
2022-06-16 04:04:22,273 - Epoch: [43][  600/  766]    Loss 5.054184    mAP 0.791246    
2022-06-16 04:04:35,615 - Epoch: [43][  766/  766]    Loss 5.056771    mAP 0.927273    
2022-06-16 04:04:35,689 - ==> mAP: 0.92727    Loss: 5.057

2022-06-16 04:04:35,691 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:04:35,691 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:04:35,715 - 

2022-06-16 04:04:35,715 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:04:46,249 - Epoch: [44][  200/ 1785]    Overall Loss 4.972915    Objective Loss 4.972915                                        LR 0.001000    Time 0.052657    
2022-06-16 04:04:56,658 - Epoch: [44][  400/ 1785]    Overall Loss 4.972095    Objective Loss 4.972095                                        LR 0.001000    Time 0.052344    
2022-06-16 04:05:06,725 - Epoch: [44][  600/ 1785]    Overall Loss 4.973170    Objective Loss 4.973170                                        LR 0.001000    Time 0.051672    
2022-06-16 04:05:17,008 - Epoch: [44][  800/ 1785]    Overall Loss 4.979159    Objective Loss 4.979159                                        LR 0.001000    Time 0.051605    
2022-06-16 04:05:27,158 - Epoch: [44][ 1000/ 1785]    Overall Loss 4.982732    Objective Loss 4.982732                                        LR 0.001000    Time 0.051432    
2022-06-16 04:05:37,236 - Epoch: [44][ 1200/ 1785]    Overall Loss 4.984335    Objective Loss 4.984335                                        LR 0.001000    Time 0.051257    
2022-06-16 04:05:47,306 - Epoch: [44][ 1400/ 1785]    Overall Loss 4.987005    Objective Loss 4.987005                                        LR 0.001000    Time 0.051126    
2022-06-16 04:05:57,377 - Epoch: [44][ 1600/ 1785]    Overall Loss 4.988055    Objective Loss 4.988055                                        LR 0.001000    Time 0.051028    
2022-06-16 04:06:06,673 - Epoch: [44][ 1785/ 1785]    Overall Loss 4.988689    Objective Loss 4.988689                                        LR 0.001000    Time 0.050947    
2022-06-16 04:06:06,726 - --- validate (epoch=44)-----------
2022-06-16 04:06:06,726 - 12251 samples (16 per mini-batch)
2022-06-16 04:06:22,812 - Epoch: [44][  200/  766]    Loss 5.057172    mAP 0.856341    
2022-06-16 04:06:38,685 - Epoch: [44][  400/  766]    Loss 5.064287    mAP 0.868687    
2022-06-16 04:06:54,655 - Epoch: [44][  600/  766]    Loss 5.064461    mAP 0.727080    
2022-06-16 04:07:07,888 - Epoch: [44][  766/  766]    Loss 5.063498    mAP 0.757576    
2022-06-16 04:07:07,945 - ==> mAP: 0.75758    Loss: 5.063

2022-06-16 04:07:07,948 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:07:07,948 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:07:07,965 - 

2022-06-16 04:07:07,965 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:07:18,593 - Epoch: [45][  200/ 1785]    Overall Loss 4.988501    Objective Loss 4.988501                                        LR 0.001000    Time 0.053128    
2022-06-16 04:07:28,982 - Epoch: [45][  400/ 1785]    Overall Loss 4.984117    Objective Loss 4.984117                                        LR 0.001000    Time 0.052530    
2022-06-16 04:07:39,328 - Epoch: [45][  600/ 1785]    Overall Loss 4.977949    Objective Loss 4.977949                                        LR 0.001000    Time 0.052260    
2022-06-16 04:07:49,778 - Epoch: [45][  800/ 1785]    Overall Loss 4.974565    Objective Loss 4.974565                                        LR 0.001000    Time 0.052256    
2022-06-16 04:08:00,281 - Epoch: [45][ 1000/ 1785]    Overall Loss 4.981271    Objective Loss 4.981271                                        LR 0.001000    Time 0.052305    
2022-06-16 04:08:10,820 - Epoch: [45][ 1200/ 1785]    Overall Loss 4.986830    Objective Loss 4.986830                                        LR 0.001000    Time 0.052369    
2022-06-16 04:08:21,338 - Epoch: [45][ 1400/ 1785]    Overall Loss 4.985918    Objective Loss 4.985918                                        LR 0.001000    Time 0.052398    
2022-06-16 04:08:31,892 - Epoch: [45][ 1600/ 1785]    Overall Loss 4.988004    Objective Loss 4.988004                                        LR 0.001000    Time 0.052444    
2022-06-16 04:08:41,631 - Epoch: [45][ 1785/ 1785]    Overall Loss 4.988341    Objective Loss 4.988341                                        LR 0.001000    Time 0.052464    
2022-06-16 04:08:41,672 - --- validate (epoch=45)-----------
2022-06-16 04:08:41,672 - 12251 samples (16 per mini-batch)
2022-06-16 04:08:57,982 - Epoch: [45][  200/  766]    Loss 5.042985    mAP 0.788182    
2022-06-16 04:09:14,181 - Epoch: [45][  400/  766]    Loss 5.038141    mAP 0.969773    
2022-06-16 04:09:30,459 - Epoch: [45][  600/  766]    Loss 5.038021    mAP 0.868182    
2022-06-16 04:09:43,984 - Epoch: [45][  766/  766]    Loss 5.035324    mAP 0.723906    
2022-06-16 04:09:44,041 - ==> mAP: 0.72391    Loss: 5.035

2022-06-16 04:09:44,043 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:09:44,043 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:09:44,067 - 

2022-06-16 04:09:44,067 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:09:54,254 - Epoch: [46][  200/ 1785]    Overall Loss 4.989632    Objective Loss 4.989632                                        LR 0.001000    Time 0.050919    
2022-06-16 04:10:04,400 - Epoch: [46][  400/ 1785]    Overall Loss 4.981537    Objective Loss 4.981537                                        LR 0.001000    Time 0.050821    
2022-06-16 04:10:14,774 - Epoch: [46][  600/ 1785]    Overall Loss 4.981676    Objective Loss 4.981676                                        LR 0.001000    Time 0.051167    
2022-06-16 04:10:25,067 - Epoch: [46][  800/ 1785]    Overall Loss 4.980882    Objective Loss 4.980882                                        LR 0.001000    Time 0.051239    
2022-06-16 04:10:35,074 - Epoch: [46][ 1000/ 1785]    Overall Loss 4.982306    Objective Loss 4.982306                                        LR 0.001000    Time 0.050996    
2022-06-16 04:10:45,229 - Epoch: [46][ 1200/ 1785]    Overall Loss 4.984432    Objective Loss 4.984432                                        LR 0.001000    Time 0.050957    
2022-06-16 04:10:55,311 - Epoch: [46][ 1400/ 1785]    Overall Loss 4.988348    Objective Loss 4.988348                                        LR 0.001000    Time 0.050878    
2022-06-16 04:11:05,461 - Epoch: [46][ 1600/ 1785]    Overall Loss 4.989966    Objective Loss 4.989966                                        LR 0.001000    Time 0.050861    
2022-06-16 04:11:14,741 - Epoch: [46][ 1785/ 1785]    Overall Loss 4.988345    Objective Loss 4.988345                                        LR 0.001000    Time 0.050787    
2022-06-16 04:11:14,803 - --- validate (epoch=46)-----------
2022-06-16 04:11:14,804 - 12251 samples (16 per mini-batch)
2022-06-16 04:11:30,880 - Epoch: [46][  200/  766]    Loss 5.065429    mAP 0.683838    
2022-06-16 04:11:46,929 - Epoch: [46][  400/  766]    Loss 5.047163    mAP 0.939394    
2022-06-16 04:12:02,996 - Epoch: [46][  600/  766]    Loss 5.054044    mAP 0.972727    
2022-06-16 04:12:16,440 - Epoch: [46][  766/  766]    Loss 5.052750    mAP 0.583333    
2022-06-16 04:12:16,496 - ==> mAP: 0.58333    Loss: 5.053

2022-06-16 04:12:16,498 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:12:16,498 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:12:16,524 - 

2022-06-16 04:12:16,524 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:12:26,653 - Epoch: [47][  200/ 1785]    Overall Loss 4.971487    Objective Loss 4.971487                                        LR 0.001000    Time 0.050632    
2022-06-16 04:12:36,653 - Epoch: [47][  400/ 1785]    Overall Loss 4.965487    Objective Loss 4.965487                                        LR 0.001000    Time 0.050310    
2022-06-16 04:12:46,656 - Epoch: [47][  600/ 1785]    Overall Loss 4.972956    Objective Loss 4.972956                                        LR 0.001000    Time 0.050209    
2022-06-16 04:12:56,676 - Epoch: [47][  800/ 1785]    Overall Loss 4.980074    Objective Loss 4.980074                                        LR 0.001000    Time 0.050179    
2022-06-16 04:13:06,674 - Epoch: [47][ 1000/ 1785]    Overall Loss 4.980530    Objective Loss 4.980530                                        LR 0.001000    Time 0.050139    
2022-06-16 04:13:16,682 - Epoch: [47][ 1200/ 1785]    Overall Loss 4.982846    Objective Loss 4.982846                                        LR 0.001000    Time 0.050121    
2022-06-16 04:13:26,654 - Epoch: [47][ 1400/ 1785]    Overall Loss 4.985160    Objective Loss 4.985160                                        LR 0.001000    Time 0.050082    
2022-06-16 04:13:36,696 - Epoch: [47][ 1600/ 1785]    Overall Loss 4.985342    Objective Loss 4.985342                                        LR 0.001000    Time 0.050097    
2022-06-16 04:13:45,950 - Epoch: [47][ 1785/ 1785]    Overall Loss 4.987797    Objective Loss 4.987797                                        LR 0.001000    Time 0.050088    
2022-06-16 04:13:46,035 - --- validate (epoch=47)-----------
2022-06-16 04:13:46,035 - 12251 samples (16 per mini-batch)
2022-06-16 04:14:02,229 - Epoch: [47][  200/  766]    Loss 5.076891    mAP 0.735354    
2022-06-16 04:14:18,292 - Epoch: [47][  400/  766]    Loss 5.074985    mAP 0.878788    
2022-06-16 04:14:34,345 - Epoch: [47][  600/  766]    Loss 5.069159    mAP 0.774675    
2022-06-16 04:14:47,575 - Epoch: [47][  766/  766]    Loss 5.071941    mAP 0.798295    
2022-06-16 04:14:47,614 - ==> mAP: 0.79830    Loss: 5.072

2022-06-16 04:14:47,616 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:14:47,616 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:14:47,641 - 

2022-06-16 04:14:47,641 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:14:57,717 - Epoch: [48][  200/ 1785]    Overall Loss 4.980783    Objective Loss 4.980783                                        LR 0.001000    Time 0.050368    
2022-06-16 04:15:07,692 - Epoch: [48][  400/ 1785]    Overall Loss 4.976695    Objective Loss 4.976695                                        LR 0.001000    Time 0.050116    
2022-06-16 04:15:17,600 - Epoch: [48][  600/ 1785]    Overall Loss 4.979383    Objective Loss 4.979383                                        LR 0.001000    Time 0.049919    
2022-06-16 04:15:27,577 - Epoch: [48][  800/ 1785]    Overall Loss 4.981600    Objective Loss 4.981600                                        LR 0.001000    Time 0.049909    
2022-06-16 04:15:37,648 - Epoch: [48][ 1000/ 1785]    Overall Loss 4.986055    Objective Loss 4.986055                                        LR 0.001000    Time 0.049996    
2022-06-16 04:15:47,742 - Epoch: [48][ 1200/ 1785]    Overall Loss 4.984912    Objective Loss 4.984912                                        LR 0.001000    Time 0.050073    
2022-06-16 04:15:57,737 - Epoch: [48][ 1400/ 1785]    Overall Loss 4.986575    Objective Loss 4.986575                                        LR 0.001000    Time 0.050058    
2022-06-16 04:16:07,794 - Epoch: [48][ 1600/ 1785]    Overall Loss 4.985656    Objective Loss 4.985656                                        LR 0.001000    Time 0.050085    
2022-06-16 04:16:17,063 - Epoch: [48][ 1785/ 1785]    Overall Loss 4.983528    Objective Loss 4.983528                                        LR 0.001000    Time 0.050086    
2022-06-16 04:16:17,110 - --- validate (epoch=48)-----------
2022-06-16 04:16:17,111 - 12251 samples (16 per mini-batch)
2022-06-16 04:16:33,578 - Epoch: [48][  200/  766]    Loss 5.025141    mAP 0.858586    
2022-06-16 04:16:49,985 - Epoch: [48][  400/  766]    Loss 5.043592    mAP 0.848485    
2022-06-16 04:17:06,415 - Epoch: [48][  600/  766]    Loss 5.051203    mAP 0.760101    
2022-06-16 04:17:20,030 - Epoch: [48][  766/  766]    Loss 5.050704    mAP 0.888889    
2022-06-16 04:17:20,098 - ==> mAP: 0.88889    Loss: 5.051

2022-06-16 04:17:20,101 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:17:20,101 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:17:20,124 - 

2022-06-16 04:17:20,125 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:17:30,337 - Epoch: [49][  200/ 1785]    Overall Loss 4.965811    Objective Loss 4.965811                                        LR 0.001000    Time 0.051047    
2022-06-16 04:17:40,378 - Epoch: [49][  400/ 1785]    Overall Loss 4.959224    Objective Loss 4.959224                                        LR 0.001000    Time 0.050622    
2022-06-16 04:17:50,687 - Epoch: [49][  600/ 1785]    Overall Loss 4.965965    Objective Loss 4.965965                                        LR 0.001000    Time 0.050926    
2022-06-16 04:18:01,054 - Epoch: [49][  800/ 1785]    Overall Loss 4.973554    Objective Loss 4.973554                                        LR 0.001000    Time 0.051151    
2022-06-16 04:18:11,401 - Epoch: [49][ 1000/ 1785]    Overall Loss 4.977682    Objective Loss 4.977682                                        LR 0.001000    Time 0.051266    
2022-06-16 04:18:21,523 - Epoch: [49][ 1200/ 1785]    Overall Loss 4.980308    Objective Loss 4.980308                                        LR 0.001000    Time 0.051154    
2022-06-16 04:18:31,548 - Epoch: [49][ 1400/ 1785]    Overall Loss 4.980184    Objective Loss 4.980184                                        LR 0.001000    Time 0.051006    
2022-06-16 04:18:41,687 - Epoch: [49][ 1600/ 1785]    Overall Loss 4.979991    Objective Loss 4.979991                                        LR 0.001000    Time 0.050966    
2022-06-16 04:18:51,002 - Epoch: [49][ 1785/ 1785]    Overall Loss 4.982913    Objective Loss 4.982913                                        LR 0.001000    Time 0.050901    
2022-06-16 04:18:51,055 - --- validate (epoch=49)-----------
2022-06-16 04:18:51,056 - 12251 samples (16 per mini-batch)
2022-06-16 04:19:07,367 - Epoch: [49][  200/  766]    Loss 5.038782    mAP 0.686932    
2022-06-16 04:19:23,510 - Epoch: [49][  400/  766]    Loss 5.037497    mAP 0.870909    
2022-06-16 04:19:39,917 - Epoch: [49][  600/  766]    Loss 5.034887    mAP 0.779221    
2022-06-16 04:19:53,602 - Epoch: [49][  766/  766]    Loss 5.035447    mAP 0.809091    
2022-06-16 04:19:53,671 - ==> mAP: 0.80909    Loss: 5.035

2022-06-16 04:19:53,673 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:19:53,673 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:19:53,697 - 

2022-06-16 04:19:53,697 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:20:04,270 - Epoch: [50][  200/ 1785]    Overall Loss 4.976605    Objective Loss 4.976605                                        LR 0.001000    Time 0.052849    
2022-06-16 04:20:14,772 - Epoch: [50][  400/ 1785]    Overall Loss 4.976529    Objective Loss 4.976529                                        LR 0.001000    Time 0.052675    
2022-06-16 04:20:25,271 - Epoch: [50][  600/ 1785]    Overall Loss 4.977170    Objective Loss 4.977170                                        LR 0.001000    Time 0.052612    
2022-06-16 04:20:35,239 - Epoch: [50][  800/ 1785]    Overall Loss 4.978122    Objective Loss 4.978122                                        LR 0.001000    Time 0.051916    
2022-06-16 04:20:45,183 - Epoch: [50][ 1000/ 1785]    Overall Loss 4.975589    Objective Loss 4.975589                                        LR 0.001000    Time 0.051476    
2022-06-16 04:20:55,272 - Epoch: [50][ 1200/ 1785]    Overall Loss 4.978033    Objective Loss 4.978033                                        LR 0.001000    Time 0.051302    
2022-06-16 04:21:05,381 - Epoch: [50][ 1400/ 1785]    Overall Loss 4.980154    Objective Loss 4.980154                                        LR 0.001000    Time 0.051192    
2022-06-16 04:21:15,463 - Epoch: [50][ 1600/ 1785]    Overall Loss 4.981017    Objective Loss 4.981017                                        LR 0.001000    Time 0.051093    
2022-06-16 04:21:24,708 - Epoch: [50][ 1785/ 1785]    Overall Loss 4.982003    Objective Loss 4.982003                                        LR 0.001000    Time 0.050976    
2022-06-16 04:21:24,766 - --- validate (epoch=50)-----------
2022-06-16 04:21:24,766 - 12251 samples (16 per mini-batch)
2022-06-16 04:21:40,913 - Epoch: [50][  200/  766]    Loss 5.034318    mAP 0.547727    
2022-06-16 04:21:56,942 - Epoch: [50][  400/  766]    Loss 5.042902    mAP 0.909091    
2022-06-16 04:22:12,988 - Epoch: [50][  600/  766]    Loss 5.049555    mAP 0.954545    
2022-06-16 04:22:26,178 - Epoch: [50][  766/  766]    Loss 5.044263    mAP 0.707386    
2022-06-16 04:22:26,235 - ==> mAP: 0.70739    Loss: 5.044

2022-06-16 04:22:26,238 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:22:26,238 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:22:26,265 - 

2022-06-16 04:22:26,265 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:22:36,313 - Epoch: [51][  200/ 1785]    Overall Loss 4.979595    Objective Loss 4.979595                                        LR 0.001000    Time 0.050223    
2022-06-16 04:22:46,504 - Epoch: [51][  400/ 1785]    Overall Loss 4.970479    Objective Loss 4.970479                                        LR 0.001000    Time 0.050584    
2022-06-16 04:22:56,746 - Epoch: [51][  600/ 1785]    Overall Loss 4.975503    Objective Loss 4.975503                                        LR 0.001000    Time 0.050790    
2022-06-16 04:23:06,786 - Epoch: [51][  800/ 1785]    Overall Loss 4.974049    Objective Loss 4.974049                                        LR 0.001000    Time 0.050640    
2022-06-16 04:23:16,834 - Epoch: [51][ 1000/ 1785]    Overall Loss 4.972047    Objective Loss 4.972047                                        LR 0.001000    Time 0.050558    
2022-06-16 04:23:26,825 - Epoch: [51][ 1200/ 1785]    Overall Loss 4.976586    Objective Loss 4.976586                                        LR 0.001000    Time 0.050456    
2022-06-16 04:23:36,888 - Epoch: [51][ 1400/ 1785]    Overall Loss 4.979811    Objective Loss 4.979811                                        LR 0.001000    Time 0.050434    
2022-06-16 04:23:46,994 - Epoch: [51][ 1600/ 1785]    Overall Loss 4.979282    Objective Loss 4.979282                                        LR 0.001000    Time 0.050445    
2022-06-16 04:23:56,316 - Epoch: [51][ 1785/ 1785]    Overall Loss 4.981989    Objective Loss 4.981989                                        LR 0.001000    Time 0.050438    
2022-06-16 04:23:56,389 - --- validate (epoch=51)-----------
2022-06-16 04:23:56,390 - 12251 samples (16 per mini-batch)
2022-06-16 04:24:12,515 - Epoch: [51][  200/  766]    Loss 5.070052    mAP 0.893506    
2022-06-16 04:24:28,570 - Epoch: [51][  400/  766]    Loss 5.068407    mAP 0.936364    
2022-06-16 04:24:44,647 - Epoch: [51][  600/  766]    Loss 5.076596    mAP 0.637662    
2022-06-16 04:24:57,988 - Epoch: [51][  766/  766]    Loss 5.077917    mAP 0.787879    
2022-06-16 04:24:58,040 - ==> mAP: 0.78788    Loss: 5.078

2022-06-16 04:24:58,042 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:24:58,042 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:24:58,067 - 

2022-06-16 04:24:58,067 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:25:08,734 - Epoch: [52][  200/ 1785]    Overall Loss 4.964178    Objective Loss 4.964178                                        LR 0.001000    Time 0.053319    
2022-06-16 04:25:18,684 - Epoch: [52][  400/ 1785]    Overall Loss 4.964279    Objective Loss 4.964279                                        LR 0.001000    Time 0.051531    
2022-06-16 04:25:28,719 - Epoch: [52][  600/ 1785]    Overall Loss 4.971150    Objective Loss 4.971150                                        LR 0.001000    Time 0.051075    
2022-06-16 04:25:38,740 - Epoch: [52][  800/ 1785]    Overall Loss 4.972644    Objective Loss 4.972644                                        LR 0.001000    Time 0.050830    
2022-06-16 04:25:48,772 - Epoch: [52][ 1000/ 1785]    Overall Loss 4.976663    Objective Loss 4.976663                                        LR 0.001000    Time 0.050693    
2022-06-16 04:25:58,840 - Epoch: [52][ 1200/ 1785]    Overall Loss 4.975068    Objective Loss 4.975068                                        LR 0.001000    Time 0.050633    
2022-06-16 04:26:08,877 - Epoch: [52][ 1400/ 1785]    Overall Loss 4.976636    Objective Loss 4.976636                                        LR 0.001000    Time 0.050567    
2022-06-16 04:26:18,862 - Epoch: [52][ 1600/ 1785]    Overall Loss 4.978599    Objective Loss 4.978599                                        LR 0.001000    Time 0.050486    
2022-06-16 04:26:28,099 - Epoch: [52][ 1785/ 1785]    Overall Loss 4.981706    Objective Loss 4.981706                                        LR 0.001000    Time 0.050427    
2022-06-16 04:26:28,177 - --- validate (epoch=52)-----------
2022-06-16 04:26:28,178 - 12251 samples (16 per mini-batch)
2022-06-16 04:26:44,494 - Epoch: [52][  200/  766]    Loss 5.059788    mAP 0.887879    
2022-06-16 04:27:00,632 - Epoch: [52][  400/  766]    Loss 5.053432    mAP 0.838384    
2022-06-16 04:27:16,676 - Epoch: [52][  600/  766]    Loss 5.048841    mAP 0.772727    
2022-06-16 04:27:30,083 - Epoch: [52][  766/  766]    Loss 5.046462    mAP 0.954545    
2022-06-16 04:27:30,141 - ==> mAP: 0.95455    Loss: 5.046

2022-06-16 04:27:30,143 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:27:30,143 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:27:30,167 - 

2022-06-16 04:27:30,167 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:27:40,620 - Epoch: [53][  200/ 1785]    Overall Loss 4.976851    Objective Loss 4.976851                                        LR 0.001000    Time 0.052252    
2022-06-16 04:27:50,656 - Epoch: [53][  400/ 1785]    Overall Loss 4.970479    Objective Loss 4.970479                                        LR 0.001000    Time 0.051210    
2022-06-16 04:28:00,702 - Epoch: [53][  600/ 1785]    Overall Loss 4.972683    Objective Loss 4.972683                                        LR 0.001000    Time 0.050880    
2022-06-16 04:28:10,767 - Epoch: [53][  800/ 1785]    Overall Loss 4.972543    Objective Loss 4.972543                                        LR 0.001000    Time 0.050740    
2022-06-16 04:28:20,830 - Epoch: [53][ 1000/ 1785]    Overall Loss 4.970608    Objective Loss 4.970608                                        LR 0.001000    Time 0.050652    
2022-06-16 04:28:30,866 - Epoch: [53][ 1200/ 1785]    Overall Loss 4.974725    Objective Loss 4.974725                                        LR 0.001000    Time 0.050572    
2022-06-16 04:28:40,909 - Epoch: [53][ 1400/ 1785]    Overall Loss 4.974566    Objective Loss 4.974566                                        LR 0.001000    Time 0.050519    
2022-06-16 04:28:50,983 - Epoch: [53][ 1600/ 1785]    Overall Loss 4.978405    Objective Loss 4.978405                                        LR 0.001000    Time 0.050500    
2022-06-16 04:29:00,405 - Epoch: [53][ 1785/ 1785]    Overall Loss 4.979469    Objective Loss 4.979469                                        LR 0.001000    Time 0.050543    
2022-06-16 04:29:00,445 - --- validate (epoch=53)-----------
2022-06-16 04:29:00,445 - 12251 samples (16 per mini-batch)
2022-06-16 04:29:16,662 - Epoch: [53][  200/  766]    Loss 5.075620    mAP 0.936364    
2022-06-16 04:29:32,698 - Epoch: [53][  400/  766]    Loss 5.069299    mAP 0.879091    
2022-06-16 04:29:48,758 - Epoch: [53][  600/  766]    Loss 5.064537    mAP 0.707071    
2022-06-16 04:30:01,917 - Epoch: [53][  766/  766]    Loss 5.066402    mAP 0.888889    
2022-06-16 04:30:01,955 - ==> mAP: 0.88889    Loss: 5.066

2022-06-16 04:30:01,957 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:30:01,958 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:30:01,974 - 

2022-06-16 04:30:01,974 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:30:12,346 - Epoch: [54][  200/ 1785]    Overall Loss 4.968978    Objective Loss 4.968978                                        LR 0.001000    Time 0.051847    
2022-06-16 04:30:22,404 - Epoch: [54][  400/ 1785]    Overall Loss 4.965776    Objective Loss 4.965776                                        LR 0.001000    Time 0.051063    
2022-06-16 04:30:32,403 - Epoch: [54][  600/ 1785]    Overall Loss 4.971741    Objective Loss 4.971741                                        LR 0.001000    Time 0.050704    
2022-06-16 04:30:42,646 - Epoch: [54][  800/ 1785]    Overall Loss 4.968633    Objective Loss 4.968633                                        LR 0.001000    Time 0.050830    
2022-06-16 04:30:52,797 - Epoch: [54][ 1000/ 1785]    Overall Loss 4.969415    Objective Loss 4.969415                                        LR 0.001000    Time 0.050812    
2022-06-16 04:31:02,764 - Epoch: [54][ 1200/ 1785]    Overall Loss 4.968528    Objective Loss 4.968528                                        LR 0.001000    Time 0.050648    
2022-06-16 04:31:12,737 - Epoch: [54][ 1400/ 1785]    Overall Loss 4.971510    Objective Loss 4.971510                                        LR 0.001000    Time 0.050534    
2022-06-16 04:31:23,042 - Epoch: [54][ 1600/ 1785]    Overall Loss 4.973079    Objective Loss 4.973079                                        LR 0.001000    Time 0.050657    
2022-06-16 04:31:32,468 - Epoch: [54][ 1785/ 1785]    Overall Loss 4.976371    Objective Loss 4.976371                                        LR 0.001000    Time 0.050686    
2022-06-16 04:31:32,538 - --- validate (epoch=54)-----------
2022-06-16 04:31:32,539 - 12251 samples (16 per mini-batch)
2022-06-16 04:31:48,749 - Epoch: [54][  200/  766]    Loss 5.060070    mAP 0.838384    
2022-06-16 04:32:04,706 - Epoch: [54][  400/  766]    Loss 5.066871    mAP 0.777778    
2022-06-16 04:32:20,833 - Epoch: [54][  600/  766]    Loss 5.063090    mAP 0.784848    
2022-06-16 04:32:34,249 - Epoch: [54][  766/  766]    Loss 5.061532    mAP 0.852273    
2022-06-16 04:32:34,304 - ==> mAP: 0.85227    Loss: 5.062

2022-06-16 04:32:34,307 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:32:34,307 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:32:34,334 - 

2022-06-16 04:32:34,334 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:32:45,164 - Epoch: [55][  200/ 1785]    Overall Loss 4.953768    Objective Loss 4.953768                                        LR 0.001000    Time 0.054134    
2022-06-16 04:32:55,738 - Epoch: [55][  400/ 1785]    Overall Loss 4.954247    Objective Loss 4.954247                                        LR 0.001000    Time 0.053499    
2022-06-16 04:33:06,330 - Epoch: [55][  600/ 1785]    Overall Loss 4.962975    Objective Loss 4.962975                                        LR 0.001000    Time 0.053316    
2022-06-16 04:33:16,951 - Epoch: [55][  800/ 1785]    Overall Loss 4.970821    Objective Loss 4.970821                                        LR 0.001000    Time 0.053260    
2022-06-16 04:33:26,909 - Epoch: [55][ 1000/ 1785]    Overall Loss 4.975162    Objective Loss 4.975162                                        LR 0.001000    Time 0.052564    
2022-06-16 04:33:36,904 - Epoch: [55][ 1200/ 1785]    Overall Loss 4.978631    Objective Loss 4.978631                                        LR 0.001000    Time 0.052130    
2022-06-16 04:33:46,967 - Epoch: [55][ 1400/ 1785]    Overall Loss 4.980133    Objective Loss 4.980133                                        LR 0.001000    Time 0.051870    
2022-06-16 04:33:57,029 - Epoch: [55][ 1600/ 1785]    Overall Loss 4.979391    Objective Loss 4.979391                                        LR 0.001000    Time 0.051674    
2022-06-16 04:34:06,303 - Epoch: [55][ 1785/ 1785]    Overall Loss 4.981098    Objective Loss 4.981098                                        LR 0.001000    Time 0.051513    
2022-06-16 04:34:06,373 - --- validate (epoch=55)-----------
2022-06-16 04:34:06,373 - 12251 samples (16 per mini-batch)
2022-06-16 04:34:22,960 - Epoch: [55][  200/  766]    Loss 5.044785    mAP 0.913636    
2022-06-16 04:34:39,123 - Epoch: [55][  400/  766]    Loss 5.048906    mAP 0.779545    
2022-06-16 04:34:55,397 - Epoch: [55][  600/  766]    Loss 5.056386    mAP 0.847727    
2022-06-16 04:35:08,918 - Epoch: [55][  766/  766]    Loss 5.055804    mAP 0.715909    
2022-06-16 04:35:08,962 - ==> mAP: 0.71591    Loss: 5.056

2022-06-16 04:35:08,965 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:35:08,965 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:35:08,988 - 

2022-06-16 04:35:08,988 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:35:19,087 - Epoch: [56][  200/ 1785]    Overall Loss 4.960618    Objective Loss 4.960618                                        LR 0.001000    Time 0.050478    
2022-06-16 04:35:29,059 - Epoch: [56][  400/ 1785]    Overall Loss 4.965565    Objective Loss 4.965565                                        LR 0.001000    Time 0.050165    
2022-06-16 04:35:39,093 - Epoch: [56][  600/ 1785]    Overall Loss 4.966793    Objective Loss 4.966793                                        LR 0.001000    Time 0.050163    
2022-06-16 04:35:49,121 - Epoch: [56][  800/ 1785]    Overall Loss 4.967664    Objective Loss 4.967664                                        LR 0.001000    Time 0.050155    
2022-06-16 04:35:59,127 - Epoch: [56][ 1000/ 1785]    Overall Loss 4.972459    Objective Loss 4.972459                                        LR 0.001000    Time 0.050128    
2022-06-16 04:36:09,147 - Epoch: [56][ 1200/ 1785]    Overall Loss 4.973608    Objective Loss 4.973608                                        LR 0.001000    Time 0.050122    
2022-06-16 04:36:19,467 - Epoch: [56][ 1400/ 1785]    Overall Loss 4.976187    Objective Loss 4.976187                                        LR 0.001000    Time 0.050331    
2022-06-16 04:36:29,626 - Epoch: [56][ 1600/ 1785]    Overall Loss 4.976147    Objective Loss 4.976147                                        LR 0.001000    Time 0.050388    
2022-06-16 04:36:38,935 - Epoch: [56][ 1785/ 1785]    Overall Loss 4.978812    Objective Loss 4.978812                                        LR 0.001000    Time 0.050380    
2022-06-16 04:36:39,032 - --- validate (epoch=56)-----------
2022-06-16 04:36:39,032 - 12251 samples (16 per mini-batch)
2022-06-16 04:36:55,213 - Epoch: [56][  200/  766]    Loss 5.086779    mAP 0.727273    
2022-06-16 04:37:11,298 - Epoch: [56][  400/  766]    Loss 5.081044    mAP 0.836364    
2022-06-16 04:37:27,475 - Epoch: [56][  600/  766]    Loss 5.081706    mAP 0.784091    
2022-06-16 04:37:40,800 - Epoch: [56][  766/  766]    Loss 5.080943    mAP 0.551136    
2022-06-16 04:37:40,881 - ==> mAP: 0.55114    Loss: 5.081

2022-06-16 04:37:40,883 - ==> Best [mAP: 1.000000   vloss: 5.078272   Sparsity:0.29   Params: 334556 on epoch: 27]
2022-06-16 04:37:40,884 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:37:40,907 - 

2022-06-16 04:37:40,907 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:37:51,594 - Epoch: [57][  200/ 1785]    Overall Loss 4.966453    Objective Loss 4.966453                                        LR 0.001000    Time 0.053423    
2022-06-16 04:38:02,114 - Epoch: [57][  400/ 1785]    Overall Loss 4.961064    Objective Loss 4.961064                                        LR 0.001000    Time 0.053004    
2022-06-16 04:38:12,633 - Epoch: [57][  600/ 1785]    Overall Loss 4.963934    Objective Loss 4.963934                                        LR 0.001000    Time 0.052866    
2022-06-16 04:38:23,166 - Epoch: [57][  800/ 1785]    Overall Loss 4.965223    Objective Loss 4.965223                                        LR 0.001000    Time 0.052813    
2022-06-16 04:38:33,801 - Epoch: [57][ 1000/ 1785]    Overall Loss 4.966496    Objective Loss 4.966496                                        LR 0.001000    Time 0.052883    
2022-06-16 04:38:44,488 - Epoch: [57][ 1200/ 1785]    Overall Loss 4.972005    Objective Loss 4.972005                                        LR 0.001000    Time 0.052974    
2022-06-16 04:38:54,756 - Epoch: [57][ 1400/ 1785]    Overall Loss 4.971690    Objective Loss 4.971690                                        LR 0.001000    Time 0.052739    
2022-06-16 04:39:05,009 - Epoch: [57][ 1600/ 1785]    Overall Loss 4.973666    Objective Loss 4.973666                                        LR 0.001000    Time 0.052554    
2022-06-16 04:39:14,448 - Epoch: [57][ 1785/ 1785]    Overall Loss 4.976601    Objective Loss 4.976601                                        LR 0.001000    Time 0.052393    
2022-06-16 04:39:14,487 - --- validate (epoch=57)-----------
2022-06-16 04:39:14,487 - 12251 samples (16 per mini-batch)
2022-06-16 04:39:30,515 - Epoch: [57][  200/  766]    Loss 5.066368    mAP 0.612121    
2022-06-16 04:39:46,476 - Epoch: [57][  400/  766]    Loss 5.063696    mAP 0.790909    
2022-06-16 04:40:02,543 - Epoch: [57][  600/  766]    Loss 5.058925    mAP 0.808081    
2022-06-16 04:40:15,880 - Epoch: [57][  766/  766]    Loss 5.052065    mAP 1.000000    
2022-06-16 04:40:15,922 - ==> mAP: 1.00000    Loss: 5.052

2022-06-16 04:40:15,924 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 04:40:15,924 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:40:15,951 - 

2022-06-16 04:40:15,951 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:40:26,028 - Epoch: [58][  200/ 1785]    Overall Loss 4.966392    Objective Loss 4.966392                                        LR 0.001000    Time 0.050370    
2022-06-16 04:40:35,961 - Epoch: [58][  400/ 1785]    Overall Loss 4.967532    Objective Loss 4.967532                                        LR 0.001000    Time 0.050013    
2022-06-16 04:40:45,979 - Epoch: [58][  600/ 1785]    Overall Loss 4.966228    Objective Loss 4.966228                                        LR 0.001000    Time 0.050035    
2022-06-16 04:40:55,996 - Epoch: [58][  800/ 1785]    Overall Loss 4.972089    Objective Loss 4.972089                                        LR 0.001000    Time 0.050045    
2022-06-16 04:41:06,030 - Epoch: [58][ 1000/ 1785]    Overall Loss 4.970509    Objective Loss 4.970509                                        LR 0.001000    Time 0.050068    
2022-06-16 04:41:16,291 - Epoch: [58][ 1200/ 1785]    Overall Loss 4.973598    Objective Loss 4.973598                                        LR 0.001000    Time 0.050272    
2022-06-16 04:41:26,306 - Epoch: [58][ 1400/ 1785]    Overall Loss 4.974415    Objective Loss 4.974415                                        LR 0.001000    Time 0.050243    
2022-06-16 04:41:36,687 - Epoch: [58][ 1600/ 1785]    Overall Loss 4.974324    Objective Loss 4.974324                                        LR 0.001000    Time 0.050450    
2022-06-16 04:41:46,365 - Epoch: [58][ 1785/ 1785]    Overall Loss 4.976081    Objective Loss 4.976081                                        LR 0.001000    Time 0.050642    
2022-06-16 04:41:46,404 - --- validate (epoch=58)-----------
2022-06-16 04:41:46,404 - 12251 samples (16 per mini-batch)
2022-06-16 04:42:02,665 - Epoch: [58][  200/  766]    Loss 5.051332    mAP 0.933333    
2022-06-16 04:42:18,797 - Epoch: [58][  400/  766]    Loss 5.054945    mAP 0.762626    
2022-06-16 04:42:35,150 - Epoch: [58][  600/  766]    Loss 5.056876    mAP 0.797727    
2022-06-16 04:42:48,695 - Epoch: [58][  766/  766]    Loss 5.060297    mAP 0.797980    
2022-06-16 04:42:48,744 - ==> mAP: 0.79798    Loss: 5.060

2022-06-16 04:42:48,747 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 04:42:48,747 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:42:48,772 - 

2022-06-16 04:42:48,772 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:42:58,859 - Epoch: [59][  200/ 1785]    Overall Loss 4.958123    Objective Loss 4.958123                                        LR 0.001000    Time 0.050422    
2022-06-16 04:43:08,782 - Epoch: [59][  400/ 1785]    Overall Loss 4.960798    Objective Loss 4.960798                                        LR 0.001000    Time 0.049995    
2022-06-16 04:43:18,801 - Epoch: [59][  600/ 1785]    Overall Loss 4.962572    Objective Loss 4.962572                                        LR 0.001000    Time 0.050027    
2022-06-16 04:43:28,931 - Epoch: [59][  800/ 1785]    Overall Loss 4.964022    Objective Loss 4.964022                                        LR 0.001000    Time 0.050180    
2022-06-16 04:43:39,091 - Epoch: [59][ 1000/ 1785]    Overall Loss 4.965129    Objective Loss 4.965129                                        LR 0.001000    Time 0.050302    
2022-06-16 04:43:49,190 - Epoch: [59][ 1200/ 1785]    Overall Loss 4.965905    Objective Loss 4.965905                                        LR 0.001000    Time 0.050332    
2022-06-16 04:43:59,182 - Epoch: [59][ 1400/ 1785]    Overall Loss 4.970525    Objective Loss 4.970525                                        LR 0.001000    Time 0.050277    
2022-06-16 04:44:09,192 - Epoch: [59][ 1600/ 1785]    Overall Loss 4.972881    Objective Loss 4.972881                                        LR 0.001000    Time 0.050248    
2022-06-16 04:44:18,444 - Epoch: [59][ 1785/ 1785]    Overall Loss 4.974417    Objective Loss 4.974417                                        LR 0.001000    Time 0.050222    
2022-06-16 04:44:18,488 - --- validate (epoch=59)-----------
2022-06-16 04:44:18,489 - 12251 samples (16 per mini-batch)
2022-06-16 04:44:34,819 - Epoch: [59][  200/  766]    Loss 5.049789    mAP 0.808081    
2022-06-16 04:44:50,944 - Epoch: [59][  400/  766]    Loss 5.053410    mAP 0.896061    
2022-06-16 04:45:07,179 - Epoch: [59][  600/  766]    Loss 5.057536    mAP 0.963636    
2022-06-16 04:45:20,708 - Epoch: [59][  766/  766]    Loss 5.060433    mAP 0.852273    
2022-06-16 04:45:20,752 - ==> mAP: 0.85227    Loss: 5.060

2022-06-16 04:45:20,755 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 04:45:20,755 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:45:20,778 - 

2022-06-16 04:45:20,779 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:45:31,664 - Epoch: [60][  200/ 1785]    Overall Loss 4.972536    Objective Loss 4.972536                                        LR 0.001000    Time 0.054412    
2022-06-16 04:45:42,168 - Epoch: [60][  400/ 1785]    Overall Loss 4.967912    Objective Loss 4.967912                                        LR 0.001000    Time 0.053460    
2022-06-16 04:45:52,333 - Epoch: [60][  600/ 1785]    Overall Loss 4.964034    Objective Loss 4.964034                                        LR 0.001000    Time 0.052579    
2022-06-16 04:46:02,889 - Epoch: [60][  800/ 1785]    Overall Loss 4.965637    Objective Loss 4.965637                                        LR 0.001000    Time 0.052627    
2022-06-16 04:46:13,409 - Epoch: [60][ 1000/ 1785]    Overall Loss 4.965848    Objective Loss 4.965848                                        LR 0.001000    Time 0.052619    
2022-06-16 04:46:24,045 - Epoch: [60][ 1200/ 1785]    Overall Loss 4.968752    Objective Loss 4.968752                                        LR 0.001000    Time 0.052711    
2022-06-16 04:46:34,194 - Epoch: [60][ 1400/ 1785]    Overall Loss 4.969358    Objective Loss 4.969358                                        LR 0.001000    Time 0.052429    
2022-06-16 04:46:44,281 - Epoch: [60][ 1600/ 1785]    Overall Loss 4.971301    Objective Loss 4.971301                                        LR 0.001000    Time 0.052179    
2022-06-16 04:46:53,557 - Epoch: [60][ 1785/ 1785]    Overall Loss 4.973572    Objective Loss 4.973572                                        LR 0.001000    Time 0.051966    
2022-06-16 04:46:53,595 - --- validate (epoch=60)-----------
2022-06-16 04:46:53,595 - 12251 samples (16 per mini-batch)
2022-06-16 04:47:09,721 - Epoch: [60][  200/  766]    Loss 5.071823    mAP 0.676768    
2022-06-16 04:47:25,750 - Epoch: [60][  400/  766]    Loss 5.064809    mAP 0.860000    
2022-06-16 04:47:41,745 - Epoch: [60][  600/  766]    Loss 5.064878    mAP 0.763131    
2022-06-16 04:47:55,026 - Epoch: [60][  766/  766]    Loss 5.067128    mAP 0.831650    
2022-06-16 04:47:55,068 - ==> mAP: 0.83165    Loss: 5.067

2022-06-16 04:47:55,071 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 04:47:55,071 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:47:55,098 - 

2022-06-16 04:47:55,098 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:48:05,986 - Epoch: [61][  200/ 1785]    Overall Loss 4.961990    Objective Loss 4.961990                                        LR 0.001000    Time 0.054422    
2022-06-16 04:48:15,999 - Epoch: [61][  400/ 1785]    Overall Loss 4.955999    Objective Loss 4.955999                                        LR 0.001000    Time 0.052240    
2022-06-16 04:48:26,134 - Epoch: [61][  600/ 1785]    Overall Loss 4.959583    Objective Loss 4.959583                                        LR 0.001000    Time 0.051715    
2022-06-16 04:48:36,205 - Epoch: [61][  800/ 1785]    Overall Loss 4.958786    Objective Loss 4.958786                                        LR 0.001000    Time 0.051372    
2022-06-16 04:48:46,305 - Epoch: [61][ 1000/ 1785]    Overall Loss 4.964140    Objective Loss 4.964140                                        LR 0.001000    Time 0.051196    
2022-06-16 04:48:56,401 - Epoch: [61][ 1200/ 1785]    Overall Loss 4.966079    Objective Loss 4.966079                                        LR 0.001000    Time 0.051074    
2022-06-16 04:49:06,438 - Epoch: [61][ 1400/ 1785]    Overall Loss 4.971647    Objective Loss 4.971647                                        LR 0.001000    Time 0.050946    
2022-06-16 04:49:16,635 - Epoch: [61][ 1600/ 1785]    Overall Loss 4.972889    Objective Loss 4.972889                                        LR 0.001000    Time 0.050950    
2022-06-16 04:49:26,365 - Epoch: [61][ 1785/ 1785]    Overall Loss 4.975016    Objective Loss 4.975016                                        LR 0.001000    Time 0.051119    
2022-06-16 04:49:26,411 - --- validate (epoch=61)-----------
2022-06-16 04:49:26,411 - 12251 samples (16 per mini-batch)
2022-06-16 04:49:42,685 - Epoch: [61][  200/  766]    Loss 5.060544    mAP 0.899242    
2022-06-16 04:49:58,836 - Epoch: [61][  400/  766]    Loss 5.048084    mAP 0.848636    
2022-06-16 04:50:15,034 - Epoch: [61][  600/  766]    Loss 5.044733    mAP 0.906061    
2022-06-16 04:50:28,547 - Epoch: [61][  766/  766]    Loss 5.043451    mAP 0.844156    
2022-06-16 04:50:28,640 - ==> mAP: 0.84416    Loss: 5.043

2022-06-16 04:50:28,644 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 04:50:28,644 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:50:28,678 - 

2022-06-16 04:50:28,679 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:50:38,810 - Epoch: [62][  200/ 1785]    Overall Loss 4.957336    Objective Loss 4.957336                                        LR 0.001000    Time 0.050640    
2022-06-16 04:50:48,698 - Epoch: [62][  400/ 1785]    Overall Loss 4.956674    Objective Loss 4.956674                                        LR 0.001000    Time 0.050034    
2022-06-16 04:50:58,862 - Epoch: [62][  600/ 1785]    Overall Loss 4.965809    Objective Loss 4.965809                                        LR 0.001000    Time 0.050294    
2022-06-16 04:51:09,319 - Epoch: [62][  800/ 1785]    Overall Loss 4.967715    Objective Loss 4.967715                                        LR 0.001000    Time 0.050789    
2022-06-16 04:51:19,832 - Epoch: [62][ 1000/ 1785]    Overall Loss 4.968765    Objective Loss 4.968765                                        LR 0.001000    Time 0.051142    
2022-06-16 04:51:30,370 - Epoch: [62][ 1200/ 1785]    Overall Loss 4.970005    Objective Loss 4.970005                                        LR 0.001000    Time 0.051399    
2022-06-16 04:51:40,931 - Epoch: [62][ 1400/ 1785]    Overall Loss 4.970836    Objective Loss 4.970836                                        LR 0.001000    Time 0.051598    
2022-06-16 04:51:51,465 - Epoch: [62][ 1600/ 1785]    Overall Loss 4.970438    Objective Loss 4.970438                                        LR 0.001000    Time 0.051731    
2022-06-16 04:52:01,067 - Epoch: [62][ 1785/ 1785]    Overall Loss 4.971553    Objective Loss 4.971553                                        LR 0.001000    Time 0.051747    
2022-06-16 04:52:01,113 - --- validate (epoch=62)-----------
2022-06-16 04:52:01,113 - 12251 samples (16 per mini-batch)
2022-06-16 04:52:17,285 - Epoch: [62][  200/  766]    Loss 5.064974    mAP 0.972727    
2022-06-16 04:52:33,222 - Epoch: [62][  400/  766]    Loss 5.059292    mAP 0.824675    
2022-06-16 04:52:49,351 - Epoch: [62][  600/  766]    Loss 5.060792    mAP 0.880000    
2022-06-16 04:53:02,658 - Epoch: [62][  766/  766]    Loss 5.061781    mAP 0.797980    
2022-06-16 04:53:02,717 - ==> mAP: 0.79798    Loss: 5.062

2022-06-16 04:53:02,721 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 04:53:02,721 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:53:02,750 - 

2022-06-16 04:53:02,751 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:53:12,855 - Epoch: [63][  200/ 1785]    Overall Loss 4.980245    Objective Loss 4.980245                                        LR 0.001000    Time 0.050507    
2022-06-16 04:53:22,775 - Epoch: [63][  400/ 1785]    Overall Loss 4.970499    Objective Loss 4.970499                                        LR 0.001000    Time 0.050048    
2022-06-16 04:53:32,676 - Epoch: [63][  600/ 1785]    Overall Loss 4.971195    Objective Loss 4.971195                                        LR 0.001000    Time 0.049863    
2022-06-16 04:53:42,656 - Epoch: [63][  800/ 1785]    Overall Loss 4.971666    Objective Loss 4.971666                                        LR 0.001000    Time 0.049871    
2022-06-16 04:53:52,666 - Epoch: [63][ 1000/ 1785]    Overall Loss 4.973644    Objective Loss 4.973644                                        LR 0.001000    Time 0.049905    
2022-06-16 04:54:02,679 - Epoch: [63][ 1200/ 1785]    Overall Loss 4.970959    Objective Loss 4.970959                                        LR 0.001000    Time 0.049930    
2022-06-16 04:54:12,697 - Epoch: [63][ 1400/ 1785]    Overall Loss 4.970189    Objective Loss 4.970189                                        LR 0.001000    Time 0.049951    
2022-06-16 04:54:22,752 - Epoch: [63][ 1600/ 1785]    Overall Loss 4.973348    Objective Loss 4.973348                                        LR 0.001000    Time 0.049991    
2022-06-16 04:54:32,089 - Epoch: [63][ 1785/ 1785]    Overall Loss 4.974601    Objective Loss 4.974601                                        LR 0.001000    Time 0.050039    
2022-06-16 04:54:32,143 - --- validate (epoch=63)-----------
2022-06-16 04:54:32,143 - 12251 samples (16 per mini-batch)
2022-06-16 04:54:48,432 - Epoch: [63][  200/  766]    Loss 5.051664    mAP 0.575758    
2022-06-16 04:55:04,624 - Epoch: [63][  400/  766]    Loss 5.047021    mAP 0.687157    
2022-06-16 04:55:20,843 - Epoch: [63][  600/  766]    Loss 5.047191    mAP 0.935354    
2022-06-16 04:55:34,187 - Epoch: [63][  766/  766]    Loss 5.046065    mAP 0.731061    
2022-06-16 04:55:34,242 - ==> mAP: 0.73106    Loss: 5.046

2022-06-16 04:55:34,245 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 04:55:34,245 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:55:34,270 - 

2022-06-16 04:55:34,270 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:55:44,429 - Epoch: [64][  200/ 1785]    Overall Loss 4.945270    Objective Loss 4.945270                                        LR 0.001000    Time 0.050782    
2022-06-16 04:55:54,422 - Epoch: [64][  400/ 1785]    Overall Loss 4.959677    Objective Loss 4.959677                                        LR 0.001000    Time 0.050369    
2022-06-16 04:56:04,417 - Epoch: [64][  600/ 1785]    Overall Loss 4.966330    Objective Loss 4.966330                                        LR 0.001000    Time 0.050234    
2022-06-16 04:56:14,597 - Epoch: [64][  800/ 1785]    Overall Loss 4.969103    Objective Loss 4.969103                                        LR 0.001000    Time 0.050398    
2022-06-16 04:56:24,667 - Epoch: [64][ 1000/ 1785]    Overall Loss 4.969573    Objective Loss 4.969573                                        LR 0.001000    Time 0.050386    
2022-06-16 04:56:34,910 - Epoch: [64][ 1200/ 1785]    Overall Loss 4.972132    Objective Loss 4.972132                                        LR 0.001000    Time 0.050523    
2022-06-16 04:56:45,015 - Epoch: [64][ 1400/ 1785]    Overall Loss 4.971598    Objective Loss 4.971598                                        LR 0.001000    Time 0.050522    
2022-06-16 04:56:55,068 - Epoch: [64][ 1600/ 1785]    Overall Loss 4.973146    Objective Loss 4.973146                                        LR 0.001000    Time 0.050488    
2022-06-16 04:57:04,358 - Epoch: [64][ 1785/ 1785]    Overall Loss 4.972417    Objective Loss 4.972417                                        LR 0.001000    Time 0.050459    
2022-06-16 04:57:04,401 - --- validate (epoch=64)-----------
2022-06-16 04:57:04,401 - 12251 samples (16 per mini-batch)
2022-06-16 04:57:20,806 - Epoch: [64][  200/  766]    Loss 5.029069    mAP 0.929293    
2022-06-16 04:57:37,039 - Epoch: [64][  400/  766]    Loss 5.039743    mAP 0.774015    
2022-06-16 04:57:53,177 - Epoch: [64][  600/  766]    Loss 5.033290    mAP 0.927273    
2022-06-16 04:58:06,692 - Epoch: [64][  766/  766]    Loss 5.036624    mAP 0.941077    
2022-06-16 04:58:06,766 - ==> mAP: 0.94108    Loss: 5.037

2022-06-16 04:58:06,769 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 04:58:06,769 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 04:58:06,796 - 

2022-06-16 04:58:06,796 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 04:58:17,104 - Epoch: [65][  200/ 1785]    Overall Loss 4.957260    Objective Loss 4.957260                                        LR 0.001000    Time 0.051523    
2022-06-16 04:58:27,617 - Epoch: [65][  400/ 1785]    Overall Loss 4.959869    Objective Loss 4.959869                                        LR 0.001000    Time 0.052040    
2022-06-16 04:58:38,140 - Epoch: [65][  600/ 1785]    Overall Loss 4.959840    Objective Loss 4.959840                                        LR 0.001000    Time 0.052228    
2022-06-16 04:58:48,694 - Epoch: [65][  800/ 1785]    Overall Loss 4.965245    Objective Loss 4.965245                                        LR 0.001000    Time 0.052361    
2022-06-16 04:58:59,275 - Epoch: [65][ 1000/ 1785]    Overall Loss 4.968924    Objective Loss 4.968924                                        LR 0.001000    Time 0.052468    
2022-06-16 04:59:09,849 - Epoch: [65][ 1200/ 1785]    Overall Loss 4.969433    Objective Loss 4.969433                                        LR 0.001000    Time 0.052533    
2022-06-16 04:59:20,476 - Epoch: [65][ 1400/ 1785]    Overall Loss 4.968378    Objective Loss 4.968378                                        LR 0.001000    Time 0.052618    
2022-06-16 04:59:30,976 - Epoch: [65][ 1600/ 1785]    Overall Loss 4.970974    Objective Loss 4.970974                                        LR 0.001000    Time 0.052602    
2022-06-16 04:59:40,595 - Epoch: [65][ 1785/ 1785]    Overall Loss 4.973230    Objective Loss 4.973230                                        LR 0.001000    Time 0.052538    
2022-06-16 04:59:40,649 - --- validate (epoch=65)-----------
2022-06-16 04:59:40,649 - 12251 samples (16 per mini-batch)
2022-06-16 04:59:57,015 - Epoch: [65][  200/  766]    Loss 5.040433    mAP 0.901515    
2022-06-16 05:00:13,226 - Epoch: [65][  400/  766]    Loss 5.045398    mAP 0.935065    
2022-06-16 05:00:29,421 - Epoch: [65][  600/  766]    Loss 5.039272    mAP 0.947403    
2022-06-16 05:00:42,858 - Epoch: [65][  766/  766]    Loss 5.040166    mAP 0.854545    
2022-06-16 05:00:42,943 - ==> mAP: 0.85455    Loss: 5.040

2022-06-16 05:00:42,946 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:00:42,946 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:00:42,973 - 

2022-06-16 05:00:42,973 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:00:53,142 - Epoch: [66][  200/ 1785]    Overall Loss 4.952559    Objective Loss 4.952559                                        LR 0.001000    Time 0.050831    
2022-06-16 05:01:03,071 - Epoch: [66][  400/ 1785]    Overall Loss 4.952670    Objective Loss 4.952670                                        LR 0.001000    Time 0.050234    
2022-06-16 05:01:13,056 - Epoch: [66][  600/ 1785]    Overall Loss 4.953769    Objective Loss 4.953769                                        LR 0.001000    Time 0.050128    
2022-06-16 05:01:23,082 - Epoch: [66][  800/ 1785]    Overall Loss 4.962049    Objective Loss 4.962049                                        LR 0.001000    Time 0.050126    
2022-06-16 05:01:33,051 - Epoch: [66][ 1000/ 1785]    Overall Loss 4.961961    Objective Loss 4.961961                                        LR 0.001000    Time 0.050068    
2022-06-16 05:01:43,080 - Epoch: [66][ 1200/ 1785]    Overall Loss 4.963628    Objective Loss 4.963628                                        LR 0.001000    Time 0.050079    
2022-06-16 05:01:53,183 - Epoch: [66][ 1400/ 1785]    Overall Loss 4.967425    Objective Loss 4.967425                                        LR 0.001000    Time 0.050139    
2022-06-16 05:02:03,281 - Epoch: [66][ 1600/ 1785]    Overall Loss 4.968409    Objective Loss 4.968409                                        LR 0.001000    Time 0.050182    
2022-06-16 05:02:12,603 - Epoch: [66][ 1785/ 1785]    Overall Loss 4.972417    Objective Loss 4.972417                                        LR 0.001000    Time 0.050202    
2022-06-16 05:02:12,657 - --- validate (epoch=66)-----------
2022-06-16 05:02:12,657 - 12251 samples (16 per mini-batch)
2022-06-16 05:02:28,642 - Epoch: [66][  200/  766]    Loss 5.101119    mAP 0.682540    
2022-06-16 05:02:44,418 - Epoch: [66][  400/  766]    Loss 5.095945    mAP 0.754546    
2022-06-16 05:03:00,290 - Epoch: [66][  600/  766]    Loss 5.093682    mAP 0.810326    
2022-06-16 05:03:13,455 - Epoch: [66][  766/  766]    Loss 5.092799    mAP 0.848485    
2022-06-16 05:03:13,494 - ==> mAP: 0.84848    Loss: 5.093

2022-06-16 05:03:13,496 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:03:13,496 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:03:13,512 - 

2022-06-16 05:03:13,513 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:03:23,941 - Epoch: [67][  200/ 1785]    Overall Loss 4.964703    Objective Loss 4.964703                                        LR 0.001000    Time 0.052129    
2022-06-16 05:03:34,385 - Epoch: [67][  400/ 1785]    Overall Loss 4.954073    Objective Loss 4.954073                                        LR 0.001000    Time 0.052169    
2022-06-16 05:03:44,826 - Epoch: [67][  600/ 1785]    Overall Loss 4.957987    Objective Loss 4.957987                                        LR 0.001000    Time 0.052177    
2022-06-16 05:03:54,783 - Epoch: [67][  800/ 1785]    Overall Loss 4.957421    Objective Loss 4.957421                                        LR 0.001000    Time 0.051577    
2022-06-16 05:04:04,680 - Epoch: [67][ 1000/ 1785]    Overall Loss 4.962841    Objective Loss 4.962841                                        LR 0.001000    Time 0.051156    
2022-06-16 05:04:14,605 - Epoch: [67][ 1200/ 1785]    Overall Loss 4.963755    Objective Loss 4.963755                                        LR 0.001000    Time 0.050900    
2022-06-16 05:04:24,545 - Epoch: [67][ 1400/ 1785]    Overall Loss 4.965804    Objective Loss 4.965804                                        LR 0.001000    Time 0.050727    
2022-06-16 05:04:34,429 - Epoch: [67][ 1600/ 1785]    Overall Loss 4.968909    Objective Loss 4.968909                                        LR 0.001000    Time 0.050562    
2022-06-16 05:04:43,576 - Epoch: [67][ 1785/ 1785]    Overall Loss 4.971966    Objective Loss 4.971966                                        LR 0.001000    Time 0.050445    
2022-06-16 05:04:43,659 - --- validate (epoch=67)-----------
2022-06-16 05:04:43,659 - 12251 samples (16 per mini-batch)
2022-06-16 05:04:59,896 - Epoch: [67][  200/  766]    Loss 5.055925    mAP 0.738636    
2022-06-16 05:05:15,980 - Epoch: [67][  400/  766]    Loss 5.062275    mAP 0.792727    
2022-06-16 05:05:32,194 - Epoch: [67][  600/  766]    Loss 5.060027    mAP 0.853333    
2022-06-16 05:05:45,642 - Epoch: [67][  766/  766]    Loss 5.060696    mAP 0.714286    
2022-06-16 05:05:45,696 - ==> mAP: 0.71429    Loss: 5.061

2022-06-16 05:05:45,698 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:05:45,698 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:05:45,722 - 

2022-06-16 05:05:45,722 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:05:56,344 - Epoch: [68][  200/ 1785]    Overall Loss 4.957501    Objective Loss 4.957501                                        LR 0.001000    Time 0.053098    
2022-06-16 05:06:06,776 - Epoch: [68][  400/ 1785]    Overall Loss 4.957093    Objective Loss 4.957093                                        LR 0.001000    Time 0.052625    
2022-06-16 05:06:17,140 - Epoch: [68][  600/ 1785]    Overall Loss 4.957841    Objective Loss 4.957841                                        LR 0.001000    Time 0.052353    
2022-06-16 05:06:27,548 - Epoch: [68][  800/ 1785]    Overall Loss 4.963333    Objective Loss 4.963333                                        LR 0.001000    Time 0.052272    
2022-06-16 05:06:37,977 - Epoch: [68][ 1000/ 1785]    Overall Loss 4.967485    Objective Loss 4.967485                                        LR 0.001000    Time 0.052245    
2022-06-16 05:06:48,374 - Epoch: [68][ 1200/ 1785]    Overall Loss 4.969256    Objective Loss 4.969256                                        LR 0.001000    Time 0.052200    
2022-06-16 05:06:58,936 - Epoch: [68][ 1400/ 1785]    Overall Loss 4.970172    Objective Loss 4.970172                                        LR 0.001000    Time 0.052286    
2022-06-16 05:07:09,487 - Epoch: [68][ 1600/ 1785]    Overall Loss 4.969039    Objective Loss 4.969039                                        LR 0.001000    Time 0.052343    
2022-06-16 05:07:19,243 - Epoch: [68][ 1785/ 1785]    Overall Loss 4.972249    Objective Loss 4.972249                                        LR 0.001000    Time 0.052383    
2022-06-16 05:07:19,294 - --- validate (epoch=68)-----------
2022-06-16 05:07:19,294 - 12251 samples (16 per mini-batch)
2022-06-16 05:07:35,752 - Epoch: [68][  200/  766]    Loss 5.072314    mAP 0.910000    
2022-06-16 05:07:51,916 - Epoch: [68][  400/  766]    Loss 5.080161    mAP 0.742184    
2022-06-16 05:08:08,124 - Epoch: [68][  600/  766]    Loss 5.080445    mAP 0.634343    
2022-06-16 05:08:21,534 - Epoch: [68][  766/  766]    Loss 5.072977    mAP 0.865584    
2022-06-16 05:08:21,610 - ==> mAP: 0.86558    Loss: 5.073

2022-06-16 05:08:21,613 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:08:21,613 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:08:21,637 - 

2022-06-16 05:08:21,637 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:08:32,359 - Epoch: [69][  200/ 1785]    Overall Loss 4.989372    Objective Loss 4.989372                                        LR 0.001000    Time 0.053599    
2022-06-16 05:08:42,919 - Epoch: [69][  400/ 1785]    Overall Loss 4.972780    Objective Loss 4.972780                                        LR 0.001000    Time 0.053194    
2022-06-16 05:08:53,451 - Epoch: [69][  600/ 1785]    Overall Loss 4.972992    Objective Loss 4.972992                                        LR 0.001000    Time 0.053014    
2022-06-16 05:09:04,069 - Epoch: [69][  800/ 1785]    Overall Loss 4.972464    Objective Loss 4.972464                                        LR 0.001000    Time 0.053030    
2022-06-16 05:09:14,657 - Epoch: [69][ 1000/ 1785]    Overall Loss 4.969766    Objective Loss 4.969766                                        LR 0.001000    Time 0.053010    
2022-06-16 05:09:25,166 - Epoch: [69][ 1200/ 1785]    Overall Loss 4.969939    Objective Loss 4.969939                                        LR 0.001000    Time 0.052931    
2022-06-16 05:09:35,566 - Epoch: [69][ 1400/ 1785]    Overall Loss 4.969803    Objective Loss 4.969803                                        LR 0.001000    Time 0.052797    
2022-06-16 05:09:46,093 - Epoch: [69][ 1600/ 1785]    Overall Loss 4.971452    Objective Loss 4.971452                                        LR 0.001000    Time 0.052776    
2022-06-16 05:09:55,954 - Epoch: [69][ 1785/ 1785]    Overall Loss 4.972191    Objective Loss 4.972191                                        LR 0.001000    Time 0.052829    
2022-06-16 05:09:55,993 - --- validate (epoch=69)-----------
2022-06-16 05:09:55,993 - 12251 samples (16 per mini-batch)
2022-06-16 05:10:12,222 - Epoch: [69][  200/  766]    Loss 5.030436    mAP 0.808802    
2022-06-16 05:10:28,274 - Epoch: [69][  400/  766]    Loss 5.046836    mAP 1.000000    
2022-06-16 05:10:44,381 - Epoch: [69][  600/  766]    Loss 5.043164    mAP 0.927273    
2022-06-16 05:10:57,592 - Epoch: [69][  766/  766]    Loss 5.043004    mAP 0.808081    
2022-06-16 05:10:57,666 - ==> mAP: 0.80808    Loss: 5.043

2022-06-16 05:10:57,669 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:10:57,669 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:10:57,693 - 

2022-06-16 05:10:57,693 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:11:08,261 - Epoch: [70][  200/ 1785]    Overall Loss 4.966440    Objective Loss 4.966440                                        LR 0.001000    Time 0.052830    
2022-06-16 05:11:18,589 - Epoch: [70][  400/ 1785]    Overall Loss 4.962235    Objective Loss 4.962235                                        LR 0.001000    Time 0.052229    
2022-06-16 05:11:28,443 - Epoch: [70][  600/ 1785]    Overall Loss 4.967240    Objective Loss 4.967240                                        LR 0.001000    Time 0.051240    
2022-06-16 05:11:38,295 - Epoch: [70][  800/ 1785]    Overall Loss 4.967984    Objective Loss 4.967984                                        LR 0.001000    Time 0.050743    
2022-06-16 05:11:48,206 - Epoch: [70][ 1000/ 1785]    Overall Loss 4.967159    Objective Loss 4.967159                                        LR 0.001000    Time 0.050503    
2022-06-16 05:11:58,164 - Epoch: [70][ 1200/ 1785]    Overall Loss 4.970469    Objective Loss 4.970469                                        LR 0.001000    Time 0.050383    
2022-06-16 05:12:08,183 - Epoch: [70][ 1400/ 1785]    Overall Loss 4.971288    Objective Loss 4.971288                                        LR 0.001000    Time 0.050340    
2022-06-16 05:12:18,629 - Epoch: [70][ 1600/ 1785]    Overall Loss 4.970809    Objective Loss 4.970809                                        LR 0.001000    Time 0.050575    
2022-06-16 05:12:28,013 - Epoch: [70][ 1785/ 1785]    Overall Loss 4.969724    Objective Loss 4.969724                                        LR 0.001000    Time 0.050589    
2022-06-16 05:12:28,052 - --- validate (epoch=70)-----------
2022-06-16 05:12:28,052 - 12251 samples (16 per mini-batch)
2022-06-16 05:12:44,326 - Epoch: [70][  200/  766]    Loss 5.050629    mAP 0.649793    
2022-06-16 05:13:00,418 - Epoch: [70][  400/  766]    Loss 5.043020    mAP 0.921818    
2022-06-16 05:13:16,585 - Epoch: [70][  600/  766]    Loss 5.042509    mAP 0.848485    
2022-06-16 05:13:29,836 - Epoch: [70][  766/  766]    Loss 5.035310    mAP 0.888889    
2022-06-16 05:13:29,888 - ==> mAP: 0.88889    Loss: 5.035

2022-06-16 05:13:29,891 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:13:29,891 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:13:29,914 - 

2022-06-16 05:13:29,914 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:13:40,749 - Epoch: [71][  200/ 1785]    Overall Loss 4.945847    Objective Loss 4.945847                                        LR 0.001000    Time 0.054159    
2022-06-16 05:13:50,732 - Epoch: [71][  400/ 1785]    Overall Loss 4.951875    Objective Loss 4.951875                                        LR 0.001000    Time 0.052033    
2022-06-16 05:14:00,717 - Epoch: [71][  600/ 1785]    Overall Loss 4.954082    Objective Loss 4.954082                                        LR 0.001000    Time 0.051326    
2022-06-16 05:14:10,685 - Epoch: [71][  800/ 1785]    Overall Loss 4.957789    Objective Loss 4.957789                                        LR 0.001000    Time 0.050952    
2022-06-16 05:14:20,666 - Epoch: [71][ 1000/ 1785]    Overall Loss 4.963149    Objective Loss 4.963149                                        LR 0.001000    Time 0.050741    
2022-06-16 05:14:30,687 - Epoch: [71][ 1200/ 1785]    Overall Loss 4.966625    Objective Loss 4.966625                                        LR 0.001000    Time 0.050633    
2022-06-16 05:14:40,699 - Epoch: [71][ 1400/ 1785]    Overall Loss 4.967746    Objective Loss 4.967746                                        LR 0.001000    Time 0.050549    
2022-06-16 05:14:50,757 - Epoch: [71][ 1600/ 1785]    Overall Loss 4.969455    Objective Loss 4.969455                                        LR 0.001000    Time 0.050516    
2022-06-16 05:15:00,100 - Epoch: [71][ 1785/ 1785]    Overall Loss 4.970974    Objective Loss 4.970974                                        LR 0.001000    Time 0.050514    
2022-06-16 05:15:00,141 - --- validate (epoch=71)-----------
2022-06-16 05:15:00,141 - 12251 samples (16 per mini-batch)
2022-06-16 05:15:16,765 - Epoch: [71][  200/  766]    Loss 5.047724    mAP 0.727273    
2022-06-16 05:15:33,158 - Epoch: [71][  400/  766]    Loss 5.047405    mAP 0.787879    
2022-06-16 05:15:49,618 - Epoch: [71][  600/  766]    Loss 5.043932    mAP 0.857576    
2022-06-16 05:16:03,314 - Epoch: [71][  766/  766]    Loss 5.043942    mAP 0.629870    
2022-06-16 05:16:03,410 - ==> mAP: 0.62987    Loss: 5.044

2022-06-16 05:16:03,413 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:16:03,413 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:16:03,433 - 

2022-06-16 05:16:03,433 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:16:13,532 - Epoch: [72][  200/ 1785]    Overall Loss 4.959487    Objective Loss 4.959487                                        LR 0.001000    Time 0.050481    
2022-06-16 05:16:23,591 - Epoch: [72][  400/ 1785]    Overall Loss 4.954756    Objective Loss 4.954756                                        LR 0.001000    Time 0.050384    
2022-06-16 05:16:33,655 - Epoch: [72][  600/ 1785]    Overall Loss 4.951003    Objective Loss 4.951003                                        LR 0.001000    Time 0.050358    
2022-06-16 05:16:43,678 - Epoch: [72][  800/ 1785]    Overall Loss 4.958357    Objective Loss 4.958357                                        LR 0.001000    Time 0.050295    
2022-06-16 05:16:53,791 - Epoch: [72][ 1000/ 1785]    Overall Loss 4.961556    Objective Loss 4.961556                                        LR 0.001000    Time 0.050348    
2022-06-16 05:17:03,989 - Epoch: [72][ 1200/ 1785]    Overall Loss 4.961210    Objective Loss 4.961210                                        LR 0.001000    Time 0.050453    
2022-06-16 05:17:14,033 - Epoch: [72][ 1400/ 1785]    Overall Loss 4.963448    Objective Loss 4.963448                                        LR 0.001000    Time 0.050418    
2022-06-16 05:17:24,267 - Epoch: [72][ 1600/ 1785]    Overall Loss 4.965891    Objective Loss 4.965891                                        LR 0.001000    Time 0.050511    
2022-06-16 05:17:33,533 - Epoch: [72][ 1785/ 1785]    Overall Loss 4.969356    Objective Loss 4.969356                                        LR 0.001000    Time 0.050466    
2022-06-16 05:17:33,577 - --- validate (epoch=72)-----------
2022-06-16 05:17:33,577 - 12251 samples (16 per mini-batch)
2022-06-16 05:17:49,655 - Epoch: [72][  200/  766]    Loss 5.049265    mAP 0.763636    
2022-06-16 05:18:05,661 - Epoch: [72][  400/  766]    Loss 5.038251    mAP 0.782828    
2022-06-16 05:18:21,720 - Epoch: [72][  600/  766]    Loss 5.046823    mAP 0.476479    
2022-06-16 05:18:35,008 - Epoch: [72][  766/  766]    Loss 5.046282    mAP 0.784091    
2022-06-16 05:18:35,069 - ==> mAP: 0.78409    Loss: 5.046

2022-06-16 05:18:35,071 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:18:35,071 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:18:35,089 - 

2022-06-16 05:18:35,089 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:18:45,401 - Epoch: [73][  200/ 1785]    Overall Loss 4.946171    Objective Loss 4.946171                                        LR 0.001000    Time 0.051549    
2022-06-16 05:18:55,444 - Epoch: [73][  400/ 1785]    Overall Loss 4.944178    Objective Loss 4.944178                                        LR 0.001000    Time 0.050876    
2022-06-16 05:19:05,493 - Epoch: [73][  600/ 1785]    Overall Loss 4.953008    Objective Loss 4.953008                                        LR 0.001000    Time 0.050663    
2022-06-16 05:19:15,526 - Epoch: [73][  800/ 1785]    Overall Loss 4.958389    Objective Loss 4.958389                                        LR 0.001000    Time 0.050535    
2022-06-16 05:19:25,564 - Epoch: [73][ 1000/ 1785]    Overall Loss 4.960788    Objective Loss 4.960788                                        LR 0.001000    Time 0.050464    
2022-06-16 05:19:35,595 - Epoch: [73][ 1200/ 1785]    Overall Loss 4.965282    Objective Loss 4.965282                                        LR 0.001000    Time 0.050411    
2022-06-16 05:19:45,629 - Epoch: [73][ 1400/ 1785]    Overall Loss 4.967503    Objective Loss 4.967503                                        LR 0.001000    Time 0.050375    
2022-06-16 05:19:55,664 - Epoch: [73][ 1600/ 1785]    Overall Loss 4.968552    Objective Loss 4.968552                                        LR 0.001000    Time 0.050349    
2022-06-16 05:20:04,922 - Epoch: [73][ 1785/ 1785]    Overall Loss 4.967640    Objective Loss 4.967640                                        LR 0.001000    Time 0.050316    
2022-06-16 05:20:04,982 - --- validate (epoch=73)-----------
2022-06-16 05:20:04,982 - 12251 samples (16 per mini-batch)
2022-06-16 05:20:21,322 - Epoch: [73][  200/  766]    Loss 5.031277    mAP 0.772727    
2022-06-16 05:20:37,720 - Epoch: [73][  400/  766]    Loss 5.028512    mAP 0.737374    
2022-06-16 05:20:53,930 - Epoch: [73][  600/  766]    Loss 5.034392    mAP 0.824242    
2022-06-16 05:21:07,322 - Epoch: [73][  766/  766]    Loss 5.030180    mAP 0.715152    
2022-06-16 05:21:07,378 - ==> mAP: 0.71515    Loss: 5.030

2022-06-16 05:21:07,380 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:21:07,380 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:21:07,404 - 

2022-06-16 05:21:07,404 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:21:18,053 - Epoch: [74][  200/ 1785]    Overall Loss 4.950989    Objective Loss 4.950989                                        LR 0.001000    Time 0.053230    
2022-06-16 05:21:28,507 - Epoch: [74][  400/ 1785]    Overall Loss 4.966988    Objective Loss 4.966988                                        LR 0.001000    Time 0.052746    
2022-06-16 05:21:38,529 - Epoch: [74][  600/ 1785]    Overall Loss 4.972672    Objective Loss 4.972672                                        LR 0.001000    Time 0.051864    
2022-06-16 05:21:48,566 - Epoch: [74][  800/ 1785]    Overall Loss 4.969241    Objective Loss 4.969241                                        LR 0.001000    Time 0.051442    
2022-06-16 05:21:59,059 - Epoch: [74][ 1000/ 1785]    Overall Loss 4.968049    Objective Loss 4.968049                                        LR 0.001000    Time 0.051644    
2022-06-16 05:22:09,204 - Epoch: [74][ 1200/ 1785]    Overall Loss 4.969302    Objective Loss 4.969302                                        LR 0.001000    Time 0.051489    
2022-06-16 05:22:19,258 - Epoch: [74][ 1400/ 1785]    Overall Loss 4.969098    Objective Loss 4.969098                                        LR 0.001000    Time 0.051314    
2022-06-16 05:22:29,434 - Epoch: [74][ 1600/ 1785]    Overall Loss 4.968993    Objective Loss 4.968993                                        LR 0.001000    Time 0.051258    
2022-06-16 05:22:38,768 - Epoch: [74][ 1785/ 1785]    Overall Loss 4.969721    Objective Loss 4.969721                                        LR 0.001000    Time 0.051174    
2022-06-16 05:22:38,850 - --- validate (epoch=74)-----------
2022-06-16 05:22:38,851 - 12251 samples (16 per mini-batch)
2022-06-16 05:22:55,404 - Epoch: [74][  200/  766]    Loss 5.064106    mAP 0.750000    
2022-06-16 05:23:11,739 - Epoch: [74][  400/  766]    Loss 5.057924    mAP 0.520202    
2022-06-16 05:23:28,231 - Epoch: [74][  600/  766]    Loss 5.051970    mAP 0.883333    
2022-06-16 05:23:41,903 - Epoch: [74][  766/  766]    Loss 5.053302    mAP 0.863636    
2022-06-16 05:23:41,958 - ==> mAP: 0.86364    Loss: 5.053

2022-06-16 05:23:41,960 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:23:41,960 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:23:41,984 - 

2022-06-16 05:23:41,984 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:23:52,642 - Epoch: [75][  200/ 1785]    Overall Loss 4.962784    Objective Loss 4.962784                                        LR 0.001000    Time 0.053274    
2022-06-16 05:24:03,162 - Epoch: [75][  400/ 1785]    Overall Loss 4.953750    Objective Loss 4.953750                                        LR 0.001000    Time 0.052932    
2022-06-16 05:24:13,679 - Epoch: [75][  600/ 1785]    Overall Loss 4.955107    Objective Loss 4.955107                                        LR 0.001000    Time 0.052814    
2022-06-16 05:24:24,259 - Epoch: [75][  800/ 1785]    Overall Loss 4.958084    Objective Loss 4.958084                                        LR 0.001000    Time 0.052834    
2022-06-16 05:24:34,819 - Epoch: [75][ 1000/ 1785]    Overall Loss 4.959765    Objective Loss 4.959765                                        LR 0.001000    Time 0.052825    
2022-06-16 05:24:45,358 - Epoch: [75][ 1200/ 1785]    Overall Loss 4.959803    Objective Loss 4.959803                                        LR 0.001000    Time 0.052802    
2022-06-16 05:24:55,875 - Epoch: [75][ 1400/ 1785]    Overall Loss 4.959776    Objective Loss 4.959776                                        LR 0.001000    Time 0.052769    
2022-06-16 05:25:06,363 - Epoch: [75][ 1600/ 1785]    Overall Loss 4.964493    Objective Loss 4.964493                                        LR 0.001000    Time 0.052727    
2022-06-16 05:25:16,059 - Epoch: [75][ 1785/ 1785]    Overall Loss 4.967428    Objective Loss 4.967428                                        LR 0.001000    Time 0.052693    
2022-06-16 05:25:16,139 - --- validate (epoch=75)-----------
2022-06-16 05:25:16,139 - 12251 samples (16 per mini-batch)
2022-06-16 05:25:32,343 - Epoch: [75][  200/  766]    Loss 5.036358    mAP 0.936364    
2022-06-16 05:25:48,421 - Epoch: [75][  400/  766]    Loss 5.050000    mAP 0.556818    
2022-06-16 05:26:04,556 - Epoch: [75][  600/  766]    Loss 5.049237    mAP 0.936364    
2022-06-16 05:26:18,045 - Epoch: [75][  766/  766]    Loss 5.050221    mAP 0.764310    
2022-06-16 05:26:18,091 - ==> mAP: 0.76431    Loss: 5.050

2022-06-16 05:26:18,093 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:26:18,093 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:26:18,117 - 

2022-06-16 05:26:18,117 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:26:29,002 - Epoch: [76][  200/ 1785]    Overall Loss 4.953595    Objective Loss 4.953595                                        LR 0.001000    Time 0.054411    
2022-06-16 05:26:39,426 - Epoch: [76][  400/ 1785]    Overall Loss 4.952684    Objective Loss 4.952684                                        LR 0.001000    Time 0.053261    
2022-06-16 05:26:49,398 - Epoch: [76][  600/ 1785]    Overall Loss 4.952689    Objective Loss 4.952689                                        LR 0.001000    Time 0.052125    
2022-06-16 05:26:59,429 - Epoch: [76][  800/ 1785]    Overall Loss 4.956798    Objective Loss 4.956798                                        LR 0.001000    Time 0.051629    
2022-06-16 05:27:09,413 - Epoch: [76][ 1000/ 1785]    Overall Loss 4.961552    Objective Loss 4.961552                                        LR 0.001000    Time 0.051286    
2022-06-16 05:27:19,382 - Epoch: [76][ 1200/ 1785]    Overall Loss 4.962322    Objective Loss 4.962322                                        LR 0.001000    Time 0.051044    
2022-06-16 05:27:29,362 - Epoch: [76][ 1400/ 1785]    Overall Loss 4.961145    Objective Loss 4.961145                                        LR 0.001000    Time 0.050879    
2022-06-16 05:27:39,312 - Epoch: [76][ 1600/ 1785]    Overall Loss 4.967123    Objective Loss 4.967123                                        LR 0.001000    Time 0.050737    
2022-06-16 05:27:48,527 - Epoch: [76][ 1785/ 1785]    Overall Loss 4.967767    Objective Loss 4.967767                                        LR 0.001000    Time 0.050640    
2022-06-16 05:27:48,588 - --- validate (epoch=76)-----------
2022-06-16 05:27:48,588 - 12251 samples (16 per mini-batch)
2022-06-16 05:28:04,974 - Epoch: [76][  200/  766]    Loss 5.072317    mAP 0.800000    
2022-06-16 05:28:21,298 - Epoch: [76][  400/  766]    Loss 5.070999    mAP 0.707071    
2022-06-16 05:28:37,658 - Epoch: [76][  600/  766]    Loss 5.068428    mAP 0.681818    
2022-06-16 05:28:51,220 - Epoch: [76][  766/  766]    Loss 5.074128    mAP 0.667532    
2022-06-16 05:28:51,271 - ==> mAP: 0.66753    Loss: 5.074

2022-06-16 05:28:51,274 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:28:51,274 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:28:51,301 - 

2022-06-16 05:28:51,301 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:29:01,463 - Epoch: [77][  200/ 1785]    Overall Loss 4.946784    Objective Loss 4.946784                                        LR 0.001000    Time 0.050795    
2022-06-16 05:29:11,455 - Epoch: [77][  400/ 1785]    Overall Loss 4.950519    Objective Loss 4.950519                                        LR 0.001000    Time 0.050374    
2022-06-16 05:29:21,722 - Epoch: [77][  600/ 1785]    Overall Loss 4.950556    Objective Loss 4.950556                                        LR 0.001000    Time 0.050690    
2022-06-16 05:29:32,089 - Epoch: [77][  800/ 1785]    Overall Loss 4.957832    Objective Loss 4.957832                                        LR 0.001000    Time 0.050973    
2022-06-16 05:29:42,416 - Epoch: [77][ 1000/ 1785]    Overall Loss 4.959772    Objective Loss 4.959772                                        LR 0.001000    Time 0.051104    
2022-06-16 05:29:52,809 - Epoch: [77][ 1200/ 1785]    Overall Loss 4.962824    Objective Loss 4.962824                                        LR 0.001000    Time 0.051245    
2022-06-16 05:30:03,291 - Epoch: [77][ 1400/ 1785]    Overall Loss 4.966481    Objective Loss 4.966481                                        LR 0.001000    Time 0.051411    
2022-06-16 05:30:13,903 - Epoch: [77][ 1600/ 1785]    Overall Loss 4.965070    Objective Loss 4.965070                                        LR 0.001000    Time 0.051615    
2022-06-16 05:30:23,437 - Epoch: [77][ 1785/ 1785]    Overall Loss 4.966202    Objective Loss 4.966202                                        LR 0.001000    Time 0.051606    
2022-06-16 05:30:23,482 - --- validate (epoch=77)-----------
2022-06-16 05:30:23,482 - 12251 samples (16 per mini-batch)
2022-06-16 05:30:39,726 - Epoch: [77][  200/  766]    Loss 5.041403    mAP 0.904545    
2022-06-16 05:30:55,812 - Epoch: [77][  400/  766]    Loss 5.042373    mAP 0.838068    
2022-06-16 05:31:11,979 - Epoch: [77][  600/  766]    Loss 5.044748    mAP 0.866667    
2022-06-16 05:31:25,350 - Epoch: [77][  766/  766]    Loss 5.048056    mAP 0.766595    
2022-06-16 05:31:25,439 - ==> mAP: 0.76659    Loss: 5.048

2022-06-16 05:31:25,442 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:31:25,442 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:31:25,469 - 

2022-06-16 05:31:25,470 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:31:35,657 - Epoch: [78][  200/ 1785]    Overall Loss 4.944985    Objective Loss 4.944985                                        LR 0.001000    Time 0.050922    
2022-06-16 05:31:45,774 - Epoch: [78][  400/ 1785]    Overall Loss 4.959147    Objective Loss 4.959147                                        LR 0.001000    Time 0.050749    
2022-06-16 05:31:55,949 - Epoch: [78][  600/ 1785]    Overall Loss 4.956910    Objective Loss 4.956910                                        LR 0.001000    Time 0.050787    
2022-06-16 05:32:06,152 - Epoch: [78][  800/ 1785]    Overall Loss 4.960179    Objective Loss 4.960179                                        LR 0.001000    Time 0.050841    
2022-06-16 05:32:16,439 - Epoch: [78][ 1000/ 1785]    Overall Loss 4.959136    Objective Loss 4.959136                                        LR 0.001000    Time 0.050958    
2022-06-16 05:32:26,567 - Epoch: [78][ 1200/ 1785]    Overall Loss 4.963017    Objective Loss 4.963017                                        LR 0.001000    Time 0.050903    
2022-06-16 05:32:36,824 - Epoch: [78][ 1400/ 1785]    Overall Loss 4.962715    Objective Loss 4.962715                                        LR 0.001000    Time 0.050956    
2022-06-16 05:32:46,948 - Epoch: [78][ 1600/ 1785]    Overall Loss 4.965114    Objective Loss 4.965114                                        LR 0.001000    Time 0.050913    
2022-06-16 05:32:56,673 - Epoch: [78][ 1785/ 1785]    Overall Loss 4.967411    Objective Loss 4.967411                                        LR 0.001000    Time 0.051083    
2022-06-16 05:32:56,757 - --- validate (epoch=78)-----------
2022-06-16 05:32:56,757 - 12251 samples (16 per mini-batch)
2022-06-16 05:33:13,087 - Epoch: [78][  200/  766]    Loss 5.021929    mAP 0.773864    
2022-06-16 05:33:29,210 - Epoch: [78][  400/  766]    Loss 5.048280    mAP 0.931818    
2022-06-16 05:33:45,321 - Epoch: [78][  600/  766]    Loss 5.043769    mAP 0.787879    
2022-06-16 05:33:58,670 - Epoch: [78][  766/  766]    Loss 5.041755    mAP 0.939394    
2022-06-16 05:33:58,763 - ==> mAP: 0.93939    Loss: 5.042

2022-06-16 05:33:58,766 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:33:58,766 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:33:58,789 - 

2022-06-16 05:33:58,790 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:34:09,147 - Epoch: [79][  200/ 1785]    Overall Loss 4.949813    Objective Loss 4.949813                                        LR 0.001000    Time 0.051771    
2022-06-16 05:34:19,119 - Epoch: [79][  400/ 1785]    Overall Loss 4.952257    Objective Loss 4.952257                                        LR 0.001000    Time 0.050810    
2022-06-16 05:34:29,053 - Epoch: [79][  600/ 1785]    Overall Loss 4.958757    Objective Loss 4.958757                                        LR 0.001000    Time 0.050428    
2022-06-16 05:34:38,984 - Epoch: [79][  800/ 1785]    Overall Loss 4.961650    Objective Loss 4.961650                                        LR 0.001000    Time 0.050231    
2022-06-16 05:34:48,922 - Epoch: [79][ 1000/ 1785]    Overall Loss 4.962248    Objective Loss 4.962248                                        LR 0.001000    Time 0.050122    
2022-06-16 05:34:58,809 - Epoch: [79][ 1200/ 1785]    Overall Loss 4.967267    Objective Loss 4.967267                                        LR 0.001000    Time 0.050006    
2022-06-16 05:35:08,699 - Epoch: [79][ 1400/ 1785]    Overall Loss 4.966892    Objective Loss 4.966892                                        LR 0.001000    Time 0.049925    
2022-06-16 05:35:18,656 - Epoch: [79][ 1600/ 1785]    Overall Loss 4.967349    Objective Loss 4.967349                                        LR 0.001000    Time 0.049906    
2022-06-16 05:35:27,855 - Epoch: [79][ 1785/ 1785]    Overall Loss 4.968358    Objective Loss 4.968358                                        LR 0.001000    Time 0.049886    
2022-06-16 05:35:27,944 - --- validate (epoch=79)-----------
2022-06-16 05:35:27,944 - 12251 samples (16 per mini-batch)
2022-06-16 05:35:44,262 - Epoch: [79][  200/  766]    Loss 5.032263    mAP 0.767593    
2022-06-16 05:36:00,519 - Epoch: [79][  400/  766]    Loss 5.029189    mAP 0.843434    
2022-06-16 05:36:16,745 - Epoch: [79][  600/  766]    Loss 5.028097    mAP 0.918182    
2022-06-16 05:36:30,156 - Epoch: [79][  766/  766]    Loss 5.032844    mAP 0.818182    
2022-06-16 05:36:30,200 - ==> mAP: 0.81818    Loss: 5.033

2022-06-16 05:36:30,202 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:36:30,202 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:36:30,226 - 

2022-06-16 05:36:30,226 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:36:40,659 - Epoch: [80][  200/ 1785]    Overall Loss 4.941946    Objective Loss 4.941946                                        LR 0.001000    Time 0.052150    
2022-06-16 05:36:50,588 - Epoch: [80][  400/ 1785]    Overall Loss 4.937482    Objective Loss 4.937482                                        LR 0.001000    Time 0.050892    
2022-06-16 05:37:00,536 - Epoch: [80][  600/ 1785]    Overall Loss 4.947280    Objective Loss 4.947280                                        LR 0.001000    Time 0.050506    
2022-06-16 05:37:10,510 - Epoch: [80][  800/ 1785]    Overall Loss 4.953404    Objective Loss 4.953404                                        LR 0.001000    Time 0.050344    
2022-06-16 05:37:20,512 - Epoch: [80][ 1000/ 1785]    Overall Loss 4.954066    Objective Loss 4.954066                                        LR 0.001000    Time 0.050275    
2022-06-16 05:37:30,514 - Epoch: [80][ 1200/ 1785]    Overall Loss 4.961036    Objective Loss 4.961036                                        LR 0.001000    Time 0.050229    
2022-06-16 05:37:40,604 - Epoch: [80][ 1400/ 1785]    Overall Loss 4.961661    Objective Loss 4.961661                                        LR 0.001000    Time 0.050259    
2022-06-16 05:37:50,692 - Epoch: [80][ 1600/ 1785]    Overall Loss 4.966799    Objective Loss 4.966799                                        LR 0.001000    Time 0.050280    
2022-06-16 05:38:00,011 - Epoch: [80][ 1785/ 1785]    Overall Loss 4.967107    Objective Loss 4.967107                                        LR 0.001000    Time 0.050289    
2022-06-16 05:38:00,056 - --- validate (epoch=80)-----------
2022-06-16 05:38:00,056 - 12251 samples (16 per mini-batch)
2022-06-16 05:38:16,455 - Epoch: [80][  200/  766]    Loss 5.042231    mAP 0.858923    
2022-06-16 05:38:32,684 - Epoch: [80][  400/  766]    Loss 5.052281    mAP 0.792208    
2022-06-16 05:38:48,777 - Epoch: [80][  600/  766]    Loss 5.051507    mAP 0.772273    
2022-06-16 05:39:02,282 - Epoch: [80][  766/  766]    Loss 5.047490    mAP 0.800000    
2022-06-16 05:39:02,336 - ==> mAP: 0.80000    Loss: 5.047

2022-06-16 05:39:02,339 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:39:02,339 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:39:02,366 - 

2022-06-16 05:39:02,366 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:39:12,555 - Epoch: [81][  200/ 1785]    Overall Loss 4.942333    Objective Loss 4.942333                                        LR 0.001000    Time 0.050928    
2022-06-16 05:39:22,521 - Epoch: [81][  400/ 1785]    Overall Loss 4.945681    Objective Loss 4.945681                                        LR 0.001000    Time 0.050374    
2022-06-16 05:39:32,551 - Epoch: [81][  600/ 1785]    Overall Loss 4.952878    Objective Loss 4.952878                                        LR 0.001000    Time 0.050297    
2022-06-16 05:39:42,505 - Epoch: [81][  800/ 1785]    Overall Loss 4.952527    Objective Loss 4.952527                                        LR 0.001000    Time 0.050162    
2022-06-16 05:39:52,745 - Epoch: [81][ 1000/ 1785]    Overall Loss 4.955833    Objective Loss 4.955833                                        LR 0.001000    Time 0.050367    
2022-06-16 05:40:03,041 - Epoch: [81][ 1200/ 1785]    Overall Loss 4.960053    Objective Loss 4.960053                                        LR 0.001000    Time 0.050552    
2022-06-16 05:40:13,257 - Epoch: [81][ 1400/ 1785]    Overall Loss 4.960268    Objective Loss 4.960268                                        LR 0.001000    Time 0.050625    
2022-06-16 05:40:23,380 - Epoch: [81][ 1600/ 1785]    Overall Loss 4.963566    Objective Loss 4.963566                                        LR 0.001000    Time 0.050623    
2022-06-16 05:40:32,661 - Epoch: [81][ 1785/ 1785]    Overall Loss 4.966083    Objective Loss 4.966083                                        LR 0.001000    Time 0.050575    
2022-06-16 05:40:32,710 - --- validate (epoch=81)-----------
2022-06-16 05:40:32,711 - 12251 samples (16 per mini-batch)
2022-06-16 05:40:48,955 - Epoch: [81][  200/  766]    Loss 5.047559    mAP 0.845455    
2022-06-16 05:41:05,052 - Epoch: [81][  400/  766]    Loss 5.045729    mAP 0.656566    
2022-06-16 05:41:21,191 - Epoch: [81][  600/  766]    Loss 5.052867    mAP 0.874069    
2022-06-16 05:41:34,527 - Epoch: [81][  766/  766]    Loss 5.047400    mAP 0.597403    
2022-06-16 05:41:34,622 - ==> mAP: 0.59740    Loss: 5.047

2022-06-16 05:41:34,625 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:41:34,625 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:41:34,645 - 

2022-06-16 05:41:34,645 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:41:44,827 - Epoch: [82][  200/ 1785]    Overall Loss 4.943765    Objective Loss 4.943765                                        LR 0.001000    Time 0.050894    
2022-06-16 05:41:54,683 - Epoch: [82][  400/ 1785]    Overall Loss 4.960616    Objective Loss 4.960616                                        LR 0.001000    Time 0.050081    
2022-06-16 05:42:04,564 - Epoch: [82][  600/ 1785]    Overall Loss 4.957128    Objective Loss 4.957128                                        LR 0.001000    Time 0.049854    
2022-06-16 05:42:14,977 - Epoch: [82][  800/ 1785]    Overall Loss 4.960246    Objective Loss 4.960246                                        LR 0.001000    Time 0.050403    
2022-06-16 05:42:25,077 - Epoch: [82][ 1000/ 1785]    Overall Loss 4.961963    Objective Loss 4.961963                                        LR 0.001000    Time 0.050421    
2022-06-16 05:42:35,042 - Epoch: [82][ 1200/ 1785]    Overall Loss 4.965657    Objective Loss 4.965657                                        LR 0.001000    Time 0.050320    
2022-06-16 05:42:45,071 - Epoch: [82][ 1400/ 1785]    Overall Loss 4.967383    Objective Loss 4.967383                                        LR 0.001000    Time 0.050293    
2022-06-16 05:42:55,050 - Epoch: [82][ 1600/ 1785]    Overall Loss 4.967825    Objective Loss 4.967825                                        LR 0.001000    Time 0.050242    
2022-06-16 05:43:04,326 - Epoch: [82][ 1785/ 1785]    Overall Loss 4.967850    Objective Loss 4.967850                                        LR 0.001000    Time 0.050231    
2022-06-16 05:43:04,377 - --- validate (epoch=82)-----------
2022-06-16 05:43:04,377 - 12251 samples (16 per mini-batch)
2022-06-16 05:43:20,703 - Epoch: [82][  200/  766]    Loss 5.029842    mAP 0.781818    
2022-06-16 05:43:36,760 - Epoch: [82][  400/  766]    Loss 5.040635    mAP 0.822727    
2022-06-16 05:43:52,865 - Epoch: [82][  600/  766]    Loss 5.046713    mAP 0.954545    
2022-06-16 05:44:06,300 - Epoch: [82][  766/  766]    Loss 5.046479    mAP 0.727273    
2022-06-16 05:44:06,349 - ==> mAP: 0.72727    Loss: 5.046

2022-06-16 05:44:06,352 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:44:06,352 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:44:06,379 - 

2022-06-16 05:44:06,379 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:44:17,154 - Epoch: [83][  200/ 1785]    Overall Loss 4.944963    Objective Loss 4.944963                                        LR 0.001000    Time 0.053858    
2022-06-16 05:44:27,764 - Epoch: [83][  400/ 1785]    Overall Loss 4.955053    Objective Loss 4.955053                                        LR 0.001000    Time 0.053448    
2022-06-16 05:44:37,884 - Epoch: [83][  600/ 1785]    Overall Loss 4.959761    Objective Loss 4.959761                                        LR 0.001000    Time 0.052496    
2022-06-16 05:44:48,531 - Epoch: [83][  800/ 1785]    Overall Loss 4.963151    Objective Loss 4.963151                                        LR 0.001000    Time 0.052677    
2022-06-16 05:44:59,165 - Epoch: [83][ 1000/ 1785]    Overall Loss 4.960773    Objective Loss 4.960773                                        LR 0.001000    Time 0.052774    
2022-06-16 05:45:09,668 - Epoch: [83][ 1200/ 1785]    Overall Loss 4.960021    Objective Loss 4.960021                                        LR 0.001000    Time 0.052729    
2022-06-16 05:45:19,741 - Epoch: [83][ 1400/ 1785]    Overall Loss 4.960911    Objective Loss 4.960911                                        LR 0.001000    Time 0.052390    
2022-06-16 05:45:29,831 - Epoch: [83][ 1600/ 1785]    Overall Loss 4.963969    Objective Loss 4.963969                                        LR 0.001000    Time 0.052146    
2022-06-16 05:45:39,153 - Epoch: [83][ 1785/ 1785]    Overall Loss 4.963893    Objective Loss 4.963893                                        LR 0.001000    Time 0.051963    
2022-06-16 05:45:39,200 - --- validate (epoch=83)-----------
2022-06-16 05:45:39,200 - 12251 samples (16 per mini-batch)
2022-06-16 05:45:55,523 - Epoch: [83][  200/  766]    Loss 5.048175    mAP 0.963636    
2022-06-16 05:46:11,764 - Epoch: [83][  400/  766]    Loss 5.045154    mAP 0.809091    
2022-06-16 05:46:28,179 - Epoch: [83][  600/  766]    Loss 5.052064    mAP 0.740909    
2022-06-16 05:46:41,648 - Epoch: [83][  766/  766]    Loss 5.055099    mAP 0.858586    
2022-06-16 05:46:41,703 - ==> mAP: 0.85859    Loss: 5.055

2022-06-16 05:46:41,705 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:46:41,705 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:46:41,721 - 

2022-06-16 05:46:41,722 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:46:51,851 - Epoch: [84][  200/ 1785]    Overall Loss 4.948418    Objective Loss 4.948418                                        LR 0.001000    Time 0.050631    
2022-06-16 05:47:01,784 - Epoch: [84][  400/ 1785]    Overall Loss 4.953596    Objective Loss 4.953596                                        LR 0.001000    Time 0.050144    
2022-06-16 05:47:11,823 - Epoch: [84][  600/ 1785]    Overall Loss 4.951497    Objective Loss 4.951497                                        LR 0.001000    Time 0.050158    
2022-06-16 05:47:21,883 - Epoch: [84][  800/ 1785]    Overall Loss 4.956451    Objective Loss 4.956451                                        LR 0.001000    Time 0.050191    
2022-06-16 05:47:31,953 - Epoch: [84][ 1000/ 1785]    Overall Loss 4.956533    Objective Loss 4.956533                                        LR 0.001000    Time 0.050221    
2022-06-16 05:47:42,043 - Epoch: [84][ 1200/ 1785]    Overall Loss 4.962902    Objective Loss 4.962902                                        LR 0.001000    Time 0.050257    
2022-06-16 05:47:52,088 - Epoch: [84][ 1400/ 1785]    Overall Loss 4.964426    Objective Loss 4.964426                                        LR 0.001000    Time 0.050252    
2022-06-16 05:48:02,225 - Epoch: [84][ 1600/ 1785]    Overall Loss 4.963847    Objective Loss 4.963847                                        LR 0.001000    Time 0.050304    
2022-06-16 05:48:11,512 - Epoch: [84][ 1785/ 1785]    Overall Loss 4.966246    Objective Loss 4.966246                                        LR 0.001000    Time 0.050293    
2022-06-16 05:48:11,559 - --- validate (epoch=84)-----------
2022-06-16 05:48:11,559 - 12251 samples (16 per mini-batch)
2022-06-16 05:48:27,935 - Epoch: [84][  200/  766]    Loss 5.023248    mAP 0.884848    
2022-06-16 05:48:44,232 - Epoch: [84][  400/  766]    Loss 5.030664    mAP 0.871591    
2022-06-16 05:49:00,535 - Epoch: [84][  600/  766]    Loss 5.033976    mAP 0.810101    
2022-06-16 05:49:13,960 - Epoch: [84][  766/  766]    Loss 5.033301    mAP 0.978182    
2022-06-16 05:49:14,023 - ==> mAP: 0.97818    Loss: 5.033

2022-06-16 05:49:14,026 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:49:14,026 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:49:14,049 - 

2022-06-16 05:49:14,049 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:49:24,598 - Epoch: [85][  200/ 1785]    Overall Loss 4.940251    Objective Loss 4.940251                                        LR 0.001000    Time 0.052727    
2022-06-16 05:49:35,054 - Epoch: [85][  400/ 1785]    Overall Loss 4.941755    Objective Loss 4.941755                                        LR 0.001000    Time 0.052499    
2022-06-16 05:49:45,072 - Epoch: [85][  600/ 1785]    Overall Loss 4.950418    Objective Loss 4.950418                                        LR 0.001000    Time 0.051693    
2022-06-16 05:49:55,265 - Epoch: [85][  800/ 1785]    Overall Loss 4.957653    Objective Loss 4.957653                                        LR 0.001000    Time 0.051509    
2022-06-16 05:50:05,693 - Epoch: [85][ 1000/ 1785]    Overall Loss 4.956488    Objective Loss 4.956488                                        LR 0.001000    Time 0.051633    
2022-06-16 05:50:16,047 - Epoch: [85][ 1200/ 1785]    Overall Loss 4.956033    Objective Loss 4.956033                                        LR 0.001000    Time 0.051654    
2022-06-16 05:50:26,000 - Epoch: [85][ 1400/ 1785]    Overall Loss 4.958958    Objective Loss 4.958958                                        LR 0.001000    Time 0.051383    
2022-06-16 05:50:35,964 - Epoch: [85][ 1600/ 1785]    Overall Loss 4.961822    Objective Loss 4.961822                                        LR 0.001000    Time 0.051186    
2022-06-16 05:50:45,152 - Epoch: [85][ 1785/ 1785]    Overall Loss 4.965244    Objective Loss 4.965244                                        LR 0.001000    Time 0.051028    
2022-06-16 05:50:45,195 - --- validate (epoch=85)-----------
2022-06-16 05:50:45,195 - 12251 samples (16 per mini-batch)
2022-06-16 05:51:01,456 - Epoch: [85][  200/  766]    Loss 5.027281    mAP 0.838384    
2022-06-16 05:51:17,627 - Epoch: [85][  400/  766]    Loss 5.024010    mAP 0.845455    
2022-06-16 05:51:33,822 - Epoch: [85][  600/  766]    Loss 5.015041    mAP 0.828283    
2022-06-16 05:51:47,199 - Epoch: [85][  766/  766]    Loss 5.018054    mAP 0.689394    
2022-06-16 05:51:47,242 - ==> mAP: 0.68939    Loss: 5.018

2022-06-16 05:51:47,244 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:51:47,245 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:51:47,272 - 

2022-06-16 05:51:47,272 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:51:57,421 - Epoch: [86][  200/ 1785]    Overall Loss 4.944190    Objective Loss 4.944190                                        LR 0.001000    Time 0.050731    
2022-06-16 05:52:07,411 - Epoch: [86][  400/ 1785]    Overall Loss 4.946714    Objective Loss 4.946714                                        LR 0.001000    Time 0.050335    
2022-06-16 05:52:17,390 - Epoch: [86][  600/ 1785]    Overall Loss 4.948860    Objective Loss 4.948860                                        LR 0.001000    Time 0.050184    
2022-06-16 05:52:27,390 - Epoch: [86][  800/ 1785]    Overall Loss 4.951925    Objective Loss 4.951925                                        LR 0.001000    Time 0.050137    
2022-06-16 05:52:37,401 - Epoch: [86][ 1000/ 1785]    Overall Loss 4.954748    Objective Loss 4.954748                                        LR 0.001000    Time 0.050118    
2022-06-16 05:52:47,412 - Epoch: [86][ 1200/ 1785]    Overall Loss 4.958968    Objective Loss 4.958968                                        LR 0.001000    Time 0.050106    
2022-06-16 05:52:57,442 - Epoch: [86][ 1400/ 1785]    Overall Loss 4.963194    Objective Loss 4.963194                                        LR 0.001000    Time 0.050111    
2022-06-16 05:53:07,519 - Epoch: [86][ 1600/ 1785]    Overall Loss 4.966296    Objective Loss 4.966296                                        LR 0.001000    Time 0.050144    
2022-06-16 05:53:16,797 - Epoch: [86][ 1785/ 1785]    Overall Loss 4.965772    Objective Loss 4.965772                                        LR 0.001000    Time 0.050144    
2022-06-16 05:53:16,870 - --- validate (epoch=86)-----------
2022-06-16 05:53:16,870 - 12251 samples (16 per mini-batch)
2022-06-16 05:53:33,179 - Epoch: [86][  200/  766]    Loss 5.022043    mAP 0.817172    
2022-06-16 05:53:49,361 - Epoch: [86][  400/  766]    Loss 5.029083    mAP 0.856061    
2022-06-16 05:54:05,589 - Epoch: [86][  600/  766]    Loss 5.031910    mAP 0.846801    
2022-06-16 05:54:19,012 - Epoch: [86][  766/  766]    Loss 5.031541    mAP 0.715909    
2022-06-16 05:54:19,095 - ==> mAP: 0.71591    Loss: 5.032

2022-06-16 05:54:19,098 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:54:19,098 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:54:19,125 - 

2022-06-16 05:54:19,125 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:54:29,852 - Epoch: [87][  200/ 1785]    Overall Loss 4.950753    Objective Loss 4.950753                                        LR 0.001000    Time 0.053622    
2022-06-16 05:54:40,125 - Epoch: [87][  400/ 1785]    Overall Loss 4.945351    Objective Loss 4.945351                                        LR 0.001000    Time 0.052489    
2022-06-16 05:54:50,375 - Epoch: [87][  600/ 1785]    Overall Loss 4.950843    Objective Loss 4.950843                                        LR 0.001000    Time 0.052072    
2022-06-16 05:55:00,438 - Epoch: [87][  800/ 1785]    Overall Loss 4.951335    Objective Loss 4.951335                                        LR 0.001000    Time 0.051630    
2022-06-16 05:55:10,536 - Epoch: [87][ 1000/ 1785]    Overall Loss 4.955023    Objective Loss 4.955023                                        LR 0.001000    Time 0.051401    
2022-06-16 05:55:20,528 - Epoch: [87][ 1200/ 1785]    Overall Loss 4.958056    Objective Loss 4.958056                                        LR 0.001000    Time 0.051159    
2022-06-16 05:55:30,499 - Epoch: [87][ 1400/ 1785]    Overall Loss 4.959990    Objective Loss 4.959990                                        LR 0.001000    Time 0.050971    
2022-06-16 05:55:40,522 - Epoch: [87][ 1600/ 1785]    Overall Loss 4.962531    Objective Loss 4.962531                                        LR 0.001000    Time 0.050863    
2022-06-16 05:55:49,793 - Epoch: [87][ 1785/ 1785]    Overall Loss 4.964429    Objective Loss 4.964429                                        LR 0.001000    Time 0.050784    
2022-06-16 05:55:49,840 - --- validate (epoch=87)-----------
2022-06-16 05:55:49,840 - 12251 samples (16 per mini-batch)
2022-06-16 05:56:06,178 - Epoch: [87][  200/  766]    Loss 5.036524    mAP 0.908182    
2022-06-16 05:56:22,314 - Epoch: [87][  400/  766]    Loss 5.020030    mAP 0.798822    
2022-06-16 05:56:38,441 - Epoch: [87][  600/  766]    Loss 5.026316    mAP 0.756453    
2022-06-16 05:56:51,843 - Epoch: [87][  766/  766]    Loss 5.028421    mAP 0.848485    
2022-06-16 05:56:51,912 - ==> mAP: 0.84848    Loss: 5.028

2022-06-16 05:56:51,915 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:56:51,915 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:56:51,939 - 

2022-06-16 05:56:51,939 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:57:02,059 - Epoch: [88][  200/ 1785]    Overall Loss 4.937303    Objective Loss 4.937303                                        LR 0.001000    Time 0.050586    
2022-06-16 05:57:12,088 - Epoch: [88][  400/ 1785]    Overall Loss 4.957522    Objective Loss 4.957522                                        LR 0.001000    Time 0.050361    
2022-06-16 05:57:22,129 - Epoch: [88][  600/ 1785]    Overall Loss 4.963600    Objective Loss 4.963600                                        LR 0.001000    Time 0.050305    
2022-06-16 05:57:32,213 - Epoch: [88][  800/ 1785]    Overall Loss 4.958879    Objective Loss 4.958879                                        LR 0.001000    Time 0.050331    
2022-06-16 05:57:42,300 - Epoch: [88][ 1000/ 1785]    Overall Loss 4.963144    Objective Loss 4.963144                                        LR 0.001000    Time 0.050350    
2022-06-16 05:57:52,287 - Epoch: [88][ 1200/ 1785]    Overall Loss 4.964480    Objective Loss 4.964480                                        LR 0.001000    Time 0.050279    
2022-06-16 05:58:02,267 - Epoch: [88][ 1400/ 1785]    Overall Loss 4.964589    Objective Loss 4.964589                                        LR 0.001000    Time 0.050224    
2022-06-16 05:58:12,222 - Epoch: [88][ 1600/ 1785]    Overall Loss 4.966164    Objective Loss 4.966164                                        LR 0.001000    Time 0.050167    
2022-06-16 05:58:21,430 - Epoch: [88][ 1785/ 1785]    Overall Loss 4.966131    Objective Loss 4.966131                                        LR 0.001000    Time 0.050125    
2022-06-16 05:58:21,480 - --- validate (epoch=88)-----------
2022-06-16 05:58:21,480 - 12251 samples (16 per mini-batch)
2022-06-16 05:58:37,668 - Epoch: [88][  200/  766]    Loss 5.025993    mAP 0.704545    
2022-06-16 05:58:53,893 - Epoch: [88][  400/  766]    Loss 5.034871    mAP 0.888889    
2022-06-16 05:59:10,274 - Epoch: [88][  600/  766]    Loss 5.040367    mAP 0.818182    
2022-06-16 05:59:23,845 - Epoch: [88][  766/  766]    Loss 5.040759    mAP 0.917749    
2022-06-16 05:59:23,887 - ==> mAP: 0.91775    Loss: 5.041

2022-06-16 05:59:23,890 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 05:59:23,890 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 05:59:23,911 - 

2022-06-16 05:59:23,912 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 05:59:34,204 - Epoch: [89][  200/ 1785]    Overall Loss 4.949561    Objective Loss 4.949561                                        LR 0.001000    Time 0.051449    
2022-06-16 05:59:44,178 - Epoch: [89][  400/ 1785]    Overall Loss 4.957312    Objective Loss 4.957312                                        LR 0.001000    Time 0.050655    
2022-06-16 05:59:54,220 - Epoch: [89][  600/ 1785]    Overall Loss 4.955743    Objective Loss 4.955743                                        LR 0.001000    Time 0.050503    
2022-06-16 06:00:04,320 - Epoch: [89][  800/ 1785]    Overall Loss 4.959170    Objective Loss 4.959170                                        LR 0.001000    Time 0.050500    
2022-06-16 06:00:14,805 - Epoch: [89][ 1000/ 1785]    Overall Loss 4.961417    Objective Loss 4.961417                                        LR 0.001000    Time 0.050882    
2022-06-16 06:00:25,260 - Epoch: [89][ 1200/ 1785]    Overall Loss 4.961742    Objective Loss 4.961742                                        LR 0.001000    Time 0.051113    
2022-06-16 06:00:35,582 - Epoch: [89][ 1400/ 1785]    Overall Loss 4.961484    Objective Loss 4.961484                                        LR 0.001000    Time 0.051182    
2022-06-16 06:00:46,243 - Epoch: [89][ 1600/ 1785]    Overall Loss 4.962889    Objective Loss 4.962889                                        LR 0.001000    Time 0.051447    
2022-06-16 06:00:55,794 - Epoch: [89][ 1785/ 1785]    Overall Loss 4.963194    Objective Loss 4.963194                                        LR 0.001000    Time 0.051464    
2022-06-16 06:00:55,838 - --- validate (epoch=89)-----------
2022-06-16 06:00:55,839 - 12251 samples (16 per mini-batch)
2022-06-16 06:01:12,124 - Epoch: [89][  200/  766]    Loss 5.056374    mAP 0.981818    
2022-06-16 06:01:28,334 - Epoch: [89][  400/  766]    Loss 5.048285    mAP 0.863636    
2022-06-16 06:01:44,474 - Epoch: [89][  600/  766]    Loss 5.056046    mAP 0.707071    
2022-06-16 06:01:57,846 - Epoch: [89][  766/  766]    Loss 5.053083    mAP 0.954545    
2022-06-16 06:01:57,904 - ==> mAP: 0.95455    Loss: 5.053

2022-06-16 06:01:57,906 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 06:01:57,906 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 06:01:57,924 - 

2022-06-16 06:01:57,924 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 06:02:08,471 - Epoch: [90][  200/ 1785]    Overall Loss 4.952737    Objective Loss 4.952737                                        LR 0.001000    Time 0.052723    
2022-06-16 06:02:18,473 - Epoch: [90][  400/ 1785]    Overall Loss 4.958286    Objective Loss 4.958286                                        LR 0.001000    Time 0.051361    
2022-06-16 06:02:28,485 - Epoch: [90][  600/ 1785]    Overall Loss 4.954607    Objective Loss 4.954607                                        LR 0.001000    Time 0.050925    
2022-06-16 06:02:38,504 - Epoch: [90][  800/ 1785]    Overall Loss 4.955519    Objective Loss 4.955519                                        LR 0.001000    Time 0.050715    
2022-06-16 06:02:48,602 - Epoch: [90][ 1000/ 1785]    Overall Loss 4.957491    Objective Loss 4.957491                                        LR 0.001000    Time 0.050667    
2022-06-16 06:02:59,000 - Epoch: [90][ 1200/ 1785]    Overall Loss 4.958332    Objective Loss 4.958332                                        LR 0.001000    Time 0.050886    
2022-06-16 06:03:09,399 - Epoch: [90][ 1400/ 1785]    Overall Loss 4.960164    Objective Loss 4.960164                                        LR 0.001000    Time 0.051044    
2022-06-16 06:03:19,779 - Epoch: [90][ 1600/ 1785]    Overall Loss 4.962448    Objective Loss 4.962448                                        LR 0.001000    Time 0.051150    
2022-06-16 06:03:29,296 - Epoch: [90][ 1785/ 1785]    Overall Loss 4.963820    Objective Loss 4.963820                                        LR 0.001000    Time 0.051179    
2022-06-16 06:03:29,335 - --- validate (epoch=90)-----------
2022-06-16 06:03:29,335 - 12251 samples (16 per mini-batch)
2022-06-16 06:03:45,622 - Epoch: [90][  200/  766]    Loss 5.026625    mAP 0.636364    
2022-06-16 06:04:01,801 - Epoch: [90][  400/  766]    Loss 5.029171    mAP 0.858586    
2022-06-16 06:04:18,040 - Epoch: [90][  600/  766]    Loss 5.028915    mAP 0.896212    
2022-06-16 06:04:31,485 - Epoch: [90][  766/  766]    Loss 5.026419    mAP 0.878788    
2022-06-16 06:04:31,545 - ==> mAP: 0.87879    Loss: 5.026

2022-06-16 06:04:31,547 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 06:04:31,548 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 06:04:31,565 - 

2022-06-16 06:04:31,565 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 06:04:42,133 - Epoch: [91][  200/ 1785]    Overall Loss 4.936232    Objective Loss 4.936232                                        LR 0.001000    Time 0.052826    
2022-06-16 06:04:52,411 - Epoch: [91][  400/ 1785]    Overall Loss 4.941252    Objective Loss 4.941252                                        LR 0.001000    Time 0.052104    
2022-06-16 06:05:02,381 - Epoch: [91][  600/ 1785]    Overall Loss 4.945569    Objective Loss 4.945569                                        LR 0.001000    Time 0.051349    
2022-06-16 06:05:12,420 - Epoch: [91][  800/ 1785]    Overall Loss 4.948072    Objective Loss 4.948072                                        LR 0.001000    Time 0.051057    
2022-06-16 06:05:22,721 - Epoch: [91][ 1000/ 1785]    Overall Loss 4.948222    Objective Loss 4.948222                                        LR 0.001000    Time 0.051145    
2022-06-16 06:05:33,098 - Epoch: [91][ 1200/ 1785]    Overall Loss 4.952598    Objective Loss 4.952598                                        LR 0.001000    Time 0.051267    
2022-06-16 06:05:43,381 - Epoch: [91][ 1400/ 1785]    Overall Loss 4.955156    Objective Loss 4.955156                                        LR 0.001000    Time 0.051286    
2022-06-16 06:05:53,528 - Epoch: [91][ 1600/ 1785]    Overall Loss 4.961344    Objective Loss 4.961344                                        LR 0.001000    Time 0.051216    
2022-06-16 06:06:03,077 - Epoch: [91][ 1785/ 1785]    Overall Loss 4.963494    Objective Loss 4.963494                                        LR 0.001000    Time 0.051257    
2022-06-16 06:06:03,158 - --- validate (epoch=91)-----------
2022-06-16 06:06:03,159 - 12251 samples (16 per mini-batch)
2022-06-16 06:06:19,314 - Epoch: [91][  200/  766]    Loss 5.033440    mAP 0.905455    
2022-06-16 06:06:35,420 - Epoch: [91][  400/  766]    Loss 5.038493    mAP 0.703030    
2022-06-16 06:06:51,578 - Epoch: [91][  600/  766]    Loss 5.034411    mAP 0.838384    
2022-06-16 06:07:04,851 - Epoch: [91][  766/  766]    Loss 5.037542    mAP 0.557576    
2022-06-16 06:07:04,896 - ==> mAP: 0.55758    Loss: 5.038

2022-06-16 06:07:04,899 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 06:07:04,899 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 06:07:04,923 - 

2022-06-16 06:07:04,923 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 06:07:15,252 - Epoch: [92][  200/ 1785]    Overall Loss 4.935597    Objective Loss 4.935597                                        LR 0.001000    Time 0.051631    
2022-06-16 06:07:25,144 - Epoch: [92][  400/ 1785]    Overall Loss 4.936955    Objective Loss 4.936955                                        LR 0.001000    Time 0.050540    
2022-06-16 06:07:35,404 - Epoch: [92][  600/ 1785]    Overall Loss 4.943235    Objective Loss 4.943235                                        LR 0.001000    Time 0.050790    
2022-06-16 06:07:45,344 - Epoch: [92][  800/ 1785]    Overall Loss 4.946899    Objective Loss 4.946899                                        LR 0.001000    Time 0.050515    
2022-06-16 06:07:55,325 - Epoch: [92][ 1000/ 1785]    Overall Loss 4.954730    Objective Loss 4.954730                                        LR 0.001000    Time 0.050392    
2022-06-16 06:08:05,281 - Epoch: [92][ 1200/ 1785]    Overall Loss 4.958431    Objective Loss 4.958431                                        LR 0.001000    Time 0.050288    
2022-06-16 06:08:15,252 - Epoch: [92][ 1400/ 1785]    Overall Loss 4.958154    Objective Loss 4.958154                                        LR 0.001000    Time 0.050225    
2022-06-16 06:08:25,785 - Epoch: [92][ 1600/ 1785]    Overall Loss 4.961787    Objective Loss 4.961787                                        LR 0.001000    Time 0.050528    
2022-06-16 06:08:35,061 - Epoch: [92][ 1785/ 1785]    Overall Loss 4.962332    Objective Loss 4.962332                                        LR 0.001000    Time 0.050487    
2022-06-16 06:08:35,104 - --- validate (epoch=92)-----------
2022-06-16 06:08:35,105 - 12251 samples (16 per mini-batch)
2022-06-16 06:08:51,179 - Epoch: [92][  200/  766]    Loss 5.063121    mAP 0.878788    
2022-06-16 06:09:07,181 - Epoch: [92][  400/  766]    Loss 5.052260    mAP 0.837576    
2022-06-16 06:09:23,214 - Epoch: [92][  600/  766]    Loss 5.042668    mAP 0.718939    
2022-06-16 06:09:36,466 - Epoch: [92][  766/  766]    Loss 5.034686    mAP 0.670455    
2022-06-16 06:09:36,554 - ==> mAP: 0.67045    Loss: 5.035

2022-06-16 06:09:36,556 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 06:09:36,557 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 06:09:36,580 - 

2022-06-16 06:09:36,580 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 06:09:47,215 - Epoch: [93][  200/ 1785]    Overall Loss 4.928841    Objective Loss 4.928841                                        LR 0.001000    Time 0.053160    
2022-06-16 06:09:57,624 - Epoch: [93][  400/ 1785]    Overall Loss 4.942329    Objective Loss 4.942329                                        LR 0.001000    Time 0.052597    
2022-06-16 06:10:08,093 - Epoch: [93][  600/ 1785]    Overall Loss 4.949823    Objective Loss 4.949823                                        LR 0.001000    Time 0.052511    
2022-06-16 06:10:18,549 - Epoch: [93][  800/ 1785]    Overall Loss 4.952813    Objective Loss 4.952813                                        LR 0.001000    Time 0.052450    
2022-06-16 06:10:29,030 - Epoch: [93][ 1000/ 1785]    Overall Loss 4.957759    Objective Loss 4.957759                                        LR 0.001000    Time 0.052440    
2022-06-16 06:10:39,049 - Epoch: [93][ 1200/ 1785]    Overall Loss 4.955051    Objective Loss 4.955051                                        LR 0.001000    Time 0.052047    
2022-06-16 06:10:48,989 - Epoch: [93][ 1400/ 1785]    Overall Loss 4.957644    Objective Loss 4.957644                                        LR 0.001000    Time 0.051710    
2022-06-16 06:10:58,950 - Epoch: [93][ 1600/ 1785]    Overall Loss 4.958991    Objective Loss 4.958991                                        LR 0.001000    Time 0.051471    
2022-06-16 06:11:08,195 - Epoch: [93][ 1785/ 1785]    Overall Loss 4.960296    Objective Loss 4.960296                                        LR 0.001000    Time 0.051315    
2022-06-16 06:11:08,249 - --- validate (epoch=93)-----------
2022-06-16 06:11:08,250 - 12251 samples (16 per mini-batch)
2022-06-16 06:11:24,434 - Epoch: [93][  200/  766]    Loss 5.071837    mAP 0.837013    
2022-06-16 06:11:40,443 - Epoch: [93][  400/  766]    Loss 5.056180    mAP 0.695623    
2022-06-16 06:11:56,490 - Epoch: [93][  600/  766]    Loss 5.056938    mAP 0.950000    
2022-06-16 06:12:09,743 - Epoch: [93][  766/  766]    Loss 5.061919    mAP 0.484848    
2022-06-16 06:12:09,838 - ==> mAP: 0.48485    Loss: 5.062

2022-06-16 06:12:09,841 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 06:12:09,841 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 06:12:09,866 - 

2022-06-16 06:12:09,867 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 06:12:20,480 - Epoch: [94][  200/ 1785]    Overall Loss 4.933131    Objective Loss 4.933131                                        LR 0.001000    Time 0.053051    
2022-06-16 06:12:30,970 - Epoch: [94][  400/ 1785]    Overall Loss 4.943753    Objective Loss 4.943753                                        LR 0.001000    Time 0.052747    
2022-06-16 06:12:40,954 - Epoch: [94][  600/ 1785]    Overall Loss 4.951848    Objective Loss 4.951848                                        LR 0.001000    Time 0.051801    
2022-06-16 06:12:51,003 - Epoch: [94][  800/ 1785]    Overall Loss 4.953324    Objective Loss 4.953324                                        LR 0.001000    Time 0.051410    
2022-06-16 06:13:01,081 - Epoch: [94][ 1000/ 1785]    Overall Loss 4.958917    Objective Loss 4.958917                                        LR 0.001000    Time 0.051204    
2022-06-16 06:13:11,117 - Epoch: [94][ 1200/ 1785]    Overall Loss 4.961050    Objective Loss 4.961050                                        LR 0.001000    Time 0.051032    
2022-06-16 06:13:21,174 - Epoch: [94][ 1400/ 1785]    Overall Loss 4.961917    Objective Loss 4.961917                                        LR 0.001000    Time 0.050923    
2022-06-16 06:13:31,254 - Epoch: [94][ 1600/ 1785]    Overall Loss 4.962423    Objective Loss 4.962423                                        LR 0.001000    Time 0.050857    
2022-06-16 06:13:40,544 - Epoch: [94][ 1785/ 1785]    Overall Loss 4.962047    Objective Loss 4.962047                                        LR 0.001000    Time 0.050789    
2022-06-16 06:13:40,603 - --- validate (epoch=94)-----------
2022-06-16 06:13:40,603 - 12251 samples (16 per mini-batch)
2022-06-16 06:13:56,718 - Epoch: [94][  200/  766]    Loss 5.046775    mAP 0.918182    
2022-06-16 06:14:12,754 - Epoch: [94][  400/  766]    Loss 5.053844    mAP 0.883636    
2022-06-16 06:14:28,763 - Epoch: [94][  600/  766]    Loss 5.052135    mAP 0.823232    
2022-06-16 06:14:42,079 - Epoch: [94][  766/  766]    Loss 5.054692    mAP 0.729545    
2022-06-16 06:14:42,131 - ==> mAP: 0.72955    Loss: 5.055

2022-06-16 06:14:42,134 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 06:14:42,134 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 06:14:42,161 - 

2022-06-16 06:14:42,161 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 06:14:52,915 - Epoch: [95][  200/ 1785]    Overall Loss 4.944266    Objective Loss 4.944266                                        LR 0.001000    Time 0.053758    
2022-06-16 06:15:03,178 - Epoch: [95][  400/ 1785]    Overall Loss 4.953856    Objective Loss 4.953856                                        LR 0.001000    Time 0.052530    
2022-06-16 06:15:13,282 - Epoch: [95][  600/ 1785]    Overall Loss 4.949568    Objective Loss 4.949568                                        LR 0.001000    Time 0.051857    
2022-06-16 06:15:23,734 - Epoch: [95][  800/ 1785]    Overall Loss 4.952536    Objective Loss 4.952536                                        LR 0.001000    Time 0.051955    
2022-06-16 06:15:34,243 - Epoch: [95][ 1000/ 1785]    Overall Loss 4.953678    Objective Loss 4.953678                                        LR 0.001000    Time 0.052072    
2022-06-16 06:15:44,759 - Epoch: [95][ 1200/ 1785]    Overall Loss 4.959519    Objective Loss 4.959519                                        LR 0.001000    Time 0.052154    
2022-06-16 06:15:55,003 - Epoch: [95][ 1400/ 1785]    Overall Loss 4.960759    Objective Loss 4.960759                                        LR 0.001000    Time 0.052020    
2022-06-16 06:16:05,298 - Epoch: [95][ 1600/ 1785]    Overall Loss 4.962119    Objective Loss 4.962119                                        LR 0.001000    Time 0.051951    
2022-06-16 06:16:14,474 - Epoch: [95][ 1785/ 1785]    Overall Loss 4.963075    Objective Loss 4.963075                                        LR 0.001000    Time 0.051706    
2022-06-16 06:16:14,534 - --- validate (epoch=95)-----------
2022-06-16 06:16:14,534 - 12251 samples (16 per mini-batch)
2022-06-16 06:16:30,694 - Epoch: [95][  200/  766]    Loss 5.039309    mAP 0.747475    
2022-06-16 06:16:46,700 - Epoch: [95][  400/  766]    Loss 5.042856    mAP 0.727273    
2022-06-16 06:17:02,791 - Epoch: [95][  600/  766]    Loss 5.040587    mAP 0.963524    
2022-06-16 06:17:16,228 - Epoch: [95][  766/  766]    Loss 5.045872    mAP 0.803977    
2022-06-16 06:17:16,273 - ==> mAP: 0.80398    Loss: 5.046

2022-06-16 06:17:16,275 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 06:17:16,275 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 06:17:16,299 - 

2022-06-16 06:17:16,299 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 06:17:26,364 - Epoch: [96][  200/ 1785]    Overall Loss 4.957289    Objective Loss 4.957289                                        LR 0.001000    Time 0.050313    
2022-06-16 06:17:36,810 - Epoch: [96][  400/ 1785]    Overall Loss 4.956116    Objective Loss 4.956116                                        LR 0.001000    Time 0.051265    
2022-06-16 06:17:47,279 - Epoch: [96][  600/ 1785]    Overall Loss 4.952917    Objective Loss 4.952917                                        LR 0.001000    Time 0.051622    
2022-06-16 06:17:57,270 - Epoch: [96][  800/ 1785]    Overall Loss 4.958855    Objective Loss 4.958855                                        LR 0.001000    Time 0.051203    
2022-06-16 06:18:07,281 - Epoch: [96][ 1000/ 1785]    Overall Loss 4.958756    Objective Loss 4.958756                                        LR 0.001000    Time 0.050971    
2022-06-16 06:18:17,435 - Epoch: [96][ 1200/ 1785]    Overall Loss 4.956347    Objective Loss 4.956347                                        LR 0.001000    Time 0.050936    
2022-06-16 06:18:27,627 - Epoch: [96][ 1400/ 1785]    Overall Loss 4.957605    Objective Loss 4.957605                                        LR 0.001000    Time 0.050938    
2022-06-16 06:18:37,817 - Epoch: [96][ 1600/ 1785]    Overall Loss 4.960525    Objective Loss 4.960525                                        LR 0.001000    Time 0.050938    
2022-06-16 06:18:47,122 - Epoch: [96][ 1785/ 1785]    Overall Loss 4.963797    Objective Loss 4.963797                                        LR 0.001000    Time 0.050871    
2022-06-16 06:18:47,169 - --- validate (epoch=96)-----------
2022-06-16 06:18:47,169 - 12251 samples (16 per mini-batch)
2022-06-16 06:19:03,472 - Epoch: [96][  200/  766]    Loss 5.055471    mAP 0.845118    
2022-06-16 06:19:19,580 - Epoch: [96][  400/  766]    Loss 5.056708    mAP 0.881313    
2022-06-16 06:19:35,746 - Epoch: [96][  600/  766]    Loss 5.049683    mAP 0.927273    
2022-06-16 06:19:49,102 - Epoch: [96][  766/  766]    Loss 5.048492    mAP 0.627273    
2022-06-16 06:19:49,194 - ==> mAP: 0.62727    Loss: 5.048

2022-06-16 06:19:49,196 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 06:19:49,196 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 06:19:49,220 - 

2022-06-16 06:19:49,220 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 06:19:59,249 - Epoch: [97][  200/ 1785]    Overall Loss 4.931326    Objective Loss 4.931326                                        LR 0.001000    Time 0.050131    
2022-06-16 06:20:09,140 - Epoch: [97][  400/ 1785]    Overall Loss 4.942058    Objective Loss 4.942058                                        LR 0.001000    Time 0.049788    
2022-06-16 06:20:19,461 - Epoch: [97][  600/ 1785]    Overall Loss 4.944487    Objective Loss 4.944487                                        LR 0.001000    Time 0.050390    
2022-06-16 06:20:29,805 - Epoch: [97][  800/ 1785]    Overall Loss 4.950163    Objective Loss 4.950163                                        LR 0.001000    Time 0.050720    
2022-06-16 06:20:39,835 - Epoch: [97][ 1000/ 1785]    Overall Loss 4.956240    Objective Loss 4.956240                                        LR 0.001000    Time 0.050604    
2022-06-16 06:20:49,794 - Epoch: [97][ 1200/ 1785]    Overall Loss 4.958175    Objective Loss 4.958175                                        LR 0.001000    Time 0.050467    
2022-06-16 06:20:59,793 - Epoch: [97][ 1400/ 1785]    Overall Loss 4.959346    Objective Loss 4.959346                                        LR 0.001000    Time 0.050398    
2022-06-16 06:21:09,878 - Epoch: [97][ 1600/ 1785]    Overall Loss 4.962098    Objective Loss 4.962098                                        LR 0.001000    Time 0.050400    
2022-06-16 06:21:19,465 - Epoch: [97][ 1785/ 1785]    Overall Loss 4.963341    Objective Loss 4.963341                                        LR 0.001000    Time 0.050546    
2022-06-16 06:21:19,510 - --- validate (epoch=97)-----------
2022-06-16 06:21:19,510 - 12251 samples (16 per mini-batch)
2022-06-16 06:21:35,982 - Epoch: [97][  200/  766]    Loss 5.065081    mAP 0.722583    
2022-06-16 06:21:52,040 - Epoch: [97][  400/  766]    Loss 5.056418    mAP 0.723377    
2022-06-16 06:22:08,126 - Epoch: [97][  600/  766]    Loss 5.056558    mAP 0.779461    
2022-06-16 06:22:21,527 - Epoch: [97][  766/  766]    Loss 5.056946    mAP 0.730640    
2022-06-16 06:22:21,573 - ==> mAP: 0.73064    Loss: 5.057

2022-06-16 06:22:21,576 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 06:22:21,576 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 06:22:21,600 - 

2022-06-16 06:22:21,600 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 06:22:31,719 - Epoch: [98][  200/ 1785]    Overall Loss 4.950227    Objective Loss 4.950227                                        LR 0.001000    Time 0.050579    
2022-06-16 06:22:41,740 - Epoch: [98][  400/ 1785]    Overall Loss 4.950737    Objective Loss 4.950737                                        LR 0.001000    Time 0.050338    
2022-06-16 06:22:51,746 - Epoch: [98][  600/ 1785]    Overall Loss 4.953138    Objective Loss 4.953138                                        LR 0.001000    Time 0.050231    
2022-06-16 06:23:01,780 - Epoch: [98][  800/ 1785]    Overall Loss 4.952367    Objective Loss 4.952367                                        LR 0.001000    Time 0.050214    
2022-06-16 06:23:11,910 - Epoch: [98][ 1000/ 1785]    Overall Loss 4.957682    Objective Loss 4.957682                                        LR 0.001000    Time 0.050300    
2022-06-16 06:23:22,074 - Epoch: [98][ 1200/ 1785]    Overall Loss 4.959802    Objective Loss 4.959802                                        LR 0.001000    Time 0.050385    
2022-06-16 06:23:32,350 - Epoch: [98][ 1400/ 1785]    Overall Loss 4.961448    Objective Loss 4.961448                                        LR 0.001000    Time 0.050525    
2022-06-16 06:23:42,604 - Epoch: [98][ 1600/ 1785]    Overall Loss 4.960976    Objective Loss 4.960976                                        LR 0.001000    Time 0.050617    
2022-06-16 06:23:51,938 - Epoch: [98][ 1785/ 1785]    Overall Loss 4.961363    Objective Loss 4.961363                                        LR 0.001000    Time 0.050600    
2022-06-16 06:23:51,978 - --- validate (epoch=98)-----------
2022-06-16 06:23:51,979 - 12251 samples (16 per mini-batch)
2022-06-16 06:24:08,049 - Epoch: [98][  200/  766]    Loss 5.060584    mAP 0.918831    
2022-06-16 06:24:23,993 - Epoch: [98][  400/  766]    Loss 5.058622    mAP 0.808081    
2022-06-16 06:24:40,195 - Epoch: [98][  600/  766]    Loss 5.055291    mAP 0.814141    
2022-06-16 06:24:53,564 - Epoch: [98][  766/  766]    Loss 5.052450    mAP 0.775758    
2022-06-16 06:24:53,608 - ==> mAP: 0.77576    Loss: 5.052

2022-06-16 06:24:53,611 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 06:24:53,611 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 06:24:53,639 - 

2022-06-16 06:24:53,639 - Training epoch: 28548 samples (16 per mini-batch)
2022-06-16 06:25:04,027 - Epoch: [99][  200/ 1785]    Overall Loss 4.954984    Objective Loss 4.954984                                        LR 0.001000    Time 0.051925    
2022-06-16 06:25:14,178 - Epoch: [99][  400/ 1785]    Overall Loss 4.955917    Objective Loss 4.955917                                        LR 0.001000    Time 0.051336    
2022-06-16 06:25:24,510 - Epoch: [99][  600/ 1785]    Overall Loss 4.959964    Objective Loss 4.959964                                        LR 0.001000    Time 0.051440    
2022-06-16 06:25:34,644 - Epoch: [99][  800/ 1785]    Overall Loss 4.963264    Objective Loss 4.963264                                        LR 0.001000    Time 0.051245    
2022-06-16 06:25:44,660 - Epoch: [99][ 1000/ 1785]    Overall Loss 4.964582    Objective Loss 4.964582                                        LR 0.001000    Time 0.051010    
2022-06-16 06:25:55,038 - Epoch: [99][ 1200/ 1785]    Overall Loss 4.962605    Objective Loss 4.962605                                        LR 0.001000    Time 0.051155    
2022-06-16 06:26:05,423 - Epoch: [99][ 1400/ 1785]    Overall Loss 4.963009    Objective Loss 4.963009                                        LR 0.001000    Time 0.051264    
2022-06-16 06:26:15,647 - Epoch: [99][ 1600/ 1785]    Overall Loss 4.965191    Objective Loss 4.965191                                        LR 0.001000    Time 0.051244    
2022-06-16 06:26:24,984 - Epoch: [99][ 1785/ 1785]    Overall Loss 4.965477    Objective Loss 4.965477                                        LR 0.001000    Time 0.051163    
2022-06-16 06:26:25,028 - --- validate (epoch=99)-----------
2022-06-16 06:26:25,029 - 12251 samples (16 per mini-batch)
2022-06-16 06:26:41,425 - Epoch: [99][  200/  766]    Loss 5.044046    mAP 0.603896    
2022-06-16 06:26:57,637 - Epoch: [99][  400/  766]    Loss 5.054849    mAP 0.903636    
2022-06-16 06:27:14,035 - Epoch: [99][  600/  766]    Loss 5.051956    mAP 0.717460    
2022-06-16 06:27:27,642 - Epoch: [99][  766/  766]    Loss 5.047481    mAP 0.768939    
2022-06-16 06:27:27,698 - ==> mAP: 0.76894    Loss: 5.047

2022-06-16 06:27:27,700 - ==> Best [mAP: 1.000000   vloss: 5.052065   Sparsity:0.29   Params: 334563 on epoch: 57]
2022-06-16 06:27:27,700 - Saving checkpoint to: logs/2022.06.16-021553/qat_checkpoint.pth.tar
2022-06-16 06:27:27,724 - --- test ---------------------
2022-06-16 06:27:27,724 - 12251 samples (16 per mini-batch)
2022-06-16 06:27:44,078 - Test: [  200/  766]    Loss 5.034787    mAP 0.659933    
2022-06-16 06:28:00,253 - Test: [  400/  766]    Loss 5.045569    mAP 0.844697    
2022-06-16 06:28:16,475 - Test: [  600/  766]    Loss 5.046415    mAP 0.545455    
2022-06-16 06:28:29,972 - Test: [  766/  766]    Loss 5.046904    mAP 0.772727    
2022-06-16 06:28:30,040 - ==> mAP: 0.77273    Loss: 5.047

2022-06-16 06:28:30,099 - 
2022-06-16 06:28:30,102 - Log file for this run: /home/ermanokman/repos/github/ai8x-training-detection/logs/2022.06.16-021553/2022.06.16-021553.log
