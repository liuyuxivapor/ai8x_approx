2023-04-26 18:43:48,348 - Log file for this run: /home/seldauyanik/Workspace/ai8x-training/logs/2023.04.26-184348/2023.04.26-184348.log
2023-04-26 18:43:49,930 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2023-04-26 18:43:49,930 - Optimizer Args: {'lr': 0.002, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 1e-06, 'amsgrad': False}
2023-04-26 18:43:49,958 - Dataset sizes:
	training=16551
	validation=4952
	test=4952
2023-04-26 18:43:49,958 - Reading compression schedule from: policies/schedule-pascalvoc.yaml
2023-04-26 18:43:49,963 - 

2023-04-26 18:43:49,963 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 18:44:01,396 - Epoch: [0][   50/  518]    Overall Loss 7.581112    Objective Loss 7.581112                                        LR 0.002000    Time 0.228623    
2023-04-26 18:44:11,478 - Epoch: [0][  100/  518]    Overall Loss 6.786543    Objective Loss 6.786543                                        LR 0.002000    Time 0.215111    
2023-04-26 18:44:21,551 - Epoch: [0][  150/  518]    Overall Loss 6.485756    Objective Loss 6.485756                                        LR 0.002000    Time 0.210545    
2023-04-26 18:44:31,671 - Epoch: [0][  200/  518]    Overall Loss 6.324189    Objective Loss 6.324189                                        LR 0.002000    Time 0.208506    
2023-04-26 18:44:41,703 - Epoch: [0][  250/  518]    Overall Loss 6.215689    Objective Loss 6.215689                                        LR 0.002000    Time 0.206925    
2023-04-26 18:44:51,848 - Epoch: [0][  300/  518]    Overall Loss 6.137906    Objective Loss 6.137906                                        LR 0.002000    Time 0.206247    
2023-04-26 18:45:01,964 - Epoch: [0][  350/  518]    Overall Loss 6.079170    Objective Loss 6.079170                                        LR 0.002000    Time 0.205681    
2023-04-26 18:45:12,098 - Epoch: [0][  400/  518]    Overall Loss 6.035478    Objective Loss 6.035478                                        LR 0.002000    Time 0.205302    
2023-04-26 18:45:22,227 - Epoch: [0][  450/  518]    Overall Loss 5.992094    Objective Loss 5.992094                                        LR 0.002000    Time 0.204996    
2023-04-26 18:45:32,251 - Epoch: [0][  500/  518]    Overall Loss 5.954386    Objective Loss 5.954386                                        LR 0.002000    Time 0.204542    
2023-04-26 18:45:35,743 - Epoch: [0][  518/  518]    Overall Loss 5.943826    Objective Loss 5.943826                                        LR 0.002000    Time 0.204174    
2023-04-26 18:45:35,811 - --- validate (epoch=0)-----------
2023-04-26 18:45:35,812 - 4952 samples (32 per mini-batch)
2023-04-26 18:45:41,263 - Epoch: [0][   50/  155]    Loss 5.680794    mAP 0.000000    
2023-04-26 18:45:46,387 - Epoch: [0][  100/  155]    Loss 5.710366    mAP 0.000000    
2023-04-26 18:45:51,463 - Epoch: [0][  150/  155]    Loss 5.700281    mAP 0.000000    
2023-04-26 18:45:51,917 - Epoch: [0][  155/  155]    Loss 5.696242    mAP 0.000000    
2023-04-26 18:45:51,979 - ==> mAP: 0.00000    Loss: 5.696

2023-04-26 18:45:51,982 - ==> Best [mAP: 0.000000   vloss: 5.696242   Sparsity:0.00   Params: 2177088 on epoch: 0]
2023-04-26 18:45:51,982 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 18:45:52,022 - 

2023-04-26 18:45:52,022 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 18:46:02,849 - Epoch: [1][   50/  518]    Overall Loss 5.506161    Objective Loss 5.506161                                        LR 0.002000    Time 0.216471    
2023-04-26 18:46:13,031 - Epoch: [1][  100/  518]    Overall Loss 5.493601    Objective Loss 5.493601                                        LR 0.002000    Time 0.210041    
2023-04-26 18:46:23,132 - Epoch: [1][  150/  518]    Overall Loss 5.511360    Objective Loss 5.511360                                        LR 0.002000    Time 0.207356    
2023-04-26 18:46:33,304 - Epoch: [1][  200/  518]    Overall Loss 5.523178    Objective Loss 5.523178                                        LR 0.002000    Time 0.206367    
2023-04-26 18:46:43,506 - Epoch: [1][  250/  518]    Overall Loss 5.508800    Objective Loss 5.508800                                        LR 0.002000    Time 0.205897    
2023-04-26 18:46:53,699 - Epoch: [1][  300/  518]    Overall Loss 5.483558    Objective Loss 5.483558                                        LR 0.002000    Time 0.205552    
2023-04-26 18:47:03,787 - Epoch: [1][  350/  518]    Overall Loss 5.475019    Objective Loss 5.475019                                        LR 0.002000    Time 0.205007    
2023-04-26 18:47:13,897 - Epoch: [1][  400/  518]    Overall Loss 5.457925    Objective Loss 5.457925                                        LR 0.002000    Time 0.204652    
2023-04-26 18:47:24,001 - Epoch: [1][  450/  518]    Overall Loss 5.445572    Objective Loss 5.445572                                        LR 0.002000    Time 0.204361    
2023-04-26 18:47:34,164 - Epoch: [1][  500/  518]    Overall Loss 5.431971    Objective Loss 5.431971                                        LR 0.002000    Time 0.204248    
2023-04-26 18:47:37,700 - Epoch: [1][  518/  518]    Overall Loss 5.429640    Objective Loss 5.429640                                        LR 0.002000    Time 0.203977    
2023-04-26 18:47:37,772 - --- validate (epoch=1)-----------
2023-04-26 18:47:37,772 - 4952 samples (32 per mini-batch)
2023-04-26 18:47:43,291 - Epoch: [1][   50/  155]    Loss 5.518327    mAP 0.000000    
2023-04-26 18:47:48,514 - Epoch: [1][  100/  155]    Loss 5.516963    mAP 0.000000    
2023-04-26 18:47:53,745 - Epoch: [1][  150/  155]    Loss 5.495558    mAP 0.000000    
2023-04-26 18:47:54,202 - Epoch: [1][  155/  155]    Loss 5.498510    mAP 0.000000    
2023-04-26 18:47:54,270 - ==> mAP: 0.00000    Loss: 5.499

2023-04-26 18:47:54,274 - ==> Best [mAP: 0.000000   vloss: 5.498510   Sparsity:0.00   Params: 2177088 on epoch: 1]
2023-04-26 18:47:54,274 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 18:47:54,327 - 

2023-04-26 18:47:54,327 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 18:48:05,180 - Epoch: [2][   50/  518]    Overall Loss 5.289046    Objective Loss 5.289046                                        LR 0.002000    Time 0.217002    
2023-04-26 18:48:15,349 - Epoch: [2][  100/  518]    Overall Loss 5.266754    Objective Loss 5.266754                                        LR 0.002000    Time 0.210174    
2023-04-26 18:48:25,580 - Epoch: [2][  150/  518]    Overall Loss 5.231322    Objective Loss 5.231322                                        LR 0.002000    Time 0.208311    
2023-04-26 18:48:35,801 - Epoch: [2][  200/  518]    Overall Loss 5.226539    Objective Loss 5.226539                                        LR 0.002000    Time 0.207330    
2023-04-26 18:48:45,946 - Epoch: [2][  250/  518]    Overall Loss 5.226818    Objective Loss 5.226818                                        LR 0.002000    Time 0.206436    
2023-04-26 18:48:56,108 - Epoch: [2][  300/  518]    Overall Loss 5.207170    Objective Loss 5.207170                                        LR 0.002000    Time 0.205899    
2023-04-26 18:49:06,204 - Epoch: [2][  350/  518]    Overall Loss 5.188172    Objective Loss 5.188172                                        LR 0.002000    Time 0.205327    
2023-04-26 18:49:16,402 - Epoch: [2][  400/  518]    Overall Loss 5.175901    Objective Loss 5.175901                                        LR 0.002000    Time 0.205151    
2023-04-26 18:49:26,611 - Epoch: [2][  450/  518]    Overall Loss 5.165071    Objective Loss 5.165071                                        LR 0.002000    Time 0.205039    
2023-04-26 18:49:36,857 - Epoch: [2][  500/  518]    Overall Loss 5.159868    Objective Loss 5.159868                                        LR 0.002000    Time 0.205025    
2023-04-26 18:49:40,430 - Epoch: [2][  518/  518]    Overall Loss 5.160328    Objective Loss 5.160328                                        LR 0.002000    Time 0.204797    
2023-04-26 18:49:40,502 - --- validate (epoch=2)-----------
2023-04-26 18:49:40,502 - 4952 samples (32 per mini-batch)
2023-04-26 18:49:46,016 - Epoch: [2][   50/  155]    Loss 5.206715    mAP 0.000170    
2023-04-26 18:49:51,206 - Epoch: [2][  100/  155]    Loss 5.168171    mAP 0.000465    
2023-04-26 18:49:56,345 - Epoch: [2][  150/  155]    Loss 5.182317    mAP 0.000478    
2023-04-26 18:49:56,803 - Epoch: [2][  155/  155]    Loss 5.184851    mAP 0.000576    
2023-04-26 18:49:56,862 - ==> mAP: 0.00058    Loss: 5.185

2023-04-26 18:49:56,866 - ==> Best [mAP: 0.000576   vloss: 5.184851   Sparsity:0.00   Params: 2177088 on epoch: 2]
2023-04-26 18:49:56,866 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 18:49:56,920 - 

2023-04-26 18:49:56,920 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 18:50:07,801 - Epoch: [3][   50/  518]    Overall Loss 5.062207    Objective Loss 5.062207                                        LR 0.002000    Time 0.217572    
2023-04-26 18:50:17,924 - Epoch: [3][  100/  518]    Overall Loss 5.082694    Objective Loss 5.082694                                        LR 0.002000    Time 0.209997    
2023-04-26 18:50:28,038 - Epoch: [3][  150/  518]    Overall Loss 5.053928    Objective Loss 5.053928                                        LR 0.002000    Time 0.207413    
2023-04-26 18:50:38,266 - Epoch: [3][  200/  518]    Overall Loss 5.035621    Objective Loss 5.035621                                        LR 0.002000    Time 0.206692    
2023-04-26 18:50:48,414 - Epoch: [3][  250/  518]    Overall Loss 5.007172    Objective Loss 5.007172                                        LR 0.002000    Time 0.205941    
2023-04-26 18:50:58,609 - Epoch: [3][  300/  518]    Overall Loss 5.004353    Objective Loss 5.004353                                        LR 0.002000    Time 0.205594    
2023-04-26 18:51:08,750 - Epoch: [3][  350/  518]    Overall Loss 4.996206    Objective Loss 4.996206                                        LR 0.002000    Time 0.205194    
2023-04-26 18:51:18,936 - Epoch: [3][  400/  518]    Overall Loss 4.991833    Objective Loss 4.991833                                        LR 0.002000    Time 0.205006    
2023-04-26 18:51:29,081 - Epoch: [3][  450/  518]    Overall Loss 4.982553    Objective Loss 4.982553                                        LR 0.002000    Time 0.204769    
2023-04-26 18:51:39,208 - Epoch: [3][  500/  518]    Overall Loss 4.978779    Objective Loss 4.978779                                        LR 0.002000    Time 0.204543    
2023-04-26 18:51:42,700 - Epoch: [3][  518/  518]    Overall Loss 4.978215    Objective Loss 4.978215                                        LR 0.002000    Time 0.204176    
2023-04-26 18:51:42,772 - --- validate (epoch=3)-----------
2023-04-26 18:51:42,773 - 4952 samples (32 per mini-batch)
2023-04-26 18:51:48,405 - Epoch: [3][   50/  155]    Loss 5.365351    mAP 0.006468    
2023-04-26 18:51:53,628 - Epoch: [3][  100/  155]    Loss 5.345745    mAP 0.004709    
2023-04-26 18:51:58,791 - Epoch: [3][  150/  155]    Loss 5.341064    mAP 0.005464    
2023-04-26 18:51:59,248 - Epoch: [3][  155/  155]    Loss 5.341885    mAP 0.005324    
2023-04-26 18:51:59,313 - ==> mAP: 0.00532    Loss: 5.342

2023-04-26 18:51:59,317 - ==> Best [mAP: 0.005324   vloss: 5.341885   Sparsity:0.00   Params: 2177088 on epoch: 3]
2023-04-26 18:51:59,317 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 18:51:59,370 - 

2023-04-26 18:51:59,371 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 18:52:10,153 - Epoch: [4][   50/  518]    Overall Loss 4.907613    Objective Loss 4.907613                                        LR 0.002000    Time 0.215580    
2023-04-26 18:52:20,347 - Epoch: [4][  100/  518]    Overall Loss 4.901172    Objective Loss 4.901172                                        LR 0.002000    Time 0.209717    
2023-04-26 18:52:30,455 - Epoch: [4][  150/  518]    Overall Loss 4.891361    Objective Loss 4.891361                                        LR 0.002000    Time 0.207190    
2023-04-26 18:52:40,556 - Epoch: [4][  200/  518]    Overall Loss 4.875586    Objective Loss 4.875586                                        LR 0.002000    Time 0.205887    
2023-04-26 18:52:50,706 - Epoch: [4][  250/  518]    Overall Loss 4.869341    Objective Loss 4.869341                                        LR 0.002000    Time 0.205305    
2023-04-26 18:53:00,853 - Epoch: [4][  300/  518]    Overall Loss 4.862331    Objective Loss 4.862331                                        LR 0.002000    Time 0.204904    
2023-04-26 18:53:10,972 - Epoch: [4][  350/  518]    Overall Loss 4.855282    Objective Loss 4.855282                                        LR 0.002000    Time 0.204537    
2023-04-26 18:53:21,104 - Epoch: [4][  400/  518]    Overall Loss 4.853889    Objective Loss 4.853889                                        LR 0.002000    Time 0.204297    
2023-04-26 18:53:31,220 - Epoch: [4][  450/  518]    Overall Loss 4.844303    Objective Loss 4.844303                                        LR 0.002000    Time 0.204074    
2023-04-26 18:53:41,410 - Epoch: [4][  500/  518]    Overall Loss 4.842758    Objective Loss 4.842758                                        LR 0.002000    Time 0.204044    
2023-04-26 18:53:44,957 - Epoch: [4][  518/  518]    Overall Loss 4.841576    Objective Loss 4.841576                                        LR 0.002000    Time 0.203799    
2023-04-26 18:53:45,028 - --- validate (epoch=4)-----------
2023-04-26 18:53:45,029 - 4952 samples (32 per mini-batch)
2023-04-26 18:53:50,655 - Epoch: [4][   50/  155]    Loss 5.044647    mAP 0.014012    
2023-04-26 18:53:55,863 - Epoch: [4][  100/  155]    Loss 5.024860    mAP 0.013300    
2023-04-26 18:54:01,053 - Epoch: [4][  150/  155]    Loss 5.035821    mAP 0.012227    
2023-04-26 18:54:01,516 - Epoch: [4][  155/  155]    Loss 5.036174    mAP 0.012532    
2023-04-26 18:54:01,583 - ==> mAP: 0.01253    Loss: 5.036

2023-04-26 18:54:01,587 - ==> Best [mAP: 0.012532   vloss: 5.036174   Sparsity:0.00   Params: 2177088 on epoch: 4]
2023-04-26 18:54:01,587 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 18:54:01,640 - 

2023-04-26 18:54:01,640 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 18:54:12,674 - Epoch: [5][   50/  518]    Overall Loss 4.813672    Objective Loss 4.813672                                        LR 0.002000    Time 0.220623    
2023-04-26 18:54:22,905 - Epoch: [5][  100/  518]    Overall Loss 4.788561    Objective Loss 4.788561                                        LR 0.002000    Time 0.212601    
2023-04-26 18:54:32,990 - Epoch: [5][  150/  518]    Overall Loss 4.775404    Objective Loss 4.775404                                        LR 0.002000    Time 0.208956    
2023-04-26 18:54:43,072 - Epoch: [5][  200/  518]    Overall Loss 4.777132    Objective Loss 4.777132                                        LR 0.002000    Time 0.207118    
2023-04-26 18:54:53,251 - Epoch: [5][  250/  518]    Overall Loss 4.772787    Objective Loss 4.772787                                        LR 0.002000    Time 0.206405    
2023-04-26 18:55:03,379 - Epoch: [5][  300/  518]    Overall Loss 4.763455    Objective Loss 4.763455                                        LR 0.002000    Time 0.205761    
2023-04-26 18:55:13,570 - Epoch: [5][  350/  518]    Overall Loss 4.761734    Objective Loss 4.761734                                        LR 0.002000    Time 0.205479    
2023-04-26 18:55:23,677 - Epoch: [5][  400/  518]    Overall Loss 4.754184    Objective Loss 4.754184                                        LR 0.002000    Time 0.205057    
2023-04-26 18:55:33,827 - Epoch: [5][  450/  518]    Overall Loss 4.747047    Objective Loss 4.747047                                        LR 0.002000    Time 0.204825    
2023-04-26 18:55:43,947 - Epoch: [5][  500/  518]    Overall Loss 4.745136    Objective Loss 4.745136                                        LR 0.002000    Time 0.204578    
2023-04-26 18:55:47,483 - Epoch: [5][  518/  518]    Overall Loss 4.748110    Objective Loss 4.748110                                        LR 0.002000    Time 0.204296    
2023-04-26 18:55:47,554 - --- validate (epoch=5)-----------
2023-04-26 18:55:47,554 - 4952 samples (32 per mini-batch)
2023-04-26 18:55:53,243 - Epoch: [5][   50/  155]    Loss 4.921851    mAP 0.029119    
2023-04-26 18:55:58,547 - Epoch: [5][  100/  155]    Loss 4.927791    mAP 0.030656    
2023-04-26 18:56:03,804 - Epoch: [5][  150/  155]    Loss 4.930954    mAP 0.033773    
2023-04-26 18:56:04,269 - Epoch: [5][  155/  155]    Loss 4.933616    mAP 0.032943    
2023-04-26 18:56:04,351 - ==> mAP: 0.03294    Loss: 4.934

2023-04-26 18:56:04,355 - ==> Best [mAP: 0.032943   vloss: 4.933616   Sparsity:0.00   Params: 2177088 on epoch: 5]
2023-04-26 18:56:04,355 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 18:56:04,407 - 

2023-04-26 18:56:04,407 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 18:56:15,377 - Epoch: [6][   50/  518]    Overall Loss 4.761142    Objective Loss 4.761142                                        LR 0.002000    Time 0.219336    
2023-04-26 18:56:25,530 - Epoch: [6][  100/  518]    Overall Loss 4.713612    Objective Loss 4.713612                                        LR 0.002000    Time 0.211178    
2023-04-26 18:56:35,647 - Epoch: [6][  150/  518]    Overall Loss 4.683662    Objective Loss 4.683662                                        LR 0.002000    Time 0.208225    
2023-04-26 18:56:45,908 - Epoch: [6][  200/  518]    Overall Loss 4.681057    Objective Loss 4.681057                                        LR 0.002000    Time 0.207467    
2023-04-26 18:56:56,087 - Epoch: [6][  250/  518]    Overall Loss 4.673279    Objective Loss 4.673279                                        LR 0.002000    Time 0.206681    
2023-04-26 18:57:06,321 - Epoch: [6][  300/  518]    Overall Loss 4.665199    Objective Loss 4.665199                                        LR 0.002000    Time 0.206341    
2023-04-26 18:57:16,459 - Epoch: [6][  350/  518]    Overall Loss 4.665004    Objective Loss 4.665004                                        LR 0.002000    Time 0.205825    
2023-04-26 18:57:26,684 - Epoch: [6][  400/  518]    Overall Loss 4.662627    Objective Loss 4.662627                                        LR 0.002000    Time 0.205655    
2023-04-26 18:57:36,828 - Epoch: [6][  450/  518]    Overall Loss 4.649736    Objective Loss 4.649736                                        LR 0.002000    Time 0.205344    
2023-04-26 18:57:46,919 - Epoch: [6][  500/  518]    Overall Loss 4.650286    Objective Loss 4.650286                                        LR 0.002000    Time 0.204989    
2023-04-26 18:57:50,486 - Epoch: [6][  518/  518]    Overall Loss 4.654031    Objective Loss 4.654031                                        LR 0.002000    Time 0.204750    
2023-04-26 18:57:50,557 - --- validate (epoch=6)-----------
2023-04-26 18:57:50,558 - 4952 samples (32 per mini-batch)
2023-04-26 18:57:56,131 - Epoch: [6][   50/  155]    Loss 4.963509    mAP 0.014467    
2023-04-26 18:58:01,369 - Epoch: [6][  100/  155]    Loss 4.986738    mAP 0.016083    
2023-04-26 18:58:06,569 - Epoch: [6][  150/  155]    Loss 5.008911    mAP 0.014756    
2023-04-26 18:58:07,031 - Epoch: [6][  155/  155]    Loss 5.012071    mAP 0.014594    
2023-04-26 18:58:07,103 - ==> mAP: 0.01459    Loss: 5.012

2023-04-26 18:58:07,106 - ==> Best [mAP: 0.032943   vloss: 4.933616   Sparsity:0.00   Params: 2177088 on epoch: 5]
2023-04-26 18:58:07,106 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 18:58:07,144 - 

2023-04-26 18:58:07,144 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 18:58:17,953 - Epoch: [7][   50/  518]    Overall Loss 4.582747    Objective Loss 4.582747                                        LR 0.002000    Time 0.216120    
2023-04-26 18:58:28,101 - Epoch: [7][  100/  518]    Overall Loss 4.596874    Objective Loss 4.596874                                        LR 0.002000    Time 0.209524    
2023-04-26 18:58:38,312 - Epoch: [7][  150/  518]    Overall Loss 4.591949    Objective Loss 4.591949                                        LR 0.002000    Time 0.207750    
2023-04-26 18:58:48,444 - Epoch: [7][  200/  518]    Overall Loss 4.569472    Objective Loss 4.569472                                        LR 0.002000    Time 0.206464    
2023-04-26 18:58:58,595 - Epoch: [7][  250/  518]    Overall Loss 4.567704    Objective Loss 4.567704                                        LR 0.002000    Time 0.205766    
2023-04-26 18:59:08,735 - Epoch: [7][  300/  518]    Overall Loss 4.563120    Objective Loss 4.563120                                        LR 0.002000    Time 0.205267    
2023-04-26 18:59:18,862 - Epoch: [7][  350/  518]    Overall Loss 4.561089    Objective Loss 4.561089                                        LR 0.002000    Time 0.204875    
2023-04-26 18:59:28,995 - Epoch: [7][  400/  518]    Overall Loss 4.561284    Objective Loss 4.561284                                        LR 0.002000    Time 0.204593    
2023-04-26 18:59:39,055 - Epoch: [7][  450/  518]    Overall Loss 4.562529    Objective Loss 4.562529                                        LR 0.002000    Time 0.204212    
2023-04-26 18:59:49,213 - Epoch: [7][  500/  518]    Overall Loss 4.566850    Objective Loss 4.566850                                        LR 0.002000    Time 0.204104    
2023-04-26 18:59:52,705 - Epoch: [7][  518/  518]    Overall Loss 4.564621    Objective Loss 4.564621                                        LR 0.002000    Time 0.203752    
2023-04-26 18:59:52,774 - --- validate (epoch=7)-----------
2023-04-26 18:59:52,775 - 4952 samples (32 per mini-batch)
2023-04-26 18:59:58,560 - Epoch: [7][   50/  155]    Loss 5.062050    mAP 0.034304    
2023-04-26 19:00:03,983 - Epoch: [7][  100/  155]    Loss 5.053016    mAP 0.037425    
2023-04-26 19:00:09,375 - Epoch: [7][  150/  155]    Loss 5.071941    mAP 0.037422    
2023-04-26 19:00:09,855 - Epoch: [7][  155/  155]    Loss 5.073614    mAP 0.037261    
2023-04-26 19:00:09,915 - ==> mAP: 0.03726    Loss: 5.074

2023-04-26 19:00:09,918 - ==> Best [mAP: 0.037261   vloss: 5.073614   Sparsity:0.00   Params: 2177088 on epoch: 7]
2023-04-26 19:00:09,919 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:00:09,981 - 

2023-04-26 19:00:09,981 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:00:20,959 - Epoch: [8][   50/  518]    Overall Loss 4.502025    Objective Loss 4.502025                                        LR 0.002000    Time 0.219507    
2023-04-26 19:00:31,062 - Epoch: [8][  100/  518]    Overall Loss 4.501439    Objective Loss 4.501439                                        LR 0.002000    Time 0.210761    
2023-04-26 19:00:41,230 - Epoch: [8][  150/  518]    Overall Loss 4.510735    Objective Loss 4.510735                                        LR 0.002000    Time 0.208284    
2023-04-26 19:00:51,408 - Epoch: [8][  200/  518]    Overall Loss 4.524754    Objective Loss 4.524754                                        LR 0.002000    Time 0.207094    
2023-04-26 19:01:01,587 - Epoch: [8][  250/  518]    Overall Loss 4.506519    Objective Loss 4.506519                                        LR 0.002000    Time 0.206386    
2023-04-26 19:01:11,768 - Epoch: [8][  300/  518]    Overall Loss 4.502182    Objective Loss 4.502182                                        LR 0.002000    Time 0.205918    
2023-04-26 19:01:21,860 - Epoch: [8][  350/  518]    Overall Loss 4.504581    Objective Loss 4.504581                                        LR 0.002000    Time 0.205332    
2023-04-26 19:01:31,999 - Epoch: [8][  400/  518]    Overall Loss 4.501232    Objective Loss 4.501232                                        LR 0.002000    Time 0.205010    
2023-04-26 19:01:42,044 - Epoch: [8][  450/  518]    Overall Loss 4.495451    Objective Loss 4.495451                                        LR 0.002000    Time 0.204548    
2023-04-26 19:01:52,138 - Epoch: [8][  500/  518]    Overall Loss 4.499646    Objective Loss 4.499646                                        LR 0.002000    Time 0.204278    
2023-04-26 19:01:55,685 - Epoch: [8][  518/  518]    Overall Loss 4.495841    Objective Loss 4.495841                                        LR 0.002000    Time 0.204026    
2023-04-26 19:01:55,756 - --- validate (epoch=8)-----------
2023-04-26 19:01:55,756 - 4952 samples (32 per mini-batch)
2023-04-26 19:02:01,534 - Epoch: [8][   50/  155]    Loss 4.721816    mAP 0.058889    
2023-04-26 19:02:07,038 - Epoch: [8][  100/  155]    Loss 4.740076    mAP 0.057760    
2023-04-26 19:02:12,490 - Epoch: [8][  150/  155]    Loss 4.747500    mAP 0.055603    
2023-04-26 19:02:12,968 - Epoch: [8][  155/  155]    Loss 4.744856    mAP 0.055541    
2023-04-26 19:02:13,041 - ==> mAP: 0.05554    Loss: 4.745

2023-04-26 19:02:13,045 - ==> Best [mAP: 0.055541   vloss: 4.744856   Sparsity:0.00   Params: 2177088 on epoch: 8]
2023-04-26 19:02:13,045 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:02:13,098 - 

2023-04-26 19:02:13,098 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:02:24,017 - Epoch: [9][   50/  518]    Overall Loss 4.460543    Objective Loss 4.460543                                        LR 0.002000    Time 0.218337    
2023-04-26 19:02:34,170 - Epoch: [9][  100/  518]    Overall Loss 4.445796    Objective Loss 4.445796                                        LR 0.002000    Time 0.210683    
2023-04-26 19:02:44,444 - Epoch: [9][  150/  518]    Overall Loss 4.418630    Objective Loss 4.418630                                        LR 0.002000    Time 0.208936    
2023-04-26 19:02:54,556 - Epoch: [9][  200/  518]    Overall Loss 4.430761    Objective Loss 4.430761                                        LR 0.002000    Time 0.207255    
2023-04-26 19:03:04,703 - Epoch: [9][  250/  518]    Overall Loss 4.417511    Objective Loss 4.417511                                        LR 0.002000    Time 0.206383    
2023-04-26 19:03:14,999 - Epoch: [9][  300/  518]    Overall Loss 4.421122    Objective Loss 4.421122                                        LR 0.002000    Time 0.206301    
2023-04-26 19:03:25,170 - Epoch: [9][  350/  518]    Overall Loss 4.422536    Objective Loss 4.422536                                        LR 0.002000    Time 0.205885    
2023-04-26 19:03:35,336 - Epoch: [9][  400/  518]    Overall Loss 4.423683    Objective Loss 4.423683                                        LR 0.002000    Time 0.205560    
2023-04-26 19:03:45,524 - Epoch: [9][  450/  518]    Overall Loss 4.419972    Objective Loss 4.419972                                        LR 0.002000    Time 0.205356    
2023-04-26 19:03:55,698 - Epoch: [9][  500/  518]    Overall Loss 4.418808    Objective Loss 4.418808                                        LR 0.002000    Time 0.205165    
2023-04-26 19:03:59,277 - Epoch: [9][  518/  518]    Overall Loss 4.417766    Objective Loss 4.417766                                        LR 0.002000    Time 0.204945    
2023-04-26 19:03:59,348 - --- validate (epoch=9)-----------
2023-04-26 19:03:59,348 - 4952 samples (32 per mini-batch)
2023-04-26 19:04:05,375 - Epoch: [9][   50/  155]    Loss 5.143822    mAP 0.064267    
2023-04-26 19:04:11,076 - Epoch: [9][  100/  155]    Loss 5.134260    mAP 0.061424    
2023-04-26 19:04:16,802 - Epoch: [9][  150/  155]    Loss 5.135877    mAP 0.060140    
2023-04-26 19:04:17,303 - Epoch: [9][  155/  155]    Loss 5.135221    mAP 0.059388    
2023-04-26 19:04:17,372 - ==> mAP: 0.05939    Loss: 5.135

2023-04-26 19:04:17,375 - ==> Best [mAP: 0.059388   vloss: 5.135221   Sparsity:0.00   Params: 2177088 on epoch: 9]
2023-04-26 19:04:17,375 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:04:17,428 - 

2023-04-26 19:04:17,428 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:04:28,420 - Epoch: [10][   50/  518]    Overall Loss 4.393080    Objective Loss 4.393080                                        LR 0.002000    Time 0.219771    
2023-04-26 19:04:38,628 - Epoch: [10][  100/  518]    Overall Loss 4.355729    Objective Loss 4.355729                                        LR 0.002000    Time 0.211955    
2023-04-26 19:04:48,910 - Epoch: [10][  150/  518]    Overall Loss 4.363539    Objective Loss 4.363539                                        LR 0.002000    Time 0.209837    
2023-04-26 19:04:59,203 - Epoch: [10][  200/  518]    Overall Loss 4.380264    Objective Loss 4.380264                                        LR 0.002000    Time 0.208834    
2023-04-26 19:05:09,538 - Epoch: [10][  250/  518]    Overall Loss 4.374612    Objective Loss 4.374612                                        LR 0.002000    Time 0.208400    
2023-04-26 19:05:19,723 - Epoch: [10][  300/  518]    Overall Loss 4.378651    Objective Loss 4.378651                                        LR 0.002000    Time 0.207613    
2023-04-26 19:05:29,977 - Epoch: [10][  350/  518]    Overall Loss 4.369861    Objective Loss 4.369861                                        LR 0.002000    Time 0.207245    
2023-04-26 19:05:40,159 - Epoch: [10][  400/  518]    Overall Loss 4.373089    Objective Loss 4.373089                                        LR 0.002000    Time 0.206792    
2023-04-26 19:05:50,408 - Epoch: [10][  450/  518]    Overall Loss 4.370237    Objective Loss 4.370237                                        LR 0.002000    Time 0.206586    
2023-04-26 19:06:00,672 - Epoch: [10][  500/  518]    Overall Loss 4.364309    Objective Loss 4.364309                                        LR 0.002000    Time 0.206451    
2023-04-26 19:06:04,229 - Epoch: [10][  518/  518]    Overall Loss 4.361516    Objective Loss 4.361516                                        LR 0.002000    Time 0.206144    
2023-04-26 19:06:04,301 - --- validate (epoch=10)-----------
2023-04-26 19:06:04,301 - 4952 samples (32 per mini-batch)
2023-04-26 19:06:10,110 - Epoch: [10][   50/  155]    Loss 4.825384    mAP 0.073129    
2023-04-26 19:06:15,544 - Epoch: [10][  100/  155]    Loss 4.818518    mAP 0.066655    
2023-04-26 19:06:20,979 - Epoch: [10][  150/  155]    Loss 4.822191    mAP 0.063338    
2023-04-26 19:06:21,466 - Epoch: [10][  155/  155]    Loss 4.823679    mAP 0.063435    
2023-04-26 19:06:21,538 - ==> mAP: 0.06343    Loss: 4.824

2023-04-26 19:06:21,541 - ==> Best [mAP: 0.063435   vloss: 4.823679   Sparsity:0.00   Params: 2177088 on epoch: 10]
2023-04-26 19:06:21,541 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:06:21,595 - 

2023-04-26 19:06:21,595 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:06:32,531 - Epoch: [11][   50/  518]    Overall Loss 4.295898    Objective Loss 4.295898                                        LR 0.002000    Time 0.218666    
2023-04-26 19:06:42,717 - Epoch: [11][  100/  518]    Overall Loss 4.285344    Objective Loss 4.285344                                        LR 0.002000    Time 0.211173    
2023-04-26 19:06:52,986 - Epoch: [11][  150/  518]    Overall Loss 4.298929    Objective Loss 4.298929                                        LR 0.002000    Time 0.209234    
2023-04-26 19:07:03,262 - Epoch: [11][  200/  518]    Overall Loss 4.311870    Objective Loss 4.311870                                        LR 0.002000    Time 0.208297    
2023-04-26 19:07:13,421 - Epoch: [11][  250/  518]    Overall Loss 4.301560    Objective Loss 4.301560                                        LR 0.002000    Time 0.207265    
2023-04-26 19:07:23,703 - Epoch: [11][  300/  518]    Overall Loss 4.315415    Objective Loss 4.315415                                        LR 0.002000    Time 0.206991    
2023-04-26 19:07:33,895 - Epoch: [11][  350/  518]    Overall Loss 4.320717    Objective Loss 4.320717                                        LR 0.002000    Time 0.206536    
2023-04-26 19:07:44,040 - Epoch: [11][  400/  518]    Overall Loss 4.315042    Objective Loss 4.315042                                        LR 0.002000    Time 0.206076    
2023-04-26 19:07:54,179 - Epoch: [11][  450/  518]    Overall Loss 4.315157    Objective Loss 4.315157                                        LR 0.002000    Time 0.205708    
2023-04-26 19:08:04,418 - Epoch: [11][  500/  518]    Overall Loss 4.300534    Objective Loss 4.300534                                        LR 0.002000    Time 0.205611    
2023-04-26 19:08:07,994 - Epoch: [11][  518/  518]    Overall Loss 4.299196    Objective Loss 4.299196                                        LR 0.002000    Time 0.205368    
2023-04-26 19:08:08,064 - --- validate (epoch=11)-----------
2023-04-26 19:08:08,065 - 4952 samples (32 per mini-batch)
2023-04-26 19:08:13,950 - Epoch: [11][   50/  155]    Loss 4.640636    mAP 0.045781    
2023-04-26 19:08:19,565 - Epoch: [11][  100/  155]    Loss 4.613115    mAP 0.053575    
2023-04-26 19:08:25,072 - Epoch: [11][  150/  155]    Loss 4.614694    mAP 0.053276    
2023-04-26 19:08:25,553 - Epoch: [11][  155/  155]    Loss 4.612869    mAP 0.052856    
2023-04-26 19:08:25,624 - ==> mAP: 0.05286    Loss: 4.613

2023-04-26 19:08:25,628 - ==> Best [mAP: 0.063435   vloss: 4.823679   Sparsity:0.00   Params: 2177088 on epoch: 10]
2023-04-26 19:08:25,629 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:08:25,667 - 

2023-04-26 19:08:25,668 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:08:36,846 - Epoch: [12][   50/  518]    Overall Loss 4.303558    Objective Loss 4.303558                                        LR 0.002000    Time 0.223509    
2023-04-26 19:08:47,072 - Epoch: [12][  100/  518]    Overall Loss 4.276266    Objective Loss 4.276266                                        LR 0.002000    Time 0.213995    
2023-04-26 19:08:57,233 - Epoch: [12][  150/  518]    Overall Loss 4.275499    Objective Loss 4.275499                                        LR 0.002000    Time 0.210398    
2023-04-26 19:09:07,468 - Epoch: [12][  200/  518]    Overall Loss 4.282149    Objective Loss 4.282149                                        LR 0.002000    Time 0.208963    
2023-04-26 19:09:17,658 - Epoch: [12][  250/  518]    Overall Loss 4.287495    Objective Loss 4.287495                                        LR 0.002000    Time 0.207925    
2023-04-26 19:09:27,871 - Epoch: [12][  300/  518]    Overall Loss 4.273264    Objective Loss 4.273264                                        LR 0.002000    Time 0.207309    
2023-04-26 19:09:38,017 - Epoch: [12][  350/  518]    Overall Loss 4.271317    Objective Loss 4.271317                                        LR 0.002000    Time 0.206676    
2023-04-26 19:09:48,237 - Epoch: [12][  400/  518]    Overall Loss 4.269400    Objective Loss 4.269400                                        LR 0.002000    Time 0.206388    
2023-04-26 19:09:58,482 - Epoch: [12][  450/  518]    Overall Loss 4.264516    Objective Loss 4.264516                                        LR 0.002000    Time 0.206220    
2023-04-26 19:10:08,661 - Epoch: [12][  500/  518]    Overall Loss 4.264997    Objective Loss 4.264997                                        LR 0.002000    Time 0.205951    
2023-04-26 19:10:12,171 - Epoch: [12][  518/  518]    Overall Loss 4.266283    Objective Loss 4.266283                                        LR 0.002000    Time 0.205569    
2023-04-26 19:10:12,241 - --- validate (epoch=12)-----------
2023-04-26 19:10:12,242 - 4952 samples (32 per mini-batch)
2023-04-26 19:10:18,625 - Epoch: [12][   50/  155]    Loss 4.800670    mAP 0.058946    
2023-04-26 19:10:24,522 - Epoch: [12][  100/  155]    Loss 4.795041    mAP 0.056466    
2023-04-26 19:10:30,419 - Epoch: [12][  150/  155]    Loss 4.792190    mAP 0.056867    
2023-04-26 19:10:30,939 - Epoch: [12][  155/  155]    Loss 4.796340    mAP 0.056103    
2023-04-26 19:10:31,022 - ==> mAP: 0.05610    Loss: 4.796

2023-04-26 19:10:31,026 - ==> Best [mAP: 0.063435   vloss: 4.823679   Sparsity:0.00   Params: 2177088 on epoch: 10]
2023-04-26 19:10:31,026 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:10:31,064 - 

2023-04-26 19:10:31,064 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:10:41,994 - Epoch: [13][   50/  518]    Overall Loss 4.196735    Objective Loss 4.196735                                        LR 0.002000    Time 0.218536    
2023-04-26 19:10:52,200 - Epoch: [13][  100/  518]    Overall Loss 4.183296    Objective Loss 4.183296                                        LR 0.002000    Time 0.211312    
2023-04-26 19:11:02,461 - Epoch: [13][  150/  518]    Overall Loss 4.188301    Objective Loss 4.188301                                        LR 0.002000    Time 0.209273    
2023-04-26 19:11:12,737 - Epoch: [13][  200/  518]    Overall Loss 4.173528    Objective Loss 4.173528                                        LR 0.002000    Time 0.208324    
2023-04-26 19:11:22,908 - Epoch: [13][  250/  518]    Overall Loss 4.177827    Objective Loss 4.177827                                        LR 0.002000    Time 0.207338    
2023-04-26 19:11:33,158 - Epoch: [13][  300/  518]    Overall Loss 4.175789    Objective Loss 4.175789                                        LR 0.002000    Time 0.206943    
2023-04-26 19:11:43,352 - Epoch: [13][  350/  518]    Overall Loss 4.180161    Objective Loss 4.180161                                        LR 0.002000    Time 0.206500    
2023-04-26 19:11:53,587 - Epoch: [13][  400/  518]    Overall Loss 4.175336    Objective Loss 4.175336                                        LR 0.002000    Time 0.206271    
2023-04-26 19:12:03,778 - Epoch: [13][  450/  518]    Overall Loss 4.180783    Objective Loss 4.180783                                        LR 0.002000    Time 0.205994    
2023-04-26 19:12:14,016 - Epoch: [13][  500/  518]    Overall Loss 4.185341    Objective Loss 4.185341                                        LR 0.002000    Time 0.205868    
2023-04-26 19:12:17,586 - Epoch: [13][  518/  518]    Overall Loss 4.181640    Objective Loss 4.181640                                        LR 0.002000    Time 0.205605    
2023-04-26 19:12:17,658 - --- validate (epoch=13)-----------
2023-04-26 19:12:17,658 - 4952 samples (32 per mini-batch)
2023-04-26 19:12:23,607 - Epoch: [13][   50/  155]    Loss 4.433584    mAP 0.114606    
2023-04-26 19:12:29,268 - Epoch: [13][  100/  155]    Loss 4.417048    mAP 0.111954    
2023-04-26 19:12:34,956 - Epoch: [13][  150/  155]    Loss 4.414147    mAP 0.116542    
2023-04-26 19:12:35,442 - Epoch: [13][  155/  155]    Loss 4.415760    mAP 0.115995    
2023-04-26 19:12:35,512 - ==> mAP: 0.11600    Loss: 4.416

2023-04-26 19:12:35,515 - ==> Best [mAP: 0.115995   vloss: 4.415760   Sparsity:0.00   Params: 2177088 on epoch: 13]
2023-04-26 19:12:35,515 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:12:35,568 - 

2023-04-26 19:12:35,568 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:12:46,537 - Epoch: [14][   50/  518]    Overall Loss 4.242636    Objective Loss 4.242636                                        LR 0.002000    Time 0.219317    
2023-04-26 19:12:56,781 - Epoch: [14][  100/  518]    Overall Loss 4.192554    Objective Loss 4.192554                                        LR 0.002000    Time 0.212080    
2023-04-26 19:13:07,000 - Epoch: [14][  150/  518]    Overall Loss 4.167381    Objective Loss 4.167381                                        LR 0.002000    Time 0.209503    
2023-04-26 19:13:17,191 - Epoch: [14][  200/  518]    Overall Loss 4.156668    Objective Loss 4.156668                                        LR 0.002000    Time 0.208077    
2023-04-26 19:13:27,445 - Epoch: [14][  250/  518]    Overall Loss 4.155878    Objective Loss 4.155878                                        LR 0.002000    Time 0.207470    
2023-04-26 19:13:37,691 - Epoch: [14][  300/  518]    Overall Loss 4.155114    Objective Loss 4.155114                                        LR 0.002000    Time 0.207039    
2023-04-26 19:13:47,958 - Epoch: [14][  350/  518]    Overall Loss 4.153790    Objective Loss 4.153790                                        LR 0.002000    Time 0.206791    
2023-04-26 19:13:58,197 - Epoch: [14][  400/  518]    Overall Loss 4.153019    Objective Loss 4.153019                                        LR 0.002000    Time 0.206536    
2023-04-26 19:14:08,425 - Epoch: [14][  450/  518]    Overall Loss 4.150084    Objective Loss 4.150084                                        LR 0.002000    Time 0.206314    
2023-04-26 19:14:18,571 - Epoch: [14][  500/  518]    Overall Loss 4.152941    Objective Loss 4.152941                                        LR 0.002000    Time 0.205970    
2023-04-26 19:14:22,103 - Epoch: [14][  518/  518]    Overall Loss 4.153623    Objective Loss 4.153623                                        LR 0.002000    Time 0.205630    
2023-04-26 19:14:22,174 - --- validate (epoch=14)-----------
2023-04-26 19:14:22,175 - 4952 samples (32 per mini-batch)
2023-04-26 19:14:28,324 - Epoch: [14][   50/  155]    Loss 4.813039    mAP 0.075604    
2023-04-26 19:14:34,110 - Epoch: [14][  100/  155]    Loss 4.796694    mAP 0.079456    
2023-04-26 19:14:39,884 - Epoch: [14][  150/  155]    Loss 4.789978    mAP 0.079511    
2023-04-26 19:14:40,394 - Epoch: [14][  155/  155]    Loss 4.787882    mAP 0.079263    
2023-04-26 19:14:40,459 - ==> mAP: 0.07926    Loss: 4.788

2023-04-26 19:14:40,463 - ==> Best [mAP: 0.115995   vloss: 4.415760   Sparsity:0.00   Params: 2177088 on epoch: 13]
2023-04-26 19:14:40,463 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:14:40,500 - 

2023-04-26 19:14:40,501 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:14:51,361 - Epoch: [15][   50/  518]    Overall Loss 4.151980    Objective Loss 4.151980                                        LR 0.002000    Time 0.217146    
2023-04-26 19:15:01,622 - Epoch: [15][  100/  518]    Overall Loss 4.142035    Objective Loss 4.142035                                        LR 0.002000    Time 0.211171    
2023-04-26 19:15:11,845 - Epoch: [15][  150/  518]    Overall Loss 4.115489    Objective Loss 4.115489                                        LR 0.002000    Time 0.208922    
2023-04-26 19:15:22,099 - Epoch: [15][  200/  518]    Overall Loss 4.119777    Objective Loss 4.119777                                        LR 0.002000    Time 0.207952    
2023-04-26 19:15:32,368 - Epoch: [15][  250/  518]    Overall Loss 4.116136    Objective Loss 4.116136                                        LR 0.002000    Time 0.207433    
2023-04-26 19:15:42,528 - Epoch: [15][  300/  518]    Overall Loss 4.126147    Objective Loss 4.126147                                        LR 0.002000    Time 0.206722    
2023-04-26 19:15:52,741 - Epoch: [15][  350/  518]    Overall Loss 4.115392    Objective Loss 4.115392                                        LR 0.002000    Time 0.206364    
2023-04-26 19:16:02,923 - Epoch: [15][  400/  518]    Overall Loss 4.107901    Objective Loss 4.107901                                        LR 0.002000    Time 0.206020    
2023-04-26 19:16:13,164 - Epoch: [15][  450/  518]    Overall Loss 4.105802    Objective Loss 4.105802                                        LR 0.002000    Time 0.205882    
2023-04-26 19:16:23,424 - Epoch: [15][  500/  518]    Overall Loss 4.108065    Objective Loss 4.108065                                        LR 0.002000    Time 0.205810    
2023-04-26 19:16:26,946 - Epoch: [15][  518/  518]    Overall Loss 4.109577    Objective Loss 4.109577                                        LR 0.002000    Time 0.205458    
2023-04-26 19:16:27,018 - --- validate (epoch=15)-----------
2023-04-26 19:16:27,018 - 4952 samples (32 per mini-batch)
2023-04-26 19:16:33,000 - Epoch: [15][   50/  155]    Loss 4.402553    mAP 0.109158    
2023-04-26 19:16:38,579 - Epoch: [15][  100/  155]    Loss 4.399216    mAP 0.113464    
2023-04-26 19:16:44,207 - Epoch: [15][  150/  155]    Loss 4.418735    mAP 0.108262    
2023-04-26 19:16:44,695 - Epoch: [15][  155/  155]    Loss 4.420749    mAP 0.108318    
2023-04-26 19:16:44,769 - ==> mAP: 0.10832    Loss: 4.421

2023-04-26 19:16:44,773 - ==> Best [mAP: 0.115995   vloss: 4.415760   Sparsity:0.00   Params: 2177088 on epoch: 13]
2023-04-26 19:16:44,773 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:16:44,810 - 

2023-04-26 19:16:44,810 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:16:55,808 - Epoch: [16][   50/  518]    Overall Loss 4.116832    Objective Loss 4.116832                                        LR 0.002000    Time 0.219899    
2023-04-26 19:17:05,997 - Epoch: [16][  100/  518]    Overall Loss 4.103914    Objective Loss 4.103914                                        LR 0.002000    Time 0.211826    
2023-04-26 19:17:16,247 - Epoch: [16][  150/  518]    Overall Loss 4.097176    Objective Loss 4.097176                                        LR 0.002000    Time 0.209536    
2023-04-26 19:17:26,483 - Epoch: [16][  200/  518]    Overall Loss 4.083888    Objective Loss 4.083888                                        LR 0.002000    Time 0.208327    
2023-04-26 19:17:36,661 - Epoch: [16][  250/  518]    Overall Loss 4.079944    Objective Loss 4.079944                                        LR 0.002000    Time 0.207368    
2023-04-26 19:17:46,853 - Epoch: [16][  300/  518]    Overall Loss 4.082135    Objective Loss 4.082135                                        LR 0.002000    Time 0.206773    
2023-04-26 19:17:57,055 - Epoch: [16][  350/  518]    Overall Loss 4.078410    Objective Loss 4.078410                                        LR 0.002000    Time 0.206377    
2023-04-26 19:18:07,318 - Epoch: [16][  400/  518]    Overall Loss 4.081991    Objective Loss 4.081991                                        LR 0.002000    Time 0.206235    
2023-04-26 19:18:17,581 - Epoch: [16][  450/  518]    Overall Loss 4.076967    Objective Loss 4.076967                                        LR 0.002000    Time 0.206121    
2023-04-26 19:18:27,804 - Epoch: [16][  500/  518]    Overall Loss 4.076922    Objective Loss 4.076922                                        LR 0.002000    Time 0.205953    
2023-04-26 19:18:31,351 - Epoch: [16][  518/  518]    Overall Loss 4.075091    Objective Loss 4.075091                                        LR 0.002000    Time 0.205643    
2023-04-26 19:18:31,422 - --- validate (epoch=16)-----------
2023-04-26 19:18:31,423 - 4952 samples (32 per mini-batch)
2023-04-26 19:18:37,572 - Epoch: [16][   50/  155]    Loss 4.420284    mAP 0.122161    
2023-04-26 19:18:43,284 - Epoch: [16][  100/  155]    Loss 4.440816    mAP 0.117954    
2023-04-26 19:18:48,984 - Epoch: [16][  150/  155]    Loss 4.458437    mAP 0.114768    
2023-04-26 19:18:49,489 - Epoch: [16][  155/  155]    Loss 4.461949    mAP 0.114185    
2023-04-26 19:18:49,560 - ==> mAP: 0.11418    Loss: 4.462

2023-04-26 19:18:49,564 - ==> Best [mAP: 0.115995   vloss: 4.415760   Sparsity:0.00   Params: 2177088 on epoch: 13]
2023-04-26 19:18:49,564 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:18:49,602 - 

2023-04-26 19:18:49,602 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:19:00,583 - Epoch: [17][   50/  518]    Overall Loss 4.079230    Objective Loss 4.079230                                        LR 0.002000    Time 0.219566    
2023-04-26 19:19:10,803 - Epoch: [17][  100/  518]    Overall Loss 4.053898    Objective Loss 4.053898                                        LR 0.002000    Time 0.211968    
2023-04-26 19:19:21,021 - Epoch: [17][  150/  518]    Overall Loss 4.019556    Objective Loss 4.019556                                        LR 0.002000    Time 0.209422    
2023-04-26 19:19:31,364 - Epoch: [17][  200/  518]    Overall Loss 4.028954    Objective Loss 4.028954                                        LR 0.002000    Time 0.208772    
2023-04-26 19:19:41,584 - Epoch: [17][  250/  518]    Overall Loss 4.026170    Objective Loss 4.026170                                        LR 0.002000    Time 0.207892    
2023-04-26 19:19:51,910 - Epoch: [17][  300/  518]    Overall Loss 4.039356    Objective Loss 4.039356                                        LR 0.002000    Time 0.207656    
2023-04-26 19:20:02,138 - Epoch: [17][  350/  518]    Overall Loss 4.039866    Objective Loss 4.039866                                        LR 0.002000    Time 0.207209    
2023-04-26 19:20:12,363 - Epoch: [17][  400/  518]    Overall Loss 4.037899    Objective Loss 4.037899                                        LR 0.002000    Time 0.206868    
2023-04-26 19:20:22,612 - Epoch: [17][  450/  518]    Overall Loss 4.039425    Objective Loss 4.039425                                        LR 0.002000    Time 0.206655    
2023-04-26 19:20:32,860 - Epoch: [17][  500/  518]    Overall Loss 4.033516    Objective Loss 4.033516                                        LR 0.002000    Time 0.206481    
2023-04-26 19:20:36,355 - Epoch: [17][  518/  518]    Overall Loss 4.035337    Objective Loss 4.035337                                        LR 0.002000    Time 0.206053    
2023-04-26 19:20:36,428 - --- validate (epoch=17)-----------
2023-04-26 19:20:36,428 - 4952 samples (32 per mini-batch)
2023-04-26 19:20:42,902 - Epoch: [17][   50/  155]    Loss 4.762335    mAP 0.131815    
2023-04-26 19:20:48,997 - Epoch: [17][  100/  155]    Loss 4.806852    mAP 0.128137    
2023-04-26 19:20:54,997 - Epoch: [17][  150/  155]    Loss 4.802011    mAP 0.121530    
2023-04-26 19:20:55,535 - Epoch: [17][  155/  155]    Loss 4.799436    mAP 0.120673    
2023-04-26 19:20:55,606 - ==> mAP: 0.12067    Loss: 4.799

2023-04-26 19:20:55,610 - ==> Best [mAP: 0.120673   vloss: 4.799436   Sparsity:0.00   Params: 2177088 on epoch: 17]
2023-04-26 19:20:55,610 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:20:55,662 - 

2023-04-26 19:20:55,662 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:21:06,614 - Epoch: [18][   50/  518]    Overall Loss 3.970579    Objective Loss 3.970579                                        LR 0.002000    Time 0.218986    
2023-04-26 19:21:16,837 - Epoch: [18][  100/  518]    Overall Loss 3.947567    Objective Loss 3.947567                                        LR 0.002000    Time 0.211701    
2023-04-26 19:21:26,989 - Epoch: [18][  150/  518]    Overall Loss 3.976780    Objective Loss 3.976780                                        LR 0.002000    Time 0.208804    
2023-04-26 19:21:37,229 - Epoch: [18][  200/  518]    Overall Loss 3.974091    Objective Loss 3.974091                                        LR 0.002000    Time 0.207797    
2023-04-26 19:21:47,383 - Epoch: [18][  250/  518]    Overall Loss 3.988732    Objective Loss 3.988732                                        LR 0.002000    Time 0.206846    
2023-04-26 19:21:57,566 - Epoch: [18][  300/  518]    Overall Loss 3.992228    Objective Loss 3.992228                                        LR 0.002000    Time 0.206308    
2023-04-26 19:22:07,873 - Epoch: [18][  350/  518]    Overall Loss 3.987963    Objective Loss 3.987963                                        LR 0.002000    Time 0.206280    
2023-04-26 19:22:18,115 - Epoch: [18][  400/  518]    Overall Loss 3.991340    Objective Loss 3.991340                                        LR 0.002000    Time 0.206095    
2023-04-26 19:22:28,420 - Epoch: [18][  450/  518]    Overall Loss 3.984131    Objective Loss 3.984131                                        LR 0.002000    Time 0.206092    
2023-04-26 19:22:38,603 - Epoch: [18][  500/  518]    Overall Loss 3.989479    Objective Loss 3.989479                                        LR 0.002000    Time 0.205846    
2023-04-26 19:22:42,174 - Epoch: [18][  518/  518]    Overall Loss 3.988706    Objective Loss 3.988706                                        LR 0.002000    Time 0.205585    
2023-04-26 19:22:42,245 - --- validate (epoch=18)-----------
2023-04-26 19:22:42,246 - 4952 samples (32 per mini-batch)
2023-04-26 19:22:48,313 - Epoch: [18][   50/  155]    Loss 4.251801    mAP 0.173031    
2023-04-26 19:22:53,995 - Epoch: [18][  100/  155]    Loss 4.231337    mAP 0.170363    
2023-04-26 19:22:59,676 - Epoch: [18][  150/  155]    Loss 4.226679    mAP 0.168388    
2023-04-26 19:23:00,180 - Epoch: [18][  155/  155]    Loss 4.226456    mAP 0.167918    
2023-04-26 19:23:00,261 - ==> mAP: 0.16792    Loss: 4.226

2023-04-26 19:23:00,265 - ==> Best [mAP: 0.167918   vloss: 4.226456   Sparsity:0.00   Params: 2177088 on epoch: 18]
2023-04-26 19:23:00,265 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:23:00,318 - 

2023-04-26 19:23:00,318 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:23:11,477 - Epoch: [19][   50/  518]    Overall Loss 4.001551    Objective Loss 4.001551                                        LR 0.002000    Time 0.223133    
2023-04-26 19:23:21,660 - Epoch: [19][  100/  518]    Overall Loss 3.995545    Objective Loss 3.995545                                        LR 0.002000    Time 0.213374    
2023-04-26 19:23:31,883 - Epoch: [19][  150/  518]    Overall Loss 3.996790    Objective Loss 3.996790                                        LR 0.002000    Time 0.210393    
2023-04-26 19:23:42,025 - Epoch: [19][  200/  518]    Overall Loss 3.989041    Objective Loss 3.989041                                        LR 0.002000    Time 0.208497    
2023-04-26 19:23:52,285 - Epoch: [19][  250/  518]    Overall Loss 3.978226    Objective Loss 3.978226                                        LR 0.002000    Time 0.207829    
2023-04-26 19:24:02,494 - Epoch: [19][  300/  518]    Overall Loss 3.972049    Objective Loss 3.972049                                        LR 0.002000    Time 0.207216    
2023-04-26 19:24:12,716 - Epoch: [19][  350/  518]    Overall Loss 3.960278    Objective Loss 3.960278                                        LR 0.002000    Time 0.206814    
2023-04-26 19:24:22,973 - Epoch: [19][  400/  518]    Overall Loss 3.957989    Objective Loss 3.957989                                        LR 0.002000    Time 0.206602    
2023-04-26 19:24:33,323 - Epoch: [19][  450/  518]    Overall Loss 3.961067    Objective Loss 3.961067                                        LR 0.002000    Time 0.206641    
2023-04-26 19:24:43,597 - Epoch: [19][  500/  518]    Overall Loss 3.961536    Objective Loss 3.961536                                        LR 0.002000    Time 0.206523    
2023-04-26 19:24:47,134 - Epoch: [19][  518/  518]    Overall Loss 3.956841    Objective Loss 3.956841                                        LR 0.002000    Time 0.206172    
2023-04-26 19:24:47,206 - --- validate (epoch=19)-----------
2023-04-26 19:24:47,207 - 4952 samples (32 per mini-batch)
2023-04-26 19:24:53,441 - Epoch: [19][   50/  155]    Loss 4.269452    mAP 0.142271    
2023-04-26 19:24:59,339 - Epoch: [19][  100/  155]    Loss 4.236129    mAP 0.147522    
2023-04-26 19:25:05,207 - Epoch: [19][  150/  155]    Loss 4.235864    mAP 0.149067    
2023-04-26 19:25:05,733 - Epoch: [19][  155/  155]    Loss 4.231082    mAP 0.150857    
2023-04-26 19:25:05,799 - ==> mAP: 0.15086    Loss: 4.231

2023-04-26 19:25:05,803 - ==> Best [mAP: 0.167918   vloss: 4.226456   Sparsity:0.00   Params: 2177088 on epoch: 18]
2023-04-26 19:25:05,803 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:25:05,908 - 

2023-04-26 19:25:05,909 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:25:16,935 - Epoch: [20][   50/  518]    Overall Loss 3.930722    Objective Loss 3.930722                                        LR 0.002000    Time 0.220481    
2023-04-26 19:25:27,190 - Epoch: [20][  100/  518]    Overall Loss 3.935600    Objective Loss 3.935600                                        LR 0.002000    Time 0.212764    
2023-04-26 19:25:37,405 - Epoch: [20][  150/  518]    Overall Loss 3.936906    Objective Loss 3.936906                                        LR 0.002000    Time 0.209932    
2023-04-26 19:25:47,658 - Epoch: [20][  200/  518]    Overall Loss 3.939340    Objective Loss 3.939340                                        LR 0.002000    Time 0.208709    
2023-04-26 19:25:58,039 - Epoch: [20][  250/  518]    Overall Loss 3.955782    Objective Loss 3.955782                                        LR 0.002000    Time 0.208485    
2023-04-26 19:26:08,279 - Epoch: [20][  300/  518]    Overall Loss 3.947473    Objective Loss 3.947473                                        LR 0.002000    Time 0.207866    
2023-04-26 19:26:18,508 - Epoch: [20][  350/  518]    Overall Loss 3.938997    Objective Loss 3.938997                                        LR 0.002000    Time 0.207391    
2023-04-26 19:26:28,810 - Epoch: [20][  400/  518]    Overall Loss 3.946688    Objective Loss 3.946688                                        LR 0.002000    Time 0.207219    
2023-04-26 19:26:39,090 - Epoch: [20][  450/  518]    Overall Loss 3.944617    Objective Loss 3.944617                                        LR 0.002000    Time 0.207034    
2023-04-26 19:26:49,271 - Epoch: [20][  500/  518]    Overall Loss 3.939596    Objective Loss 3.939596                                        LR 0.002000    Time 0.206690    
2023-04-26 19:26:52,776 - Epoch: [20][  518/  518]    Overall Loss 3.938067    Objective Loss 3.938067                                        LR 0.002000    Time 0.206273    
2023-04-26 19:26:52,847 - --- validate (epoch=20)-----------
2023-04-26 19:26:52,847 - 4952 samples (32 per mini-batch)
2023-04-26 19:26:59,200 - Epoch: [20][   50/  155]    Loss 4.565711    mAP 0.131542    
2023-04-26 19:27:05,091 - Epoch: [20][  100/  155]    Loss 4.575539    mAP 0.126785    
2023-04-26 19:27:11,005 - Epoch: [20][  150/  155]    Loss 4.588142    mAP 0.129081    
2023-04-26 19:27:11,537 - Epoch: [20][  155/  155]    Loss 4.592676    mAP 0.129046    
2023-04-26 19:27:11,610 - ==> mAP: 0.12905    Loss: 4.593

2023-04-26 19:27:11,613 - ==> Best [mAP: 0.167918   vloss: 4.226456   Sparsity:0.00   Params: 2177088 on epoch: 18]
2023-04-26 19:27:11,614 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:27:11,652 - 

2023-04-26 19:27:11,652 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:27:22,726 - Epoch: [21][   50/  518]    Overall Loss 3.908323    Objective Loss 3.908323                                        LR 0.002000    Time 0.221428    
2023-04-26 19:27:32,958 - Epoch: [21][  100/  518]    Overall Loss 3.895153    Objective Loss 3.895153                                        LR 0.002000    Time 0.213009    
2023-04-26 19:27:43,101 - Epoch: [21][  150/  518]    Overall Loss 3.894633    Objective Loss 3.894633                                        LR 0.002000    Time 0.209615    
2023-04-26 19:27:53,304 - Epoch: [21][  200/  518]    Overall Loss 3.908060    Objective Loss 3.908060                                        LR 0.002000    Time 0.208217    
2023-04-26 19:28:03,479 - Epoch: [21][  250/  518]    Overall Loss 3.896410    Objective Loss 3.896410                                        LR 0.002000    Time 0.207270    
2023-04-26 19:28:13,677 - Epoch: [21][  300/  518]    Overall Loss 3.905670    Objective Loss 3.905670                                        LR 0.002000    Time 0.206713    
2023-04-26 19:28:23,929 - Epoch: [21][  350/  518]    Overall Loss 3.911942    Objective Loss 3.911942                                        LR 0.002000    Time 0.206468    
2023-04-26 19:28:34,039 - Epoch: [21][  400/  518]    Overall Loss 3.902162    Objective Loss 3.902162                                        LR 0.002000    Time 0.205932    
2023-04-26 19:28:44,256 - Epoch: [21][  450/  518]    Overall Loss 3.898106    Objective Loss 3.898106                                        LR 0.002000    Time 0.205751    
2023-04-26 19:28:54,388 - Epoch: [21][  500/  518]    Overall Loss 3.899317    Objective Loss 3.899317                                        LR 0.002000    Time 0.205437    
2023-04-26 19:28:57,941 - Epoch: [21][  518/  518]    Overall Loss 3.903420    Objective Loss 3.903420                                        LR 0.002000    Time 0.205155    
2023-04-26 19:28:58,013 - --- validate (epoch=21)-----------
2023-04-26 19:28:58,013 - 4952 samples (32 per mini-batch)
2023-04-26 19:29:04,353 - Epoch: [21][   50/  155]    Loss 4.045565    mAP 0.202458    
2023-04-26 19:29:10,206 - Epoch: [21][  100/  155]    Loss 4.073936    mAP 0.203286    
2023-04-26 19:29:16,051 - Epoch: [21][  150/  155]    Loss 4.073577    mAP 0.202198    
2023-04-26 19:29:16,582 - Epoch: [21][  155/  155]    Loss 4.073908    mAP 0.202613    
2023-04-26 19:29:16,646 - ==> mAP: 0.20261    Loss: 4.074

2023-04-26 19:29:16,650 - ==> Best [mAP: 0.202613   vloss: 4.073908   Sparsity:0.00   Params: 2177088 on epoch: 21]
2023-04-26 19:29:16,650 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:29:16,703 - 

2023-04-26 19:29:16,703 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:29:27,746 - Epoch: [22][   50/  518]    Overall Loss 3.835769    Objective Loss 3.835769                                        LR 0.002000    Time 0.220792    
2023-04-26 19:29:37,971 - Epoch: [22][  100/  518]    Overall Loss 3.836642    Objective Loss 3.836642                                        LR 0.002000    Time 0.212632    
2023-04-26 19:29:48,193 - Epoch: [22][  150/  518]    Overall Loss 3.847628    Objective Loss 3.847628                                        LR 0.002000    Time 0.209888    
2023-04-26 19:29:58,414 - Epoch: [22][  200/  518]    Overall Loss 3.865865    Objective Loss 3.865865                                        LR 0.002000    Time 0.208514    
2023-04-26 19:30:08,678 - Epoch: [22][  250/  518]    Overall Loss 3.863067    Objective Loss 3.863067                                        LR 0.002000    Time 0.207863    
2023-04-26 19:30:18,907 - Epoch: [22][  300/  518]    Overall Loss 3.847202    Objective Loss 3.847202                                        LR 0.002000    Time 0.207308    
2023-04-26 19:30:29,219 - Epoch: [22][  350/  518]    Overall Loss 3.847502    Objective Loss 3.847502                                        LR 0.002000    Time 0.207152    
2023-04-26 19:30:39,424 - Epoch: [22][  400/  518]    Overall Loss 3.855860    Objective Loss 3.855860                                        LR 0.002000    Time 0.206765    
2023-04-26 19:30:49,684 - Epoch: [22][  450/  518]    Overall Loss 3.853795    Objective Loss 3.853795                                        LR 0.002000    Time 0.206589    
2023-04-26 19:30:59,862 - Epoch: [22][  500/  518]    Overall Loss 3.857798    Objective Loss 3.857798                                        LR 0.002000    Time 0.206282    
2023-04-26 19:31:03,446 - Epoch: [22][  518/  518]    Overall Loss 3.858813    Objective Loss 3.858813                                        LR 0.002000    Time 0.206032    
2023-04-26 19:31:03,519 - --- validate (epoch=22)-----------
2023-04-26 19:31:03,519 - 4952 samples (32 per mini-batch)
2023-04-26 19:31:09,988 - Epoch: [22][   50/  155]    Loss 4.445878    mAP 0.189565    
2023-04-26 19:31:16,048 - Epoch: [22][  100/  155]    Loss 4.429628    mAP 0.191483    
2023-04-26 19:31:22,134 - Epoch: [22][  150/  155]    Loss 4.408893    mAP 0.195891    
2023-04-26 19:31:22,663 - Epoch: [22][  155/  155]    Loss 4.409934    mAP 0.194164    
2023-04-26 19:31:22,734 - ==> mAP: 0.19416    Loss: 4.410

2023-04-26 19:31:22,738 - ==> Best [mAP: 0.202613   vloss: 4.073908   Sparsity:0.00   Params: 2177088 on epoch: 21]
2023-04-26 19:31:22,738 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:31:22,775 - 

2023-04-26 19:31:22,776 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:31:33,838 - Epoch: [23][   50/  518]    Overall Loss 3.869186    Objective Loss 3.869186                                        LR 0.002000    Time 0.221199    
2023-04-26 19:31:44,135 - Epoch: [23][  100/  518]    Overall Loss 3.829768    Objective Loss 3.829768                                        LR 0.002000    Time 0.213554    
2023-04-26 19:31:54,432 - Epoch: [23][  150/  518]    Overall Loss 3.855845    Objective Loss 3.855845                                        LR 0.002000    Time 0.210999    
2023-04-26 19:32:04,702 - Epoch: [23][  200/  518]    Overall Loss 3.846239    Objective Loss 3.846239                                        LR 0.002000    Time 0.209593    
2023-04-26 19:32:14,868 - Epoch: [23][  250/  518]    Overall Loss 3.844984    Objective Loss 3.844984                                        LR 0.002000    Time 0.208333    
2023-04-26 19:32:25,154 - Epoch: [23][  300/  518]    Overall Loss 3.843301    Objective Loss 3.843301                                        LR 0.002000    Time 0.207890    
2023-04-26 19:32:35,430 - Epoch: [23][  350/  518]    Overall Loss 3.839943    Objective Loss 3.839943                                        LR 0.002000    Time 0.207547    
2023-04-26 19:32:45,761 - Epoch: [23][  400/  518]    Overall Loss 3.837681    Objective Loss 3.837681                                        LR 0.002000    Time 0.207428    
2023-04-26 19:32:55,936 - Epoch: [23][  450/  518]    Overall Loss 3.835670    Objective Loss 3.835670                                        LR 0.002000    Time 0.206989    
2023-04-26 19:33:06,195 - Epoch: [23][  500/  518]    Overall Loss 3.843143    Objective Loss 3.843143                                        LR 0.002000    Time 0.206803    
2023-04-26 19:33:09,758 - Epoch: [23][  518/  518]    Overall Loss 3.840426    Objective Loss 3.840426                                        LR 0.002000    Time 0.206494    
2023-04-26 19:33:09,830 - --- validate (epoch=23)-----------
2023-04-26 19:33:09,830 - 4952 samples (32 per mini-batch)
2023-04-26 19:33:15,956 - Epoch: [23][   50/  155]    Loss 4.180120    mAP 0.185807    
2023-04-26 19:33:21,736 - Epoch: [23][  100/  155]    Loss 4.199617    mAP 0.195664    
2023-04-26 19:33:27,486 - Epoch: [23][  150/  155]    Loss 4.189676    mAP 0.194113    
2023-04-26 19:33:27,998 - Epoch: [23][  155/  155]    Loss 4.187840    mAP 0.194759    
2023-04-26 19:33:28,072 - ==> mAP: 0.19476    Loss: 4.188

2023-04-26 19:33:28,076 - ==> Best [mAP: 0.202613   vloss: 4.073908   Sparsity:0.00   Params: 2177088 on epoch: 21]
2023-04-26 19:33:28,076 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:33:28,114 - 

2023-04-26 19:33:28,114 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:33:39,165 - Epoch: [24][   50/  518]    Overall Loss 3.852586    Objective Loss 3.852586                                        LR 0.002000    Time 0.220965    
2023-04-26 19:33:49,492 - Epoch: [24][  100/  518]    Overall Loss 3.816194    Objective Loss 3.816194                                        LR 0.002000    Time 0.213735    
2023-04-26 19:33:59,723 - Epoch: [24][  150/  518]    Overall Loss 3.791940    Objective Loss 3.791940                                        LR 0.002000    Time 0.210685    
2023-04-26 19:34:10,057 - Epoch: [24][  200/  518]    Overall Loss 3.796997    Objective Loss 3.796997                                        LR 0.002000    Time 0.209679    
2023-04-26 19:34:20,331 - Epoch: [24][  250/  518]    Overall Loss 3.805953    Objective Loss 3.805953                                        LR 0.002000    Time 0.208831    
2023-04-26 19:34:30,521 - Epoch: [24][  300/  518]    Overall Loss 3.812328    Objective Loss 3.812328                                        LR 0.002000    Time 0.207986    
2023-04-26 19:34:40,742 - Epoch: [24][  350/  518]    Overall Loss 3.820318    Objective Loss 3.820318                                        LR 0.002000    Time 0.207474    
2023-04-26 19:34:50,961 - Epoch: [24][  400/  518]    Overall Loss 3.820000    Objective Loss 3.820000                                        LR 0.002000    Time 0.207081    
2023-04-26 19:35:01,131 - Epoch: [24][  450/  518]    Overall Loss 3.816098    Objective Loss 3.816098                                        LR 0.002000    Time 0.206669    
2023-04-26 19:35:11,448 - Epoch: [24][  500/  518]    Overall Loss 3.819255    Objective Loss 3.819255                                        LR 0.002000    Time 0.206633    
2023-04-26 19:35:15,041 - Epoch: [24][  518/  518]    Overall Loss 3.821565    Objective Loss 3.821565                                        LR 0.002000    Time 0.206387    
2023-04-26 19:35:15,112 - --- validate (epoch=24)-----------
2023-04-26 19:35:15,113 - 4952 samples (32 per mini-batch)
2023-04-26 19:35:21,318 - Epoch: [24][   50/  155]    Loss 4.332407    mAP 0.180267    
2023-04-26 19:35:27,294 - Epoch: [24][  100/  155]    Loss 4.284126    mAP 0.179955    
2023-04-26 19:35:33,172 - Epoch: [24][  150/  155]    Loss 4.283788    mAP 0.177347    
2023-04-26 19:35:33,691 - Epoch: [24][  155/  155]    Loss 4.284801    mAP 0.177002    
2023-04-26 19:35:33,761 - ==> mAP: 0.17700    Loss: 4.285

2023-04-26 19:35:33,765 - ==> Best [mAP: 0.202613   vloss: 4.073908   Sparsity:0.00   Params: 2177088 on epoch: 21]
2023-04-26 19:35:33,765 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:35:33,802 - 

2023-04-26 19:35:33,802 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:35:44,748 - Epoch: [25][   50/  518]    Overall Loss 3.780812    Objective Loss 3.780812                                        LR 0.002000    Time 0.218849    
2023-04-26 19:35:55,128 - Epoch: [25][  100/  518]    Overall Loss 3.791213    Objective Loss 3.791213                                        LR 0.002000    Time 0.213211    
2023-04-26 19:36:05,359 - Epoch: [25][  150/  518]    Overall Loss 3.790964    Objective Loss 3.790964                                        LR 0.002000    Time 0.210336    
2023-04-26 19:36:15,618 - Epoch: [25][  200/  518]    Overall Loss 3.788943    Objective Loss 3.788943                                        LR 0.002000    Time 0.209041    
2023-04-26 19:36:25,868 - Epoch: [25][  250/  518]    Overall Loss 3.784437    Objective Loss 3.784437                                        LR 0.002000    Time 0.208225    
2023-04-26 19:36:36,185 - Epoch: [25][  300/  518]    Overall Loss 3.796403    Objective Loss 3.796403                                        LR 0.002000    Time 0.207907    
2023-04-26 19:36:46,434 - Epoch: [25][  350/  518]    Overall Loss 3.788934    Objective Loss 3.788934                                        LR 0.002000    Time 0.207484    
2023-04-26 19:36:56,635 - Epoch: [25][  400/  518]    Overall Loss 3.792496    Objective Loss 3.792496                                        LR 0.002000    Time 0.207046    
2023-04-26 19:37:06,790 - Epoch: [25][  450/  518]    Overall Loss 3.789324    Objective Loss 3.789324                                        LR 0.002000    Time 0.206604    
2023-04-26 19:37:17,052 - Epoch: [25][  500/  518]    Overall Loss 3.786370    Objective Loss 3.786370                                        LR 0.002000    Time 0.206463    
2023-04-26 19:37:20,621 - Epoch: [25][  518/  518]    Overall Loss 3.785088    Objective Loss 3.785088                                        LR 0.002000    Time 0.206178    
2023-04-26 19:37:20,694 - --- validate (epoch=25)-----------
2023-04-26 19:37:20,694 - 4952 samples (32 per mini-batch)
2023-04-26 19:37:26,885 - Epoch: [25][   50/  155]    Loss 4.178306    mAP 0.182515    
2023-04-26 19:37:32,692 - Epoch: [25][  100/  155]    Loss 4.171574    mAP 0.186471    
2023-04-26 19:37:38,488 - Epoch: [25][  150/  155]    Loss 4.170928    mAP 0.193311    
2023-04-26 19:37:38,997 - Epoch: [25][  155/  155]    Loss 4.164609    mAP 0.192613    
2023-04-26 19:37:39,059 - ==> mAP: 0.19261    Loss: 4.165

2023-04-26 19:37:39,063 - ==> Best [mAP: 0.202613   vloss: 4.073908   Sparsity:0.00   Params: 2177088 on epoch: 21]
2023-04-26 19:37:39,063 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:37:39,100 - 

2023-04-26 19:37:39,100 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:37:49,978 - Epoch: [26][   50/  518]    Overall Loss 3.813190    Objective Loss 3.813190                                        LR 0.002000    Time 0.217500    
2023-04-26 19:38:00,245 - Epoch: [26][  100/  518]    Overall Loss 3.786629    Objective Loss 3.786629                                        LR 0.002000    Time 0.211400    
2023-04-26 19:38:10,494 - Epoch: [26][  150/  518]    Overall Loss 3.792274    Objective Loss 3.792274                                        LR 0.002000    Time 0.209252    
2023-04-26 19:38:20,641 - Epoch: [26][  200/  518]    Overall Loss 3.768918    Objective Loss 3.768918                                        LR 0.002000    Time 0.207668    
2023-04-26 19:38:30,838 - Epoch: [26][  250/  518]    Overall Loss 3.761646    Objective Loss 3.761646                                        LR 0.002000    Time 0.206914    
2023-04-26 19:38:40,989 - Epoch: [26][  300/  518]    Overall Loss 3.766099    Objective Loss 3.766099                                        LR 0.002000    Time 0.206259    
2023-04-26 19:38:51,226 - Epoch: [26][  350/  518]    Overall Loss 3.769137    Objective Loss 3.769137                                        LR 0.002000    Time 0.206037    
2023-04-26 19:39:01,464 - Epoch: [26][  400/  518]    Overall Loss 3.776168    Objective Loss 3.776168                                        LR 0.002000    Time 0.205874    
2023-04-26 19:39:11,613 - Epoch: [26][  450/  518]    Overall Loss 3.776124    Objective Loss 3.776124                                        LR 0.002000    Time 0.205548    
2023-04-26 19:39:21,990 - Epoch: [26][  500/  518]    Overall Loss 3.775858    Objective Loss 3.775858                                        LR 0.002000    Time 0.205745    
2023-04-26 19:39:25,569 - Epoch: [26][  518/  518]    Overall Loss 3.776813    Objective Loss 3.776813                                        LR 0.002000    Time 0.205504    
2023-04-26 19:39:25,641 - --- validate (epoch=26)-----------
2023-04-26 19:39:25,642 - 4952 samples (32 per mini-batch)
2023-04-26 19:39:31,821 - Epoch: [26][   50/  155]    Loss 4.097317    mAP 0.206061    
2023-04-26 19:39:37,665 - Epoch: [26][  100/  155]    Loss 4.058297    mAP 0.214264    
2023-04-26 19:39:43,521 - Epoch: [26][  150/  155]    Loss 4.050810    mAP 0.214144    
2023-04-26 19:39:44,034 - Epoch: [26][  155/  155]    Loss 4.050778    mAP 0.214986    
2023-04-26 19:39:44,104 - ==> mAP: 0.21499    Loss: 4.051

2023-04-26 19:39:44,107 - ==> Best [mAP: 0.214986   vloss: 4.050778   Sparsity:0.00   Params: 2177088 on epoch: 26]
2023-04-26 19:39:44,107 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:39:44,160 - 

2023-04-26 19:39:44,160 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:39:55,109 - Epoch: [27][   50/  518]    Overall Loss 3.735010    Objective Loss 3.735010                                        LR 0.002000    Time 0.218922    
2023-04-26 19:40:05,505 - Epoch: [27][  100/  518]    Overall Loss 3.758400    Objective Loss 3.758400                                        LR 0.002000    Time 0.213408    
2023-04-26 19:40:15,619 - Epoch: [27][  150/  518]    Overall Loss 3.750613    Objective Loss 3.750613                                        LR 0.002000    Time 0.209686    
2023-04-26 19:40:25,843 - Epoch: [27][  200/  518]    Overall Loss 3.746376    Objective Loss 3.746376                                        LR 0.002000    Time 0.208375    
2023-04-26 19:40:36,062 - Epoch: [27][  250/  518]    Overall Loss 3.750954    Objective Loss 3.750954                                        LR 0.002000    Time 0.207572    
2023-04-26 19:40:46,399 - Epoch: [27][  300/  518]    Overall Loss 3.754447    Objective Loss 3.754447                                        LR 0.002000    Time 0.207425    
2023-04-26 19:40:56,675 - Epoch: [27][  350/  518]    Overall Loss 3.744555    Objective Loss 3.744555                                        LR 0.002000    Time 0.207150    
2023-04-26 19:41:06,903 - Epoch: [27][  400/  518]    Overall Loss 3.739720    Objective Loss 3.739720                                        LR 0.002000    Time 0.206820    
2023-04-26 19:41:17,153 - Epoch: [27][  450/  518]    Overall Loss 3.742962    Objective Loss 3.742962                                        LR 0.002000    Time 0.206616    
2023-04-26 19:41:27,391 - Epoch: [27][  500/  518]    Overall Loss 3.740664    Objective Loss 3.740664                                        LR 0.002000    Time 0.206426    
2023-04-26 19:41:31,020 - Epoch: [27][  518/  518]    Overall Loss 3.741702    Objective Loss 3.741702                                        LR 0.002000    Time 0.206258    
2023-04-26 19:41:31,091 - --- validate (epoch=27)-----------
2023-04-26 19:41:31,091 - 4952 samples (32 per mini-batch)
2023-04-26 19:41:37,275 - Epoch: [27][   50/  155]    Loss 4.034730    mAP 0.212614    
2023-04-26 19:41:43,111 - Epoch: [27][  100/  155]    Loss 4.050146    mAP 0.217550    
2023-04-26 19:41:48,960 - Epoch: [27][  150/  155]    Loss 4.054650    mAP 0.222874    
2023-04-26 19:41:49,484 - Epoch: [27][  155/  155]    Loss 4.051917    mAP 0.224382    
2023-04-26 19:41:49,555 - ==> mAP: 0.22438    Loss: 4.052

2023-04-26 19:41:49,559 - ==> Best [mAP: 0.224382   vloss: 4.051917   Sparsity:0.00   Params: 2177088 on epoch: 27]
2023-04-26 19:41:49,559 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:41:49,611 - 

2023-04-26 19:41:49,611 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:42:00,579 - Epoch: [28][   50/  518]    Overall Loss 3.793618    Objective Loss 3.793618                                        LR 0.002000    Time 0.219293    
2023-04-26 19:42:10,759 - Epoch: [28][  100/  518]    Overall Loss 3.783070    Objective Loss 3.783070                                        LR 0.002000    Time 0.211428    
2023-04-26 19:42:20,873 - Epoch: [28][  150/  518]    Overall Loss 3.757351    Objective Loss 3.757351                                        LR 0.002000    Time 0.208373    
2023-04-26 19:42:31,207 - Epoch: [28][  200/  518]    Overall Loss 3.750747    Objective Loss 3.750747                                        LR 0.002000    Time 0.207940    
2023-04-26 19:42:41,443 - Epoch: [28][  250/  518]    Overall Loss 3.743433    Objective Loss 3.743433                                        LR 0.002000    Time 0.207290    
2023-04-26 19:42:51,638 - Epoch: [28][  300/  518]    Overall Loss 3.739596    Objective Loss 3.739596                                        LR 0.002000    Time 0.206717    
2023-04-26 19:43:01,807 - Epoch: [28][  350/  518]    Overall Loss 3.738357    Objective Loss 3.738357                                        LR 0.002000    Time 0.206237    
2023-04-26 19:43:12,021 - Epoch: [28][  400/  518]    Overall Loss 3.733618    Objective Loss 3.733618                                        LR 0.002000    Time 0.205987    
2023-04-26 19:43:22,272 - Epoch: [28][  450/  518]    Overall Loss 3.731523    Objective Loss 3.731523                                        LR 0.002000    Time 0.205877    
2023-04-26 19:43:32,520 - Epoch: [28][  500/  518]    Overall Loss 3.728978    Objective Loss 3.728978                                        LR 0.002000    Time 0.205782    
2023-04-26 19:43:36,097 - Epoch: [28][  518/  518]    Overall Loss 3.729820    Objective Loss 3.729820                                        LR 0.002000    Time 0.205536    
2023-04-26 19:43:36,168 - --- validate (epoch=28)-----------
2023-04-26 19:43:36,169 - 4952 samples (32 per mini-batch)
2023-04-26 19:43:42,674 - Epoch: [28][   50/  155]    Loss 3.996921    mAP 0.238958    
2023-04-26 19:43:48,796 - Epoch: [28][  100/  155]    Loss 3.998303    mAP 0.241040    
2023-04-26 19:43:54,975 - Epoch: [28][  150/  155]    Loss 3.959077    mAP 0.244770    
2023-04-26 19:43:55,539 - Epoch: [28][  155/  155]    Loss 3.956869    mAP 0.244790    
2023-04-26 19:43:55,609 - ==> mAP: 0.24479    Loss: 3.957

2023-04-26 19:43:55,613 - ==> Best [mAP: 0.244790   vloss: 3.956869   Sparsity:0.00   Params: 2177088 on epoch: 28]
2023-04-26 19:43:55,613 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:43:55,664 - 

2023-04-26 19:43:55,664 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:44:06,598 - Epoch: [29][   50/  518]    Overall Loss 3.756586    Objective Loss 3.756586                                        LR 0.002000    Time 0.218626    
2023-04-26 19:44:16,818 - Epoch: [29][  100/  518]    Overall Loss 3.722885    Objective Loss 3.722885                                        LR 0.002000    Time 0.211493    
2023-04-26 19:44:27,104 - Epoch: [29][  150/  518]    Overall Loss 3.723105    Objective Loss 3.723105                                        LR 0.002000    Time 0.209556    
2023-04-26 19:44:37,311 - Epoch: [29][  200/  518]    Overall Loss 3.705128    Objective Loss 3.705128                                        LR 0.002000    Time 0.208198    
2023-04-26 19:44:47,618 - Epoch: [29][  250/  518]    Overall Loss 3.718329    Objective Loss 3.718329                                        LR 0.002000    Time 0.207777    
2023-04-26 19:44:57,744 - Epoch: [29][  300/  518]    Overall Loss 3.704645    Objective Loss 3.704645                                        LR 0.002000    Time 0.206897    
2023-04-26 19:45:08,048 - Epoch: [29][  350/  518]    Overall Loss 3.705383    Objective Loss 3.705383                                        LR 0.002000    Time 0.206776    
2023-04-26 19:45:18,358 - Epoch: [29][  400/  518]    Overall Loss 3.709987    Objective Loss 3.709987                                        LR 0.002000    Time 0.206699    
2023-04-26 19:45:28,623 - Epoch: [29][  450/  518]    Overall Loss 3.708574    Objective Loss 3.708574                                        LR 0.002000    Time 0.206541    
2023-04-26 19:45:39,012 - Epoch: [29][  500/  518]    Overall Loss 3.704994    Objective Loss 3.704994                                        LR 0.002000    Time 0.206660    
2023-04-26 19:45:42,624 - Epoch: [29][  518/  518]    Overall Loss 3.705613    Objective Loss 3.705613                                        LR 0.002000    Time 0.206450    
2023-04-26 19:45:42,695 - --- validate (epoch=29)-----------
2023-04-26 19:45:42,695 - 4952 samples (32 per mini-batch)
2023-04-26 19:45:49,021 - Epoch: [29][   50/  155]    Loss 4.020824    mAP 0.251332    
2023-04-26 19:45:54,915 - Epoch: [29][  100/  155]    Loss 3.995273    mAP 0.247810    
2023-04-26 19:46:00,817 - Epoch: [29][  150/  155]    Loss 3.990509    mAP 0.236123    
2023-04-26 19:46:01,343 - Epoch: [29][  155/  155]    Loss 3.993245    mAP 0.234295    
2023-04-26 19:46:01,405 - ==> mAP: 0.23429    Loss: 3.993

2023-04-26 19:46:01,409 - ==> Best [mAP: 0.244790   vloss: 3.956869   Sparsity:0.00   Params: 2177088 on epoch: 28]
2023-04-26 19:46:01,409 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:46:01,471 - 

2023-04-26 19:46:01,471 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:46:12,471 - Epoch: [30][   50/  518]    Overall Loss 3.675683    Objective Loss 3.675683                                        LR 0.002000    Time 0.219910    
2023-04-26 19:46:22,648 - Epoch: [30][  100/  518]    Overall Loss 3.712482    Objective Loss 3.712482                                        LR 0.002000    Time 0.211708    
2023-04-26 19:46:32,913 - Epoch: [30][  150/  518]    Overall Loss 3.693862    Objective Loss 3.693862                                        LR 0.002000    Time 0.209560    
2023-04-26 19:46:43,155 - Epoch: [30][  200/  518]    Overall Loss 3.696428    Objective Loss 3.696428                                        LR 0.002000    Time 0.208372    
2023-04-26 19:46:53,516 - Epoch: [30][  250/  518]    Overall Loss 3.707046    Objective Loss 3.707046                                        LR 0.002000    Time 0.208133    
2023-04-26 19:47:03,734 - Epoch: [30][  300/  518]    Overall Loss 3.708627    Objective Loss 3.708627                                        LR 0.002000    Time 0.207500    
2023-04-26 19:47:13,998 - Epoch: [30][  350/  518]    Overall Loss 3.699401    Objective Loss 3.699401                                        LR 0.002000    Time 0.207179    
2023-04-26 19:47:24,261 - Epoch: [30][  400/  518]    Overall Loss 3.692252    Objective Loss 3.692252                                        LR 0.002000    Time 0.206933    
2023-04-26 19:47:34,462 - Epoch: [30][  450/  518]    Overall Loss 3.699528    Objective Loss 3.699528                                        LR 0.002000    Time 0.206606    
2023-04-26 19:47:44,675 - Epoch: [30][  500/  518]    Overall Loss 3.699541    Objective Loss 3.699541                                        LR 0.002000    Time 0.206369    
2023-04-26 19:47:48,209 - Epoch: [30][  518/  518]    Overall Loss 3.700829    Objective Loss 3.700829                                        LR 0.002000    Time 0.206019    
2023-04-26 19:47:48,281 - --- validate (epoch=30)-----------
2023-04-26 19:47:48,282 - 4952 samples (32 per mini-batch)
2023-04-26 19:47:54,683 - Epoch: [30][   50/  155]    Loss 4.046191    mAP 0.231719    
2023-04-26 19:48:00,684 - Epoch: [30][  100/  155]    Loss 3.991807    mAP 0.229803    
2023-04-26 19:48:06,686 - Epoch: [30][  150/  155]    Loss 4.003231    mAP 0.227844    
2023-04-26 19:48:07,222 - Epoch: [30][  155/  155]    Loss 4.001645    mAP 0.227649    
2023-04-26 19:48:07,291 - ==> mAP: 0.22765    Loss: 4.002

2023-04-26 19:48:07,295 - ==> Best [mAP: 0.244790   vloss: 3.956869   Sparsity:0.00   Params: 2177088 on epoch: 28]
2023-04-26 19:48:07,295 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:48:07,332 - 

2023-04-26 19:48:07,332 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:48:18,320 - Epoch: [31][   50/  518]    Overall Loss 3.676557    Objective Loss 3.676557                                        LR 0.002000    Time 0.219686    
2023-04-26 19:48:28,566 - Epoch: [31][  100/  518]    Overall Loss 3.667549    Objective Loss 3.667549                                        LR 0.002000    Time 0.212293    
2023-04-26 19:48:38,806 - Epoch: [31][  150/  518]    Overall Loss 3.662500    Objective Loss 3.662500                                        LR 0.002000    Time 0.209786    
2023-04-26 19:48:48,946 - Epoch: [31][  200/  518]    Overall Loss 3.668876    Objective Loss 3.668876                                        LR 0.002000    Time 0.208030    
2023-04-26 19:48:59,267 - Epoch: [31][  250/  518]    Overall Loss 3.679939    Objective Loss 3.679939                                        LR 0.002000    Time 0.207699    
2023-04-26 19:49:09,418 - Epoch: [31][  300/  518]    Overall Loss 3.678177    Objective Loss 3.678177                                        LR 0.002000    Time 0.206915    
2023-04-26 19:49:19,649 - Epoch: [31][  350/  518]    Overall Loss 3.679737    Objective Loss 3.679737                                        LR 0.002000    Time 0.206584    
2023-04-26 19:49:29,768 - Epoch: [31][  400/  518]    Overall Loss 3.685045    Objective Loss 3.685045                                        LR 0.002000    Time 0.206054    
2023-04-26 19:49:40,023 - Epoch: [31][  450/  518]    Overall Loss 3.688929    Objective Loss 3.688929                                        LR 0.002000    Time 0.205943    
2023-04-26 19:49:50,162 - Epoch: [31][  500/  518]    Overall Loss 3.682723    Objective Loss 3.682723                                        LR 0.002000    Time 0.205623    
2023-04-26 19:49:53,736 - Epoch: [31][  518/  518]    Overall Loss 3.686206    Objective Loss 3.686206                                        LR 0.002000    Time 0.205377    
2023-04-26 19:49:53,808 - --- validate (epoch=31)-----------
2023-04-26 19:49:53,808 - 4952 samples (32 per mini-batch)
2023-04-26 19:50:00,279 - Epoch: [31][   50/  155]    Loss 4.071385    mAP 0.216501    
2023-04-26 19:50:06,482 - Epoch: [31][  100/  155]    Loss 4.040853    mAP 0.226701    
2023-04-26 19:50:12,577 - Epoch: [31][  150/  155]    Loss 4.045206    mAP 0.221586    
2023-04-26 19:50:13,108 - Epoch: [31][  155/  155]    Loss 4.039146    mAP 0.223440    
2023-04-26 19:50:13,181 - ==> mAP: 0.22344    Loss: 4.039

2023-04-26 19:50:13,184 - ==> Best [mAP: 0.244790   vloss: 3.956869   Sparsity:0.00   Params: 2177088 on epoch: 28]
2023-04-26 19:50:13,185 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:50:13,222 - 

2023-04-26 19:50:13,222 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:50:24,256 - Epoch: [32][   50/  518]    Overall Loss 3.622508    Objective Loss 3.622508                                        LR 0.002000    Time 0.220619    
2023-04-26 19:50:34,459 - Epoch: [32][  100/  518]    Overall Loss 3.621469    Objective Loss 3.621469                                        LR 0.002000    Time 0.212327    
2023-04-26 19:50:44,654 - Epoch: [32][  150/  518]    Overall Loss 3.639146    Objective Loss 3.639146                                        LR 0.002000    Time 0.209505    
2023-04-26 19:50:54,893 - Epoch: [32][  200/  518]    Overall Loss 3.640208    Objective Loss 3.640208                                        LR 0.002000    Time 0.208316    
2023-04-26 19:51:05,123 - Epoch: [32][  250/  518]    Overall Loss 3.658617    Objective Loss 3.658617                                        LR 0.002000    Time 0.207565    
2023-04-26 19:51:15,376 - Epoch: [32][  300/  518]    Overall Loss 3.663944    Objective Loss 3.663944                                        LR 0.002000    Time 0.207144    
2023-04-26 19:51:25,527 - Epoch: [32][  350/  518]    Overall Loss 3.656344    Objective Loss 3.656344                                        LR 0.002000    Time 0.206550    
2023-04-26 19:51:35,726 - Epoch: [32][  400/  518]    Overall Loss 3.657006    Objective Loss 3.657006                                        LR 0.002000    Time 0.206224    
2023-04-26 19:51:45,963 - Epoch: [32][  450/  518]    Overall Loss 3.648701    Objective Loss 3.648701                                        LR 0.002000    Time 0.206056    
2023-04-26 19:51:56,114 - Epoch: [32][  500/  518]    Overall Loss 3.650677    Objective Loss 3.650677                                        LR 0.002000    Time 0.205749    
2023-04-26 19:51:59,632 - Epoch: [32][  518/  518]    Overall Loss 3.656804    Objective Loss 3.656804                                        LR 0.002000    Time 0.205389    
2023-04-26 19:51:59,704 - --- validate (epoch=32)-----------
2023-04-26 19:51:59,705 - 4952 samples (32 per mini-batch)
2023-04-26 19:52:06,251 - Epoch: [32][   50/  155]    Loss 4.161220    mAP 0.220729    
2023-04-26 19:52:12,371 - Epoch: [32][  100/  155]    Loss 4.140896    mAP 0.217663    
2023-04-26 19:52:18,491 - Epoch: [32][  150/  155]    Loss 4.170464    mAP 0.213553    
2023-04-26 19:52:19,034 - Epoch: [32][  155/  155]    Loss 4.173628    mAP 0.213481    
2023-04-26 19:52:19,100 - ==> mAP: 0.21348    Loss: 4.174

2023-04-26 19:52:19,103 - ==> Best [mAP: 0.244790   vloss: 3.956869   Sparsity:0.00   Params: 2177088 on epoch: 28]
2023-04-26 19:52:19,103 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:52:19,141 - 

2023-04-26 19:52:19,141 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:52:30,156 - Epoch: [33][   50/  518]    Overall Loss 3.814897    Objective Loss 3.814897                                        LR 0.002000    Time 0.220241    
2023-04-26 19:52:40,403 - Epoch: [33][  100/  518]    Overall Loss 3.734574    Objective Loss 3.734574                                        LR 0.002000    Time 0.212570    
2023-04-26 19:52:50,604 - Epoch: [33][  150/  518]    Overall Loss 3.715674    Objective Loss 3.715674                                        LR 0.002000    Time 0.209715    
2023-04-26 19:53:00,811 - Epoch: [33][  200/  518]    Overall Loss 3.700233    Objective Loss 3.700233                                        LR 0.002000    Time 0.208310    
2023-04-26 19:53:11,065 - Epoch: [33][  250/  518]    Overall Loss 3.689503    Objective Loss 3.689503                                        LR 0.002000    Time 0.207658    
2023-04-26 19:53:21,311 - Epoch: [33][  300/  518]    Overall Loss 3.679951    Objective Loss 3.679951                                        LR 0.002000    Time 0.207198    
2023-04-26 19:53:31,528 - Epoch: [33][  350/  518]    Overall Loss 3.682826    Objective Loss 3.682826                                        LR 0.002000    Time 0.206785    
2023-04-26 19:53:41,788 - Epoch: [33][  400/  518]    Overall Loss 3.686880    Objective Loss 3.686880                                        LR 0.002000    Time 0.206583    
2023-04-26 19:53:52,090 - Epoch: [33][  450/  518]    Overall Loss 3.685774    Objective Loss 3.685774                                        LR 0.002000    Time 0.206517    
2023-04-26 19:54:02,387 - Epoch: [33][  500/  518]    Overall Loss 3.678560    Objective Loss 3.678560                                        LR 0.002000    Time 0.206457    
2023-04-26 19:54:05,962 - Epoch: [33][  518/  518]    Overall Loss 3.681652    Objective Loss 3.681652                                        LR 0.002000    Time 0.206182    
2023-04-26 19:54:06,033 - --- validate (epoch=33)-----------
2023-04-26 19:54:06,033 - 4952 samples (32 per mini-batch)
2023-04-26 19:54:12,477 - Epoch: [33][   50/  155]    Loss 3.864882    mAP 0.261107    
2023-04-26 19:54:18,567 - Epoch: [33][  100/  155]    Loss 3.880147    mAP 0.255303    
2023-04-26 19:54:24,607 - Epoch: [33][  150/  155]    Loss 3.882949    mAP 0.254966    
2023-04-26 19:54:25,137 - Epoch: [33][  155/  155]    Loss 3.877640    mAP 0.253832    
2023-04-26 19:54:25,207 - ==> mAP: 0.25383    Loss: 3.878

2023-04-26 19:54:25,211 - ==> Best [mAP: 0.253832   vloss: 3.877640   Sparsity:0.00   Params: 2177088 on epoch: 33]
2023-04-26 19:54:25,211 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:54:25,263 - 

2023-04-26 19:54:25,263 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:54:36,254 - Epoch: [34][   50/  518]    Overall Loss 3.577139    Objective Loss 3.577139                                        LR 0.002000    Time 0.219770    
2023-04-26 19:54:46,513 - Epoch: [34][  100/  518]    Overall Loss 3.557859    Objective Loss 3.557859                                        LR 0.002000    Time 0.212453    
2023-04-26 19:54:56,729 - Epoch: [34][  150/  518]    Overall Loss 3.567130    Objective Loss 3.567130                                        LR 0.002000    Time 0.209733    
2023-04-26 19:55:07,037 - Epoch: [34][  200/  518]    Overall Loss 3.570533    Objective Loss 3.570533                                        LR 0.002000    Time 0.208830    
2023-04-26 19:55:17,237 - Epoch: [34][  250/  518]    Overall Loss 3.578371    Objective Loss 3.578371                                        LR 0.002000    Time 0.207858    
2023-04-26 19:55:27,418 - Epoch: [34][  300/  518]    Overall Loss 3.585870    Objective Loss 3.585870                                        LR 0.002000    Time 0.207147    
2023-04-26 19:55:37,671 - Epoch: [34][  350/  518]    Overall Loss 3.599762    Objective Loss 3.599762                                        LR 0.002000    Time 0.206844    
2023-04-26 19:55:47,814 - Epoch: [34][  400/  518]    Overall Loss 3.605205    Objective Loss 3.605205                                        LR 0.002000    Time 0.206343    
2023-04-26 19:55:58,088 - Epoch: [34][  450/  518]    Overall Loss 3.608041    Objective Loss 3.608041                                        LR 0.002000    Time 0.206242    
2023-04-26 19:56:08,298 - Epoch: [34][  500/  518]    Overall Loss 3.608538    Objective Loss 3.608538                                        LR 0.002000    Time 0.206034    
2023-04-26 19:56:11,846 - Epoch: [34][  518/  518]    Overall Loss 3.609947    Objective Loss 3.609947                                        LR 0.002000    Time 0.205725    
2023-04-26 19:56:11,917 - --- validate (epoch=34)-----------
2023-04-26 19:56:11,917 - 4952 samples (32 per mini-batch)
2023-04-26 19:56:18,336 - Epoch: [34][   50/  155]    Loss 3.938545    mAP 0.276593    
2023-04-26 19:56:24,441 - Epoch: [34][  100/  155]    Loss 3.924729    mAP 0.274265    
2023-04-26 19:56:30,524 - Epoch: [34][  150/  155]    Loss 3.902601    mAP 0.281820    
2023-04-26 19:56:31,057 - Epoch: [34][  155/  155]    Loss 3.908049    mAP 0.282017    
2023-04-26 19:56:31,127 - ==> mAP: 0.28202    Loss: 3.908

2023-04-26 19:56:31,130 - ==> Best [mAP: 0.282017   vloss: 3.908049   Sparsity:0.00   Params: 2177088 on epoch: 34]
2023-04-26 19:56:31,131 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:56:31,181 - 

2023-04-26 19:56:31,182 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:56:42,172 - Epoch: [35][   50/  518]    Overall Loss 3.674274    Objective Loss 3.674274                                        LR 0.002000    Time 0.219753    
2023-04-26 19:56:52,397 - Epoch: [35][  100/  518]    Overall Loss 3.631758    Objective Loss 3.631758                                        LR 0.002000    Time 0.212114    
2023-04-26 19:57:02,686 - Epoch: [35][  150/  518]    Overall Loss 3.635628    Objective Loss 3.635628                                        LR 0.002000    Time 0.209989    
2023-04-26 19:57:12,911 - Epoch: [35][  200/  518]    Overall Loss 3.622842    Objective Loss 3.622842                                        LR 0.002000    Time 0.208610    
2023-04-26 19:57:23,105 - Epoch: [35][  250/  518]    Overall Loss 3.622560    Objective Loss 3.622560                                        LR 0.002000    Time 0.207656    
2023-04-26 19:57:33,356 - Epoch: [35][  300/  518]    Overall Loss 3.613039    Objective Loss 3.613039                                        LR 0.002000    Time 0.207212    
2023-04-26 19:57:43,449 - Epoch: [35][  350/  518]    Overall Loss 3.611793    Objective Loss 3.611793                                        LR 0.002000    Time 0.206443    
2023-04-26 19:57:53,746 - Epoch: [35][  400/  518]    Overall Loss 3.612367    Objective Loss 3.612367                                        LR 0.002000    Time 0.206375    
2023-04-26 19:58:04,008 - Epoch: [35][  450/  518]    Overall Loss 3.605167    Objective Loss 3.605167                                        LR 0.002000    Time 0.206246    
2023-04-26 19:58:14,237 - Epoch: [35][  500/  518]    Overall Loss 3.607668    Objective Loss 3.607668                                        LR 0.002000    Time 0.206075    
2023-04-26 19:58:17,811 - Epoch: [35][  518/  518]    Overall Loss 3.613131    Objective Loss 3.613131                                        LR 0.002000    Time 0.205813    
2023-04-26 19:58:17,882 - --- validate (epoch=35)-----------
2023-04-26 19:58:17,883 - 4952 samples (32 per mini-batch)
2023-04-26 19:58:24,325 - Epoch: [35][   50/  155]    Loss 3.782484    mAP 0.274633    
2023-04-26 19:58:30,437 - Epoch: [35][  100/  155]    Loss 3.781611    mAP 0.274225    
2023-04-26 19:58:36,540 - Epoch: [35][  150/  155]    Loss 3.762132    mAP 0.282572    
2023-04-26 19:58:37,088 - Epoch: [35][  155/  155]    Loss 3.764001    mAP 0.282334    
2023-04-26 19:58:37,163 - ==> mAP: 0.28233    Loss: 3.764

2023-04-26 19:58:37,167 - ==> Best [mAP: 0.282334   vloss: 3.764001   Sparsity:0.00   Params: 2177088 on epoch: 35]
2023-04-26 19:58:37,167 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 19:58:37,217 - 

2023-04-26 19:58:37,217 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 19:58:48,325 - Epoch: [36][   50/  518]    Overall Loss 3.571954    Objective Loss 3.571954                                        LR 0.002000    Time 0.222087    
2023-04-26 19:58:58,542 - Epoch: [36][  100/  518]    Overall Loss 3.575150    Objective Loss 3.575150                                        LR 0.002000    Time 0.213202    
2023-04-26 19:59:08,706 - Epoch: [36][  150/  518]    Overall Loss 3.573098    Objective Loss 3.573098                                        LR 0.002000    Time 0.209883    
2023-04-26 19:59:18,994 - Epoch: [36][  200/  518]    Overall Loss 3.579652    Objective Loss 3.579652                                        LR 0.002000    Time 0.208842    
2023-04-26 19:59:29,234 - Epoch: [36][  250/  518]    Overall Loss 3.573026    Objective Loss 3.573026                                        LR 0.002000    Time 0.208030    
2023-04-26 19:59:39,467 - Epoch: [36][  300/  518]    Overall Loss 3.577472    Objective Loss 3.577472                                        LR 0.002000    Time 0.207461    
2023-04-26 19:59:49,737 - Epoch: [36][  350/  518]    Overall Loss 3.582137    Objective Loss 3.582137                                        LR 0.002000    Time 0.207163    
2023-04-26 20:00:00,026 - Epoch: [36][  400/  518]    Overall Loss 3.583557    Objective Loss 3.583557                                        LR 0.002000    Time 0.206985    
2023-04-26 20:00:10,316 - Epoch: [36][  450/  518]    Overall Loss 3.583362    Objective Loss 3.583362                                        LR 0.002000    Time 0.206849    
2023-04-26 20:00:20,453 - Epoch: [36][  500/  518]    Overall Loss 3.587749    Objective Loss 3.587749                                        LR 0.002000    Time 0.206437    
2023-04-26 20:00:23,983 - Epoch: [36][  518/  518]    Overall Loss 3.587257    Objective Loss 3.587257                                        LR 0.002000    Time 0.206076    
2023-04-26 20:00:24,054 - --- validate (epoch=36)-----------
2023-04-26 20:00:24,055 - 4952 samples (32 per mini-batch)
2023-04-26 20:00:30,249 - Epoch: [36][   50/  155]    Loss 4.117269    mAP 0.209553    
2023-04-26 20:00:36,140 - Epoch: [36][  100/  155]    Loss 4.103442    mAP 0.210367    
2023-04-26 20:00:42,001 - Epoch: [36][  150/  155]    Loss 4.103325    mAP 0.214652    
2023-04-26 20:00:42,520 - Epoch: [36][  155/  155]    Loss 4.108443    mAP 0.212777    
2023-04-26 20:00:42,583 - ==> mAP: 0.21278    Loss: 4.108

2023-04-26 20:00:42,586 - ==> Best [mAP: 0.282334   vloss: 3.764001   Sparsity:0.00   Params: 2177088 on epoch: 35]
2023-04-26 20:00:42,586 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:00:42,625 - 

2023-04-26 20:00:42,625 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:00:53,644 - Epoch: [37][   50/  518]    Overall Loss 3.544465    Objective Loss 3.544465                                        LR 0.002000    Time 0.220334    
2023-04-26 20:01:03,921 - Epoch: [37][  100/  518]    Overall Loss 3.548942    Objective Loss 3.548942                                        LR 0.002000    Time 0.212915    
2023-04-26 20:01:14,036 - Epoch: [37][  150/  518]    Overall Loss 3.549602    Objective Loss 3.549602                                        LR 0.002000    Time 0.209363    
2023-04-26 20:01:24,213 - Epoch: [37][  200/  518]    Overall Loss 3.548648    Objective Loss 3.548648                                        LR 0.002000    Time 0.207899    
2023-04-26 20:01:34,359 - Epoch: [37][  250/  518]    Overall Loss 3.555897    Objective Loss 3.555897                                        LR 0.002000    Time 0.206897    
2023-04-26 20:01:44,536 - Epoch: [37][  300/  518]    Overall Loss 3.559496    Objective Loss 3.559496                                        LR 0.002000    Time 0.206332    
2023-04-26 20:01:54,676 - Epoch: [37][  350/  518]    Overall Loss 3.560734    Objective Loss 3.560734                                        LR 0.002000    Time 0.205823    
2023-04-26 20:02:04,934 - Epoch: [37][  400/  518]    Overall Loss 3.568569    Objective Loss 3.568569                                        LR 0.002000    Time 0.205737    
2023-04-26 20:02:15,263 - Epoch: [37][  450/  518]    Overall Loss 3.570110    Objective Loss 3.570110                                        LR 0.002000    Time 0.205826    
2023-04-26 20:02:25,474 - Epoch: [37][  500/  518]    Overall Loss 3.567891    Objective Loss 3.567891                                        LR 0.002000    Time 0.205663    
2023-04-26 20:02:28,983 - Epoch: [37][  518/  518]    Overall Loss 3.570881    Objective Loss 3.570881                                        LR 0.002000    Time 0.205289    
2023-04-26 20:02:29,071 - --- validate (epoch=37)-----------
2023-04-26 20:02:29,072 - 4952 samples (32 per mini-batch)
2023-04-26 20:02:35,452 - Epoch: [37][   50/  155]    Loss 3.817792    mAP 0.276327    
2023-04-26 20:02:41,446 - Epoch: [37][  100/  155]    Loss 3.836885    mAP 0.277180    
2023-04-26 20:02:47,470 - Epoch: [37][  150/  155]    Loss 3.820092    mAP 0.274652    
2023-04-26 20:02:48,007 - Epoch: [37][  155/  155]    Loss 3.823139    mAP 0.274591    
2023-04-26 20:02:48,076 - ==> mAP: 0.27459    Loss: 3.823

2023-04-26 20:02:48,081 - ==> Best [mAP: 0.282334   vloss: 3.764001   Sparsity:0.00   Params: 2177088 on epoch: 35]
2023-04-26 20:02:48,081 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:02:48,119 - 

2023-04-26 20:02:48,119 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:02:59,151 - Epoch: [38][   50/  518]    Overall Loss 3.623772    Objective Loss 3.623772                                        LR 0.002000    Time 0.220576    
2023-04-26 20:03:09,379 - Epoch: [38][  100/  518]    Overall Loss 3.624112    Objective Loss 3.624112                                        LR 0.002000    Time 0.212554    
2023-04-26 20:03:19,675 - Epoch: [38][  150/  518]    Overall Loss 3.618546    Objective Loss 3.618546                                        LR 0.002000    Time 0.210327    
2023-04-26 20:03:29,868 - Epoch: [38][  200/  518]    Overall Loss 3.591136    Objective Loss 3.591136                                        LR 0.002000    Time 0.208703    
2023-04-26 20:03:40,107 - Epoch: [38][  250/  518]    Overall Loss 3.575868    Objective Loss 3.575868                                        LR 0.002000    Time 0.207911    
2023-04-26 20:03:50,328 - Epoch: [38][  300/  518]    Overall Loss 3.580700    Objective Loss 3.580700                                        LR 0.002000    Time 0.207325    
2023-04-26 20:04:00,588 - Epoch: [38][  350/  518]    Overall Loss 3.571287    Objective Loss 3.571287                                        LR 0.002000    Time 0.207017    
2023-04-26 20:04:10,882 - Epoch: [38][  400/  518]    Overall Loss 3.568911    Objective Loss 3.568911                                        LR 0.002000    Time 0.206871    
2023-04-26 20:04:21,148 - Epoch: [38][  450/  518]    Overall Loss 3.567397    Objective Loss 3.567397                                        LR 0.002000    Time 0.206694    
2023-04-26 20:04:31,389 - Epoch: [38][  500/  518]    Overall Loss 3.560225    Objective Loss 3.560225                                        LR 0.002000    Time 0.206503    
2023-04-26 20:04:34,941 - Epoch: [38][  518/  518]    Overall Loss 3.559654    Objective Loss 3.559654                                        LR 0.002000    Time 0.206184    
2023-04-26 20:04:35,015 - --- validate (epoch=38)-----------
2023-04-26 20:04:35,016 - 4952 samples (32 per mini-batch)
2023-04-26 20:04:41,442 - Epoch: [38][   50/  155]    Loss 3.865955    mAP 0.248079    
2023-04-26 20:04:47,535 - Epoch: [38][  100/  155]    Loss 3.887044    mAP 0.250255    
2023-04-26 20:04:53,512 - Epoch: [38][  150/  155]    Loss 3.880935    mAP 0.250191    
2023-04-26 20:04:54,078 - Epoch: [38][  155/  155]    Loss 3.877326    mAP 0.251635    
2023-04-26 20:04:54,147 - ==> mAP: 0.25164    Loss: 3.877

2023-04-26 20:04:54,151 - ==> Best [mAP: 0.282334   vloss: 3.764001   Sparsity:0.00   Params: 2177088 on epoch: 35]
2023-04-26 20:04:54,151 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:04:54,189 - 

2023-04-26 20:04:54,189 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:05:05,071 - Epoch: [39][   50/  518]    Overall Loss 3.602041    Objective Loss 3.602041                                        LR 0.002000    Time 0.217582    
2023-04-26 20:05:15,331 - Epoch: [39][  100/  518]    Overall Loss 3.553775    Objective Loss 3.553775                                        LR 0.002000    Time 0.211373    
2023-04-26 20:05:25,532 - Epoch: [39][  150/  518]    Overall Loss 3.551157    Objective Loss 3.551157                                        LR 0.002000    Time 0.208913    
2023-04-26 20:05:35,715 - Epoch: [39][  200/  518]    Overall Loss 3.542589    Objective Loss 3.542589                                        LR 0.002000    Time 0.207592    
2023-04-26 20:05:45,903 - Epoch: [39][  250/  518]    Overall Loss 3.538071    Objective Loss 3.538071                                        LR 0.002000    Time 0.206820    
2023-04-26 20:05:56,130 - Epoch: [39][  300/  518]    Overall Loss 3.533322    Objective Loss 3.533322                                        LR 0.002000    Time 0.206434    
2023-04-26 20:06:06,365 - Epoch: [39][  350/  518]    Overall Loss 3.536428    Objective Loss 3.536428                                        LR 0.002000    Time 0.206181    
2023-04-26 20:06:16,541 - Epoch: [39][  400/  518]    Overall Loss 3.544190    Objective Loss 3.544190                                        LR 0.002000    Time 0.205845    
2023-04-26 20:06:26,810 - Epoch: [39][  450/  518]    Overall Loss 3.542994    Objective Loss 3.542994                                        LR 0.002000    Time 0.205789    
2023-04-26 20:06:37,095 - Epoch: [39][  500/  518]    Overall Loss 3.548683    Objective Loss 3.548683                                        LR 0.002000    Time 0.205778    
2023-04-26 20:06:40,597 - Epoch: [39][  518/  518]    Overall Loss 3.550863    Objective Loss 3.550863                                        LR 0.002000    Time 0.205386    
2023-04-26 20:06:40,667 - --- validate (epoch=39)-----------
2023-04-26 20:06:40,668 - 4952 samples (32 per mini-batch)
2023-04-26 20:06:47,182 - Epoch: [39][   50/  155]    Loss 3.681846    mAP 0.303396    
2023-04-26 20:06:53,307 - Epoch: [39][  100/  155]    Loss 3.693414    mAP 0.291396    
2023-04-26 20:06:59,354 - Epoch: [39][  150/  155]    Loss 3.716486    mAP 0.289095    
2023-04-26 20:06:59,914 - Epoch: [39][  155/  155]    Loss 3.715739    mAP 0.289792    
2023-04-26 20:06:59,985 - ==> mAP: 0.28979    Loss: 3.716

2023-04-26 20:06:59,989 - ==> Best [mAP: 0.289792   vloss: 3.715739   Sparsity:0.00   Params: 2177088 on epoch: 39]
2023-04-26 20:06:59,990 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:07:00,042 - 

2023-04-26 20:07:00,043 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:07:11,169 - Epoch: [40][   50/  518]    Overall Loss 3.568132    Objective Loss 3.568132                                        LR 0.002000    Time 0.222481    
2023-04-26 20:07:21,398 - Epoch: [40][  100/  518]    Overall Loss 3.570336    Objective Loss 3.570336                                        LR 0.002000    Time 0.213505    
2023-04-26 20:07:31,657 - Epoch: [40][  150/  518]    Overall Loss 3.545196    Objective Loss 3.545196                                        LR 0.002000    Time 0.210721    
2023-04-26 20:07:41,873 - Epoch: [40][  200/  518]    Overall Loss 3.558941    Objective Loss 3.558941                                        LR 0.002000    Time 0.209111    
2023-04-26 20:07:52,137 - Epoch: [40][  250/  518]    Overall Loss 3.557941    Objective Loss 3.557941                                        LR 0.002000    Time 0.208339    
2023-04-26 20:08:02,319 - Epoch: [40][  300/  518]    Overall Loss 3.551657    Objective Loss 3.551657                                        LR 0.002000    Time 0.207551    
2023-04-26 20:08:12,605 - Epoch: [40][  350/  518]    Overall Loss 3.545977    Objective Loss 3.545977                                        LR 0.002000    Time 0.207286    
2023-04-26 20:08:22,837 - Epoch: [40][  400/  518]    Overall Loss 3.547651    Objective Loss 3.547651                                        LR 0.002000    Time 0.206950    
2023-04-26 20:08:33,143 - Epoch: [40][  450/  518]    Overall Loss 3.543006    Objective Loss 3.543006                                        LR 0.002000    Time 0.206854    
2023-04-26 20:08:43,328 - Epoch: [40][  500/  518]    Overall Loss 3.541811    Objective Loss 3.541811                                        LR 0.002000    Time 0.206536    
2023-04-26 20:08:46,883 - Epoch: [40][  518/  518]    Overall Loss 3.542927    Objective Loss 3.542927                                        LR 0.002000    Time 0.206220    
2023-04-26 20:08:46,956 - --- validate (epoch=40)-----------
2023-04-26 20:08:46,956 - 4952 samples (32 per mini-batch)
2023-04-26 20:08:53,431 - Epoch: [40][   50/  155]    Loss 3.847755    mAP 0.307521    
2023-04-26 20:08:59,598 - Epoch: [40][  100/  155]    Loss 3.808445    mAP 0.297535    
2023-04-26 20:09:05,724 - Epoch: [40][  150/  155]    Loss 3.809166    mAP 0.298108    
2023-04-26 20:09:06,261 - Epoch: [40][  155/  155]    Loss 3.812876    mAP 0.298829    
2023-04-26 20:09:06,330 - ==> mAP: 0.29883    Loss: 3.813

2023-04-26 20:09:06,334 - ==> Best [mAP: 0.298829   vloss: 3.812876   Sparsity:0.00   Params: 2177088 on epoch: 40]
2023-04-26 20:09:06,334 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:09:06,385 - 

2023-04-26 20:09:06,385 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:09:17,252 - Epoch: [41][   50/  518]    Overall Loss 3.489459    Objective Loss 3.489459                                        LR 0.002000    Time 0.217276    
2023-04-26 20:09:27,488 - Epoch: [41][  100/  518]    Overall Loss 3.512971    Objective Loss 3.512971                                        LR 0.002000    Time 0.210982    
2023-04-26 20:09:37,725 - Epoch: [41][  150/  518]    Overall Loss 3.523250    Objective Loss 3.523250                                        LR 0.002000    Time 0.208886    
2023-04-26 20:09:47,947 - Epoch: [41][  200/  518]    Overall Loss 3.521917    Objective Loss 3.521917                                        LR 0.002000    Time 0.207767    
2023-04-26 20:09:58,154 - Epoch: [41][  250/  518]    Overall Loss 3.522287    Objective Loss 3.522287                                        LR 0.002000    Time 0.207037    
2023-04-26 20:10:08,397 - Epoch: [41][  300/  518]    Overall Loss 3.521559    Objective Loss 3.521559                                        LR 0.002000    Time 0.206667    
2023-04-26 20:10:18,565 - Epoch: [41][  350/  518]    Overall Loss 3.527976    Objective Loss 3.527976                                        LR 0.002000    Time 0.206189    
2023-04-26 20:10:28,760 - Epoch: [41][  400/  518]    Overall Loss 3.535820    Objective Loss 3.535820                                        LR 0.002000    Time 0.205899    
2023-04-26 20:10:39,010 - Epoch: [41][  450/  518]    Overall Loss 3.534219    Objective Loss 3.534219                                        LR 0.002000    Time 0.205795    
2023-04-26 20:10:49,275 - Epoch: [41][  500/  518]    Overall Loss 3.537574    Objective Loss 3.537574                                        LR 0.002000    Time 0.205742    
2023-04-26 20:10:52,793 - Epoch: [41][  518/  518]    Overall Loss 3.538935    Objective Loss 3.538935                                        LR 0.002000    Time 0.205384    
2023-04-26 20:10:52,865 - --- validate (epoch=41)-----------
2023-04-26 20:10:52,866 - 4952 samples (32 per mini-batch)
2023-04-26 20:10:59,310 - Epoch: [41][   50/  155]    Loss 3.768814    mAP 0.299403    
2023-04-26 20:11:05,432 - Epoch: [41][  100/  155]    Loss 3.785556    mAP 0.293750    
2023-04-26 20:11:11,482 - Epoch: [41][  150/  155]    Loss 3.781280    mAP 0.297985    
2023-04-26 20:11:12,025 - Epoch: [41][  155/  155]    Loss 3.780781    mAP 0.296725    
2023-04-26 20:11:12,087 - ==> mAP: 0.29672    Loss: 3.781

2023-04-26 20:11:12,090 - ==> Best [mAP: 0.298829   vloss: 3.812876   Sparsity:0.00   Params: 2177088 on epoch: 40]
2023-04-26 20:11:12,090 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:11:12,128 - 

2023-04-26 20:11:12,128 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:11:23,234 - Epoch: [42][   50/  518]    Overall Loss 3.510524    Objective Loss 3.510524                                        LR 0.002000    Time 0.222050    
2023-04-26 20:11:33,507 - Epoch: [42][  100/  518]    Overall Loss 3.504875    Objective Loss 3.504875                                        LR 0.002000    Time 0.213745    
2023-04-26 20:11:43,792 - Epoch: [42][  150/  518]    Overall Loss 3.505233    Objective Loss 3.505233                                        LR 0.002000    Time 0.211048    
2023-04-26 20:11:54,016 - Epoch: [42][  200/  518]    Overall Loss 3.490507    Objective Loss 3.490507                                        LR 0.002000    Time 0.209401    
2023-04-26 20:12:04,262 - Epoch: [42][  250/  518]    Overall Loss 3.495338    Objective Loss 3.495338                                        LR 0.002000    Time 0.208499    
2023-04-26 20:12:14,489 - Epoch: [42][  300/  518]    Overall Loss 3.509426    Objective Loss 3.509426                                        LR 0.002000    Time 0.207833    
2023-04-26 20:12:24,731 - Epoch: [42][  350/  518]    Overall Loss 3.520971    Objective Loss 3.520971                                        LR 0.002000    Time 0.207399    
2023-04-26 20:12:34,881 - Epoch: [42][  400/  518]    Overall Loss 3.523832    Objective Loss 3.523832                                        LR 0.002000    Time 0.206847    
2023-04-26 20:12:45,138 - Epoch: [42][  450/  518]    Overall Loss 3.520359    Objective Loss 3.520359                                        LR 0.002000    Time 0.206654    
2023-04-26 20:12:55,417 - Epoch: [42][  500/  518]    Overall Loss 3.511340    Objective Loss 3.511340                                        LR 0.002000    Time 0.206541    
2023-04-26 20:12:58,976 - Epoch: [42][  518/  518]    Overall Loss 3.514424    Objective Loss 3.514424                                        LR 0.002000    Time 0.206235    
2023-04-26 20:12:59,049 - --- validate (epoch=42)-----------
2023-04-26 20:12:59,050 - 4952 samples (32 per mini-batch)
2023-04-26 20:13:05,382 - Epoch: [42][   50/  155]    Loss 3.928010    mAP 0.282286    
2023-04-26 20:13:11,410 - Epoch: [42][  100/  155]    Loss 3.966494    mAP 0.271312    
2023-04-26 20:13:17,360 - Epoch: [42][  150/  155]    Loss 3.947045    mAP 0.272814    
2023-04-26 20:13:17,894 - Epoch: [42][  155/  155]    Loss 3.949347    mAP 0.273366    
2023-04-26 20:13:17,963 - ==> mAP: 0.27337    Loss: 3.949

2023-04-26 20:13:17,966 - ==> Best [mAP: 0.298829   vloss: 3.812876   Sparsity:0.00   Params: 2177088 on epoch: 40]
2023-04-26 20:13:17,966 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:13:18,004 - 

2023-04-26 20:13:18,004 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:13:28,861 - Epoch: [43][   50/  518]    Overall Loss 3.521436    Objective Loss 3.521436                                        LR 0.002000    Time 0.217075    
2023-04-26 20:13:39,042 - Epoch: [43][  100/  518]    Overall Loss 3.510122    Objective Loss 3.510122                                        LR 0.002000    Time 0.210336    
2023-04-26 20:13:49,260 - Epoch: [43][  150/  518]    Overall Loss 3.498484    Objective Loss 3.498484                                        LR 0.002000    Time 0.208334    
2023-04-26 20:13:59,468 - Epoch: [43][  200/  518]    Overall Loss 3.504267    Objective Loss 3.504267                                        LR 0.002000    Time 0.207282    
2023-04-26 20:14:09,815 - Epoch: [43][  250/  518]    Overall Loss 3.498007    Objective Loss 3.498007                                        LR 0.002000    Time 0.207207    
2023-04-26 20:14:19,996 - Epoch: [43][  300/  518]    Overall Loss 3.497244    Objective Loss 3.497244                                        LR 0.002000    Time 0.206603    
2023-04-26 20:14:30,250 - Epoch: [43][  350/  518]    Overall Loss 3.503654    Objective Loss 3.503654                                        LR 0.002000    Time 0.206381    
2023-04-26 20:14:40,535 - Epoch: [43][  400/  518]    Overall Loss 3.503583    Objective Loss 3.503583                                        LR 0.002000    Time 0.206291    
2023-04-26 20:14:50,737 - Epoch: [43][  450/  518]    Overall Loss 3.508895    Objective Loss 3.508895                                        LR 0.002000    Time 0.206037    
2023-04-26 20:15:00,901 - Epoch: [43][  500/  518]    Overall Loss 3.502664    Objective Loss 3.502664                                        LR 0.002000    Time 0.205758    
2023-04-26 20:15:04,428 - Epoch: [43][  518/  518]    Overall Loss 3.504489    Objective Loss 3.504489                                        LR 0.002000    Time 0.205416    
2023-04-26 20:15:04,499 - --- validate (epoch=43)-----------
2023-04-26 20:15:04,499 - 4952 samples (32 per mini-batch)
2023-04-26 20:15:11,050 - Epoch: [43][   50/  155]    Loss 3.761623    mAP 0.316665    
2023-04-26 20:15:17,273 - Epoch: [43][  100/  155]    Loss 3.750147    mAP 0.309042    
2023-04-26 20:15:23,498 - Epoch: [43][  150/  155]    Loss 3.773217    mAP 0.306203    
2023-04-26 20:15:24,060 - Epoch: [43][  155/  155]    Loss 3.775010    mAP 0.305906    
2023-04-26 20:15:24,131 - ==> mAP: 0.30591    Loss: 3.775

2023-04-26 20:15:24,135 - ==> Best [mAP: 0.305906   vloss: 3.775010   Sparsity:0.00   Params: 2177088 on epoch: 43]
2023-04-26 20:15:24,135 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:15:24,187 - 

2023-04-26 20:15:24,187 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:15:35,109 - Epoch: [44][   50/  518]    Overall Loss 3.431258    Objective Loss 3.431258                                        LR 0.002000    Time 0.218376    
2023-04-26 20:15:45,373 - Epoch: [44][  100/  518]    Overall Loss 3.480227    Objective Loss 3.480227                                        LR 0.002000    Time 0.211814    
2023-04-26 20:15:55,631 - Epoch: [44][  150/  518]    Overall Loss 3.474218    Objective Loss 3.474218                                        LR 0.002000    Time 0.209582    
2023-04-26 20:16:05,899 - Epoch: [44][  200/  518]    Overall Loss 3.457116    Objective Loss 3.457116                                        LR 0.002000    Time 0.208520    
2023-04-26 20:16:16,104 - Epoch: [44][  250/  518]    Overall Loss 3.448930    Objective Loss 3.448930                                        LR 0.002000    Time 0.207629    
2023-04-26 20:16:26,303 - Epoch: [44][  300/  518]    Overall Loss 3.461723    Objective Loss 3.461723                                        LR 0.002000    Time 0.207014    
2023-04-26 20:16:36,522 - Epoch: [44][  350/  518]    Overall Loss 3.473674    Objective Loss 3.473674                                        LR 0.002000    Time 0.206635    
2023-04-26 20:16:46,788 - Epoch: [44][  400/  518]    Overall Loss 3.474594    Objective Loss 3.474594                                        LR 0.002000    Time 0.206467    
2023-04-26 20:16:57,072 - Epoch: [44][  450/  518]    Overall Loss 3.472349    Objective Loss 3.472349                                        LR 0.002000    Time 0.206376    
2023-04-26 20:17:07,213 - Epoch: [44][  500/  518]    Overall Loss 3.473933    Objective Loss 3.473933                                        LR 0.002000    Time 0.206017    
2023-04-26 20:17:10,789 - Epoch: [44][  518/  518]    Overall Loss 3.477551    Objective Loss 3.477551                                        LR 0.002000    Time 0.205760    
2023-04-26 20:17:10,861 - --- validate (epoch=44)-----------
2023-04-26 20:17:10,862 - 4952 samples (32 per mini-batch)
2023-04-26 20:17:17,273 - Epoch: [44][   50/  155]    Loss 3.816290    mAP 0.268487    
2023-04-26 20:17:23,306 - Epoch: [44][  100/  155]    Loss 3.770340    mAP 0.279987    
2023-04-26 20:17:29,309 - Epoch: [44][  150/  155]    Loss 3.768426    mAP 0.282681    
2023-04-26 20:17:29,839 - Epoch: [44][  155/  155]    Loss 3.770551    mAP 0.282786    
2023-04-26 20:17:29,903 - ==> mAP: 0.28279    Loss: 3.771

2023-04-26 20:17:29,907 - ==> Best [mAP: 0.305906   vloss: 3.775010   Sparsity:0.00   Params: 2177088 on epoch: 43]
2023-04-26 20:17:29,907 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:17:29,944 - 

2023-04-26 20:17:29,944 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:17:40,993 - Epoch: [45][   50/  518]    Overall Loss 3.490834    Objective Loss 3.490834                                        LR 0.002000    Time 0.220927    
2023-04-26 20:17:51,214 - Epoch: [45][  100/  518]    Overall Loss 3.460399    Objective Loss 3.460399                                        LR 0.002000    Time 0.212657    
2023-04-26 20:18:01,351 - Epoch: [45][  150/  518]    Overall Loss 3.476447    Objective Loss 3.476447                                        LR 0.002000    Time 0.209344    
2023-04-26 20:18:11,553 - Epoch: [45][  200/  518]    Overall Loss 3.481978    Objective Loss 3.481978                                        LR 0.002000    Time 0.208010    
2023-04-26 20:18:21,826 - Epoch: [45][  250/  518]    Overall Loss 3.481621    Objective Loss 3.481621                                        LR 0.002000    Time 0.207491    
2023-04-26 20:18:32,013 - Epoch: [45][  300/  518]    Overall Loss 3.476190    Objective Loss 3.476190                                        LR 0.002000    Time 0.206861    
2023-04-26 20:18:42,380 - Epoch: [45][  350/  518]    Overall Loss 3.481439    Objective Loss 3.481439                                        LR 0.002000    Time 0.206925    
2023-04-26 20:18:52,624 - Epoch: [45][  400/  518]    Overall Loss 3.480459    Objective Loss 3.480459                                        LR 0.002000    Time 0.206664    
2023-04-26 20:19:02,797 - Epoch: [45][  450/  518]    Overall Loss 3.475061    Objective Loss 3.475061                                        LR 0.002000    Time 0.206305    
2023-04-26 20:19:13,050 - Epoch: [45][  500/  518]    Overall Loss 3.470173    Objective Loss 3.470173                                        LR 0.002000    Time 0.206178    
2023-04-26 20:19:16,584 - Epoch: [45][  518/  518]    Overall Loss 3.465247    Objective Loss 3.465247                                        LR 0.002000    Time 0.205834    
2023-04-26 20:19:16,655 - --- validate (epoch=45)-----------
2023-04-26 20:19:16,656 - 4952 samples (32 per mini-batch)
2023-04-26 20:19:23,257 - Epoch: [45][   50/  155]    Loss 3.766533    mAP 0.317185    
2023-04-26 20:19:29,549 - Epoch: [45][  100/  155]    Loss 3.765398    mAP 0.311178    
2023-04-26 20:19:35,744 - Epoch: [45][  150/  155]    Loss 3.769913    mAP 0.309027    
2023-04-26 20:19:36,290 - Epoch: [45][  155/  155]    Loss 3.761277    mAP 0.309682    
2023-04-26 20:19:36,359 - ==> mAP: 0.30968    Loss: 3.761

2023-04-26 20:19:36,363 - ==> Best [mAP: 0.309682   vloss: 3.761277   Sparsity:0.00   Params: 2177088 on epoch: 45]
2023-04-26 20:19:36,363 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:19:36,415 - 

2023-04-26 20:19:36,416 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:19:47,499 - Epoch: [46][   50/  518]    Overall Loss 3.497721    Objective Loss 3.497721                                        LR 0.002000    Time 0.221604    
2023-04-26 20:19:57,742 - Epoch: [46][  100/  518]    Overall Loss 3.454764    Objective Loss 3.454764                                        LR 0.002000    Time 0.213218    
2023-04-26 20:20:08,023 - Epoch: [46][  150/  518]    Overall Loss 3.443213    Objective Loss 3.443213                                        LR 0.002000    Time 0.210672    
2023-04-26 20:20:18,355 - Epoch: [46][  200/  518]    Overall Loss 3.448681    Objective Loss 3.448681                                        LR 0.002000    Time 0.209656    
2023-04-26 20:20:28,622 - Epoch: [46][  250/  518]    Overall Loss 3.460678    Objective Loss 3.460678                                        LR 0.002000    Time 0.208788    
2023-04-26 20:20:38,884 - Epoch: [46][  300/  518]    Overall Loss 3.465977    Objective Loss 3.465977                                        LR 0.002000    Time 0.208190    
2023-04-26 20:20:49,161 - Epoch: [46][  350/  518]    Overall Loss 3.467732    Objective Loss 3.467732                                        LR 0.002000    Time 0.207808    
2023-04-26 20:20:59,328 - Epoch: [46][  400/  518]    Overall Loss 3.463650    Objective Loss 3.463650                                        LR 0.002000    Time 0.207244    
2023-04-26 20:21:09,517 - Epoch: [46][  450/  518]    Overall Loss 3.461741    Objective Loss 3.461741                                        LR 0.002000    Time 0.206857    
2023-04-26 20:21:19,755 - Epoch: [46][  500/  518]    Overall Loss 3.463875    Objective Loss 3.463875                                        LR 0.002000    Time 0.206643    
2023-04-26 20:21:23,293 - Epoch: [46][  518/  518]    Overall Loss 3.466009    Objective Loss 3.466009                                        LR 0.002000    Time 0.206292    
2023-04-26 20:21:23,365 - --- validate (epoch=46)-----------
2023-04-26 20:21:23,365 - 4952 samples (32 per mini-batch)
2023-04-26 20:21:29,832 - Epoch: [46][   50/  155]    Loss 3.892489    mAP 0.285853    
2023-04-26 20:21:36,012 - Epoch: [46][  100/  155]    Loss 3.827351    mAP 0.299977    
2023-04-26 20:21:42,125 - Epoch: [46][  150/  155]    Loss 3.802919    mAP 0.304641    
2023-04-26 20:21:42,674 - Epoch: [46][  155/  155]    Loss 3.801894    mAP 0.304101    
2023-04-26 20:21:42,745 - ==> mAP: 0.30410    Loss: 3.802

2023-04-26 20:21:42,748 - ==> Best [mAP: 0.309682   vloss: 3.761277   Sparsity:0.00   Params: 2177088 on epoch: 45]
2023-04-26 20:21:42,748 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:21:42,786 - 

2023-04-26 20:21:42,786 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:21:53,675 - Epoch: [47][   50/  518]    Overall Loss 3.447303    Objective Loss 3.447303                                        LR 0.002000    Time 0.217715    
2023-04-26 20:22:03,857 - Epoch: [47][  100/  518]    Overall Loss 3.440827    Objective Loss 3.440827                                        LR 0.002000    Time 0.210665    
2023-04-26 20:22:14,112 - Epoch: [47][  150/  518]    Overall Loss 3.444653    Objective Loss 3.444653                                        LR 0.002000    Time 0.208799    
2023-04-26 20:22:24,447 - Epoch: [47][  200/  518]    Overall Loss 3.450487    Objective Loss 3.450487                                        LR 0.002000    Time 0.208267    
2023-04-26 20:22:34,745 - Epoch: [47][  250/  518]    Overall Loss 3.452310    Objective Loss 3.452310                                        LR 0.002000    Time 0.207796    
2023-04-26 20:22:44,929 - Epoch: [47][  300/  518]    Overall Loss 3.443788    Objective Loss 3.443788                                        LR 0.002000    Time 0.207105    
2023-04-26 20:22:55,160 - Epoch: [47][  350/  518]    Overall Loss 3.443355    Objective Loss 3.443355                                        LR 0.002000    Time 0.206746    
2023-04-26 20:23:05,341 - Epoch: [47][  400/  518]    Overall Loss 3.447309    Objective Loss 3.447309                                        LR 0.002000    Time 0.206352    
2023-04-26 20:23:15,627 - Epoch: [47][  450/  518]    Overall Loss 3.441183    Objective Loss 3.441183                                        LR 0.002000    Time 0.206278    
2023-04-26 20:23:25,812 - Epoch: [47][  500/  518]    Overall Loss 3.447577    Objective Loss 3.447577                                        LR 0.002000    Time 0.206017    
2023-04-26 20:23:29,347 - Epoch: [47][  518/  518]    Overall Loss 3.445605    Objective Loss 3.445605                                        LR 0.002000    Time 0.205681    
2023-04-26 20:23:29,419 - --- validate (epoch=47)-----------
2023-04-26 20:23:29,420 - 4952 samples (32 per mini-batch)
2023-04-26 20:23:36,022 - Epoch: [47][   50/  155]    Loss 3.842947    mAP 0.282188    
2023-04-26 20:23:42,286 - Epoch: [47][  100/  155]    Loss 3.792546    mAP 0.291131    
2023-04-26 20:23:48,489 - Epoch: [47][  150/  155]    Loss 3.792626    mAP 0.286176    
2023-04-26 20:23:49,043 - Epoch: [47][  155/  155]    Loss 3.788381    mAP 0.285970    
2023-04-26 20:23:49,115 - ==> mAP: 0.28597    Loss: 3.788

2023-04-26 20:23:49,118 - ==> Best [mAP: 0.309682   vloss: 3.761277   Sparsity:0.00   Params: 2177088 on epoch: 45]
2023-04-26 20:23:49,118 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:23:49,156 - 

2023-04-26 20:23:49,156 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:24:00,045 - Epoch: [48][   50/  518]    Overall Loss 3.406116    Objective Loss 3.406116                                        LR 0.002000    Time 0.217721    
2023-04-26 20:24:10,258 - Epoch: [48][  100/  518]    Overall Loss 3.402988    Objective Loss 3.402988                                        LR 0.002000    Time 0.210974    
2023-04-26 20:24:20,458 - Epoch: [48][  150/  518]    Overall Loss 3.420803    Objective Loss 3.420803                                        LR 0.002000    Time 0.208638    
2023-04-26 20:24:30,759 - Epoch: [48][  200/  518]    Overall Loss 3.427712    Objective Loss 3.427712                                        LR 0.002000    Time 0.207977    
2023-04-26 20:24:40,956 - Epoch: [48][  250/  518]    Overall Loss 3.437820    Objective Loss 3.437820                                        LR 0.002000    Time 0.207164    
2023-04-26 20:24:51,190 - Epoch: [48][  300/  518]    Overall Loss 3.442871    Objective Loss 3.442871                                        LR 0.002000    Time 0.206743    
2023-04-26 20:25:01,497 - Epoch: [48][  350/  518]    Overall Loss 3.442638    Objective Loss 3.442638                                        LR 0.002000    Time 0.206652    
2023-04-26 20:25:11,768 - Epoch: [48][  400/  518]    Overall Loss 3.441927    Objective Loss 3.441927                                        LR 0.002000    Time 0.206495    
2023-04-26 20:25:21,991 - Epoch: [48][  450/  518]    Overall Loss 3.440971    Objective Loss 3.440971                                        LR 0.002000    Time 0.206265    
2023-04-26 20:25:32,243 - Epoch: [48][  500/  518]    Overall Loss 3.446664    Objective Loss 3.446664                                        LR 0.002000    Time 0.206139    
2023-04-26 20:25:35,805 - Epoch: [48][  518/  518]    Overall Loss 3.442537    Objective Loss 3.442537                                        LR 0.002000    Time 0.205850    
2023-04-26 20:25:35,876 - --- validate (epoch=48)-----------
2023-04-26 20:25:35,876 - 4952 samples (32 per mini-batch)
2023-04-26 20:25:42,510 - Epoch: [48][   50/  155]    Loss 3.723890    mAP 0.327350    
2023-04-26 20:25:48,804 - Epoch: [48][  100/  155]    Loss 3.714814    mAP 0.337494    
2023-04-26 20:25:55,052 - Epoch: [48][  150/  155]    Loss 3.731914    mAP 0.337095    
2023-04-26 20:25:55,621 - Epoch: [48][  155/  155]    Loss 3.731215    mAP 0.338533    
2023-04-26 20:25:55,687 - ==> mAP: 0.33853    Loss: 3.731

2023-04-26 20:25:55,691 - ==> Best [mAP: 0.338533   vloss: 3.731215   Sparsity:0.00   Params: 2177088 on epoch: 48]
2023-04-26 20:25:55,691 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:25:55,743 - 

2023-04-26 20:25:55,743 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:26:06,872 - Epoch: [49][   50/  518]    Overall Loss 3.428500    Objective Loss 3.428500                                        LR 0.002000    Time 0.222512    
2023-04-26 20:26:17,113 - Epoch: [49][  100/  518]    Overall Loss 3.433432    Objective Loss 3.433432                                        LR 0.002000    Time 0.213654    
2023-04-26 20:26:27,375 - Epoch: [49][  150/  518]    Overall Loss 3.443077    Objective Loss 3.443077                                        LR 0.002000    Time 0.210836    
2023-04-26 20:26:37,571 - Epoch: [49][  200/  518]    Overall Loss 3.437415    Objective Loss 3.437415                                        LR 0.002000    Time 0.209102    
2023-04-26 20:26:47,893 - Epoch: [49][  250/  518]    Overall Loss 3.419378    Objective Loss 3.419378                                        LR 0.002000    Time 0.208560    
2023-04-26 20:26:58,072 - Epoch: [49][  300/  518]    Overall Loss 3.419453    Objective Loss 3.419453                                        LR 0.002000    Time 0.207726    
2023-04-26 20:27:08,288 - Epoch: [49][  350/  518]    Overall Loss 3.417985    Objective Loss 3.417985                                        LR 0.002000    Time 0.207235    
2023-04-26 20:27:18,613 - Epoch: [49][  400/  518]    Overall Loss 3.420480    Objective Loss 3.420480                                        LR 0.002000    Time 0.207138    
2023-04-26 20:27:28,771 - Epoch: [49][  450/  518]    Overall Loss 3.419378    Objective Loss 3.419378                                        LR 0.002000    Time 0.206692    
2023-04-26 20:27:39,069 - Epoch: [49][  500/  518]    Overall Loss 3.418248    Objective Loss 3.418248                                        LR 0.002000    Time 0.206616    
2023-04-26 20:27:42,565 - Epoch: [49][  518/  518]    Overall Loss 3.415481    Objective Loss 3.415481                                        LR 0.002000    Time 0.206184    
2023-04-26 20:27:42,637 - --- validate (epoch=49)-----------
2023-04-26 20:27:42,637 - 4952 samples (32 per mini-batch)
2023-04-26 20:27:49,378 - Epoch: [49][   50/  155]    Loss 3.651460    mAP 0.334100    
2023-04-26 20:27:55,699 - Epoch: [49][  100/  155]    Loss 3.653357    mAP 0.331194    
2023-04-26 20:28:02,014 - Epoch: [49][  150/  155]    Loss 3.679575    mAP 0.330264    
2023-04-26 20:28:02,583 - Epoch: [49][  155/  155]    Loss 3.681447    mAP 0.327632    
2023-04-26 20:28:02,655 - ==> mAP: 0.32763    Loss: 3.681

2023-04-26 20:28:02,659 - ==> Best [mAP: 0.338533   vloss: 3.731215   Sparsity:0.00   Params: 2177088 on epoch: 48]
2023-04-26 20:28:02,659 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:28:02,697 - 

2023-04-26 20:28:02,697 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:28:13,754 - Epoch: [50][   50/  518]    Overall Loss 3.304751    Objective Loss 3.304751                                        LR 0.000500    Time 0.221086    
2023-04-26 20:28:24,010 - Epoch: [50][  100/  518]    Overall Loss 3.283023    Objective Loss 3.283023                                        LR 0.000500    Time 0.213084    
2023-04-26 20:28:34,163 - Epoch: [50][  150/  518]    Overall Loss 3.300935    Objective Loss 3.300935                                        LR 0.000500    Time 0.209735    
2023-04-26 20:28:44,348 - Epoch: [50][  200/  518]    Overall Loss 3.296223    Objective Loss 3.296223                                        LR 0.000500    Time 0.208217    
2023-04-26 20:28:54,569 - Epoch: [50][  250/  518]    Overall Loss 3.297551    Objective Loss 3.297551                                        LR 0.000500    Time 0.207449    
2023-04-26 20:29:04,825 - Epoch: [50][  300/  518]    Overall Loss 3.295640    Objective Loss 3.295640                                        LR 0.000500    Time 0.207056    
2023-04-26 20:29:15,038 - Epoch: [50][  350/  518]    Overall Loss 3.293723    Objective Loss 3.293723                                        LR 0.000500    Time 0.206652    
2023-04-26 20:29:25,232 - Epoch: [50][  400/  518]    Overall Loss 3.286819    Objective Loss 3.286819                                        LR 0.000500    Time 0.206301    
2023-04-26 20:29:35,529 - Epoch: [50][  450/  518]    Overall Loss 3.288484    Objective Loss 3.288484                                        LR 0.000500    Time 0.206259    
2023-04-26 20:29:45,824 - Epoch: [50][  500/  518]    Overall Loss 3.277300    Objective Loss 3.277300                                        LR 0.000500    Time 0.206219    
2023-04-26 20:29:49,398 - Epoch: [50][  518/  518]    Overall Loss 3.274491    Objective Loss 3.274491                                        LR 0.000500    Time 0.205951    
2023-04-26 20:29:49,470 - --- validate (epoch=50)-----------
2023-04-26 20:29:49,470 - 4952 samples (32 per mini-batch)
2023-04-26 20:29:56,153 - Epoch: [50][   50/  155]    Loss 3.472088    mAP 0.384031    
2023-04-26 20:30:02,513 - Epoch: [50][  100/  155]    Loss 3.452169    mAP 0.376159    
2023-04-26 20:30:08,808 - Epoch: [50][  150/  155]    Loss 3.447472    mAP 0.380398    
2023-04-26 20:30:09,363 - Epoch: [50][  155/  155]    Loss 3.447414    mAP 0.379632    
2023-04-26 20:30:09,447 - ==> mAP: 0.37963    Loss: 3.447

2023-04-26 20:30:09,451 - ==> Best [mAP: 0.379632   vloss: 3.447414   Sparsity:0.00   Params: 2177088 on epoch: 50]
2023-04-26 20:30:09,451 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:30:09,503 - 

2023-04-26 20:30:09,504 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:30:20,431 - Epoch: [51][   50/  518]    Overall Loss 3.284614    Objective Loss 3.284614                                        LR 0.000500    Time 0.218490    
2023-04-26 20:30:30,585 - Epoch: [51][  100/  518]    Overall Loss 3.248077    Objective Loss 3.248077                                        LR 0.000500    Time 0.210761    
2023-04-26 20:30:40,815 - Epoch: [51][  150/  518]    Overall Loss 3.261739    Objective Loss 3.261739                                        LR 0.000500    Time 0.208700    
2023-04-26 20:30:51,049 - Epoch: [51][  200/  518]    Overall Loss 3.242826    Objective Loss 3.242826                                        LR 0.000500    Time 0.207689    
2023-04-26 20:31:01,179 - Epoch: [51][  250/  518]    Overall Loss 3.241424    Objective Loss 3.241424                                        LR 0.000500    Time 0.206662    
2023-04-26 20:31:11,518 - Epoch: [51][  300/  518]    Overall Loss 3.249414    Objective Loss 3.249414                                        LR 0.000500    Time 0.206679    
2023-04-26 20:31:21,752 - Epoch: [51][  350/  518]    Overall Loss 3.244378    Objective Loss 3.244378                                        LR 0.000500    Time 0.206385    
2023-04-26 20:31:31,971 - Epoch: [51][  400/  518]    Overall Loss 3.242994    Objective Loss 3.242994                                        LR 0.000500    Time 0.206133    
2023-04-26 20:31:42,196 - Epoch: [51][  450/  518]    Overall Loss 3.237360    Objective Loss 3.237360                                        LR 0.000500    Time 0.205948    
2023-04-26 20:31:52,429 - Epoch: [51][  500/  518]    Overall Loss 3.236309    Objective Loss 3.236309                                        LR 0.000500    Time 0.205816    
2023-04-26 20:31:55,954 - Epoch: [51][  518/  518]    Overall Loss 3.232775    Objective Loss 3.232775                                        LR 0.000500    Time 0.205467    
2023-04-26 20:31:56,025 - --- validate (epoch=51)-----------
2023-04-26 20:31:56,025 - 4952 samples (32 per mini-batch)
2023-04-26 20:32:02,771 - Epoch: [51][   50/  155]    Loss 3.435218    mAP 0.369394    
2023-04-26 20:32:09,049 - Epoch: [51][  100/  155]    Loss 3.441681    mAP 0.366511    
2023-04-26 20:32:15,370 - Epoch: [51][  150/  155]    Loss 3.419752    mAP 0.377991    
2023-04-26 20:32:15,924 - Epoch: [51][  155/  155]    Loss 3.421496    mAP 0.375533    
2023-04-26 20:32:15,998 - ==> mAP: 0.37553    Loss: 3.421

2023-04-26 20:32:16,002 - ==> Best [mAP: 0.379632   vloss: 3.447414   Sparsity:0.00   Params: 2177088 on epoch: 50]
2023-04-26 20:32:16,002 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:32:16,040 - 

2023-04-26 20:32:16,040 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:32:26,972 - Epoch: [52][   50/  518]    Overall Loss 3.207502    Objective Loss 3.207502                                        LR 0.000500    Time 0.218588    
2023-04-26 20:32:37,079 - Epoch: [52][  100/  518]    Overall Loss 3.224763    Objective Loss 3.224763                                        LR 0.000500    Time 0.210344    
2023-04-26 20:32:47,250 - Epoch: [52][  150/  518]    Overall Loss 3.219599    Objective Loss 3.219599                                        LR 0.000500    Time 0.208025    
2023-04-26 20:32:57,425 - Epoch: [52][  200/  518]    Overall Loss 3.211481    Objective Loss 3.211481                                        LR 0.000500    Time 0.206889    
2023-04-26 20:33:07,736 - Epoch: [52][  250/  518]    Overall Loss 3.209591    Objective Loss 3.209591                                        LR 0.000500    Time 0.206748    
2023-04-26 20:33:18,020 - Epoch: [52][  300/  518]    Overall Loss 3.212403    Objective Loss 3.212403                                        LR 0.000500    Time 0.206565    
2023-04-26 20:33:28,246 - Epoch: [52][  350/  518]    Overall Loss 3.210032    Objective Loss 3.210032                                        LR 0.000500    Time 0.206267    
2023-04-26 20:33:38,573 - Epoch: [52][  400/  518]    Overall Loss 3.211082    Objective Loss 3.211082                                        LR 0.000500    Time 0.206297    
2023-04-26 20:33:48,769 - Epoch: [52][  450/  518]    Overall Loss 3.209333    Objective Loss 3.209333                                        LR 0.000500    Time 0.206029    
2023-04-26 20:33:58,967 - Epoch: [52][  500/  518]    Overall Loss 3.212315    Objective Loss 3.212315                                        LR 0.000500    Time 0.205819    
2023-04-26 20:34:02,482 - Epoch: [52][  518/  518]    Overall Loss 3.210992    Objective Loss 3.210992                                        LR 0.000500    Time 0.205453    
2023-04-26 20:34:02,554 - --- validate (epoch=52)-----------
2023-04-26 20:34:02,555 - 4952 samples (32 per mini-batch)
2023-04-26 20:34:09,233 - Epoch: [52][   50/  155]    Loss 3.405044    mAP 0.362687    
2023-04-26 20:34:15,538 - Epoch: [52][  100/  155]    Loss 3.433267    mAP 0.372485    
2023-04-26 20:34:21,876 - Epoch: [52][  150/  155]    Loss 3.429350    mAP 0.377551    
2023-04-26 20:34:22,442 - Epoch: [52][  155/  155]    Loss 3.431594    mAP 0.375890    
2023-04-26 20:34:22,522 - ==> mAP: 0.37589    Loss: 3.432

2023-04-26 20:34:22,526 - ==> Best [mAP: 0.379632   vloss: 3.447414   Sparsity:0.00   Params: 2177088 on epoch: 50]
2023-04-26 20:34:22,526 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:34:22,563 - 

2023-04-26 20:34:22,563 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:34:33,571 - Epoch: [53][   50/  518]    Overall Loss 3.189725    Objective Loss 3.189725                                        LR 0.000500    Time 0.220099    
2023-04-26 20:34:43,776 - Epoch: [53][  100/  518]    Overall Loss 3.189058    Objective Loss 3.189058                                        LR 0.000500    Time 0.212086    
2023-04-26 20:34:53,998 - Epoch: [53][  150/  518]    Overall Loss 3.190356    Objective Loss 3.190356                                        LR 0.000500    Time 0.209527    
2023-04-26 20:35:04,327 - Epoch: [53][  200/  518]    Overall Loss 3.195662    Objective Loss 3.195662                                        LR 0.000500    Time 0.208781    
2023-04-26 20:35:14,550 - Epoch: [53][  250/  518]    Overall Loss 3.199295    Objective Loss 3.199295                                        LR 0.000500    Time 0.207912    
2023-04-26 20:35:24,850 - Epoch: [53][  300/  518]    Overall Loss 3.202164    Objective Loss 3.202164                                        LR 0.000500    Time 0.207585    
2023-04-26 20:35:35,087 - Epoch: [53][  350/  518]    Overall Loss 3.206032    Objective Loss 3.206032                                        LR 0.000500    Time 0.207174    
2023-04-26 20:35:45,327 - Epoch: [53][  400/  518]    Overall Loss 3.204481    Objective Loss 3.204481                                        LR 0.000500    Time 0.206874    
2023-04-26 20:35:55,575 - Epoch: [53][  450/  518]    Overall Loss 3.207273    Objective Loss 3.207273                                        LR 0.000500    Time 0.206656    
2023-04-26 20:36:05,798 - Epoch: [53][  500/  518]    Overall Loss 3.206602    Objective Loss 3.206602                                        LR 0.000500    Time 0.206434    
2023-04-26 20:36:09,354 - Epoch: [53][  518/  518]    Overall Loss 3.204893    Objective Loss 3.204893                                        LR 0.000500    Time 0.206125    
2023-04-26 20:36:09,428 - --- validate (epoch=53)-----------
2023-04-26 20:36:09,429 - 4952 samples (32 per mini-batch)
2023-04-26 20:36:16,006 - Epoch: [53][   50/  155]    Loss 3.398236    mAP 0.371203    
2023-04-26 20:36:22,273 - Epoch: [53][  100/  155]    Loss 3.433710    mAP 0.376964    
2023-04-26 20:36:28,528 - Epoch: [53][  150/  155]    Loss 3.424578    mAP 0.377383    
2023-04-26 20:36:29,086 - Epoch: [53][  155/  155]    Loss 3.426139    mAP 0.376568    
2023-04-26 20:36:29,155 - ==> mAP: 0.37657    Loss: 3.426

2023-04-26 20:36:29,158 - ==> Best [mAP: 0.379632   vloss: 3.447414   Sparsity:0.00   Params: 2177088 on epoch: 50]
2023-04-26 20:36:29,159 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:36:29,221 - 

2023-04-26 20:36:29,221 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:36:40,285 - Epoch: [54][   50/  518]    Overall Loss 3.208712    Objective Loss 3.208712                                        LR 0.000500    Time 0.221189    
2023-04-26 20:36:50,436 - Epoch: [54][  100/  518]    Overall Loss 3.179120    Objective Loss 3.179120                                        LR 0.000500    Time 0.212090    
2023-04-26 20:37:00,661 - Epoch: [54][  150/  518]    Overall Loss 3.192209    Objective Loss 3.192209                                        LR 0.000500    Time 0.209548    
2023-04-26 20:37:10,963 - Epoch: [54][  200/  518]    Overall Loss 3.189396    Objective Loss 3.189396                                        LR 0.000500    Time 0.208666    
2023-04-26 20:37:21,233 - Epoch: [54][  250/  518]    Overall Loss 3.195766    Objective Loss 3.195766                                        LR 0.000500    Time 0.208005    
2023-04-26 20:37:31,460 - Epoch: [54][  300/  518]    Overall Loss 3.199664    Objective Loss 3.199664                                        LR 0.000500    Time 0.207423    
2023-04-26 20:37:41,617 - Epoch: [54][  350/  518]    Overall Loss 3.210045    Objective Loss 3.210045                                        LR 0.000500    Time 0.206807    
2023-04-26 20:37:51,798 - Epoch: [54][  400/  518]    Overall Loss 3.209609    Objective Loss 3.209609                                        LR 0.000500    Time 0.206404    
2023-04-26 20:38:02,033 - Epoch: [54][  450/  518]    Overall Loss 3.206645    Objective Loss 3.206645                                        LR 0.000500    Time 0.206210    
2023-04-26 20:38:12,215 - Epoch: [54][  500/  518]    Overall Loss 3.204838    Objective Loss 3.204838                                        LR 0.000500    Time 0.205951    
2023-04-26 20:38:15,849 - Epoch: [54][  518/  518]    Overall Loss 3.204085    Objective Loss 3.204085                                        LR 0.000500    Time 0.205808    
2023-04-26 20:38:15,919 - --- validate (epoch=54)-----------
2023-04-26 20:38:15,919 - 4952 samples (32 per mini-batch)
2023-04-26 20:38:22,594 - Epoch: [54][   50/  155]    Loss 3.421279    mAP 0.384380    
2023-04-26 20:38:28,939 - Epoch: [54][  100/  155]    Loss 3.401631    mAP 0.380982    
2023-04-26 20:38:35,337 - Epoch: [54][  150/  155]    Loss 3.394708    mAP 0.388394    
2023-04-26 20:38:35,896 - Epoch: [54][  155/  155]    Loss 3.397305    mAP 0.387379    
2023-04-26 20:38:35,967 - ==> mAP: 0.38738    Loss: 3.397

2023-04-26 20:38:35,970 - ==> Best [mAP: 0.387379   vloss: 3.397305   Sparsity:0.00   Params: 2177088 on epoch: 54]
2023-04-26 20:38:35,971 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:38:36,022 - 

2023-04-26 20:38:36,022 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:38:47,186 - Epoch: [55][   50/  518]    Overall Loss 3.132390    Objective Loss 3.132390                                        LR 0.000500    Time 0.223222    
2023-04-26 20:38:57,372 - Epoch: [55][  100/  518]    Overall Loss 3.163234    Objective Loss 3.163234                                        LR 0.000500    Time 0.213447    
2023-04-26 20:39:07,553 - Epoch: [55][  150/  518]    Overall Loss 3.163134    Objective Loss 3.163134                                        LR 0.000500    Time 0.210161    
2023-04-26 20:39:17,785 - Epoch: [55][  200/  518]    Overall Loss 3.160218    Objective Loss 3.160218                                        LR 0.000500    Time 0.208772    
2023-04-26 20:39:28,135 - Epoch: [55][  250/  518]    Overall Loss 3.176275    Objective Loss 3.176275                                        LR 0.000500    Time 0.208413    
2023-04-26 20:39:38,338 - Epoch: [55][  300/  518]    Overall Loss 3.178024    Objective Loss 3.178024                                        LR 0.000500    Time 0.207681    
2023-04-26 20:39:48,642 - Epoch: [55][  350/  518]    Overall Loss 3.173631    Objective Loss 3.173631                                        LR 0.000500    Time 0.207449    
2023-04-26 20:39:58,787 - Epoch: [55][  400/  518]    Overall Loss 3.177462    Objective Loss 3.177462                                        LR 0.000500    Time 0.206875    
2023-04-26 20:40:08,888 - Epoch: [55][  450/  518]    Overall Loss 3.176026    Objective Loss 3.176026                                        LR 0.000500    Time 0.206331    
2023-04-26 20:40:19,097 - Epoch: [55][  500/  518]    Overall Loss 3.180188    Objective Loss 3.180188                                        LR 0.000500    Time 0.206113    
2023-04-26 20:40:22,632 - Epoch: [55][  518/  518]    Overall Loss 3.181978    Objective Loss 3.181978                                        LR 0.000500    Time 0.205775    
2023-04-26 20:40:22,703 - --- validate (epoch=55)-----------
2023-04-26 20:40:22,703 - 4952 samples (32 per mini-batch)
2023-04-26 20:40:29,454 - Epoch: [55][   50/  155]    Loss 3.415345    mAP 0.407783    
2023-04-26 20:40:35,883 - Epoch: [55][  100/  155]    Loss 3.409329    mAP 0.402358    
2023-04-26 20:40:42,282 - Epoch: [55][  150/  155]    Loss 3.442645    mAP 0.395382    
2023-04-26 20:40:42,833 - Epoch: [55][  155/  155]    Loss 3.442725    mAP 0.394178    
2023-04-26 20:40:42,905 - ==> mAP: 0.39418    Loss: 3.443

2023-04-26 20:40:42,909 - ==> Best [mAP: 0.394178   vloss: 3.442725   Sparsity:0.00   Params: 2177088 on epoch: 55]
2023-04-26 20:40:42,909 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:40:42,963 - 

2023-04-26 20:40:42,963 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:40:54,018 - Epoch: [56][   50/  518]    Overall Loss 3.205225    Objective Loss 3.205225                                        LR 0.000500    Time 0.221057    
2023-04-26 20:41:04,186 - Epoch: [56][  100/  518]    Overall Loss 3.199788    Objective Loss 3.199788                                        LR 0.000500    Time 0.212189    
2023-04-26 20:41:14,445 - Epoch: [56][  150/  518]    Overall Loss 3.213804    Objective Loss 3.213804                                        LR 0.000500    Time 0.209839    
2023-04-26 20:41:24,709 - Epoch: [56][  200/  518]    Overall Loss 3.196884    Objective Loss 3.196884                                        LR 0.000500    Time 0.208693    
2023-04-26 20:41:35,052 - Epoch: [56][  250/  518]    Overall Loss 3.194875    Objective Loss 3.194875                                        LR 0.000500    Time 0.208318    
2023-04-26 20:41:45,209 - Epoch: [56][  300/  518]    Overall Loss 3.191811    Objective Loss 3.191811                                        LR 0.000500    Time 0.207451    
2023-04-26 20:41:55,367 - Epoch: [56][  350/  518]    Overall Loss 3.185650    Objective Loss 3.185650                                        LR 0.000500    Time 0.206833    
2023-04-26 20:42:05,497 - Epoch: [56][  400/  518]    Overall Loss 3.180263    Objective Loss 3.180263                                        LR 0.000500    Time 0.206299    
2023-04-26 20:42:15,638 - Epoch: [56][  450/  518]    Overall Loss 3.185979    Objective Loss 3.185979                                        LR 0.000500    Time 0.205910    
2023-04-26 20:42:25,832 - Epoch: [56][  500/  518]    Overall Loss 3.178927    Objective Loss 3.178927                                        LR 0.000500    Time 0.205703    
2023-04-26 20:42:29,316 - Epoch: [56][  518/  518]    Overall Loss 3.176396    Objective Loss 3.176396                                        LR 0.000500    Time 0.205280    
2023-04-26 20:42:29,388 - --- validate (epoch=56)-----------
2023-04-26 20:42:29,388 - 4952 samples (32 per mini-batch)
2023-04-26 20:42:36,101 - Epoch: [56][   50/  155]    Loss 3.378481    mAP 0.411486    
2023-04-26 20:42:42,392 - Epoch: [56][  100/  155]    Loss 3.393863    mAP 0.397495    
2023-04-26 20:42:48,709 - Epoch: [56][  150/  155]    Loss 3.396721    mAP 0.392102    
2023-04-26 20:42:49,275 - Epoch: [56][  155/  155]    Loss 3.396443    mAP 0.393101    
2023-04-26 20:42:49,346 - ==> mAP: 0.39310    Loss: 3.396

2023-04-26 20:42:49,349 - ==> Best [mAP: 0.394178   vloss: 3.442725   Sparsity:0.00   Params: 2177088 on epoch: 55]
2023-04-26 20:42:49,349 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:42:49,387 - 

2023-04-26 20:42:49,387 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:43:00,289 - Epoch: [57][   50/  518]    Overall Loss 3.154996    Objective Loss 3.154996                                        LR 0.000500    Time 0.217969    
2023-04-26 20:43:10,512 - Epoch: [57][  100/  518]    Overall Loss 3.160534    Objective Loss 3.160534                                        LR 0.000500    Time 0.211203    
2023-04-26 20:43:20,731 - Epoch: [57][  150/  518]    Overall Loss 3.160064    Objective Loss 3.160064                                        LR 0.000500    Time 0.208917    
2023-04-26 20:43:30,996 - Epoch: [57][  200/  518]    Overall Loss 3.153480    Objective Loss 3.153480                                        LR 0.000500    Time 0.208006    
2023-04-26 20:43:41,238 - Epoch: [57][  250/  518]    Overall Loss 3.156463    Objective Loss 3.156463                                        LR 0.000500    Time 0.207365    
2023-04-26 20:43:51,482 - Epoch: [57][  300/  518]    Overall Loss 3.153686    Objective Loss 3.153686                                        LR 0.000500    Time 0.206944    
2023-04-26 20:44:01,746 - Epoch: [57][  350/  518]    Overall Loss 3.159447    Objective Loss 3.159447                                        LR 0.000500    Time 0.206702    
2023-04-26 20:44:11,965 - Epoch: [57][  400/  518]    Overall Loss 3.163791    Objective Loss 3.163791                                        LR 0.000500    Time 0.206408    
2023-04-26 20:44:22,205 - Epoch: [57][  450/  518]    Overall Loss 3.166946    Objective Loss 3.166946                                        LR 0.000500    Time 0.206227    
2023-04-26 20:44:32,331 - Epoch: [57][  500/  518]    Overall Loss 3.172811    Objective Loss 3.172811                                        LR 0.000500    Time 0.205853    
2023-04-26 20:44:35,896 - Epoch: [57][  518/  518]    Overall Loss 3.174809    Objective Loss 3.174809                                        LR 0.000500    Time 0.205580    
2023-04-26 20:44:35,967 - --- validate (epoch=57)-----------
2023-04-26 20:44:35,967 - 4952 samples (32 per mini-batch)
2023-04-26 20:44:42,747 - Epoch: [57][   50/  155]    Loss 3.465960    mAP 0.395502    
2023-04-26 20:44:49,189 - Epoch: [57][  100/  155]    Loss 3.441273    mAP 0.392408    
2023-04-26 20:44:55,541 - Epoch: [57][  150/  155]    Loss 3.433553    mAP 0.388557    
2023-04-26 20:44:56,107 - Epoch: [57][  155/  155]    Loss 3.433074    mAP 0.388324    
2023-04-26 20:44:56,175 - ==> mAP: 0.38832    Loss: 3.433

2023-04-26 20:44:56,178 - ==> Best [mAP: 0.394178   vloss: 3.442725   Sparsity:0.00   Params: 2177088 on epoch: 55]
2023-04-26 20:44:56,178 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:44:56,216 - 

2023-04-26 20:44:56,216 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:45:07,263 - Epoch: [58][   50/  518]    Overall Loss 3.179770    Objective Loss 3.179770                                        LR 0.000500    Time 0.220884    
2023-04-26 20:45:17,640 - Epoch: [58][  100/  518]    Overall Loss 3.159803    Objective Loss 3.159803                                        LR 0.000500    Time 0.214197    
2023-04-26 20:45:27,815 - Epoch: [58][  150/  518]    Overall Loss 3.156748    Objective Loss 3.156748                                        LR 0.000500    Time 0.210620    
2023-04-26 20:45:38,021 - Epoch: [58][  200/  518]    Overall Loss 3.170234    Objective Loss 3.170234                                        LR 0.000500    Time 0.208986    
2023-04-26 20:45:48,282 - Epoch: [58][  250/  518]    Overall Loss 3.170640    Objective Loss 3.170640                                        LR 0.000500    Time 0.208226    
2023-04-26 20:45:58,452 - Epoch: [58][  300/  518]    Overall Loss 3.169076    Objective Loss 3.169076                                        LR 0.000500    Time 0.207415    
2023-04-26 20:46:08,755 - Epoch: [58][  350/  518]    Overall Loss 3.169254    Objective Loss 3.169254                                        LR 0.000500    Time 0.207217    
2023-04-26 20:46:18,985 - Epoch: [58][  400/  518]    Overall Loss 3.167323    Objective Loss 3.167323                                        LR 0.000500    Time 0.206887    
2023-04-26 20:46:29,197 - Epoch: [58][  450/  518]    Overall Loss 3.170618    Objective Loss 3.170618                                        LR 0.000500    Time 0.206588    
2023-04-26 20:46:39,463 - Epoch: [58][  500/  518]    Overall Loss 3.164101    Objective Loss 3.164101                                        LR 0.000500    Time 0.206458    
2023-04-26 20:46:42,986 - Epoch: [58][  518/  518]    Overall Loss 3.164473    Objective Loss 3.164473                                        LR 0.000500    Time 0.206084    
2023-04-26 20:46:43,056 - --- validate (epoch=58)-----------
2023-04-26 20:46:43,056 - 4952 samples (32 per mini-batch)
2023-04-26 20:46:49,727 - Epoch: [58][   50/  155]    Loss 3.348744    mAP 0.412764    
2023-04-26 20:46:56,056 - Epoch: [58][  100/  155]    Loss 3.366947    mAP 0.397784    
2023-04-26 20:47:02,431 - Epoch: [58][  150/  155]    Loss 3.373718    mAP 0.395006    
2023-04-26 20:47:02,987 - Epoch: [58][  155/  155]    Loss 3.374902    mAP 0.394528    
2023-04-26 20:47:03,065 - ==> mAP: 0.39453    Loss: 3.375

2023-04-26 20:47:03,069 - ==> Best [mAP: 0.394528   vloss: 3.374902   Sparsity:0.00   Params: 2177088 on epoch: 58]
2023-04-26 20:47:03,069 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:47:03,123 - 

2023-04-26 20:47:03,123 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:47:14,067 - Epoch: [59][   50/  518]    Overall Loss 3.193687    Objective Loss 3.193687                                        LR 0.000500    Time 0.218812    
2023-04-26 20:47:24,309 - Epoch: [59][  100/  518]    Overall Loss 3.179797    Objective Loss 3.179797                                        LR 0.000500    Time 0.211814    
2023-04-26 20:47:34,546 - Epoch: [59][  150/  518]    Overall Loss 3.162212    Objective Loss 3.162212                                        LR 0.000500    Time 0.209444    
2023-04-26 20:47:44,766 - Epoch: [59][  200/  518]    Overall Loss 3.145455    Objective Loss 3.145455                                        LR 0.000500    Time 0.208175    
2023-04-26 20:47:55,048 - Epoch: [59][  250/  518]    Overall Loss 3.147992    Objective Loss 3.147992                                        LR 0.000500    Time 0.207664    
2023-04-26 20:48:05,281 - Epoch: [59][  300/  518]    Overall Loss 3.142017    Objective Loss 3.142017                                        LR 0.000500    Time 0.207156    
2023-04-26 20:48:15,541 - Epoch: [59][  350/  518]    Overall Loss 3.148018    Objective Loss 3.148018                                        LR 0.000500    Time 0.206872    
2023-04-26 20:48:25,851 - Epoch: [59][  400/  518]    Overall Loss 3.149484    Objective Loss 3.149484                                        LR 0.000500    Time 0.206785    
2023-04-26 20:48:36,059 - Epoch: [59][  450/  518]    Overall Loss 3.149642    Objective Loss 3.149642                                        LR 0.000500    Time 0.206490    
2023-04-26 20:48:46,305 - Epoch: [59][  500/  518]    Overall Loss 3.155940    Objective Loss 3.155940                                        LR 0.000500    Time 0.206328    
2023-04-26 20:48:49,864 - Epoch: [59][  518/  518]    Overall Loss 3.154491    Objective Loss 3.154491                                        LR 0.000500    Time 0.206029    
2023-04-26 20:48:49,935 - --- validate (epoch=59)-----------
2023-04-26 20:48:49,936 - 4952 samples (32 per mini-batch)
2023-04-26 20:48:56,581 - Epoch: [59][   50/  155]    Loss 3.383633    mAP 0.383294    
2023-04-26 20:49:02,922 - Epoch: [59][  100/  155]    Loss 3.383028    mAP 0.389660    
2023-04-26 20:49:09,209 - Epoch: [59][  150/  155]    Loss 3.397379    mAP 0.385795    
2023-04-26 20:49:09,793 - Epoch: [59][  155/  155]    Loss 3.397242    mAP 0.386290    
2023-04-26 20:49:09,866 - ==> mAP: 0.38629    Loss: 3.397

2023-04-26 20:49:09,870 - ==> Best [mAP: 0.394528   vloss: 3.374902   Sparsity:0.00   Params: 2177088 on epoch: 58]
2023-04-26 20:49:09,870 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:49:09,907 - 

2023-04-26 20:49:09,907 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:49:20,816 - Epoch: [60][   50/  518]    Overall Loss 3.107423    Objective Loss 3.107423                                        LR 0.000500    Time 0.218125    
2023-04-26 20:49:31,014 - Epoch: [60][  100/  518]    Overall Loss 3.136068    Objective Loss 3.136068                                        LR 0.000500    Time 0.211020    
2023-04-26 20:49:41,220 - Epoch: [60][  150/  518]    Overall Loss 3.141047    Objective Loss 3.141047                                        LR 0.000500    Time 0.208709    
2023-04-26 20:49:51,425 - Epoch: [60][  200/  518]    Overall Loss 3.129932    Objective Loss 3.129932                                        LR 0.000500    Time 0.207550    
2023-04-26 20:50:01,643 - Epoch: [60][  250/  518]    Overall Loss 3.140829    Objective Loss 3.140829                                        LR 0.000500    Time 0.206906    
2023-04-26 20:50:11,902 - Epoch: [60][  300/  518]    Overall Loss 3.148227    Objective Loss 3.148227                                        LR 0.000500    Time 0.206611    
2023-04-26 20:50:22,153 - Epoch: [60][  350/  518]    Overall Loss 3.146969    Objective Loss 3.146969                                        LR 0.000500    Time 0.206379    
2023-04-26 20:50:32,325 - Epoch: [60][  400/  518]    Overall Loss 3.143864    Objective Loss 3.143864                                        LR 0.000500    Time 0.206009    
2023-04-26 20:50:42,567 - Epoch: [60][  450/  518]    Overall Loss 3.149313    Objective Loss 3.149313                                        LR 0.000500    Time 0.205875    
2023-04-26 20:50:52,760 - Epoch: [60][  500/  518]    Overall Loss 3.148199    Objective Loss 3.148199                                        LR 0.000500    Time 0.205671    
2023-04-26 20:50:56,317 - Epoch: [60][  518/  518]    Overall Loss 3.147255    Objective Loss 3.147255                                        LR 0.000500    Time 0.205389    
2023-04-26 20:50:56,387 - --- validate (epoch=60)-----------
2023-04-26 20:50:56,388 - 4952 samples (32 per mini-batch)
2023-04-26 20:51:03,153 - Epoch: [60][   50/  155]    Loss 3.387491    mAP 0.391434    
2023-04-26 20:51:09,481 - Epoch: [60][  100/  155]    Loss 3.390962    mAP 0.389449    
2023-04-26 20:51:15,787 - Epoch: [60][  150/  155]    Loss 3.390970    mAP 0.394047    
2023-04-26 20:51:16,355 - Epoch: [60][  155/  155]    Loss 3.388148    mAP 0.392963    
2023-04-26 20:51:16,421 - ==> mAP: 0.39296    Loss: 3.388

2023-04-26 20:51:16,425 - ==> Best [mAP: 0.394528   vloss: 3.374902   Sparsity:0.00   Params: 2177088 on epoch: 58]
2023-04-26 20:51:16,425 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:51:16,462 - 

2023-04-26 20:51:16,462 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:51:27,301 - Epoch: [61][   50/  518]    Overall Loss 3.117575    Objective Loss 3.117575                                        LR 0.000500    Time 0.216720    
2023-04-26 20:51:37,540 - Epoch: [61][  100/  518]    Overall Loss 3.125677    Objective Loss 3.125677                                        LR 0.000500    Time 0.210734    
2023-04-26 20:51:47,846 - Epoch: [61][  150/  518]    Overall Loss 3.143474    Objective Loss 3.143474                                        LR 0.000500    Time 0.209185    
2023-04-26 20:51:58,184 - Epoch: [61][  200/  518]    Overall Loss 3.136144    Objective Loss 3.136144                                        LR 0.000500    Time 0.208570    
2023-04-26 20:52:08,411 - Epoch: [61][  250/  518]    Overall Loss 3.136594    Objective Loss 3.136594                                        LR 0.000500    Time 0.207759    
2023-04-26 20:52:18,672 - Epoch: [61][  300/  518]    Overall Loss 3.132877    Objective Loss 3.132877                                        LR 0.000500    Time 0.207330    
2023-04-26 20:52:28,856 - Epoch: [61][  350/  518]    Overall Loss 3.130455    Objective Loss 3.130455                                        LR 0.000500    Time 0.206803    
2023-04-26 20:52:39,082 - Epoch: [61][  400/  518]    Overall Loss 3.140891    Objective Loss 3.140891                                        LR 0.000500    Time 0.206513    
2023-04-26 20:52:49,281 - Epoch: [61][  450/  518]    Overall Loss 3.143083    Objective Loss 3.143083                                        LR 0.000500    Time 0.206227    
2023-04-26 20:52:59,508 - Epoch: [61][  500/  518]    Overall Loss 3.147775    Objective Loss 3.147775                                        LR 0.000500    Time 0.206057    
2023-04-26 20:53:03,089 - Epoch: [61][  518/  518]    Overall Loss 3.150098    Objective Loss 3.150098                                        LR 0.000500    Time 0.205807    
2023-04-26 20:53:03,162 - --- validate (epoch=61)-----------
2023-04-26 20:53:03,162 - 4952 samples (32 per mini-batch)
2023-04-26 20:53:09,851 - Epoch: [61][   50/  155]    Loss 3.350057    mAP 0.389158    
2023-04-26 20:53:16,167 - Epoch: [61][  100/  155]    Loss 3.388041    mAP 0.383509    
2023-04-26 20:53:22,444 - Epoch: [61][  150/  155]    Loss 3.363264    mAP 0.390989    
2023-04-26 20:53:23,008 - Epoch: [61][  155/  155]    Loss 3.363287    mAP 0.390737    
2023-04-26 20:53:23,079 - ==> mAP: 0.39074    Loss: 3.363

2023-04-26 20:53:23,083 - ==> Best [mAP: 0.394528   vloss: 3.374902   Sparsity:0.00   Params: 2177088 on epoch: 58]
2023-04-26 20:53:23,083 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:53:23,120 - 

2023-04-26 20:53:23,120 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:53:34,334 - Epoch: [62][   50/  518]    Overall Loss 3.140290    Objective Loss 3.140290                                        LR 0.000500    Time 0.224216    
2023-04-26 20:53:44,613 - Epoch: [62][  100/  518]    Overall Loss 3.134499    Objective Loss 3.134499                                        LR 0.000500    Time 0.214884    
2023-04-26 20:53:54,846 - Epoch: [62][  150/  518]    Overall Loss 3.131603    Objective Loss 3.131603                                        LR 0.000500    Time 0.211467    
2023-04-26 20:54:05,124 - Epoch: [62][  200/  518]    Overall Loss 3.149677    Objective Loss 3.149677                                        LR 0.000500    Time 0.209980    
2023-04-26 20:54:15,263 - Epoch: [62][  250/  518]    Overall Loss 3.143783    Objective Loss 3.143783                                        LR 0.000500    Time 0.208533    
2023-04-26 20:54:25,534 - Epoch: [62][  300/  518]    Overall Loss 3.142626    Objective Loss 3.142626                                        LR 0.000500    Time 0.208008    
2023-04-26 20:54:35,753 - Epoch: [62][  350/  518]    Overall Loss 3.147249    Objective Loss 3.147249                                        LR 0.000500    Time 0.207487    
2023-04-26 20:54:46,005 - Epoch: [62][  400/  518]    Overall Loss 3.146436    Objective Loss 3.146436                                        LR 0.000500    Time 0.207176    
2023-04-26 20:54:56,241 - Epoch: [62][  450/  518]    Overall Loss 3.153558    Objective Loss 3.153558                                        LR 0.000500    Time 0.206900    
2023-04-26 20:55:06,501 - Epoch: [62][  500/  518]    Overall Loss 3.156211    Objective Loss 3.156211                                        LR 0.000500    Time 0.206726    
2023-04-26 20:55:10,065 - Epoch: [62][  518/  518]    Overall Loss 3.156476    Objective Loss 3.156476                                        LR 0.000500    Time 0.206422    
2023-04-26 20:55:10,136 - --- validate (epoch=62)-----------
2023-04-26 20:55:10,137 - 4952 samples (32 per mini-batch)
2023-04-26 20:55:16,917 - Epoch: [62][   50/  155]    Loss 3.339289    mAP 0.399530    
2023-04-26 20:55:23,297 - Epoch: [62][  100/  155]    Loss 3.349719    mAP 0.397809    
2023-04-26 20:55:29,649 - Epoch: [62][  150/  155]    Loss 3.362013    mAP 0.395738    
2023-04-26 20:55:30,203 - Epoch: [62][  155/  155]    Loss 3.359395    mAP 0.394084    
2023-04-26 20:55:30,277 - ==> mAP: 0.39408    Loss: 3.359

2023-04-26 20:55:30,281 - ==> Best [mAP: 0.394528   vloss: 3.374902   Sparsity:0.00   Params: 2177088 on epoch: 58]
2023-04-26 20:55:30,281 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:55:30,318 - 

2023-04-26 20:55:30,318 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:55:41,305 - Epoch: [63][   50/  518]    Overall Loss 3.122867    Objective Loss 3.122867                                        LR 0.000500    Time 0.219674    
2023-04-26 20:55:51,537 - Epoch: [63][  100/  518]    Overall Loss 3.119196    Objective Loss 3.119196                                        LR 0.000500    Time 0.212148    
2023-04-26 20:56:01,813 - Epoch: [63][  150/  518]    Overall Loss 3.112403    Objective Loss 3.112403                                        LR 0.000500    Time 0.209923    
2023-04-26 20:56:12,049 - Epoch: [63][  200/  518]    Overall Loss 3.127661    Objective Loss 3.127661                                        LR 0.000500    Time 0.208617    
2023-04-26 20:56:22,358 - Epoch: [63][  250/  518]    Overall Loss 3.141238    Objective Loss 3.141238                                        LR 0.000500    Time 0.208122    
2023-04-26 20:56:32,528 - Epoch: [63][  300/  518]    Overall Loss 3.143976    Objective Loss 3.143976                                        LR 0.000500    Time 0.207328    
2023-04-26 20:56:42,706 - Epoch: [63][  350/  518]    Overall Loss 3.142531    Objective Loss 3.142531                                        LR 0.000500    Time 0.206788    
2023-04-26 20:56:52,897 - Epoch: [63][  400/  518]    Overall Loss 3.136535    Objective Loss 3.136535                                        LR 0.000500    Time 0.206411    
2023-04-26 20:57:03,105 - Epoch: [63][  450/  518]    Overall Loss 3.137899    Objective Loss 3.137899                                        LR 0.000500    Time 0.206158    
2023-04-26 20:57:13,352 - Epoch: [63][  500/  518]    Overall Loss 3.135020    Objective Loss 3.135020                                        LR 0.000500    Time 0.206032    
2023-04-26 20:57:16,858 - Epoch: [63][  518/  518]    Overall Loss 3.135891    Objective Loss 3.135891                                        LR 0.000500    Time 0.205640    
2023-04-26 20:57:16,929 - --- validate (epoch=63)-----------
2023-04-26 20:57:16,929 - 4952 samples (32 per mini-batch)
2023-04-26 20:57:23,783 - Epoch: [63][   50/  155]    Loss 3.321821    mAP 0.395785    
2023-04-26 20:57:30,108 - Epoch: [63][  100/  155]    Loss 3.351927    mAP 0.384170    
2023-04-26 20:57:36,518 - Epoch: [63][  150/  155]    Loss 3.347704    mAP 0.396698    
2023-04-26 20:57:37,117 - Epoch: [63][  155/  155]    Loss 3.351152    mAP 0.397624    
2023-04-26 20:57:37,180 - ==> mAP: 0.39762    Loss: 3.351

2023-04-26 20:57:37,183 - ==> Best [mAP: 0.397624   vloss: 3.351152   Sparsity:0.00   Params: 2177088 on epoch: 63]
2023-04-26 20:57:37,183 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:57:37,234 - 

2023-04-26 20:57:37,235 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:57:48,089 - Epoch: [64][   50/  518]    Overall Loss 3.154796    Objective Loss 3.154796                                        LR 0.000500    Time 0.217036    
2023-04-26 20:57:58,219 - Epoch: [64][  100/  518]    Overall Loss 3.143420    Objective Loss 3.143420                                        LR 0.000500    Time 0.209799    
2023-04-26 20:58:08,491 - Epoch: [64][  150/  518]    Overall Loss 3.137184    Objective Loss 3.137184                                        LR 0.000500    Time 0.208331    
2023-04-26 20:58:18,713 - Epoch: [64][  200/  518]    Overall Loss 3.130531    Objective Loss 3.130531                                        LR 0.000500    Time 0.207351    
2023-04-26 20:58:28,932 - Epoch: [64][  250/  518]    Overall Loss 3.119172    Objective Loss 3.119172                                        LR 0.000500    Time 0.206752    
2023-04-26 20:58:39,167 - Epoch: [64][  300/  518]    Overall Loss 3.129767    Objective Loss 3.129767                                        LR 0.000500    Time 0.206406    
2023-04-26 20:58:49,441 - Epoch: [64][  350/  518]    Overall Loss 3.130196    Objective Loss 3.130196                                        LR 0.000500    Time 0.206268    
2023-04-26 20:58:59,655 - Epoch: [64][  400/  518]    Overall Loss 3.129256    Objective Loss 3.129256                                        LR 0.000500    Time 0.206016    
2023-04-26 20:59:09,910 - Epoch: [64][  450/  518]    Overall Loss 3.131034    Objective Loss 3.131034                                        LR 0.000500    Time 0.205909    
2023-04-26 20:59:20,156 - Epoch: [64][  500/  518]    Overall Loss 3.133008    Objective Loss 3.133008                                        LR 0.000500    Time 0.205808    
2023-04-26 20:59:23,746 - Epoch: [64][  518/  518]    Overall Loss 3.133499    Objective Loss 3.133499                                        LR 0.000500    Time 0.205585    
2023-04-26 20:59:23,818 - --- validate (epoch=64)-----------
2023-04-26 20:59:23,818 - 4952 samples (32 per mini-batch)
2023-04-26 20:59:30,488 - Epoch: [64][   50/  155]    Loss 3.375057    mAP 0.409565    
2023-04-26 20:59:36,911 - Epoch: [64][  100/  155]    Loss 3.360678    mAP 0.403221    
2023-04-26 20:59:43,244 - Epoch: [64][  150/  155]    Loss 3.378996    mAP 0.398151    
2023-04-26 20:59:43,809 - Epoch: [64][  155/  155]    Loss 3.377506    mAP 0.398895    
2023-04-26 20:59:43,874 - ==> mAP: 0.39890    Loss: 3.378

2023-04-26 20:59:43,878 - ==> Best [mAP: 0.398895   vloss: 3.377506   Sparsity:0.00   Params: 2177088 on epoch: 64]
2023-04-26 20:59:43,878 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 20:59:43,931 - 

2023-04-26 20:59:43,931 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 20:59:54,989 - Epoch: [65][   50/  518]    Overall Loss 3.138288    Objective Loss 3.138288                                        LR 0.000500    Time 0.221105    
2023-04-26 21:00:05,298 - Epoch: [65][  100/  518]    Overall Loss 3.143166    Objective Loss 3.143166                                        LR 0.000500    Time 0.213626    
2023-04-26 21:00:15,480 - Epoch: [65][  150/  518]    Overall Loss 3.113511    Objective Loss 3.113511                                        LR 0.000500    Time 0.210286    
2023-04-26 21:00:25,796 - Epoch: [65][  200/  518]    Overall Loss 3.115924    Objective Loss 3.115924                                        LR 0.000500    Time 0.209286    
2023-04-26 21:00:36,024 - Epoch: [65][  250/  518]    Overall Loss 3.117818    Objective Loss 3.117818                                        LR 0.000500    Time 0.208335    
2023-04-26 21:00:46,192 - Epoch: [65][  300/  518]    Overall Loss 3.132138    Objective Loss 3.132138                                        LR 0.000500    Time 0.207497    
2023-04-26 21:00:56,495 - Epoch: [65][  350/  518]    Overall Loss 3.122980    Objective Loss 3.122980                                        LR 0.000500    Time 0.207288    
2023-04-26 21:01:06,764 - Epoch: [65][  400/  518]    Overall Loss 3.124111    Objective Loss 3.124111                                        LR 0.000500    Time 0.207047    
2023-04-26 21:01:17,000 - Epoch: [65][  450/  518]    Overall Loss 3.125051    Objective Loss 3.125051                                        LR 0.000500    Time 0.206783    
2023-04-26 21:01:27,271 - Epoch: [65][  500/  518]    Overall Loss 3.125917    Objective Loss 3.125917                                        LR 0.000500    Time 0.206643    
2023-04-26 21:01:30,835 - Epoch: [65][  518/  518]    Overall Loss 3.126202    Objective Loss 3.126202                                        LR 0.000500    Time 0.206342    
2023-04-26 21:01:30,909 - --- validate (epoch=65)-----------
2023-04-26 21:01:30,909 - 4952 samples (32 per mini-batch)
2023-04-26 21:01:37,728 - Epoch: [65][   50/  155]    Loss 3.350670    mAP 0.399979    
2023-04-26 21:01:44,118 - Epoch: [65][  100/  155]    Loss 3.336187    mAP 0.402599    
2023-04-26 21:01:50,452 - Epoch: [65][  150/  155]    Loss 3.338086    mAP 0.404383    
2023-04-26 21:01:51,027 - Epoch: [65][  155/  155]    Loss 3.340965    mAP 0.404782    
2023-04-26 21:01:51,097 - ==> mAP: 0.40478    Loss: 3.341

2023-04-26 21:01:51,100 - ==> Best [mAP: 0.404782   vloss: 3.340965   Sparsity:0.00   Params: 2177088 on epoch: 65]
2023-04-26 21:01:51,100 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:01:51,153 - 

2023-04-26 21:01:51,153 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:02:02,118 - Epoch: [66][   50/  518]    Overall Loss 3.098808    Objective Loss 3.098808                                        LR 0.000500    Time 0.219233    
2023-04-26 21:02:12,346 - Epoch: [66][  100/  518]    Overall Loss 3.106847    Objective Loss 3.106847                                        LR 0.000500    Time 0.211874    
2023-04-26 21:02:22,610 - Epoch: [66][  150/  518]    Overall Loss 3.112074    Objective Loss 3.112074                                        LR 0.000500    Time 0.209668    
2023-04-26 21:02:32,848 - Epoch: [66][  200/  518]    Overall Loss 3.104472    Objective Loss 3.104472                                        LR 0.000500    Time 0.208431    
2023-04-26 21:02:43,127 - Epoch: [66][  250/  518]    Overall Loss 3.118187    Objective Loss 3.118187                                        LR 0.000500    Time 0.207854    
2023-04-26 21:02:53,419 - Epoch: [66][  300/  518]    Overall Loss 3.126643    Objective Loss 3.126643                                        LR 0.000500    Time 0.207514    
2023-04-26 21:03:03,616 - Epoch: [66][  350/  518]    Overall Loss 3.123784    Objective Loss 3.123784                                        LR 0.000500    Time 0.207000    
2023-04-26 21:03:13,806 - Epoch: [66][  400/  518]    Overall Loss 3.124651    Objective Loss 3.124651                                        LR 0.000500    Time 0.206595    
2023-04-26 21:03:24,049 - Epoch: [66][  450/  518]    Overall Loss 3.122429    Objective Loss 3.122429                                        LR 0.000500    Time 0.206399    
2023-04-26 21:03:34,355 - Epoch: [66][  500/  518]    Overall Loss 3.116381    Objective Loss 3.116381                                        LR 0.000500    Time 0.206368    
2023-04-26 21:03:37,889 - Epoch: [66][  518/  518]    Overall Loss 3.112319    Objective Loss 3.112319                                        LR 0.000500    Time 0.206017    
2023-04-26 21:03:37,960 - --- validate (epoch=66)-----------
2023-04-26 21:03:37,960 - 4952 samples (32 per mini-batch)
2023-04-26 21:03:44,612 - Epoch: [66][   50/  155]    Loss 3.364036    mAP 0.399598    
2023-04-26 21:03:50,982 - Epoch: [66][  100/  155]    Loss 3.346426    mAP 0.401934    
2023-04-26 21:03:57,235 - Epoch: [66][  150/  155]    Loss 3.354209    mAP 0.397558    
2023-04-26 21:03:57,784 - Epoch: [66][  155/  155]    Loss 3.352599    mAP 0.396820    
2023-04-26 21:03:57,856 - ==> mAP: 0.39682    Loss: 3.353

2023-04-26 21:03:57,860 - ==> Best [mAP: 0.404782   vloss: 3.340965   Sparsity:0.00   Params: 2177088 on epoch: 65]
2023-04-26 21:03:57,860 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:03:57,898 - 

2023-04-26 21:03:57,898 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:04:08,893 - Epoch: [67][   50/  518]    Overall Loss 3.059060    Objective Loss 3.059060                                        LR 0.000500    Time 0.219845    
2023-04-26 21:04:19,143 - Epoch: [67][  100/  518]    Overall Loss 3.103236    Objective Loss 3.103236                                        LR 0.000500    Time 0.212409    
2023-04-26 21:04:29,382 - Epoch: [67][  150/  518]    Overall Loss 3.104021    Objective Loss 3.104021                                        LR 0.000500    Time 0.209856    
2023-04-26 21:04:39,612 - Epoch: [67][  200/  518]    Overall Loss 3.108865    Objective Loss 3.108865                                        LR 0.000500    Time 0.208533    
2023-04-26 21:04:49,853 - Epoch: [67][  250/  518]    Overall Loss 3.101721    Objective Loss 3.101721                                        LR 0.000500    Time 0.207782    
2023-04-26 21:05:00,132 - Epoch: [67][  300/  518]    Overall Loss 3.105551    Objective Loss 3.105551                                        LR 0.000500    Time 0.207410    
2023-04-26 21:05:10,382 - Epoch: [67][  350/  518]    Overall Loss 3.114393    Objective Loss 3.114393                                        LR 0.000500    Time 0.207062    
2023-04-26 21:05:20,613 - Epoch: [67][  400/  518]    Overall Loss 3.118361    Objective Loss 3.118361                                        LR 0.000500    Time 0.206751    
2023-04-26 21:05:30,922 - Epoch: [67][  450/  518]    Overall Loss 3.116233    Objective Loss 3.116233                                        LR 0.000500    Time 0.206686    
2023-04-26 21:05:41,218 - Epoch: [67][  500/  518]    Overall Loss 3.114102    Objective Loss 3.114102                                        LR 0.000500    Time 0.206604    
2023-04-26 21:05:44,754 - Epoch: [67][  518/  518]    Overall Loss 3.112769    Objective Loss 3.112769                                        LR 0.000500    Time 0.206252    
2023-04-26 21:05:44,827 - --- validate (epoch=67)-----------
2023-04-26 21:05:44,827 - 4952 samples (32 per mini-batch)
2023-04-26 21:05:51,579 - Epoch: [67][   50/  155]    Loss 3.360903    mAP 0.392447    
2023-04-26 21:05:57,961 - Epoch: [67][  100/  155]    Loss 3.378534    mAP 0.398061    
2023-04-26 21:06:04,293 - Epoch: [67][  150/  155]    Loss 3.333520    mAP 0.403852    
2023-04-26 21:06:04,868 - Epoch: [67][  155/  155]    Loss 3.333734    mAP 0.407427    
2023-04-26 21:06:04,937 - ==> mAP: 0.40743    Loss: 3.334

2023-04-26 21:06:04,941 - ==> Best [mAP: 0.407427   vloss: 3.333734   Sparsity:0.00   Params: 2177088 on epoch: 67]
2023-04-26 21:06:04,941 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:06:04,993 - 

2023-04-26 21:06:04,994 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:06:15,912 - Epoch: [68][   50/  518]    Overall Loss 3.108588    Objective Loss 3.108588                                        LR 0.000500    Time 0.218310    
2023-04-26 21:06:26,090 - Epoch: [68][  100/  518]    Overall Loss 3.102938    Objective Loss 3.102938                                        LR 0.000500    Time 0.210918    
2023-04-26 21:06:36,399 - Epoch: [68][  150/  518]    Overall Loss 3.096751    Objective Loss 3.096751                                        LR 0.000500    Time 0.209330    
2023-04-26 21:06:46,671 - Epoch: [68][  200/  518]    Overall Loss 3.094460    Objective Loss 3.094460                                        LR 0.000500    Time 0.208346    
2023-04-26 21:06:56,925 - Epoch: [68][  250/  518]    Overall Loss 3.096084    Objective Loss 3.096084                                        LR 0.000500    Time 0.207689    
2023-04-26 21:07:07,072 - Epoch: [68][  300/  518]    Overall Loss 3.098550    Objective Loss 3.098550                                        LR 0.000500    Time 0.206893    
2023-04-26 21:07:17,299 - Epoch: [68][  350/  518]    Overall Loss 3.099842    Objective Loss 3.099842                                        LR 0.000500    Time 0.206550    
2023-04-26 21:07:27,475 - Epoch: [68][  400/  518]    Overall Loss 3.106958    Objective Loss 3.106958                                        LR 0.000500    Time 0.206167    
2023-04-26 21:07:37,725 - Epoch: [68][  450/  518]    Overall Loss 3.104868    Objective Loss 3.104868                                        LR 0.000500    Time 0.206035    
2023-04-26 21:07:47,905 - Epoch: [68][  500/  518]    Overall Loss 3.106008    Objective Loss 3.106008                                        LR 0.000500    Time 0.205789    
2023-04-26 21:07:51,482 - Epoch: [68][  518/  518]    Overall Loss 3.107878    Objective Loss 3.107878                                        LR 0.000500    Time 0.205541    
2023-04-26 21:07:51,553 - --- validate (epoch=68)-----------
2023-04-26 21:07:51,553 - 4952 samples (32 per mini-batch)
2023-04-26 21:07:58,282 - Epoch: [68][   50/  155]    Loss 3.365922    mAP 0.390155    
2023-04-26 21:08:04,608 - Epoch: [68][  100/  155]    Loss 3.358883    mAP 0.393159    
2023-04-26 21:08:10,923 - Epoch: [68][  150/  155]    Loss 3.350316    mAP 0.394180    
2023-04-26 21:08:11,495 - Epoch: [68][  155/  155]    Loss 3.343957    mAP 0.398163    
2023-04-26 21:08:11,567 - ==> mAP: 0.39816    Loss: 3.344

2023-04-26 21:08:11,571 - ==> Best [mAP: 0.407427   vloss: 3.333734   Sparsity:0.00   Params: 2177088 on epoch: 67]
2023-04-26 21:08:11,571 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:08:11,608 - 

2023-04-26 21:08:11,608 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:08:22,809 - Epoch: [69][   50/  518]    Overall Loss 3.021820    Objective Loss 3.021820                                        LR 0.000500    Time 0.223946    
2023-04-26 21:08:33,039 - Epoch: [69][  100/  518]    Overall Loss 3.078581    Objective Loss 3.078581                                        LR 0.000500    Time 0.214261    
2023-04-26 21:08:43,308 - Epoch: [69][  150/  518]    Overall Loss 3.079610    Objective Loss 3.079610                                        LR 0.000500    Time 0.211287    
2023-04-26 21:08:53,546 - Epoch: [69][  200/  518]    Overall Loss 3.074705    Objective Loss 3.074705                                        LR 0.000500    Time 0.209648    
2023-04-26 21:09:03,883 - Epoch: [69][  250/  518]    Overall Loss 3.087258    Objective Loss 3.087258                                        LR 0.000500    Time 0.209060    
2023-04-26 21:09:14,023 - Epoch: [69][  300/  518]    Overall Loss 3.089662    Objective Loss 3.089662                                        LR 0.000500    Time 0.208012    
2023-04-26 21:09:24,323 - Epoch: [69][  350/  518]    Overall Loss 3.089213    Objective Loss 3.089213                                        LR 0.000500    Time 0.207720    
2023-04-26 21:09:34,501 - Epoch: [69][  400/  518]    Overall Loss 3.098154    Objective Loss 3.098154                                        LR 0.000500    Time 0.207196    
2023-04-26 21:09:44,666 - Epoch: [69][  450/  518]    Overall Loss 3.102012    Objective Loss 3.102012                                        LR 0.000500    Time 0.206760    
2023-04-26 21:09:54,976 - Epoch: [69][  500/  518]    Overall Loss 3.101376    Objective Loss 3.101376                                        LR 0.000500    Time 0.206700    
2023-04-26 21:09:58,540 - Epoch: [69][  518/  518]    Overall Loss 3.100698    Objective Loss 3.100698                                        LR 0.000500    Time 0.206396    
2023-04-26 21:09:58,612 - --- validate (epoch=69)-----------
2023-04-26 21:09:58,612 - 4952 samples (32 per mini-batch)
2023-04-26 21:10:05,431 - Epoch: [69][   50/  155]    Loss 3.405737    mAP 0.407957    
2023-04-26 21:10:11,779 - Epoch: [69][  100/  155]    Loss 3.369537    mAP 0.390592    
2023-04-26 21:10:18,254 - Epoch: [69][  150/  155]    Loss 3.356313    mAP 0.398457    
2023-04-26 21:10:18,826 - Epoch: [69][  155/  155]    Loss 3.354645    mAP 0.398755    
2023-04-26 21:10:18,901 - ==> mAP: 0.39876    Loss: 3.355

2023-04-26 21:10:18,906 - ==> Best [mAP: 0.407427   vloss: 3.333734   Sparsity:0.00   Params: 2177088 on epoch: 67]
2023-04-26 21:10:18,906 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:10:18,943 - 

2023-04-26 21:10:18,943 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:10:29,939 - Epoch: [70][   50/  518]    Overall Loss 3.064300    Objective Loss 3.064300                                        LR 0.000500    Time 0.219855    
2023-04-26 21:10:40,211 - Epoch: [70][  100/  518]    Overall Loss 3.095997    Objective Loss 3.095997                                        LR 0.000500    Time 0.212634    
2023-04-26 21:10:50,470 - Epoch: [70][  150/  518]    Overall Loss 3.105374    Objective Loss 3.105374                                        LR 0.000500    Time 0.210140    
2023-04-26 21:11:00,721 - Epoch: [70][  200/  518]    Overall Loss 3.105431    Objective Loss 3.105431                                        LR 0.000500    Time 0.208849    
2023-04-26 21:11:10,938 - Epoch: [70][  250/  518]    Overall Loss 3.096610    Objective Loss 3.096610                                        LR 0.000500    Time 0.207941    
2023-04-26 21:11:21,213 - Epoch: [70][  300/  518]    Overall Loss 3.095262    Objective Loss 3.095262                                        LR 0.000500    Time 0.207530    
2023-04-26 21:11:31,504 - Epoch: [70][  350/  518]    Overall Loss 3.096416    Objective Loss 3.096416                                        LR 0.000500    Time 0.207282    
2023-04-26 21:11:41,705 - Epoch: [70][  400/  518]    Overall Loss 3.097657    Objective Loss 3.097657                                        LR 0.000500    Time 0.206868    
2023-04-26 21:11:52,022 - Epoch: [70][  450/  518]    Overall Loss 3.102195    Objective Loss 3.102195                                        LR 0.000500    Time 0.206807    
2023-04-26 21:12:02,217 - Epoch: [70][  500/  518]    Overall Loss 3.104421    Objective Loss 3.104421                                        LR 0.000500    Time 0.206513    
2023-04-26 21:12:05,767 - Epoch: [70][  518/  518]    Overall Loss 3.109503    Objective Loss 3.109503                                        LR 0.000500    Time 0.206188    
2023-04-26 21:12:05,838 - --- validate (epoch=70)-----------
2023-04-26 21:12:05,838 - 4952 samples (32 per mini-batch)
2023-04-26 21:12:12,608 - Epoch: [70][   50/  155]    Loss 3.408647    mAP 0.406164    
2023-04-26 21:12:18,965 - Epoch: [70][  100/  155]    Loss 3.386827    mAP 0.406378    
2023-04-26 21:12:25,332 - Epoch: [70][  150/  155]    Loss 3.378024    mAP 0.409147    
2023-04-26 21:12:25,905 - Epoch: [70][  155/  155]    Loss 3.376234    mAP 0.410750    
2023-04-26 21:12:25,977 - ==> mAP: 0.41075    Loss: 3.376

2023-04-26 21:12:25,980 - ==> Best [mAP: 0.410750   vloss: 3.376234   Sparsity:0.00   Params: 2177088 on epoch: 70]
2023-04-26 21:12:25,981 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:12:26,032 - 

2023-04-26 21:12:26,032 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:12:37,026 - Epoch: [71][   50/  518]    Overall Loss 3.093215    Objective Loss 3.093215                                        LR 0.000500    Time 0.219815    
2023-04-26 21:12:47,177 - Epoch: [71][  100/  518]    Overall Loss 3.113340    Objective Loss 3.113340                                        LR 0.000500    Time 0.211401    
2023-04-26 21:12:57,440 - Epoch: [71][  150/  518]    Overall Loss 3.109846    Objective Loss 3.109846                                        LR 0.000500    Time 0.209348    
2023-04-26 21:13:07,661 - Epoch: [71][  200/  518]    Overall Loss 3.098533    Objective Loss 3.098533                                        LR 0.000500    Time 0.208106    
2023-04-26 21:13:17,927 - Epoch: [71][  250/  518]    Overall Loss 3.110691    Objective Loss 3.110691                                        LR 0.000500    Time 0.207540    
2023-04-26 21:13:28,074 - Epoch: [71][  300/  518]    Overall Loss 3.121218    Objective Loss 3.121218                                        LR 0.000500    Time 0.206769    
2023-04-26 21:13:38,371 - Epoch: [71][  350/  518]    Overall Loss 3.114849    Objective Loss 3.114849                                        LR 0.000500    Time 0.206646    
2023-04-26 21:13:48,561 - Epoch: [71][  400/  518]    Overall Loss 3.116040    Objective Loss 3.116040                                        LR 0.000500    Time 0.206287    
2023-04-26 21:13:58,762 - Epoch: [71][  450/  518]    Overall Loss 3.117352    Objective Loss 3.117352                                        LR 0.000500    Time 0.206031    
2023-04-26 21:14:08,885 - Epoch: [71][  500/  518]    Overall Loss 3.111811    Objective Loss 3.111811                                        LR 0.000500    Time 0.205671    
2023-04-26 21:14:12,427 - Epoch: [71][  518/  518]    Overall Loss 3.108717    Objective Loss 3.108717                                        LR 0.000500    Time 0.205360    
2023-04-26 21:14:12,499 - --- validate (epoch=71)-----------
2023-04-26 21:14:12,499 - 4952 samples (32 per mini-batch)
2023-04-26 21:14:19,303 - Epoch: [71][   50/  155]    Loss 3.339583    mAP 0.415197    
2023-04-26 21:14:25,684 - Epoch: [71][  100/  155]    Loss 3.331181    mAP 0.414131    
2023-04-26 21:14:32,027 - Epoch: [71][  150/  155]    Loss 3.308379    mAP 0.411753    
2023-04-26 21:14:32,586 - Epoch: [71][  155/  155]    Loss 3.310280    mAP 0.411791    
2023-04-26 21:14:32,652 - ==> mAP: 0.41179    Loss: 3.310

2023-04-26 21:14:32,656 - ==> Best [mAP: 0.411791   vloss: 3.310280   Sparsity:0.00   Params: 2177088 on epoch: 71]
2023-04-26 21:14:32,656 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:14:32,710 - 

2023-04-26 21:14:32,710 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:14:43,701 - Epoch: [72][   50/  518]    Overall Loss 3.097554    Objective Loss 3.097554                                        LR 0.000500    Time 0.219748    
2023-04-26 21:14:53,847 - Epoch: [72][  100/  518]    Overall Loss 3.090832    Objective Loss 3.090832                                        LR 0.000500    Time 0.211324    
2023-04-26 21:15:04,101 - Epoch: [72][  150/  518]    Overall Loss 3.076565    Objective Loss 3.076565                                        LR 0.000500    Time 0.209228    
2023-04-26 21:15:14,307 - Epoch: [72][  200/  518]    Overall Loss 3.082248    Objective Loss 3.082248                                        LR 0.000500    Time 0.207943    
2023-04-26 21:15:24,597 - Epoch: [72][  250/  518]    Overall Loss 3.081627    Objective Loss 3.081627                                        LR 0.000500    Time 0.207507    
2023-04-26 21:15:34,812 - Epoch: [72][  300/  518]    Overall Loss 3.081565    Objective Loss 3.081565                                        LR 0.000500    Time 0.206969    
2023-04-26 21:15:45,087 - Epoch: [72][  350/  518]    Overall Loss 3.088581    Objective Loss 3.088581                                        LR 0.000500    Time 0.206753    
2023-04-26 21:15:55,310 - Epoch: [72][  400/  518]    Overall Loss 3.077697    Objective Loss 3.077697                                        LR 0.000500    Time 0.206464    
2023-04-26 21:16:05,592 - Epoch: [72][  450/  518]    Overall Loss 3.081504    Objective Loss 3.081504                                        LR 0.000500    Time 0.206367    
2023-04-26 21:16:15,847 - Epoch: [72][  500/  518]    Overall Loss 3.080206    Objective Loss 3.080206                                        LR 0.000500    Time 0.206238    
2023-04-26 21:16:19,327 - Epoch: [72][  518/  518]    Overall Loss 3.083708    Objective Loss 3.083708                                        LR 0.000500    Time 0.205788    
2023-04-26 21:16:19,398 - --- validate (epoch=72)-----------
2023-04-26 21:16:19,399 - 4952 samples (32 per mini-batch)
2023-04-26 21:16:26,153 - Epoch: [72][   50/  155]    Loss 3.361813    mAP 0.412380    
2023-04-26 21:16:32,556 - Epoch: [72][  100/  155]    Loss 3.369219    mAP 0.409617    
2023-04-26 21:16:38,935 - Epoch: [72][  150/  155]    Loss 3.371567    mAP 0.408592    
2023-04-26 21:16:39,499 - Epoch: [72][  155/  155]    Loss 3.373593    mAP 0.408687    
2023-04-26 21:16:39,567 - ==> mAP: 0.40869    Loss: 3.374

2023-04-26 21:16:39,571 - ==> Best [mAP: 0.411791   vloss: 3.310280   Sparsity:0.00   Params: 2177088 on epoch: 71]
2023-04-26 21:16:39,571 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:16:39,608 - 

2023-04-26 21:16:39,608 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:16:50,732 - Epoch: [73][   50/  518]    Overall Loss 3.102592    Objective Loss 3.102592                                        LR 0.000500    Time 0.222429    
2023-04-26 21:17:00,978 - Epoch: [73][  100/  518]    Overall Loss 3.106973    Objective Loss 3.106973                                        LR 0.000500    Time 0.213661    
2023-04-26 21:17:11,208 - Epoch: [73][  150/  518]    Overall Loss 3.110413    Objective Loss 3.110413                                        LR 0.000500    Time 0.210627    
2023-04-26 21:17:21,371 - Epoch: [73][  200/  518]    Overall Loss 3.100662    Objective Loss 3.100662                                        LR 0.000500    Time 0.208779    
2023-04-26 21:17:31,645 - Epoch: [73][  250/  518]    Overall Loss 3.094244    Objective Loss 3.094244                                        LR 0.000500    Time 0.208110    
2023-04-26 21:17:41,902 - Epoch: [73][  300/  518]    Overall Loss 3.096750    Objective Loss 3.096750                                        LR 0.000500    Time 0.207609    
2023-04-26 21:17:52,144 - Epoch: [73][  350/  518]    Overall Loss 3.100564    Objective Loss 3.100564                                        LR 0.000500    Time 0.207211    
2023-04-26 21:18:02,333 - Epoch: [73][  400/  518]    Overall Loss 3.097194    Objective Loss 3.097194                                        LR 0.000500    Time 0.206777    
2023-04-26 21:18:12,498 - Epoch: [73][  450/  518]    Overall Loss 3.096925    Objective Loss 3.096925                                        LR 0.000500    Time 0.206387    
2023-04-26 21:18:22,710 - Epoch: [73][  500/  518]    Overall Loss 3.091646    Objective Loss 3.091646                                        LR 0.000500    Time 0.206168    
2023-04-26 21:18:26,194 - Epoch: [73][  518/  518]    Overall Loss 3.092107    Objective Loss 3.092107                                        LR 0.000500    Time 0.205730    
2023-04-26 21:18:26,265 - --- validate (epoch=73)-----------
2023-04-26 21:18:26,266 - 4952 samples (32 per mini-batch)
2023-04-26 21:18:32,965 - Epoch: [73][   50/  155]    Loss 3.332391    mAP 0.407473    
2023-04-26 21:18:39,301 - Epoch: [73][  100/  155]    Loss 3.350255    mAP 0.395479    
2023-04-26 21:18:45,591 - Epoch: [73][  150/  155]    Loss 3.361046    mAP 0.392722    
2023-04-26 21:18:46,150 - Epoch: [73][  155/  155]    Loss 3.354191    mAP 0.392870    
2023-04-26 21:18:46,222 - ==> mAP: 0.39287    Loss: 3.354

2023-04-26 21:18:46,226 - ==> Best [mAP: 0.411791   vloss: 3.310280   Sparsity:0.00   Params: 2177088 on epoch: 71]
2023-04-26 21:18:46,226 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:18:46,262 - 

2023-04-26 21:18:46,263 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:18:57,344 - Epoch: [74][   50/  518]    Overall Loss 3.040304    Objective Loss 3.040304                                        LR 0.000500    Time 0.221574    
2023-04-26 21:19:07,586 - Epoch: [74][  100/  518]    Overall Loss 3.068176    Objective Loss 3.068176                                        LR 0.000500    Time 0.213192    
2023-04-26 21:19:17,760 - Epoch: [74][  150/  518]    Overall Loss 3.059938    Objective Loss 3.059938                                        LR 0.000500    Time 0.209941    
2023-04-26 21:19:28,022 - Epoch: [74][  200/  518]    Overall Loss 3.070662    Objective Loss 3.070662                                        LR 0.000500    Time 0.208757    
2023-04-26 21:19:38,314 - Epoch: [74][  250/  518]    Overall Loss 3.073180    Objective Loss 3.073180                                        LR 0.000500    Time 0.208167    
2023-04-26 21:19:48,513 - Epoch: [74][  300/  518]    Overall Loss 3.071122    Objective Loss 3.071122                                        LR 0.000500    Time 0.207465    
2023-04-26 21:19:58,735 - Epoch: [74][  350/  518]    Overall Loss 3.080750    Objective Loss 3.080750                                        LR 0.000500    Time 0.207027    
2023-04-26 21:20:08,956 - Epoch: [74][  400/  518]    Overall Loss 3.073174    Objective Loss 3.073174                                        LR 0.000500    Time 0.206699    
2023-04-26 21:20:19,216 - Epoch: [74][  450/  518]    Overall Loss 3.076395    Objective Loss 3.076395                                        LR 0.000500    Time 0.206528    
2023-04-26 21:20:29,539 - Epoch: [74][  500/  518]    Overall Loss 3.084885    Objective Loss 3.084885                                        LR 0.000500    Time 0.206517    
2023-04-26 21:20:33,126 - Epoch: [74][  518/  518]    Overall Loss 3.084402    Objective Loss 3.084402                                        LR 0.000500    Time 0.206265    
2023-04-26 21:20:33,194 - --- validate (epoch=74)-----------
2023-04-26 21:20:33,195 - 4952 samples (32 per mini-batch)
2023-04-26 21:20:39,798 - Epoch: [74][   50/  155]    Loss 3.317198    mAP 0.390484    
2023-04-26 21:20:46,161 - Epoch: [74][  100/  155]    Loss 3.308566    mAP 0.400155    
2023-04-26 21:20:52,468 - Epoch: [74][  150/  155]    Loss 3.321292    mAP 0.404982    
2023-04-26 21:20:53,034 - Epoch: [74][  155/  155]    Loss 3.320980    mAP 0.405497    
2023-04-26 21:20:53,108 - ==> mAP: 0.40550    Loss: 3.321

2023-04-26 21:20:53,111 - ==> Best [mAP: 0.411791   vloss: 3.310280   Sparsity:0.00   Params: 2177088 on epoch: 71]
2023-04-26 21:20:53,111 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:20:53,149 - 

2023-04-26 21:20:53,149 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:21:04,172 - Epoch: [75][   50/  518]    Overall Loss 3.012438    Objective Loss 3.012438                                        LR 0.000500    Time 0.220409    
2023-04-26 21:21:14,450 - Epoch: [75][  100/  518]    Overall Loss 3.057305    Objective Loss 3.057305                                        LR 0.000500    Time 0.212963    
2023-04-26 21:21:24,680 - Epoch: [75][  150/  518]    Overall Loss 3.075071    Objective Loss 3.075071                                        LR 0.000500    Time 0.210164    
2023-04-26 21:21:34,797 - Epoch: [75][  200/  518]    Overall Loss 3.089745    Objective Loss 3.089745                                        LR 0.000500    Time 0.208201    
2023-04-26 21:21:45,034 - Epoch: [75][  250/  518]    Overall Loss 3.088229    Objective Loss 3.088229                                        LR 0.000500    Time 0.207505    
2023-04-26 21:21:55,299 - Epoch: [75][  300/  518]    Overall Loss 3.097151    Objective Loss 3.097151                                        LR 0.000500    Time 0.207128    
2023-04-26 21:22:05,490 - Epoch: [75][  350/  518]    Overall Loss 3.093266    Objective Loss 3.093266                                        LR 0.000500    Time 0.206654    
2023-04-26 21:22:15,660 - Epoch: [75][  400/  518]    Overall Loss 3.097098    Objective Loss 3.097098                                        LR 0.000500    Time 0.206241    
2023-04-26 21:22:25,988 - Epoch: [75][  450/  518]    Overall Loss 3.091849    Objective Loss 3.091849                                        LR 0.000500    Time 0.206274    
2023-04-26 21:22:36,232 - Epoch: [75][  500/  518]    Overall Loss 3.084035    Objective Loss 3.084035                                        LR 0.000500    Time 0.206131    
2023-04-26 21:22:39,757 - Epoch: [75][  518/  518]    Overall Loss 3.086071    Objective Loss 3.086071                                        LR 0.000500    Time 0.205771    
2023-04-26 21:22:39,827 - --- validate (epoch=75)-----------
2023-04-26 21:22:39,827 - 4952 samples (32 per mini-batch)
2023-04-26 21:22:46,539 - Epoch: [75][   50/  155]    Loss 3.290184    mAP 0.422552    
2023-04-26 21:22:53,004 - Epoch: [75][  100/  155]    Loss 3.283868    mAP 0.427047    
2023-04-26 21:22:59,374 - Epoch: [75][  150/  155]    Loss 3.306265    mAP 0.419466    
2023-04-26 21:22:59,937 - Epoch: [75][  155/  155]    Loss 3.311546    mAP 0.417850    
2023-04-26 21:23:00,010 - ==> mAP: 0.41785    Loss: 3.312

2023-04-26 21:23:00,013 - ==> Best [mAP: 0.417850   vloss: 3.311546   Sparsity:0.00   Params: 2177088 on epoch: 75]
2023-04-26 21:23:00,013 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:23:00,067 - 

2023-04-26 21:23:00,067 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:23:11,031 - Epoch: [76][   50/  518]    Overall Loss 3.096419    Objective Loss 3.096419                                        LR 0.000500    Time 0.219223    
2023-04-26 21:23:21,267 - Epoch: [76][  100/  518]    Overall Loss 3.059841    Objective Loss 3.059841                                        LR 0.000500    Time 0.211945    
2023-04-26 21:23:31,517 - Epoch: [76][  150/  518]    Overall Loss 3.087335    Objective Loss 3.087335                                        LR 0.000500    Time 0.209620    
2023-04-26 21:23:41,773 - Epoch: [76][  200/  518]    Overall Loss 3.089018    Objective Loss 3.089018                                        LR 0.000500    Time 0.208490    
2023-04-26 21:23:51,988 - Epoch: [76][  250/  518]    Overall Loss 3.092815    Objective Loss 3.092815                                        LR 0.000500    Time 0.207645    
2023-04-26 21:24:02,264 - Epoch: [76][  300/  518]    Overall Loss 3.089096    Objective Loss 3.089096                                        LR 0.000500    Time 0.207284    
2023-04-26 21:24:12,404 - Epoch: [76][  350/  518]    Overall Loss 3.080043    Objective Loss 3.080043                                        LR 0.000500    Time 0.206638    
2023-04-26 21:24:22,612 - Epoch: [76][  400/  518]    Overall Loss 3.084861    Objective Loss 3.084861                                        LR 0.000500    Time 0.206325    
2023-04-26 21:24:32,855 - Epoch: [76][  450/  518]    Overall Loss 3.081436    Objective Loss 3.081436                                        LR 0.000500    Time 0.206157    
2023-04-26 21:24:42,994 - Epoch: [76][  500/  518]    Overall Loss 3.079363    Objective Loss 3.079363                                        LR 0.000500    Time 0.205818    
2023-04-26 21:24:46,541 - Epoch: [76][  518/  518]    Overall Loss 3.083487    Objective Loss 3.083487                                        LR 0.000500    Time 0.205512    
2023-04-26 21:24:46,612 - --- validate (epoch=76)-----------
2023-04-26 21:24:46,612 - 4952 samples (32 per mini-batch)
2023-04-26 21:24:53,433 - Epoch: [76][   50/  155]    Loss 3.391189    mAP 0.393523    
2023-04-26 21:24:59,829 - Epoch: [76][  100/  155]    Loss 3.395500    mAP 0.402602    
2023-04-26 21:25:06,246 - Epoch: [76][  150/  155]    Loss 3.387967    mAP 0.398013    
2023-04-26 21:25:06,818 - Epoch: [76][  155/  155]    Loss 3.390070    mAP 0.398583    
2023-04-26 21:25:06,889 - ==> mAP: 0.39858    Loss: 3.390

2023-04-26 21:25:06,893 - ==> Best [mAP: 0.417850   vloss: 3.311546   Sparsity:0.00   Params: 2177088 on epoch: 75]
2023-04-26 21:25:06,893 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:25:07,025 - 

2023-04-26 21:25:07,025 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:25:17,969 - Epoch: [77][   50/  518]    Overall Loss 3.099658    Objective Loss 3.099658                                        LR 0.000500    Time 0.218801    
2023-04-26 21:25:28,267 - Epoch: [77][  100/  518]    Overall Loss 3.076410    Objective Loss 3.076410                                        LR 0.000500    Time 0.212360    
2023-04-26 21:25:38,486 - Epoch: [77][  150/  518]    Overall Loss 3.081601    Objective Loss 3.081601                                        LR 0.000500    Time 0.209688    
2023-04-26 21:25:48,641 - Epoch: [77][  200/  518]    Overall Loss 3.063080    Objective Loss 3.063080                                        LR 0.000500    Time 0.208033    
2023-04-26 21:25:58,923 - Epoch: [77][  250/  518]    Overall Loss 3.066031    Objective Loss 3.066031                                        LR 0.000500    Time 0.207549    
2023-04-26 21:26:09,180 - Epoch: [77][  300/  518]    Overall Loss 3.069831    Objective Loss 3.069831                                        LR 0.000500    Time 0.207141    
2023-04-26 21:26:19,371 - Epoch: [77][  350/  518]    Overall Loss 3.074110    Objective Loss 3.074110                                        LR 0.000500    Time 0.206661    
2023-04-26 21:26:29,491 - Epoch: [77][  400/  518]    Overall Loss 3.068216    Objective Loss 3.068216                                        LR 0.000500    Time 0.206125    
2023-04-26 21:26:39,798 - Epoch: [77][  450/  518]    Overall Loss 3.073999    Objective Loss 3.073999                                        LR 0.000500    Time 0.206122    
2023-04-26 21:26:50,011 - Epoch: [77][  500/  518]    Overall Loss 3.075660    Objective Loss 3.075660                                        LR 0.000500    Time 0.205933    
2023-04-26 21:26:53,531 - Epoch: [77][  518/  518]    Overall Loss 3.081390    Objective Loss 3.081390                                        LR 0.000500    Time 0.205572    
2023-04-26 21:26:53,603 - --- validate (epoch=77)-----------
2023-04-26 21:26:53,603 - 4952 samples (32 per mini-batch)
2023-04-26 21:27:00,362 - Epoch: [77][   50/  155]    Loss 3.280719    mAP 0.422440    
2023-04-26 21:27:06,716 - Epoch: [77][  100/  155]    Loss 3.292329    mAP 0.406911    
2023-04-26 21:27:13,024 - Epoch: [77][  150/  155]    Loss 3.303425    mAP 0.405631    
2023-04-26 21:27:13,584 - Epoch: [77][  155/  155]    Loss 3.299249    mAP 0.406583    
2023-04-26 21:27:13,655 - ==> mAP: 0.40658    Loss: 3.299

2023-04-26 21:27:13,658 - ==> Best [mAP: 0.417850   vloss: 3.311546   Sparsity:0.00   Params: 2177088 on epoch: 75]
2023-04-26 21:27:13,659 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:27:13,696 - 

2023-04-26 21:27:13,696 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:27:24,616 - Epoch: [78][   50/  518]    Overall Loss 3.084650    Objective Loss 3.084650                                        LR 0.000500    Time 0.218338    
2023-04-26 21:27:34,705 - Epoch: [78][  100/  518]    Overall Loss 3.058554    Objective Loss 3.058554                                        LR 0.000500    Time 0.210041    
2023-04-26 21:27:44,974 - Epoch: [78][  150/  518]    Overall Loss 3.059546    Objective Loss 3.059546                                        LR 0.000500    Time 0.208480    
2023-04-26 21:27:55,312 - Epoch: [78][  200/  518]    Overall Loss 3.054120    Objective Loss 3.054120                                        LR 0.000500    Time 0.208041    
2023-04-26 21:28:05,563 - Epoch: [78][  250/  518]    Overall Loss 3.058584    Objective Loss 3.058584                                        LR 0.000500    Time 0.207429    
2023-04-26 21:28:15,725 - Epoch: [78][  300/  518]    Overall Loss 3.067017    Objective Loss 3.067017                                        LR 0.000500    Time 0.206726    
2023-04-26 21:28:26,010 - Epoch: [78][  350/  518]    Overall Loss 3.068140    Objective Loss 3.068140                                        LR 0.000500    Time 0.206576    
2023-04-26 21:28:36,254 - Epoch: [78][  400/  518]    Overall Loss 3.068320    Objective Loss 3.068320                                        LR 0.000500    Time 0.206359    
2023-04-26 21:28:46,466 - Epoch: [78][  450/  518]    Overall Loss 3.064058    Objective Loss 3.064058                                        LR 0.000500    Time 0.206119    
2023-04-26 21:28:56,761 - Epoch: [78][  500/  518]    Overall Loss 3.062928    Objective Loss 3.062928                                        LR 0.000500    Time 0.206094    
2023-04-26 21:29:00,321 - Epoch: [78][  518/  518]    Overall Loss 3.060802    Objective Loss 3.060802                                        LR 0.000500    Time 0.205804    
2023-04-26 21:29:00,392 - --- validate (epoch=78)-----------
2023-04-26 21:29:00,393 - 4952 samples (32 per mini-batch)
2023-04-26 21:29:07,195 - Epoch: [78][   50/  155]    Loss 3.275664    mAP 0.421346    
2023-04-26 21:29:13,627 - Epoch: [78][  100/  155]    Loss 3.309077    mAP 0.413644    
2023-04-26 21:29:20,037 - Epoch: [78][  150/  155]    Loss 3.302759    mAP 0.419599    
2023-04-26 21:29:20,606 - Epoch: [78][  155/  155]    Loss 3.305679    mAP 0.416877    
2023-04-26 21:29:20,678 - ==> mAP: 0.41688    Loss: 3.306

2023-04-26 21:29:20,682 - ==> Best [mAP: 0.417850   vloss: 3.311546   Sparsity:0.00   Params: 2177088 on epoch: 75]
2023-04-26 21:29:20,682 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:29:20,719 - 

2023-04-26 21:29:20,719 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:29:31,703 - Epoch: [79][   50/  518]    Overall Loss 3.057693    Objective Loss 3.057693                                        LR 0.000500    Time 0.219620    
2023-04-26 21:29:41,866 - Epoch: [79][  100/  518]    Overall Loss 3.073515    Objective Loss 3.073515                                        LR 0.000500    Time 0.211423    
2023-04-26 21:29:52,127 - Epoch: [79][  150/  518]    Overall Loss 3.090057    Objective Loss 3.090057                                        LR 0.000500    Time 0.209340    
2023-04-26 21:30:02,387 - Epoch: [79][  200/  518]    Overall Loss 3.084578    Objective Loss 3.084578                                        LR 0.000500    Time 0.208301    
2023-04-26 21:30:12,582 - Epoch: [79][  250/  518]    Overall Loss 3.083250    Objective Loss 3.083250                                        LR 0.000500    Time 0.207412    
2023-04-26 21:30:22,781 - Epoch: [79][  300/  518]    Overall Loss 3.073419    Objective Loss 3.073419                                        LR 0.000500    Time 0.206836    
2023-04-26 21:30:32,916 - Epoch: [79][  350/  518]    Overall Loss 3.073965    Objective Loss 3.073965                                        LR 0.000500    Time 0.206241    
2023-04-26 21:30:43,135 - Epoch: [79][  400/  518]    Overall Loss 3.064530    Objective Loss 3.064530                                        LR 0.000500    Time 0.206003    
2023-04-26 21:30:53,313 - Epoch: [79][  450/  518]    Overall Loss 3.069326    Objective Loss 3.069326                                        LR 0.000500    Time 0.205728    
2023-04-26 21:31:03,517 - Epoch: [79][  500/  518]    Overall Loss 3.069837    Objective Loss 3.069837                                        LR 0.000500    Time 0.205559    
2023-04-26 21:31:07,085 - Epoch: [79][  518/  518]    Overall Loss 3.072813    Objective Loss 3.072813                                        LR 0.000500    Time 0.205303    
2023-04-26 21:31:07,158 - --- validate (epoch=79)-----------
2023-04-26 21:31:07,158 - 4952 samples (32 per mini-batch)
2023-04-26 21:31:13,847 - Epoch: [79][   50/  155]    Loss 3.295736    mAP 0.394403    
2023-04-26 21:31:20,194 - Epoch: [79][  100/  155]    Loss 3.316887    mAP 0.406956    
2023-04-26 21:31:26,518 - Epoch: [79][  150/  155]    Loss 3.304909    mAP 0.410395    
2023-04-26 21:31:27,089 - Epoch: [79][  155/  155]    Loss 3.310065    mAP 0.410770    
2023-04-26 21:31:27,157 - ==> mAP: 0.41077    Loss: 3.310

2023-04-26 21:31:27,161 - ==> Best [mAP: 0.417850   vloss: 3.311546   Sparsity:0.00   Params: 2177088 on epoch: 75]
2023-04-26 21:31:27,161 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:31:27,198 - 

2023-04-26 21:31:27,198 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:31:38,255 - Epoch: [80][   50/  518]    Overall Loss 3.059836    Objective Loss 3.059836                                        LR 0.000500    Time 0.221091    
2023-04-26 21:31:48,449 - Epoch: [80][  100/  518]    Overall Loss 3.046711    Objective Loss 3.046711                                        LR 0.000500    Time 0.212466    
2023-04-26 21:31:58,648 - Epoch: [80][  150/  518]    Overall Loss 3.053408    Objective Loss 3.053408                                        LR 0.000500    Time 0.209626    
2023-04-26 21:32:08,805 - Epoch: [80][  200/  518]    Overall Loss 3.065897    Objective Loss 3.065897                                        LR 0.000500    Time 0.207993    
2023-04-26 21:32:19,017 - Epoch: [80][  250/  518]    Overall Loss 3.065111    Objective Loss 3.065111                                        LR 0.000500    Time 0.207237    
2023-04-26 21:32:29,293 - Epoch: [80][  300/  518]    Overall Loss 3.074103    Objective Loss 3.074103                                        LR 0.000500    Time 0.206946    
2023-04-26 21:32:39,459 - Epoch: [80][  350/  518]    Overall Loss 3.065981    Objective Loss 3.065981                                        LR 0.000500    Time 0.206424    
2023-04-26 21:32:49,827 - Epoch: [80][  400/  518]    Overall Loss 3.078238    Objective Loss 3.078238                                        LR 0.000500    Time 0.206537    
2023-04-26 21:32:59,982 - Epoch: [80][  450/  518]    Overall Loss 3.076032    Objective Loss 3.076032                                        LR 0.000500    Time 0.206150    
2023-04-26 21:33:10,198 - Epoch: [80][  500/  518]    Overall Loss 3.074339    Objective Loss 3.074339                                        LR 0.000500    Time 0.205965    
2023-04-26 21:33:13,769 - Epoch: [80][  518/  518]    Overall Loss 3.072048    Objective Loss 3.072048                                        LR 0.000500    Time 0.205701    
2023-04-26 21:33:13,842 - --- validate (epoch=80)-----------
2023-04-26 21:33:13,842 - 4952 samples (32 per mini-batch)
2023-04-26 21:33:20,538 - Epoch: [80][   50/  155]    Loss 3.300232    mAP 0.415883    
2023-04-26 21:33:26,942 - Epoch: [80][  100/  155]    Loss 3.284832    mAP 0.414844    
2023-04-26 21:33:33,327 - Epoch: [80][  150/  155]    Loss 3.276248    mAP 0.415130    
2023-04-26 21:33:33,901 - Epoch: [80][  155/  155]    Loss 3.276076    mAP 0.413850    
2023-04-26 21:33:33,971 - ==> mAP: 0.41385    Loss: 3.276

2023-04-26 21:33:33,975 - ==> Best [mAP: 0.417850   vloss: 3.311546   Sparsity:0.00   Params: 2177088 on epoch: 75]
2023-04-26 21:33:33,975 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:33:34,013 - 

2023-04-26 21:33:34,013 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:33:45,035 - Epoch: [81][   50/  518]    Overall Loss 3.103088    Objective Loss 3.103088                                        LR 0.000500    Time 0.220377    
2023-04-26 21:33:55,257 - Epoch: [81][  100/  518]    Overall Loss 3.067943    Objective Loss 3.067943                                        LR 0.000500    Time 0.212393    
2023-04-26 21:34:05,454 - Epoch: [81][  150/  518]    Overall Loss 3.071235    Objective Loss 3.071235                                        LR 0.000500    Time 0.209568    
2023-04-26 21:34:15,606 - Epoch: [81][  200/  518]    Overall Loss 3.070802    Objective Loss 3.070802                                        LR 0.000500    Time 0.207927    
2023-04-26 21:34:25,843 - Epoch: [81][  250/  518]    Overall Loss 3.066253    Objective Loss 3.066253                                        LR 0.000500    Time 0.207282    
2023-04-26 21:34:36,040 - Epoch: [81][  300/  518]    Overall Loss 3.065178    Objective Loss 3.065178                                        LR 0.000500    Time 0.206720    
2023-04-26 21:34:46,243 - Epoch: [81][  350/  518]    Overall Loss 3.068817    Objective Loss 3.068817                                        LR 0.000500    Time 0.206335    
2023-04-26 21:34:56,401 - Epoch: [81][  400/  518]    Overall Loss 3.070474    Objective Loss 3.070474                                        LR 0.000500    Time 0.205935    
2023-04-26 21:35:06,658 - Epoch: [81][  450/  518]    Overall Loss 3.068171    Objective Loss 3.068171                                        LR 0.000500    Time 0.205842    
2023-04-26 21:35:16,734 - Epoch: [81][  500/  518]    Overall Loss 3.070249    Objective Loss 3.070249                                        LR 0.000500    Time 0.205406    
2023-04-26 21:35:20,281 - Epoch: [81][  518/  518]    Overall Loss 3.069608    Objective Loss 3.069608                                        LR 0.000500    Time 0.205115    
2023-04-26 21:35:20,352 - --- validate (epoch=81)-----------
2023-04-26 21:35:20,353 - 4952 samples (32 per mini-batch)
2023-04-26 21:35:27,198 - Epoch: [81][   50/  155]    Loss 3.235519    mAP 0.436340    
2023-04-26 21:35:33,552 - Epoch: [81][  100/  155]    Loss 3.263569    mAP 0.408835    
2023-04-26 21:35:39,893 - Epoch: [81][  150/  155]    Loss 3.267164    mAP 0.411733    
2023-04-26 21:35:40,466 - Epoch: [81][  155/  155]    Loss 3.276542    mAP 0.410717    
2023-04-26 21:35:40,536 - ==> mAP: 0.41072    Loss: 3.277

2023-04-26 21:35:40,539 - ==> Best [mAP: 0.417850   vloss: 3.311546   Sparsity:0.00   Params: 2177088 on epoch: 75]
2023-04-26 21:35:40,540 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:35:40,576 - 

2023-04-26 21:35:40,576 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:35:51,460 - Epoch: [82][   50/  518]    Overall Loss 3.033417    Objective Loss 3.033417                                        LR 0.000500    Time 0.217629    
2023-04-26 21:36:01,651 - Epoch: [82][  100/  518]    Overall Loss 3.048772    Objective Loss 3.048772                                        LR 0.000500    Time 0.210702    
2023-04-26 21:36:11,910 - Epoch: [82][  150/  518]    Overall Loss 3.043770    Objective Loss 3.043770                                        LR 0.000500    Time 0.208850    
2023-04-26 21:36:22,193 - Epoch: [82][  200/  518]    Overall Loss 3.058602    Objective Loss 3.058602                                        LR 0.000500    Time 0.208043    
2023-04-26 21:36:32,359 - Epoch: [82][  250/  518]    Overall Loss 3.055667    Objective Loss 3.055667                                        LR 0.000500    Time 0.207093    
2023-04-26 21:36:42,632 - Epoch: [82][  300/  518]    Overall Loss 3.063942    Objective Loss 3.063942                                        LR 0.000500    Time 0.206815    
2023-04-26 21:36:52,929 - Epoch: [82][  350/  518]    Overall Loss 3.065962    Objective Loss 3.065962                                        LR 0.000500    Time 0.206685    
2023-04-26 21:37:03,207 - Epoch: [82][  400/  518]    Overall Loss 3.057030    Objective Loss 3.057030                                        LR 0.000500    Time 0.206541    
2023-04-26 21:37:13,468 - Epoch: [82][  450/  518]    Overall Loss 3.047783    Objective Loss 3.047783                                        LR 0.000500    Time 0.206390    
2023-04-26 21:37:23,658 - Epoch: [82][  500/  518]    Overall Loss 3.052674    Objective Loss 3.052674                                        LR 0.000500    Time 0.206128    
2023-04-26 21:37:27,178 - Epoch: [82][  518/  518]    Overall Loss 3.053133    Objective Loss 3.053133                                        LR 0.000500    Time 0.205759    
2023-04-26 21:37:27,249 - --- validate (epoch=82)-----------
2023-04-26 21:37:27,250 - 4952 samples (32 per mini-batch)
2023-04-26 21:37:34,028 - Epoch: [82][   50/  155]    Loss 3.277569    mAP 0.423571    
2023-04-26 21:37:40,301 - Epoch: [82][  100/  155]    Loss 3.283835    mAP 0.415468    
2023-04-26 21:37:46,582 - Epoch: [82][  150/  155]    Loss 3.305333    mAP 0.407193    
2023-04-26 21:37:47,150 - Epoch: [82][  155/  155]    Loss 3.308270    mAP 0.406630    
2023-04-26 21:37:47,224 - ==> mAP: 0.40663    Loss: 3.308

2023-04-26 21:37:47,228 - ==> Best [mAP: 0.417850   vloss: 3.311546   Sparsity:0.00   Params: 2177088 on epoch: 75]
2023-04-26 21:37:47,228 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:37:47,265 - 

2023-04-26 21:37:47,265 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:37:58,211 - Epoch: [83][   50/  518]    Overall Loss 3.053473    Objective Loss 3.053473                                        LR 0.000500    Time 0.218862    
2023-04-26 21:38:08,500 - Epoch: [83][  100/  518]    Overall Loss 3.063033    Objective Loss 3.063033                                        LR 0.000500    Time 0.212302    
2023-04-26 21:38:18,740 - Epoch: [83][  150/  518]    Overall Loss 3.050981    Objective Loss 3.050981                                        LR 0.000500    Time 0.209792    
2023-04-26 21:38:28,959 - Epoch: [83][  200/  518]    Overall Loss 3.047372    Objective Loss 3.047372                                        LR 0.000500    Time 0.208430    
2023-04-26 21:38:39,216 - Epoch: [83][  250/  518]    Overall Loss 3.052759    Objective Loss 3.052759                                        LR 0.000500    Time 0.207762    
2023-04-26 21:38:49,365 - Epoch: [83][  300/  518]    Overall Loss 3.053307    Objective Loss 3.053307                                        LR 0.000500    Time 0.206961    
2023-04-26 21:38:59,627 - Epoch: [83][  350/  518]    Overall Loss 3.062226    Objective Loss 3.062226                                        LR 0.000500    Time 0.206710    
2023-04-26 21:39:09,907 - Epoch: [83][  400/  518]    Overall Loss 3.061813    Objective Loss 3.061813                                        LR 0.000500    Time 0.206569    
2023-04-26 21:39:20,172 - Epoch: [83][  450/  518]    Overall Loss 3.064379    Objective Loss 3.064379                                        LR 0.000500    Time 0.206423    
2023-04-26 21:39:30,453 - Epoch: [83][  500/  518]    Overall Loss 3.065424    Objective Loss 3.065424                                        LR 0.000500    Time 0.206339    
2023-04-26 21:39:33,953 - Epoch: [83][  518/  518]    Overall Loss 3.067587    Objective Loss 3.067587                                        LR 0.000500    Time 0.205926    
2023-04-26 21:39:34,027 - --- validate (epoch=83)-----------
2023-04-26 21:39:34,027 - 4952 samples (32 per mini-batch)
2023-04-26 21:39:40,752 - Epoch: [83][   50/  155]    Loss 3.306866    mAP 0.412398    
2023-04-26 21:39:47,192 - Epoch: [83][  100/  155]    Loss 3.297473    mAP 0.415307    
2023-04-26 21:39:53,488 - Epoch: [83][  150/  155]    Loss 3.307598    mAP 0.411356    
2023-04-26 21:39:54,050 - Epoch: [83][  155/  155]    Loss 3.310135    mAP 0.410024    
2023-04-26 21:39:54,120 - ==> mAP: 0.41002    Loss: 3.310

2023-04-26 21:39:54,123 - ==> Best [mAP: 0.417850   vloss: 3.311546   Sparsity:0.00   Params: 2177088 on epoch: 75]
2023-04-26 21:39:54,123 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:39:54,160 - 

2023-04-26 21:39:54,160 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:40:05,229 - Epoch: [84][   50/  518]    Overall Loss 3.032611    Objective Loss 3.032611                                        LR 0.000500    Time 0.221321    
2023-04-26 21:40:15,495 - Epoch: [84][  100/  518]    Overall Loss 3.054785    Objective Loss 3.054785                                        LR 0.000500    Time 0.213305    
2023-04-26 21:40:25,711 - Epoch: [84][  150/  518]    Overall Loss 3.058475    Objective Loss 3.058475                                        LR 0.000500    Time 0.210294    
2023-04-26 21:40:35,939 - Epoch: [84][  200/  518]    Overall Loss 3.047546    Objective Loss 3.047546                                        LR 0.000500    Time 0.208856    
2023-04-26 21:40:46,125 - Epoch: [84][  250/  518]    Overall Loss 3.050016    Objective Loss 3.050016                                        LR 0.000500    Time 0.207822    
2023-04-26 21:40:56,238 - Epoch: [84][  300/  518]    Overall Loss 3.042057    Objective Loss 3.042057                                        LR 0.000500    Time 0.206889    
2023-04-26 21:41:06,552 - Epoch: [84][  350/  518]    Overall Loss 3.041763    Objective Loss 3.041763                                        LR 0.000500    Time 0.206798    
2023-04-26 21:41:16,673 - Epoch: [84][  400/  518]    Overall Loss 3.044325    Objective Loss 3.044325                                        LR 0.000500    Time 0.206247    
2023-04-26 21:41:26,920 - Epoch: [84][  450/  518]    Overall Loss 3.048487    Objective Loss 3.048487                                        LR 0.000500    Time 0.206098    
2023-04-26 21:41:37,098 - Epoch: [84][  500/  518]    Overall Loss 3.045993    Objective Loss 3.045993                                        LR 0.000500    Time 0.205840    
2023-04-26 21:41:40,692 - Epoch: [84][  518/  518]    Overall Loss 3.048839    Objective Loss 3.048839                                        LR 0.000500    Time 0.205626    
2023-04-26 21:41:40,763 - --- validate (epoch=84)-----------
2023-04-26 21:41:40,763 - 4952 samples (32 per mini-batch)
2023-04-26 21:41:47,438 - Epoch: [84][   50/  155]    Loss 3.277342    mAP 0.430459    
2023-04-26 21:41:53,789 - Epoch: [84][  100/  155]    Loss 3.284109    mAP 0.420685    
2023-04-26 21:42:00,189 - Epoch: [84][  150/  155]    Loss 3.293465    mAP 0.416290    
2023-04-26 21:42:00,744 - Epoch: [84][  155/  155]    Loss 3.295723    mAP 0.415400    
2023-04-26 21:42:00,815 - ==> mAP: 0.41540    Loss: 3.296

2023-04-26 21:42:00,819 - ==> Best [mAP: 0.417850   vloss: 3.311546   Sparsity:0.00   Params: 2177088 on epoch: 75]
2023-04-26 21:42:00,819 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:42:00,856 - 

2023-04-26 21:42:00,856 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:42:11,822 - Epoch: [85][   50/  518]    Overall Loss 3.077004    Objective Loss 3.077004                                        LR 0.000500    Time 0.219266    
2023-04-26 21:42:22,014 - Epoch: [85][  100/  518]    Overall Loss 3.075713    Objective Loss 3.075713                                        LR 0.000500    Time 0.211531    
2023-04-26 21:42:32,241 - Epoch: [85][  150/  518]    Overall Loss 3.059461    Objective Loss 3.059461                                        LR 0.000500    Time 0.209189    
2023-04-26 21:42:42,571 - Epoch: [85][  200/  518]    Overall Loss 3.054213    Objective Loss 3.054213                                        LR 0.000500    Time 0.208536    
2023-04-26 21:42:52,839 - Epoch: [85][  250/  518]    Overall Loss 3.052558    Objective Loss 3.052558                                        LR 0.000500    Time 0.207894    
2023-04-26 21:43:03,120 - Epoch: [85][  300/  518]    Overall Loss 3.052492    Objective Loss 3.052492                                        LR 0.000500    Time 0.207508    
2023-04-26 21:43:13,435 - Epoch: [85][  350/  518]    Overall Loss 3.060990    Objective Loss 3.060990                                        LR 0.000500    Time 0.207332    
2023-04-26 21:43:23,623 - Epoch: [85][  400/  518]    Overall Loss 3.058946    Objective Loss 3.058946                                        LR 0.000500    Time 0.206881    
2023-04-26 21:43:33,877 - Epoch: [85][  450/  518]    Overall Loss 3.051452    Objective Loss 3.051452                                        LR 0.000500    Time 0.206678    
2023-04-26 21:43:44,027 - Epoch: [85][  500/  518]    Overall Loss 3.051834    Objective Loss 3.051834                                        LR 0.000500    Time 0.206306    
2023-04-26 21:43:47,548 - Epoch: [85][  518/  518]    Overall Loss 3.055367    Objective Loss 3.055367                                        LR 0.000500    Time 0.205933    
2023-04-26 21:43:47,619 - --- validate (epoch=85)-----------
2023-04-26 21:43:47,619 - 4952 samples (32 per mini-batch)
2023-04-26 21:43:54,367 - Epoch: [85][   50/  155]    Loss 3.247985    mAP 0.440270    
2023-04-26 21:44:00,817 - Epoch: [85][  100/  155]    Loss 3.278212    mAP 0.428884    
2023-04-26 21:44:07,326 - Epoch: [85][  150/  155]    Loss 3.287357    mAP 0.425913    
2023-04-26 21:44:07,912 - Epoch: [85][  155/  155]    Loss 3.290909    mAP 0.426456    
2023-04-26 21:44:07,985 - ==> mAP: 0.42646    Loss: 3.291

2023-04-26 21:44:07,989 - ==> Best [mAP: 0.426456   vloss: 3.290909   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-26 21:44:07,989 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:44:08,044 - 

2023-04-26 21:44:08,044 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:44:18,925 - Epoch: [86][   50/  518]    Overall Loss 3.026055    Objective Loss 3.026055                                        LR 0.000500    Time 0.217558    
2023-04-26 21:44:29,262 - Epoch: [86][  100/  518]    Overall Loss 3.057616    Objective Loss 3.057616                                        LR 0.000500    Time 0.212134    
2023-04-26 21:44:39,486 - Epoch: [86][  150/  518]    Overall Loss 3.062893    Objective Loss 3.062893                                        LR 0.000500    Time 0.209574    
2023-04-26 21:44:49,685 - Epoch: [86][  200/  518]    Overall Loss 3.055646    Objective Loss 3.055646                                        LR 0.000500    Time 0.208165    
2023-04-26 21:44:59,939 - Epoch: [86][  250/  518]    Overall Loss 3.042679    Objective Loss 3.042679                                        LR 0.000500    Time 0.207543    
2023-04-26 21:45:10,203 - Epoch: [86][  300/  518]    Overall Loss 3.040970    Objective Loss 3.040970                                        LR 0.000500    Time 0.207161    
2023-04-26 21:45:20,381 - Epoch: [86][  350/  518]    Overall Loss 3.049172    Objective Loss 3.049172                                        LR 0.000500    Time 0.206640    
2023-04-26 21:45:30,671 - Epoch: [86][  400/  518]    Overall Loss 3.044085    Objective Loss 3.044085                                        LR 0.000500    Time 0.206533    
2023-04-26 21:45:41,009 - Epoch: [86][  450/  518]    Overall Loss 3.039991    Objective Loss 3.039991                                        LR 0.000500    Time 0.206553    
2023-04-26 21:45:51,241 - Epoch: [86][  500/  518]    Overall Loss 3.039003    Objective Loss 3.039003                                        LR 0.000500    Time 0.206359    
2023-04-26 21:45:54,765 - Epoch: [86][  518/  518]    Overall Loss 3.040573    Objective Loss 3.040573                                        LR 0.000500    Time 0.205990    
2023-04-26 21:45:54,835 - --- validate (epoch=86)-----------
2023-04-26 21:45:54,836 - 4952 samples (32 per mini-batch)
2023-04-26 21:46:01,551 - Epoch: [86][   50/  155]    Loss 3.286394    mAP 0.410940    
2023-04-26 21:46:07,927 - Epoch: [86][  100/  155]    Loss 3.286257    mAP 0.422095    
2023-04-26 21:46:14,295 - Epoch: [86][  150/  155]    Loss 3.269299    mAP 0.422120    
2023-04-26 21:46:14,863 - Epoch: [86][  155/  155]    Loss 3.269087    mAP 0.420386    
2023-04-26 21:46:14,932 - ==> mAP: 0.42039    Loss: 3.269

2023-04-26 21:46:14,936 - ==> Best [mAP: 0.426456   vloss: 3.290909   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-26 21:46:14,936 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:46:14,973 - 

2023-04-26 21:46:14,973 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:46:26,005 - Epoch: [87][   50/  518]    Overall Loss 3.072611    Objective Loss 3.072611                                        LR 0.000500    Time 0.220567    
2023-04-26 21:46:36,189 - Epoch: [87][  100/  518]    Overall Loss 3.057235    Objective Loss 3.057235                                        LR 0.000500    Time 0.212107    
2023-04-26 21:46:46,345 - Epoch: [87][  150/  518]    Overall Loss 3.042274    Objective Loss 3.042274                                        LR 0.000500    Time 0.209100    
2023-04-26 21:46:56,628 - Epoch: [87][  200/  518]    Overall Loss 3.042593    Objective Loss 3.042593                                        LR 0.000500    Time 0.208234    
2023-04-26 21:47:06,873 - Epoch: [87][  250/  518]    Overall Loss 3.047879    Objective Loss 3.047879                                        LR 0.000500    Time 0.207560    
2023-04-26 21:47:17,051 - Epoch: [87][  300/  518]    Overall Loss 3.042576    Objective Loss 3.042576                                        LR 0.000500    Time 0.206888    
2023-04-26 21:47:27,251 - Epoch: [87][  350/  518]    Overall Loss 3.037624    Objective Loss 3.037624                                        LR 0.000500    Time 0.206472    
2023-04-26 21:47:37,466 - Epoch: [87][  400/  518]    Overall Loss 3.040583    Objective Loss 3.040583                                        LR 0.000500    Time 0.206196    
2023-04-26 21:47:47,639 - Epoch: [87][  450/  518]    Overall Loss 3.037068    Objective Loss 3.037068                                        LR 0.000500    Time 0.205888    
2023-04-26 21:47:57,880 - Epoch: [87][  500/  518]    Overall Loss 3.029901    Objective Loss 3.029901                                        LR 0.000500    Time 0.205778    
2023-04-26 21:48:01,393 - Epoch: [87][  518/  518]    Overall Loss 3.029914    Objective Loss 3.029914                                        LR 0.000500    Time 0.205408    
2023-04-26 21:48:01,464 - --- validate (epoch=87)-----------
2023-04-26 21:48:01,465 - 4952 samples (32 per mini-batch)
2023-04-26 21:48:08,273 - Epoch: [87][   50/  155]    Loss 3.274660    mAP 0.428634    
2023-04-26 21:48:14,693 - Epoch: [87][  100/  155]    Loss 3.293355    mAP 0.423144    
2023-04-26 21:48:21,080 - Epoch: [87][  150/  155]    Loss 3.287229    mAP 0.423779    
2023-04-26 21:48:21,645 - Epoch: [87][  155/  155]    Loss 3.290364    mAP 0.422433    
2023-04-26 21:48:21,712 - ==> mAP: 0.42243    Loss: 3.290

2023-04-26 21:48:21,716 - ==> Best [mAP: 0.426456   vloss: 3.290909   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-26 21:48:21,716 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:48:21,754 - 

2023-04-26 21:48:21,754 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:48:32,817 - Epoch: [88][   50/  518]    Overall Loss 2.999429    Objective Loss 2.999429                                        LR 0.000500    Time 0.221204    
2023-04-26 21:48:43,073 - Epoch: [88][  100/  518]    Overall Loss 3.030605    Objective Loss 3.030605                                        LR 0.000500    Time 0.213141    
2023-04-26 21:48:53,328 - Epoch: [88][  150/  518]    Overall Loss 3.046888    Objective Loss 3.046888                                        LR 0.000500    Time 0.210452    
2023-04-26 21:49:03,515 - Epoch: [88][  200/  518]    Overall Loss 3.045787    Objective Loss 3.045787                                        LR 0.000500    Time 0.208766    
2023-04-26 21:49:13,824 - Epoch: [88][  250/  518]    Overall Loss 3.034466    Objective Loss 3.034466                                        LR 0.000500    Time 0.208243    
2023-04-26 21:49:24,069 - Epoch: [88][  300/  518]    Overall Loss 3.039331    Objective Loss 3.039331                                        LR 0.000500    Time 0.207681    
2023-04-26 21:49:34,335 - Epoch: [88][  350/  518]    Overall Loss 3.031304    Objective Loss 3.031304                                        LR 0.000500    Time 0.207338    
2023-04-26 21:49:44,561 - Epoch: [88][  400/  518]    Overall Loss 3.032047    Objective Loss 3.032047                                        LR 0.000500    Time 0.206981    
2023-04-26 21:49:54,775 - Epoch: [88][  450/  518]    Overall Loss 3.033507    Objective Loss 3.033507                                        LR 0.000500    Time 0.206678    
2023-04-26 21:50:05,023 - Epoch: [88][  500/  518]    Overall Loss 3.034987    Objective Loss 3.034987                                        LR 0.000500    Time 0.206503    
2023-04-26 21:50:08,544 - Epoch: [88][  518/  518]    Overall Loss 3.032736    Objective Loss 3.032736                                        LR 0.000500    Time 0.206123    
2023-04-26 21:50:08,616 - --- validate (epoch=88)-----------
2023-04-26 21:50:08,617 - 4952 samples (32 per mini-batch)
2023-04-26 21:50:15,458 - Epoch: [88][   50/  155]    Loss 3.337094    mAP 0.422556    
2023-04-26 21:50:21,855 - Epoch: [88][  100/  155]    Loss 3.325244    mAP 0.418824    
2023-04-26 21:50:28,280 - Epoch: [88][  150/  155]    Loss 3.315395    mAP 0.418259    
2023-04-26 21:50:28,843 - Epoch: [88][  155/  155]    Loss 3.315596    mAP 0.418799    
2023-04-26 21:50:28,911 - ==> mAP: 0.41880    Loss: 3.316

2023-04-26 21:50:28,914 - ==> Best [mAP: 0.426456   vloss: 3.290909   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-26 21:50:28,915 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:50:28,952 - 

2023-04-26 21:50:28,952 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:50:39,925 - Epoch: [89][   50/  518]    Overall Loss 3.012969    Objective Loss 3.012969                                        LR 0.000500    Time 0.219413    
2023-04-26 21:50:50,247 - Epoch: [89][  100/  518]    Overall Loss 3.025885    Objective Loss 3.025885                                        LR 0.000500    Time 0.212908    
2023-04-26 21:51:00,508 - Epoch: [89][  150/  518]    Overall Loss 3.029334    Objective Loss 3.029334                                        LR 0.000500    Time 0.210332    
2023-04-26 21:51:10,701 - Epoch: [89][  200/  518]    Overall Loss 3.028606    Objective Loss 3.028606                                        LR 0.000500    Time 0.208705    
2023-04-26 21:51:20,928 - Epoch: [89][  250/  518]    Overall Loss 3.039650    Objective Loss 3.039650                                        LR 0.000500    Time 0.207868    
2023-04-26 21:51:31,247 - Epoch: [89][  300/  518]    Overall Loss 3.037880    Objective Loss 3.037880                                        LR 0.000500    Time 0.207614    
2023-04-26 21:51:41,557 - Epoch: [89][  350/  518]    Overall Loss 3.029558    Objective Loss 3.029558                                        LR 0.000500    Time 0.207407    
2023-04-26 21:51:51,723 - Epoch: [89][  400/  518]    Overall Loss 3.033403    Objective Loss 3.033403                                        LR 0.000500    Time 0.206893    
2023-04-26 21:52:01,935 - Epoch: [89][  450/  518]    Overall Loss 3.033591    Objective Loss 3.033591                                        LR 0.000500    Time 0.206593    
2023-04-26 21:52:12,103 - Epoch: [89][  500/  518]    Overall Loss 3.030968    Objective Loss 3.030968                                        LR 0.000500    Time 0.206266    
2023-04-26 21:52:15,604 - Epoch: [89][  518/  518]    Overall Loss 3.028423    Objective Loss 3.028423                                        LR 0.000500    Time 0.205856    
2023-04-26 21:52:15,675 - --- validate (epoch=89)-----------
2023-04-26 21:52:15,676 - 4952 samples (32 per mini-batch)
2023-04-26 21:52:22,427 - Epoch: [89][   50/  155]    Loss 3.316568    mAP 0.427851    
2023-04-26 21:52:28,802 - Epoch: [89][  100/  155]    Loss 3.301697    mAP 0.420551    
2023-04-26 21:52:35,076 - Epoch: [89][  150/  155]    Loss 3.312096    mAP 0.415417    
2023-04-26 21:52:35,635 - Epoch: [89][  155/  155]    Loss 3.310998    mAP 0.414813    
2023-04-26 21:52:35,705 - ==> mAP: 0.41481    Loss: 3.311

2023-04-26 21:52:35,709 - ==> Best [mAP: 0.426456   vloss: 3.290909   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-26 21:52:35,709 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:52:35,749 - 

2023-04-26 21:52:35,749 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:52:46,698 - Epoch: [90][   50/  518]    Overall Loss 3.054113    Objective Loss 3.054113                                        LR 0.000500    Time 0.218922    
2023-04-26 21:52:56,987 - Epoch: [90][  100/  518]    Overall Loss 3.045349    Objective Loss 3.045349                                        LR 0.000500    Time 0.212340    
2023-04-26 21:53:07,313 - Epoch: [90][  150/  518]    Overall Loss 3.045084    Objective Loss 3.045084                                        LR 0.000500    Time 0.210389    
2023-04-26 21:53:17,534 - Epoch: [90][  200/  518]    Overall Loss 3.039974    Objective Loss 3.039974                                        LR 0.000500    Time 0.208889    
2023-04-26 21:53:27,783 - Epoch: [90][  250/  518]    Overall Loss 3.032842    Objective Loss 3.032842                                        LR 0.000500    Time 0.208100    
2023-04-26 21:53:38,007 - Epoch: [90][  300/  518]    Overall Loss 3.039038    Objective Loss 3.039038                                        LR 0.000500    Time 0.207491    
2023-04-26 21:53:48,332 - Epoch: [90][  350/  518]    Overall Loss 3.036297    Objective Loss 3.036297                                        LR 0.000500    Time 0.207344    
2023-04-26 21:53:58,492 - Epoch: [90][  400/  518]    Overall Loss 3.037657    Objective Loss 3.037657                                        LR 0.000500    Time 0.206821    
2023-04-26 21:54:08,713 - Epoch: [90][  450/  518]    Overall Loss 3.041057    Objective Loss 3.041057                                        LR 0.000500    Time 0.206552    
2023-04-26 21:54:18,922 - Epoch: [90][  500/  518]    Overall Loss 3.043335    Objective Loss 3.043335                                        LR 0.000500    Time 0.206312    
2023-04-26 21:54:22,514 - Epoch: [90][  518/  518]    Overall Loss 3.040555    Objective Loss 3.040555                                        LR 0.000500    Time 0.206074    
2023-04-26 21:54:22,585 - --- validate (epoch=90)-----------
2023-04-26 21:54:22,585 - 4952 samples (32 per mini-batch)
2023-04-26 21:54:29,270 - Epoch: [90][   50/  155]    Loss 3.252711    mAP 0.399350    
2023-04-26 21:54:35,602 - Epoch: [90][  100/  155]    Loss 3.290069    mAP 0.406615    
2023-04-26 21:54:41,899 - Epoch: [90][  150/  155]    Loss 3.296188    mAP 0.403927    
2023-04-26 21:54:42,471 - Epoch: [90][  155/  155]    Loss 3.304329    mAP 0.403906    
2023-04-26 21:54:42,545 - ==> mAP: 0.40391    Loss: 3.304

2023-04-26 21:54:42,549 - ==> Best [mAP: 0.426456   vloss: 3.290909   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-26 21:54:42,549 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:54:42,586 - 

2023-04-26 21:54:42,586 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:54:53,470 - Epoch: [91][   50/  518]    Overall Loss 3.032710    Objective Loss 3.032710                                        LR 0.000500    Time 0.217621    
2023-04-26 21:55:03,745 - Epoch: [91][  100/  518]    Overall Loss 3.019805    Objective Loss 3.019805                                        LR 0.000500    Time 0.211538    
2023-04-26 21:55:13,910 - Epoch: [91][  150/  518]    Overall Loss 3.039624    Objective Loss 3.039624                                        LR 0.000500    Time 0.208783    
2023-04-26 21:55:24,080 - Epoch: [91][  200/  518]    Overall Loss 3.039293    Objective Loss 3.039293                                        LR 0.000500    Time 0.207428    
2023-04-26 21:55:34,360 - Epoch: [91][  250/  518]    Overall Loss 3.047570    Objective Loss 3.047570                                        LR 0.000500    Time 0.207056    
2023-04-26 21:55:44,667 - Epoch: [91][  300/  518]    Overall Loss 3.037238    Objective Loss 3.037238                                        LR 0.000500    Time 0.206898    
2023-04-26 21:55:54,912 - Epoch: [91][  350/  518]    Overall Loss 3.038592    Objective Loss 3.038592                                        LR 0.000500    Time 0.206607    
2023-04-26 21:56:05,103 - Epoch: [91][  400/  518]    Overall Loss 3.036638    Objective Loss 3.036638                                        LR 0.000500    Time 0.206256    
2023-04-26 21:56:15,431 - Epoch: [91][  450/  518]    Overall Loss 3.038631    Objective Loss 3.038631                                        LR 0.000500    Time 0.206285    
2023-04-26 21:56:25,683 - Epoch: [91][  500/  518]    Overall Loss 3.037446    Objective Loss 3.037446                                        LR 0.000500    Time 0.206157    
2023-04-26 21:56:29,185 - Epoch: [91][  518/  518]    Overall Loss 3.037625    Objective Loss 3.037625                                        LR 0.000500    Time 0.205754    
2023-04-26 21:56:29,258 - --- validate (epoch=91)-----------
2023-04-26 21:56:29,258 - 4952 samples (32 per mini-batch)
2023-04-26 21:56:36,122 - Epoch: [91][   50/  155]    Loss 3.258290    mAP 0.420625    
2023-04-26 21:56:42,517 - Epoch: [91][  100/  155]    Loss 3.258435    mAP 0.421614    
2023-04-26 21:56:48,888 - Epoch: [91][  150/  155]    Loss 3.282185    mAP 0.423554    
2023-04-26 21:56:49,457 - Epoch: [91][  155/  155]    Loss 3.283382    mAP 0.424389    
2023-04-26 21:56:49,529 - ==> mAP: 0.42439    Loss: 3.283

2023-04-26 21:56:49,533 - ==> Best [mAP: 0.426456   vloss: 3.290909   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-26 21:56:49,533 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:56:49,570 - 

2023-04-26 21:56:49,570 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:57:00,552 - Epoch: [92][   50/  518]    Overall Loss 3.080411    Objective Loss 3.080411                                        LR 0.000500    Time 0.219577    
2023-04-26 21:57:10,695 - Epoch: [92][  100/  518]    Overall Loss 3.013047    Objective Loss 3.013047                                        LR 0.000500    Time 0.211200    
2023-04-26 21:57:20,960 - Epoch: [92][  150/  518]    Overall Loss 3.013692    Objective Loss 3.013692                                        LR 0.000500    Time 0.209225    
2023-04-26 21:57:31,212 - Epoch: [92][  200/  518]    Overall Loss 3.018153    Objective Loss 3.018153                                        LR 0.000500    Time 0.208171    
2023-04-26 21:57:41,523 - Epoch: [92][  250/  518]    Overall Loss 3.024871    Objective Loss 3.024871                                        LR 0.000500    Time 0.207772    
2023-04-26 21:57:51,841 - Epoch: [92][  300/  518]    Overall Loss 3.031545    Objective Loss 3.031545                                        LR 0.000500    Time 0.207533    
2023-04-26 21:58:02,128 - Epoch: [92][  350/  518]    Overall Loss 3.035972    Objective Loss 3.035972                                        LR 0.000500    Time 0.207271    
2023-04-26 21:58:12,382 - Epoch: [92][  400/  518]    Overall Loss 3.034929    Objective Loss 3.034929                                        LR 0.000500    Time 0.206994    
2023-04-26 21:58:22,632 - Epoch: [92][  450/  518]    Overall Loss 3.037618    Objective Loss 3.037618                                        LR 0.000500    Time 0.206767    
2023-04-26 21:58:32,909 - Epoch: [92][  500/  518]    Overall Loss 3.034327    Objective Loss 3.034327                                        LR 0.000500    Time 0.206642    
2023-04-26 21:58:36,511 - Epoch: [92][  518/  518]    Overall Loss 3.033455    Objective Loss 3.033455                                        LR 0.000500    Time 0.206415    
2023-04-26 21:58:36,585 - --- validate (epoch=92)-----------
2023-04-26 21:58:36,585 - 4952 samples (32 per mini-batch)
2023-04-26 21:58:43,273 - Epoch: [92][   50/  155]    Loss 3.284948    mAP 0.420904    
2023-04-26 21:58:49,660 - Epoch: [92][  100/  155]    Loss 3.294987    mAP 0.416202    
2023-04-26 21:58:56,006 - Epoch: [92][  150/  155]    Loss 3.275779    mAP 0.418826    
2023-04-26 21:58:56,588 - Epoch: [92][  155/  155]    Loss 3.275896    mAP 0.418425    
2023-04-26 21:58:56,660 - ==> mAP: 0.41843    Loss: 3.276

2023-04-26 21:58:56,664 - ==> Best [mAP: 0.426456   vloss: 3.290909   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-26 21:58:56,664 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 21:58:56,700 - 

2023-04-26 21:58:56,700 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 21:59:07,693 - Epoch: [93][   50/  518]    Overall Loss 3.009648    Objective Loss 3.009648                                        LR 0.000500    Time 0.219807    
2023-04-26 21:59:17,877 - Epoch: [93][  100/  518]    Overall Loss 3.014570    Objective Loss 3.014570                                        LR 0.000500    Time 0.211718    
2023-04-26 21:59:28,092 - Epoch: [93][  150/  518]    Overall Loss 3.025954    Objective Loss 3.025954                                        LR 0.000500    Time 0.209239    
2023-04-26 21:59:38,279 - Epoch: [93][  200/  518]    Overall Loss 3.019347    Objective Loss 3.019347                                        LR 0.000500    Time 0.207856    
2023-04-26 21:59:48,588 - Epoch: [93][  250/  518]    Overall Loss 3.018910    Objective Loss 3.018910                                        LR 0.000500    Time 0.207511    
2023-04-26 21:59:58,861 - Epoch: [93][  300/  518]    Overall Loss 3.013264    Objective Loss 3.013264                                        LR 0.000500    Time 0.207166    
2023-04-26 22:00:09,031 - Epoch: [93][  350/  518]    Overall Loss 3.010237    Objective Loss 3.010237                                        LR 0.000500    Time 0.206621    
2023-04-26 22:00:19,304 - Epoch: [93][  400/  518]    Overall Loss 3.021139    Objective Loss 3.021139                                        LR 0.000500    Time 0.206474    
2023-04-26 22:00:29,582 - Epoch: [93][  450/  518]    Overall Loss 3.019903    Objective Loss 3.019903                                        LR 0.000500    Time 0.206368    
2023-04-26 22:00:39,829 - Epoch: [93][  500/  518]    Overall Loss 3.016315    Objective Loss 3.016315                                        LR 0.000500    Time 0.206223    
2023-04-26 22:00:43,405 - Epoch: [93][  518/  518]    Overall Loss 3.016078    Objective Loss 3.016078                                        LR 0.000500    Time 0.205958    
2023-04-26 22:00:43,478 - --- validate (epoch=93)-----------
2023-04-26 22:00:43,479 - 4952 samples (32 per mini-batch)
2023-04-26 22:00:50,215 - Epoch: [93][   50/  155]    Loss 3.248965    mAP 0.410667    
2023-04-26 22:00:56,554 - Epoch: [93][  100/  155]    Loss 3.257108    mAP 0.412584    
2023-04-26 22:01:02,955 - Epoch: [93][  150/  155]    Loss 3.272343    mAP 0.415088    
2023-04-26 22:01:03,536 - Epoch: [93][  155/  155]    Loss 3.272244    mAP 0.414757    
2023-04-26 22:01:03,603 - ==> mAP: 0.41476    Loss: 3.272

2023-04-26 22:01:03,607 - ==> Best [mAP: 0.426456   vloss: 3.290909   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-26 22:01:03,607 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:01:03,645 - 

2023-04-26 22:01:03,645 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:01:14,613 - Epoch: [94][   50/  518]    Overall Loss 3.087485    Objective Loss 3.087485                                        LR 0.000500    Time 0.219300    
2023-04-26 22:01:24,855 - Epoch: [94][  100/  518]    Overall Loss 3.041743    Objective Loss 3.041743                                        LR 0.000500    Time 0.212056    
2023-04-26 22:01:35,071 - Epoch: [94][  150/  518]    Overall Loss 3.035968    Objective Loss 3.035968                                        LR 0.000500    Time 0.209467    
2023-04-26 22:01:45,283 - Epoch: [94][  200/  518]    Overall Loss 3.024518    Objective Loss 3.024518                                        LR 0.000500    Time 0.208150    
2023-04-26 22:01:55,603 - Epoch: [94][  250/  518]    Overall Loss 3.032809    Objective Loss 3.032809                                        LR 0.000500    Time 0.207795    
2023-04-26 22:02:05,825 - Epoch: [94][  300/  518]    Overall Loss 3.030361    Objective Loss 3.030361                                        LR 0.000500    Time 0.207232    
2023-04-26 22:02:16,048 - Epoch: [94][  350/  518]    Overall Loss 3.033276    Objective Loss 3.033276                                        LR 0.000500    Time 0.206829    
2023-04-26 22:02:26,279 - Epoch: [94][  400/  518]    Overall Loss 3.031147    Objective Loss 3.031147                                        LR 0.000500    Time 0.206549    
2023-04-26 22:02:36,523 - Epoch: [94][  450/  518]    Overall Loss 3.030109    Objective Loss 3.030109                                        LR 0.000500    Time 0.206360    
2023-04-26 22:02:46,701 - Epoch: [94][  500/  518]    Overall Loss 3.026862    Objective Loss 3.026862                                        LR 0.000500    Time 0.206077    
2023-04-26 22:02:50,238 - Epoch: [94][  518/  518]    Overall Loss 3.026007    Objective Loss 3.026007                                        LR 0.000500    Time 0.205744    
2023-04-26 22:02:50,311 - --- validate (epoch=94)-----------
2023-04-26 22:02:50,311 - 4952 samples (32 per mini-batch)
2023-04-26 22:02:57,060 - Epoch: [94][   50/  155]    Loss 3.270680    mAP 0.418623    
2023-04-26 22:03:03,478 - Epoch: [94][  100/  155]    Loss 3.298549    mAP 0.422189    
2023-04-26 22:03:09,915 - Epoch: [94][  150/  155]    Loss 3.286012    mAP 0.424944    
2023-04-26 22:03:10,476 - Epoch: [94][  155/  155]    Loss 3.288764    mAP 0.424591    
2023-04-26 22:03:10,547 - ==> mAP: 0.42459    Loss: 3.289

2023-04-26 22:03:10,551 - ==> Best [mAP: 0.426456   vloss: 3.290909   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-26 22:03:10,551 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:03:10,587 - 

2023-04-26 22:03:10,587 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:03:21,627 - Epoch: [95][   50/  518]    Overall Loss 3.022106    Objective Loss 3.022106                                        LR 0.000500    Time 0.220731    
2023-04-26 22:03:31,868 - Epoch: [95][  100/  518]    Overall Loss 3.003707    Objective Loss 3.003707                                        LR 0.000500    Time 0.212758    
2023-04-26 22:03:42,074 - Epoch: [95][  150/  518]    Overall Loss 3.012070    Objective Loss 3.012070                                        LR 0.000500    Time 0.209870    
2023-04-26 22:03:52,348 - Epoch: [95][  200/  518]    Overall Loss 3.001260    Objective Loss 3.001260                                        LR 0.000500    Time 0.208764    
2023-04-26 22:04:02,505 - Epoch: [95][  250/  518]    Overall Loss 3.006484    Objective Loss 3.006484                                        LR 0.000500    Time 0.207634    
2023-04-26 22:04:12,783 - Epoch: [95][  300/  518]    Overall Loss 3.004067    Objective Loss 3.004067                                        LR 0.000500    Time 0.207283    
2023-04-26 22:04:23,014 - Epoch: [95][  350/  518]    Overall Loss 3.007525    Objective Loss 3.007525                                        LR 0.000500    Time 0.206897    
2023-04-26 22:04:33,255 - Epoch: [95][  400/  518]    Overall Loss 3.012224    Objective Loss 3.012224                                        LR 0.000500    Time 0.206633    
2023-04-26 22:04:43,589 - Epoch: [95][  450/  518]    Overall Loss 3.014515    Objective Loss 3.014515                                        LR 0.000500    Time 0.206636    
2023-04-26 22:04:53,850 - Epoch: [95][  500/  518]    Overall Loss 3.012069    Objective Loss 3.012069                                        LR 0.000500    Time 0.206489    
2023-04-26 22:04:57,380 - Epoch: [95][  518/  518]    Overall Loss 3.013200    Objective Loss 3.013200                                        LR 0.000500    Time 0.206127    
2023-04-26 22:04:57,451 - --- validate (epoch=95)-----------
2023-04-26 22:04:57,451 - 4952 samples (32 per mini-batch)
2023-04-26 22:05:04,378 - Epoch: [95][   50/  155]    Loss 3.269525    mAP 0.417954    
2023-04-26 22:05:10,906 - Epoch: [95][  100/  155]    Loss 3.265765    mAP 0.430830    
2023-04-26 22:05:17,277 - Epoch: [95][  150/  155]    Loss 3.278527    mAP 0.430861    
2023-04-26 22:05:17,852 - Epoch: [95][  155/  155]    Loss 3.276514    mAP 0.430350    
2023-04-26 22:05:17,923 - ==> mAP: 0.43035    Loss: 3.277

2023-04-26 22:05:17,927 - ==> Best [mAP: 0.430350   vloss: 3.276514   Sparsity:0.00   Params: 2177088 on epoch: 95]
2023-04-26 22:05:17,927 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:05:17,979 - 

2023-04-26 22:05:17,979 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:05:28,889 - Epoch: [96][   50/  518]    Overall Loss 3.048438    Objective Loss 3.048438                                        LR 0.000500    Time 0.218142    
2023-04-26 22:05:39,124 - Epoch: [96][  100/  518]    Overall Loss 3.022108    Objective Loss 3.022108                                        LR 0.000500    Time 0.211404    
2023-04-26 22:05:49,338 - Epoch: [96][  150/  518]    Overall Loss 3.010093    Objective Loss 3.010093                                        LR 0.000500    Time 0.209019    
2023-04-26 22:05:59,521 - Epoch: [96][  200/  518]    Overall Loss 3.014911    Objective Loss 3.014911                                        LR 0.000500    Time 0.207669    
2023-04-26 22:06:09,800 - Epoch: [96][  250/  518]    Overall Loss 3.017873    Objective Loss 3.017873                                        LR 0.000500    Time 0.207246    
2023-04-26 22:06:20,035 - Epoch: [96][  300/  518]    Overall Loss 3.010125    Objective Loss 3.010125                                        LR 0.000500    Time 0.206814    
2023-04-26 22:06:30,307 - Epoch: [96][  350/  518]    Overall Loss 3.014559    Objective Loss 3.014559                                        LR 0.000500    Time 0.206614    
2023-04-26 22:06:40,514 - Epoch: [96][  400/  518]    Overall Loss 3.014699    Objective Loss 3.014699                                        LR 0.000500    Time 0.206301    
2023-04-26 22:06:50,655 - Epoch: [96][  450/  518]    Overall Loss 3.014652    Objective Loss 3.014652                                        LR 0.000500    Time 0.205910    
2023-04-26 22:07:00,974 - Epoch: [96][  500/  518]    Overall Loss 3.012018    Objective Loss 3.012018                                        LR 0.000500    Time 0.205953    
2023-04-26 22:07:04,509 - Epoch: [96][  518/  518]    Overall Loss 3.012184    Objective Loss 3.012184                                        LR 0.000500    Time 0.205620    
2023-04-26 22:07:04,581 - --- validate (epoch=96)-----------
2023-04-26 22:07:04,581 - 4952 samples (32 per mini-batch)
2023-04-26 22:07:11,257 - Epoch: [96][   50/  155]    Loss 3.253489    mAP 0.408331    
2023-04-26 22:07:17,567 - Epoch: [96][  100/  155]    Loss 3.247173    mAP 0.423004    
2023-04-26 22:07:23,865 - Epoch: [96][  150/  155]    Loss 3.263947    mAP 0.418510    
2023-04-26 22:07:24,428 - Epoch: [96][  155/  155]    Loss 3.262890    mAP 0.417728    
2023-04-26 22:07:24,497 - ==> mAP: 0.41773    Loss: 3.263

2023-04-26 22:07:24,500 - ==> Best [mAP: 0.430350   vloss: 3.276514   Sparsity:0.00   Params: 2177088 on epoch: 95]
2023-04-26 22:07:24,500 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:07:24,538 - 

2023-04-26 22:07:24,538 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:07:35,421 - Epoch: [97][   50/  518]    Overall Loss 3.023703    Objective Loss 3.023703                                        LR 0.000500    Time 0.217613    
2023-04-26 22:07:45,674 - Epoch: [97][  100/  518]    Overall Loss 3.019751    Objective Loss 3.019751                                        LR 0.000500    Time 0.211318    
2023-04-26 22:07:55,871 - Epoch: [97][  150/  518]    Overall Loss 3.017469    Objective Loss 3.017469                                        LR 0.000500    Time 0.208850    
2023-04-26 22:08:05,991 - Epoch: [97][  200/  518]    Overall Loss 3.014952    Objective Loss 3.014952                                        LR 0.000500    Time 0.207229    
2023-04-26 22:08:16,147 - Epoch: [97][  250/  518]    Overall Loss 3.012114    Objective Loss 3.012114                                        LR 0.000500    Time 0.206398    
2023-04-26 22:08:26,381 - Epoch: [97][  300/  518]    Overall Loss 3.013289    Objective Loss 3.013289                                        LR 0.000500    Time 0.206107    
2023-04-26 22:08:36,604 - Epoch: [97][  350/  518]    Overall Loss 3.015412    Objective Loss 3.015412                                        LR 0.000500    Time 0.205868    
2023-04-26 22:08:46,870 - Epoch: [97][  400/  518]    Overall Loss 3.011962    Objective Loss 3.011962                                        LR 0.000500    Time 0.205794    
2023-04-26 22:08:57,099 - Epoch: [97][  450/  518]    Overall Loss 3.009770    Objective Loss 3.009770                                        LR 0.000500    Time 0.205655    
2023-04-26 22:09:07,283 - Epoch: [97][  500/  518]    Overall Loss 3.008502    Objective Loss 3.008502                                        LR 0.000500    Time 0.205455    
2023-04-26 22:09:10,819 - Epoch: [97][  518/  518]    Overall Loss 3.008551    Objective Loss 3.008551                                        LR 0.000500    Time 0.205140    
2023-04-26 22:09:10,891 - --- validate (epoch=97)-----------
2023-04-26 22:09:10,892 - 4952 samples (32 per mini-batch)
2023-04-26 22:09:17,614 - Epoch: [97][   50/  155]    Loss 3.278458    mAP 0.413386    
2023-04-26 22:09:23,960 - Epoch: [97][  100/  155]    Loss 3.279165    mAP 0.419138    
2023-04-26 22:09:30,304 - Epoch: [97][  150/  155]    Loss 3.271825    mAP 0.418983    
2023-04-26 22:09:30,864 - Epoch: [97][  155/  155]    Loss 3.272474    mAP 0.417774    
2023-04-26 22:09:30,924 - ==> mAP: 0.41777    Loss: 3.272

2023-04-26 22:09:30,928 - ==> Best [mAP: 0.430350   vloss: 3.276514   Sparsity:0.00   Params: 2177088 on epoch: 95]
2023-04-26 22:09:30,928 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:09:30,965 - 

2023-04-26 22:09:30,966 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:09:42,002 - Epoch: [98][   50/  518]    Overall Loss 3.001288    Objective Loss 3.001288                                        LR 0.000500    Time 0.220679    
2023-04-26 22:09:52,289 - Epoch: [98][  100/  518]    Overall Loss 3.035055    Objective Loss 3.035055                                        LR 0.000500    Time 0.213193    
2023-04-26 22:10:02,469 - Epoch: [98][  150/  518]    Overall Loss 3.039442    Objective Loss 3.039442                                        LR 0.000500    Time 0.209982    
2023-04-26 22:10:12,741 - Epoch: [98][  200/  518]    Overall Loss 3.038451    Objective Loss 3.038451                                        LR 0.000500    Time 0.208840    
2023-04-26 22:10:22,905 - Epoch: [98][  250/  518]    Overall Loss 3.025258    Objective Loss 3.025258                                        LR 0.000500    Time 0.207719    
2023-04-26 22:10:33,055 - Epoch: [98][  300/  518]    Overall Loss 3.020610    Objective Loss 3.020610                                        LR 0.000500    Time 0.206927    
2023-04-26 22:10:43,279 - Epoch: [98][  350/  518]    Overall Loss 3.011921    Objective Loss 3.011921                                        LR 0.000500    Time 0.206573    
2023-04-26 22:10:53,536 - Epoch: [98][  400/  518]    Overall Loss 3.004684    Objective Loss 3.004684                                        LR 0.000500    Time 0.206389    
2023-04-26 22:11:03,858 - Epoch: [98][  450/  518]    Overall Loss 3.003689    Objective Loss 3.003689                                        LR 0.000500    Time 0.206392    
2023-04-26 22:11:14,133 - Epoch: [98][  500/  518]    Overall Loss 3.006689    Objective Loss 3.006689                                        LR 0.000500    Time 0.206299    
2023-04-26 22:11:17,667 - Epoch: [98][  518/  518]    Overall Loss 3.009358    Objective Loss 3.009358                                        LR 0.000500    Time 0.205951    
2023-04-26 22:11:17,738 - --- validate (epoch=98)-----------
2023-04-26 22:11:17,739 - 4952 samples (32 per mini-batch)
2023-04-26 22:11:24,465 - Epoch: [98][   50/  155]    Loss 3.284740    mAP 0.403158    
2023-04-26 22:11:30,833 - Epoch: [98][  100/  155]    Loss 3.259959    mAP 0.410114    
2023-04-26 22:11:37,209 - Epoch: [98][  150/  155]    Loss 3.265185    mAP 0.405435    
2023-04-26 22:11:37,773 - Epoch: [98][  155/  155]    Loss 3.269737    mAP 0.405368    
2023-04-26 22:11:37,840 - ==> mAP: 0.40537    Loss: 3.270

2023-04-26 22:11:37,843 - ==> Best [mAP: 0.430350   vloss: 3.276514   Sparsity:0.00   Params: 2177088 on epoch: 95]
2023-04-26 22:11:37,844 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:11:37,881 - 

2023-04-26 22:11:37,881 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:11:48,787 - Epoch: [99][   50/  518]    Overall Loss 3.030478    Objective Loss 3.030478                                        LR 0.000500    Time 0.218076    
2023-04-26 22:11:59,001 - Epoch: [99][  100/  518]    Overall Loss 3.029376    Objective Loss 3.029376                                        LR 0.000500    Time 0.211154    
2023-04-26 22:12:09,263 - Epoch: [99][  150/  518]    Overall Loss 3.015442    Objective Loss 3.015442                                        LR 0.000500    Time 0.209171    
2023-04-26 22:12:19,493 - Epoch: [99][  200/  518]    Overall Loss 3.016862    Objective Loss 3.016862                                        LR 0.000500    Time 0.208024    
2023-04-26 22:12:29,619 - Epoch: [99][  250/  518]    Overall Loss 3.021740    Objective Loss 3.021740                                        LR 0.000500    Time 0.206916    
2023-04-26 22:12:39,885 - Epoch: [99][  300/  518]    Overall Loss 3.015623    Objective Loss 3.015623                                        LR 0.000500    Time 0.206645    
2023-04-26 22:12:50,117 - Epoch: [99][  350/  518]    Overall Loss 3.018100    Objective Loss 3.018100                                        LR 0.000500    Time 0.206353    
2023-04-26 22:13:00,312 - Epoch: [99][  400/  518]    Overall Loss 3.013573    Objective Loss 3.013573                                        LR 0.000500    Time 0.206043    
2023-04-26 22:13:10,613 - Epoch: [99][  450/  518]    Overall Loss 3.018059    Objective Loss 3.018059                                        LR 0.000500    Time 0.206036    
2023-04-26 22:13:20,792 - Epoch: [99][  500/  518]    Overall Loss 3.013358    Objective Loss 3.013358                                        LR 0.000500    Time 0.205787    
2023-04-26 22:13:24,308 - Epoch: [99][  518/  518]    Overall Loss 3.014085    Objective Loss 3.014085                                        LR 0.000500    Time 0.205423    
2023-04-26 22:13:24,380 - --- validate (epoch=99)-----------
2023-04-26 22:13:24,380 - 4952 samples (32 per mini-batch)
2023-04-26 22:13:31,110 - Epoch: [99][   50/  155]    Loss 3.243137    mAP 0.425408    
2023-04-26 22:13:37,499 - Epoch: [99][  100/  155]    Loss 3.259413    mAP 0.425161    
2023-04-26 22:13:43,878 - Epoch: [99][  150/  155]    Loss 3.257038    mAP 0.425482    
2023-04-26 22:13:44,449 - Epoch: [99][  155/  155]    Loss 3.250323    mAP 0.426379    
2023-04-26 22:13:44,517 - ==> mAP: 0.42638    Loss: 3.250

2023-04-26 22:13:44,521 - ==> Best [mAP: 0.430350   vloss: 3.276514   Sparsity:0.00   Params: 2177088 on epoch: 95]
2023-04-26 22:13:44,521 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:13:44,559 - 

2023-04-26 22:13:44,559 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:13:55,520 - Epoch: [100][   50/  518]    Overall Loss 3.010117    Objective Loss 3.010117                                        LR 0.000125    Time 0.219152    
2023-04-26 22:14:05,717 - Epoch: [100][  100/  518]    Overall Loss 3.006555    Objective Loss 3.006555                                        LR 0.000125    Time 0.211535    
2023-04-26 22:14:15,968 - Epoch: [100][  150/  518]    Overall Loss 2.984581    Objective Loss 2.984581                                        LR 0.000125    Time 0.209351    
2023-04-26 22:14:26,225 - Epoch: [100][  200/  518]    Overall Loss 2.977675    Objective Loss 2.977675                                        LR 0.000125    Time 0.208288    
2023-04-26 22:14:36,438 - Epoch: [100][  250/  518]    Overall Loss 2.967617    Objective Loss 2.967617                                        LR 0.000125    Time 0.207479    
2023-04-26 22:14:46,722 - Epoch: [100][  300/  518]    Overall Loss 2.969173    Objective Loss 2.969173                                        LR 0.000125    Time 0.207171    
2023-04-26 22:14:57,030 - Epoch: [100][  350/  518]    Overall Loss 2.974907    Objective Loss 2.974907                                        LR 0.000125    Time 0.207023    
2023-04-26 22:15:07,323 - Epoch: [100][  400/  518]    Overall Loss 2.965321    Objective Loss 2.965321                                        LR 0.000125    Time 0.206874    
2023-04-26 22:15:17,508 - Epoch: [100][  450/  518]    Overall Loss 2.959190    Objective Loss 2.959190                                        LR 0.000125    Time 0.206517    
2023-04-26 22:15:27,751 - Epoch: [100][  500/  518]    Overall Loss 2.959965    Objective Loss 2.959965                                        LR 0.000125    Time 0.206349    
2023-04-26 22:15:31,297 - Epoch: [100][  518/  518]    Overall Loss 2.957971    Objective Loss 2.957971                                        LR 0.000125    Time 0.206022    
2023-04-26 22:15:31,368 - --- validate (epoch=100)-----------
2023-04-26 22:15:31,368 - 4952 samples (32 per mini-batch)
2023-04-26 22:15:38,146 - Epoch: [100][   50/  155]    Loss 3.235764    mAP 0.456442    
2023-04-26 22:15:44,659 - Epoch: [100][  100/  155]    Loss 3.214877    mAP 0.453457    
2023-04-26 22:15:51,057 - Epoch: [100][  150/  155]    Loss 3.215314    mAP 0.441249    
2023-04-26 22:15:51,636 - Epoch: [100][  155/  155]    Loss 3.217630    mAP 0.438558    
2023-04-26 22:15:51,710 - ==> mAP: 0.43856    Loss: 3.218

2023-04-26 22:15:51,714 - ==> Best [mAP: 0.438558   vloss: 3.217630   Sparsity:0.00   Params: 2177088 on epoch: 100]
2023-04-26 22:15:51,714 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:15:51,768 - 

2023-04-26 22:15:51,768 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:16:02,643 - Epoch: [101][   50/  518]    Overall Loss 2.888214    Objective Loss 2.888214                                        LR 0.000125    Time 0.217453    
2023-04-26 22:16:12,799 - Epoch: [101][  100/  518]    Overall Loss 2.917097    Objective Loss 2.917097                                        LR 0.000125    Time 0.210263    
2023-04-26 22:16:23,062 - Epoch: [101][  150/  518]    Overall Loss 2.911463    Objective Loss 2.911463                                        LR 0.000125    Time 0.208588    
2023-04-26 22:16:33,252 - Epoch: [101][  200/  518]    Overall Loss 2.924071    Objective Loss 2.924071                                        LR 0.000125    Time 0.207379    
2023-04-26 22:16:43,485 - Epoch: [101][  250/  518]    Overall Loss 2.925205    Objective Loss 2.925205                                        LR 0.000125    Time 0.206830    
2023-04-26 22:16:53,623 - Epoch: [101][  300/  518]    Overall Loss 2.931723    Objective Loss 2.931723                                        LR 0.000125    Time 0.206148    
2023-04-26 22:17:03,861 - Epoch: [101][  350/  518]    Overall Loss 2.935371    Objective Loss 2.935371                                        LR 0.000125    Time 0.205945    
2023-04-26 22:17:14,038 - Epoch: [101][  400/  518]    Overall Loss 2.947538    Objective Loss 2.947538                                        LR 0.000125    Time 0.205639    
2023-04-26 22:17:24,150 - Epoch: [101][  450/  518]    Overall Loss 2.943304    Objective Loss 2.943304                                        LR 0.000125    Time 0.205259    
2023-04-26 22:17:34,356 - Epoch: [101][  500/  518]    Overall Loss 2.948479    Objective Loss 2.948479                                        LR 0.000125    Time 0.205142    
2023-04-26 22:17:37,868 - Epoch: [101][  518/  518]    Overall Loss 2.955450    Objective Loss 2.955450                                        LR 0.000125    Time 0.204792    
2023-04-26 22:17:37,941 - --- validate (epoch=101)-----------
2023-04-26 22:17:37,941 - 4952 samples (32 per mini-batch)
2023-04-26 22:17:44,731 - Epoch: [101][   50/  155]    Loss 3.211107    mAP 0.465825    
2023-04-26 22:17:51,162 - Epoch: [101][  100/  155]    Loss 3.214548    mAP 0.445600    
2023-04-26 22:17:57,570 - Epoch: [101][  150/  155]    Loss 3.207691    mAP 0.441602    
2023-04-26 22:17:58,146 - Epoch: [101][  155/  155]    Loss 3.211414    mAP 0.441647    
2023-04-26 22:17:58,226 - ==> mAP: 0.44165    Loss: 3.211

2023-04-26 22:17:58,230 - ==> Best [mAP: 0.441647   vloss: 3.211414   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-26 22:17:58,230 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:17:58,281 - 

2023-04-26 22:17:58,282 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:18:09,182 - Epoch: [102][   50/  518]    Overall Loss 2.958252    Objective Loss 2.958252                                        LR 0.000125    Time 0.217954    
2023-04-26 22:18:19,528 - Epoch: [102][  100/  518]    Overall Loss 2.932383    Objective Loss 2.932383                                        LR 0.000125    Time 0.212418    
2023-04-26 22:18:29,718 - Epoch: [102][  150/  518]    Overall Loss 2.928066    Objective Loss 2.928066                                        LR 0.000125    Time 0.209532    
2023-04-26 22:18:40,002 - Epoch: [102][  200/  518]    Overall Loss 2.938462    Objective Loss 2.938462                                        LR 0.000125    Time 0.208563    
2023-04-26 22:18:50,304 - Epoch: [102][  250/  518]    Overall Loss 2.956857    Objective Loss 2.956857                                        LR 0.000125    Time 0.208050    
2023-04-26 22:19:00,557 - Epoch: [102][  300/  518]    Overall Loss 2.962911    Objective Loss 2.962911                                        LR 0.000125    Time 0.207546    
2023-04-26 22:19:10,793 - Epoch: [102][  350/  518]    Overall Loss 2.956825    Objective Loss 2.956825                                        LR 0.000125    Time 0.207140    
2023-04-26 22:19:21,117 - Epoch: [102][  400/  518]    Overall Loss 2.955795    Objective Loss 2.955795                                        LR 0.000125    Time 0.207051    
2023-04-26 22:19:31,366 - Epoch: [102][  450/  518]    Overall Loss 2.956739    Objective Loss 2.956739                                        LR 0.000125    Time 0.206819    
2023-04-26 22:19:41,495 - Epoch: [102][  500/  518]    Overall Loss 2.955577    Objective Loss 2.955577                                        LR 0.000125    Time 0.206392    
2023-04-26 22:19:45,013 - Epoch: [102][  518/  518]    Overall Loss 2.957342    Objective Loss 2.957342                                        LR 0.000125    Time 0.206009    
2023-04-26 22:19:45,084 - --- validate (epoch=102)-----------
2023-04-26 22:19:45,084 - 4952 samples (32 per mini-batch)
2023-04-26 22:19:51,851 - Epoch: [102][   50/  155]    Loss 3.204228    mAP 0.444952    
2023-04-26 22:19:58,271 - Epoch: [102][  100/  155]    Loss 3.203989    mAP 0.434340    
2023-04-26 22:20:04,678 - Epoch: [102][  150/  155]    Loss 3.195629    mAP 0.426086    
2023-04-26 22:20:05,248 - Epoch: [102][  155/  155]    Loss 3.197855    mAP 0.426476    
2023-04-26 22:20:05,317 - ==> mAP: 0.42648    Loss: 3.198

2023-04-26 22:20:05,322 - ==> Best [mAP: 0.441647   vloss: 3.211414   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-26 22:20:05,322 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:20:05,359 - 

2023-04-26 22:20:05,359 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:20:16,387 - Epoch: [103][   50/  518]    Overall Loss 2.939318    Objective Loss 2.939318                                        LR 0.000125    Time 0.220508    
2023-04-26 22:20:26,564 - Epoch: [103][  100/  518]    Overall Loss 2.924776    Objective Loss 2.924776                                        LR 0.000125    Time 0.212008    
2023-04-26 22:20:36,896 - Epoch: [103][  150/  518]    Overall Loss 2.928625    Objective Loss 2.928625                                        LR 0.000125    Time 0.210206    
2023-04-26 22:20:47,213 - Epoch: [103][  200/  518]    Overall Loss 2.927562    Objective Loss 2.927562                                        LR 0.000125    Time 0.209233    
2023-04-26 22:20:57,443 - Epoch: [103][  250/  518]    Overall Loss 2.937682    Objective Loss 2.937682                                        LR 0.000125    Time 0.208300    
2023-04-26 22:21:07,734 - Epoch: [103][  300/  518]    Overall Loss 2.942553    Objective Loss 2.942553                                        LR 0.000125    Time 0.207879    
2023-04-26 22:21:17,973 - Epoch: [103][  350/  518]    Overall Loss 2.946335    Objective Loss 2.946335                                        LR 0.000125    Time 0.207433    
2023-04-26 22:21:28,193 - Epoch: [103][  400/  518]    Overall Loss 2.940493    Objective Loss 2.940493                                        LR 0.000125    Time 0.207048    
2023-04-26 22:21:38,377 - Epoch: [103][  450/  518]    Overall Loss 2.942142    Objective Loss 2.942142                                        LR 0.000125    Time 0.206670    
2023-04-26 22:21:48,658 - Epoch: [103][  500/  518]    Overall Loss 2.941153    Objective Loss 2.941153                                        LR 0.000125    Time 0.206562    
2023-04-26 22:21:52,247 - Epoch: [103][  518/  518]    Overall Loss 2.942286    Objective Loss 2.942286                                        LR 0.000125    Time 0.206312    
2023-04-26 22:21:52,320 - --- validate (epoch=103)-----------
2023-04-26 22:21:52,320 - 4952 samples (32 per mini-batch)
2023-04-26 22:21:59,094 - Epoch: [103][   50/  155]    Loss 3.176561    mAP 0.438429    
2023-04-26 22:22:05,528 - Epoch: [103][  100/  155]    Loss 3.213005    mAP 0.437919    
2023-04-26 22:22:11,899 - Epoch: [103][  150/  155]    Loss 3.201451    mAP 0.435913    
2023-04-26 22:22:12,470 - Epoch: [103][  155/  155]    Loss 3.206505    mAP 0.434697    
2023-04-26 22:22:12,539 - ==> mAP: 0.43470    Loss: 3.207

2023-04-26 22:22:12,543 - ==> Best [mAP: 0.441647   vloss: 3.211414   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-26 22:22:12,543 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:22:12,581 - 

2023-04-26 22:22:12,581 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:22:23,650 - Epoch: [104][   50/  518]    Overall Loss 3.037198    Objective Loss 3.037198                                        LR 0.000125    Time 0.221335    
2023-04-26 22:22:34,009 - Epoch: [104][  100/  518]    Overall Loss 2.981746    Objective Loss 2.981746                                        LR 0.000125    Time 0.214237    
2023-04-26 22:22:44,217 - Epoch: [104][  150/  518]    Overall Loss 2.962621    Objective Loss 2.962621                                        LR 0.000125    Time 0.210866    
2023-04-26 22:22:54,444 - Epoch: [104][  200/  518]    Overall Loss 2.948980    Objective Loss 2.948980                                        LR 0.000125    Time 0.209276    
2023-04-26 22:23:04,619 - Epoch: [104][  250/  518]    Overall Loss 2.937249    Objective Loss 2.937249                                        LR 0.000125    Time 0.208114    
2023-04-26 22:23:14,866 - Epoch: [104][  300/  518]    Overall Loss 2.934969    Objective Loss 2.934969                                        LR 0.000125    Time 0.207581    
2023-04-26 22:23:25,050 - Epoch: [104][  350/  518]    Overall Loss 2.930888    Objective Loss 2.930888                                        LR 0.000125    Time 0.207019    
2023-04-26 22:23:35,369 - Epoch: [104][  400/  518]    Overall Loss 2.937261    Objective Loss 2.937261                                        LR 0.000125    Time 0.206934    
2023-04-26 22:23:45,641 - Epoch: [104][  450/  518]    Overall Loss 2.935385    Objective Loss 2.935385                                        LR 0.000125    Time 0.206765    
2023-04-26 22:23:55,904 - Epoch: [104][  500/  518]    Overall Loss 2.934194    Objective Loss 2.934194                                        LR 0.000125    Time 0.206611    
2023-04-26 22:23:59,491 - Epoch: [104][  518/  518]    Overall Loss 2.934127    Objective Loss 2.934127                                        LR 0.000125    Time 0.206355    
2023-04-26 22:23:59,564 - --- validate (epoch=104)-----------
2023-04-26 22:23:59,564 - 4952 samples (32 per mini-batch)
2023-04-26 22:24:06,414 - Epoch: [104][   50/  155]    Loss 3.187119    mAP 0.433820    
2023-04-26 22:24:12,758 - Epoch: [104][  100/  155]    Loss 3.200280    mAP 0.428840    
2023-04-26 22:24:19,133 - Epoch: [104][  150/  155]    Loss 3.204257    mAP 0.430522    
2023-04-26 22:24:19,705 - Epoch: [104][  155/  155]    Loss 3.209947    mAP 0.427980    
2023-04-26 22:24:19,771 - ==> mAP: 0.42798    Loss: 3.210

2023-04-26 22:24:19,775 - ==> Best [mAP: 0.441647   vloss: 3.211414   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-26 22:24:19,775 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:24:19,833 - 

2023-04-26 22:24:19,833 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:24:30,884 - Epoch: [105][   50/  518]    Overall Loss 2.917454    Objective Loss 2.917454                                        LR 0.000125    Time 0.220950    
2023-04-26 22:24:41,087 - Epoch: [105][  100/  518]    Overall Loss 2.934195    Objective Loss 2.934195                                        LR 0.000125    Time 0.212488    
2023-04-26 22:24:51,261 - Epoch: [105][  150/  518]    Overall Loss 2.932761    Objective Loss 2.932761                                        LR 0.000125    Time 0.209473    
2023-04-26 22:25:01,487 - Epoch: [105][  200/  518]    Overall Loss 2.944829    Objective Loss 2.944829                                        LR 0.000125    Time 0.208228    
2023-04-26 22:25:11,611 - Epoch: [105][  250/  518]    Overall Loss 2.941132    Objective Loss 2.941132                                        LR 0.000125    Time 0.207073    
2023-04-26 22:25:21,840 - Epoch: [105][  300/  518]    Overall Loss 2.946927    Objective Loss 2.946927                                        LR 0.000125    Time 0.206652    
2023-04-26 22:25:32,077 - Epoch: [105][  350/  518]    Overall Loss 2.937404    Objective Loss 2.937404                                        LR 0.000125    Time 0.206373    
2023-04-26 22:25:42,232 - Epoch: [105][  400/  518]    Overall Loss 2.934014    Objective Loss 2.934014                                        LR 0.000125    Time 0.205961    
2023-04-26 22:25:52,436 - Epoch: [105][  450/  518]    Overall Loss 2.937216    Objective Loss 2.937216                                        LR 0.000125    Time 0.205748    
2023-04-26 22:26:02,692 - Epoch: [105][  500/  518]    Overall Loss 2.936232    Objective Loss 2.936232                                        LR 0.000125    Time 0.205682    
2023-04-26 22:26:06,173 - Epoch: [105][  518/  518]    Overall Loss 2.936125    Objective Loss 2.936125                                        LR 0.000125    Time 0.205253    
2023-04-26 22:26:06,243 - --- validate (epoch=105)-----------
2023-04-26 22:26:06,243 - 4952 samples (32 per mini-batch)
2023-04-26 22:26:13,046 - Epoch: [105][   50/  155]    Loss 3.236850    mAP 0.425872    
2023-04-26 22:26:19,463 - Epoch: [105][  100/  155]    Loss 3.198560    mAP 0.430105    
2023-04-26 22:26:25,889 - Epoch: [105][  150/  155]    Loss 3.199312    mAP 0.432550    
2023-04-26 22:26:26,471 - Epoch: [105][  155/  155]    Loss 3.199384    mAP 0.432444    
2023-04-26 22:26:26,539 - ==> mAP: 0.43244    Loss: 3.199

2023-04-26 22:26:26,543 - ==> Best [mAP: 0.441647   vloss: 3.211414   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-26 22:26:26,543 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:26:26,579 - 

2023-04-26 22:26:26,579 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:26:37,507 - Epoch: [106][   50/  518]    Overall Loss 2.923096    Objective Loss 2.923096                                        LR 0.000125    Time 0.218498    
2023-04-26 22:26:47,741 - Epoch: [106][  100/  518]    Overall Loss 2.950824    Objective Loss 2.950824                                        LR 0.000125    Time 0.211575    
2023-04-26 22:26:57,951 - Epoch: [106][  150/  518]    Overall Loss 2.932395    Objective Loss 2.932395                                        LR 0.000125    Time 0.209102    
2023-04-26 22:27:08,177 - Epoch: [106][  200/  518]    Overall Loss 2.933541    Objective Loss 2.933541                                        LR 0.000125    Time 0.207951    
2023-04-26 22:27:18,468 - Epoch: [106][  250/  518]    Overall Loss 2.927925    Objective Loss 2.927925                                        LR 0.000125    Time 0.207517    
2023-04-26 22:27:28,726 - Epoch: [106][  300/  518]    Overall Loss 2.935308    Objective Loss 2.935308                                        LR 0.000125    Time 0.207119    
2023-04-26 22:27:38,945 - Epoch: [106][  350/  518]    Overall Loss 2.936474    Objective Loss 2.936474                                        LR 0.000125    Time 0.206722    
2023-04-26 22:27:49,122 - Epoch: [106][  400/  518]    Overall Loss 2.942451    Objective Loss 2.942451                                        LR 0.000125    Time 0.206322    
2023-04-26 22:27:59,442 - Epoch: [106][  450/  518]    Overall Loss 2.939291    Objective Loss 2.939291                                        LR 0.000125    Time 0.206327    
2023-04-26 22:28:09,761 - Epoch: [106][  500/  518]    Overall Loss 2.937535    Objective Loss 2.937535                                        LR 0.000125    Time 0.206328    
2023-04-26 22:28:13,320 - Epoch: [106][  518/  518]    Overall Loss 2.939695    Objective Loss 2.939695                                        LR 0.000125    Time 0.206029    
2023-04-26 22:28:13,392 - --- validate (epoch=106)-----------
2023-04-26 22:28:13,392 - 4952 samples (32 per mini-batch)
2023-04-26 22:28:20,176 - Epoch: [106][   50/  155]    Loss 3.170670    mAP 0.444965    
2023-04-26 22:28:26,601 - Epoch: [106][  100/  155]    Loss 3.191686    mAP 0.443813    
2023-04-26 22:28:33,117 - Epoch: [106][  150/  155]    Loss 3.210862    mAP 0.435500    
2023-04-26 22:28:33,679 - Epoch: [106][  155/  155]    Loss 3.211373    mAP 0.435682    
2023-04-26 22:28:33,751 - ==> mAP: 0.43568    Loss: 3.211

2023-04-26 22:28:33,755 - ==> Best [mAP: 0.441647   vloss: 3.211414   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-26 22:28:33,755 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:28:33,792 - 

2023-04-26 22:28:33,792 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:28:44,891 - Epoch: [107][   50/  518]    Overall Loss 2.944396    Objective Loss 2.944396                                        LR 0.000125    Time 0.221930    
2023-04-26 22:28:55,127 - Epoch: [107][  100/  518]    Overall Loss 2.949427    Objective Loss 2.949427                                        LR 0.000125    Time 0.213305    
2023-04-26 22:29:05,312 - Epoch: [107][  150/  518]    Overall Loss 2.958699    Objective Loss 2.958699                                        LR 0.000125    Time 0.210092    
2023-04-26 22:29:15,529 - Epoch: [107][  200/  518]    Overall Loss 2.955864    Objective Loss 2.955864                                        LR 0.000125    Time 0.208646    
2023-04-26 22:29:25,804 - Epoch: [107][  250/  518]    Overall Loss 2.952245    Objective Loss 2.952245                                        LR 0.000125    Time 0.208010    
2023-04-26 22:29:36,083 - Epoch: [107][  300/  518]    Overall Loss 2.941340    Objective Loss 2.941340                                        LR 0.000125    Time 0.207601    
2023-04-26 22:29:46,301 - Epoch: [107][  350/  518]    Overall Loss 2.937743    Objective Loss 2.937743                                        LR 0.000125    Time 0.207131    
2023-04-26 22:29:56,573 - Epoch: [107][  400/  518]    Overall Loss 2.944926    Objective Loss 2.944926                                        LR 0.000125    Time 0.206916    
2023-04-26 22:30:06,809 - Epoch: [107][  450/  518]    Overall Loss 2.945342    Objective Loss 2.945342                                        LR 0.000125    Time 0.206668    
2023-04-26 22:30:17,111 - Epoch: [107][  500/  518]    Overall Loss 2.948695    Objective Loss 2.948695                                        LR 0.000125    Time 0.206602    
2023-04-26 22:30:20,676 - Epoch: [107][  518/  518]    Overall Loss 2.945399    Objective Loss 2.945399                                        LR 0.000125    Time 0.206304    
2023-04-26 22:30:20,748 - --- validate (epoch=107)-----------
2023-04-26 22:30:20,748 - 4952 samples (32 per mini-batch)
2023-04-26 22:30:27,486 - Epoch: [107][   50/  155]    Loss 3.260833    mAP 0.426824    
2023-04-26 22:30:33,838 - Epoch: [107][  100/  155]    Loss 3.209349    mAP 0.427305    
2023-04-26 22:30:40,282 - Epoch: [107][  150/  155]    Loss 3.210357    mAP 0.429039    
2023-04-26 22:30:40,852 - Epoch: [107][  155/  155]    Loss 3.204226    mAP 0.431480    
2023-04-26 22:30:40,923 - ==> mAP: 0.43148    Loss: 3.204

2023-04-26 22:30:40,927 - ==> Best [mAP: 0.441647   vloss: 3.211414   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-26 22:30:40,927 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:30:40,964 - 

2023-04-26 22:30:40,965 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:30:52,001 - Epoch: [108][   50/  518]    Overall Loss 2.932591    Objective Loss 2.932591                                        LR 0.000125    Time 0.220667    
2023-04-26 22:31:02,223 - Epoch: [108][  100/  518]    Overall Loss 2.924586    Objective Loss 2.924586                                        LR 0.000125    Time 0.212538    
2023-04-26 22:31:12,553 - Epoch: [108][  150/  518]    Overall Loss 2.929116    Objective Loss 2.929116                                        LR 0.000125    Time 0.210550    
2023-04-26 22:31:22,816 - Epoch: [108][  200/  518]    Overall Loss 2.911084    Objective Loss 2.911084                                        LR 0.000125    Time 0.209221    
2023-04-26 22:31:33,109 - Epoch: [108][  250/  518]    Overall Loss 2.923109    Objective Loss 2.923109                                        LR 0.000125    Time 0.208541    
2023-04-26 22:31:43,474 - Epoch: [108][  300/  518]    Overall Loss 2.928231    Objective Loss 2.928231                                        LR 0.000125    Time 0.208326    
2023-04-26 22:31:53,724 - Epoch: [108][  350/  518]    Overall Loss 2.933241    Objective Loss 2.933241                                        LR 0.000125    Time 0.207848    
2023-04-26 22:32:03,990 - Epoch: [108][  400/  518]    Overall Loss 2.936750    Objective Loss 2.936750                                        LR 0.000125    Time 0.207526    
2023-04-26 22:32:14,154 - Epoch: [108][  450/  518]    Overall Loss 2.929525    Objective Loss 2.929525                                        LR 0.000125    Time 0.207052    
2023-04-26 22:32:24,428 - Epoch: [108][  500/  518]    Overall Loss 2.930096    Objective Loss 2.930096                                        LR 0.000125    Time 0.206892    
2023-04-26 22:32:27,961 - Epoch: [108][  518/  518]    Overall Loss 2.932063    Objective Loss 2.932063                                        LR 0.000125    Time 0.206522    
2023-04-26 22:32:28,033 - --- validate (epoch=108)-----------
2023-04-26 22:32:28,034 - 4952 samples (32 per mini-batch)
2023-04-26 22:32:34,846 - Epoch: [108][   50/  155]    Loss 3.199441    mAP 0.442386    
2023-04-26 22:32:41,267 - Epoch: [108][  100/  155]    Loss 3.193845    mAP 0.448900    
2023-04-26 22:32:47,654 - Epoch: [108][  150/  155]    Loss 3.195694    mAP 0.445026    
2023-04-26 22:32:48,260 - Epoch: [108][  155/  155]    Loss 3.197665    mAP 0.443686    
2023-04-26 22:32:48,333 - ==> mAP: 0.44369    Loss: 3.198

2023-04-26 22:32:48,337 - ==> Best [mAP: 0.443686   vloss: 3.197665   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-26 22:32:48,337 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:32:48,389 - 

2023-04-26 22:32:48,389 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:32:59,165 - Epoch: [109][   50/  518]    Overall Loss 2.887553    Objective Loss 2.887553                                        LR 0.000125    Time 0.215457    
2023-04-26 22:33:09,462 - Epoch: [109][  100/  518]    Overall Loss 2.910058    Objective Loss 2.910058                                        LR 0.000125    Time 0.210684    
2023-04-26 22:33:19,759 - Epoch: [109][  150/  518]    Overall Loss 2.920642    Objective Loss 2.920642                                        LR 0.000125    Time 0.209087    
2023-04-26 22:33:29,879 - Epoch: [109][  200/  518]    Overall Loss 2.935632    Objective Loss 2.935632                                        LR 0.000125    Time 0.207411    
2023-04-26 22:33:39,974 - Epoch: [109][  250/  518]    Overall Loss 2.940065    Objective Loss 2.940065                                        LR 0.000125    Time 0.206301    
2023-04-26 22:33:50,213 - Epoch: [109][  300/  518]    Overall Loss 2.934056    Objective Loss 2.934056                                        LR 0.000125    Time 0.206041    
2023-04-26 22:34:00,492 - Epoch: [109][  350/  518]    Overall Loss 2.935914    Objective Loss 2.935914                                        LR 0.000125    Time 0.205972    
2023-04-26 22:34:10,697 - Epoch: [109][  400/  518]    Overall Loss 2.939600    Objective Loss 2.939600                                        LR 0.000125    Time 0.205732    
2023-04-26 22:34:21,018 - Epoch: [109][  450/  518]    Overall Loss 2.933231    Objective Loss 2.933231                                        LR 0.000125    Time 0.205806    
2023-04-26 22:34:31,140 - Epoch: [109][  500/  518]    Overall Loss 2.934898    Objective Loss 2.934898                                        LR 0.000125    Time 0.205465    
2023-04-26 22:34:34,702 - Epoch: [109][  518/  518]    Overall Loss 2.934411    Objective Loss 2.934411                                        LR 0.000125    Time 0.205201    
2023-04-26 22:34:34,774 - --- validate (epoch=109)-----------
2023-04-26 22:34:34,774 - 4952 samples (32 per mini-batch)
2023-04-26 22:34:41,507 - Epoch: [109][   50/  155]    Loss 3.197840    mAP 0.440234    
2023-04-26 22:34:47,938 - Epoch: [109][  100/  155]    Loss 3.206288    mAP 0.436109    
2023-04-26 22:34:54,292 - Epoch: [109][  150/  155]    Loss 3.203765    mAP 0.437864    
2023-04-26 22:34:54,849 - Epoch: [109][  155/  155]    Loss 3.199960    mAP 0.438550    
2023-04-26 22:34:54,920 - ==> mAP: 0.43855    Loss: 3.200

2023-04-26 22:34:54,924 - ==> Best [mAP: 0.443686   vloss: 3.197665   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-26 22:34:54,924 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:34:54,961 - 

2023-04-26 22:34:54,961 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:35:05,940 - Epoch: [110][   50/  518]    Overall Loss 2.900683    Objective Loss 2.900683                                        LR 0.000125    Time 0.219530    
2023-04-26 22:35:16,232 - Epoch: [110][  100/  518]    Overall Loss 2.900330    Objective Loss 2.900330                                        LR 0.000125    Time 0.212671    
2023-04-26 22:35:26,535 - Epoch: [110][  150/  518]    Overall Loss 2.915986    Objective Loss 2.915986                                        LR 0.000125    Time 0.210452    
2023-04-26 22:35:36,788 - Epoch: [110][  200/  518]    Overall Loss 2.912271    Objective Loss 2.912271                                        LR 0.000125    Time 0.209095    
2023-04-26 22:35:47,087 - Epoch: [110][  250/  518]    Overall Loss 2.924583    Objective Loss 2.924583                                        LR 0.000125    Time 0.208468    
2023-04-26 22:35:57,278 - Epoch: [110][  300/  518]    Overall Loss 2.913065    Objective Loss 2.913065                                        LR 0.000125    Time 0.207688    
2023-04-26 22:36:07,642 - Epoch: [110][  350/  518]    Overall Loss 2.920000    Objective Loss 2.920000                                        LR 0.000125    Time 0.207623    
2023-04-26 22:36:17,815 - Epoch: [110][  400/  518]    Overall Loss 2.917571    Objective Loss 2.917571                                        LR 0.000125    Time 0.207099    
2023-04-26 22:36:27,993 - Epoch: [110][  450/  518]    Overall Loss 2.914683    Objective Loss 2.914683                                        LR 0.000125    Time 0.206702    
2023-04-26 22:36:38,241 - Epoch: [110][  500/  518]    Overall Loss 2.913195    Objective Loss 2.913195                                        LR 0.000125    Time 0.206524    
2023-04-26 22:36:41,833 - Epoch: [110][  518/  518]    Overall Loss 2.915191    Objective Loss 2.915191                                        LR 0.000125    Time 0.206283    
2023-04-26 22:36:41,906 - --- validate (epoch=110)-----------
2023-04-26 22:36:41,907 - 4952 samples (32 per mini-batch)
2023-04-26 22:36:48,740 - Epoch: [110][   50/  155]    Loss 3.192275    mAP 0.445541    
2023-04-26 22:36:55,212 - Epoch: [110][  100/  155]    Loss 3.208073    mAP 0.439444    
2023-04-26 22:37:01,591 - Epoch: [110][  150/  155]    Loss 3.198112    mAP 0.434879    
2023-04-26 22:37:02,166 - Epoch: [110][  155/  155]    Loss 3.201234    mAP 0.432920    
2023-04-26 22:37:02,236 - ==> mAP: 0.43292    Loss: 3.201

2023-04-26 22:37:02,239 - ==> Best [mAP: 0.443686   vloss: 3.197665   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-26 22:37:02,239 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:37:02,278 - 

2023-04-26 22:37:02,278 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:37:13,298 - Epoch: [111][   50/  518]    Overall Loss 2.937232    Objective Loss 2.937232                                        LR 0.000125    Time 0.220345    
2023-04-26 22:37:23,562 - Epoch: [111][  100/  518]    Overall Loss 2.949875    Objective Loss 2.949875                                        LR 0.000125    Time 0.212795    
2023-04-26 22:37:33,827 - Epoch: [111][  150/  518]    Overall Loss 2.933331    Objective Loss 2.933331                                        LR 0.000125    Time 0.210285    
2023-04-26 22:37:44,099 - Epoch: [111][  200/  518]    Overall Loss 2.930911    Objective Loss 2.930911                                        LR 0.000125    Time 0.209067    
2023-04-26 22:37:54,393 - Epoch: [111][  250/  518]    Overall Loss 2.924427    Objective Loss 2.924427                                        LR 0.000125    Time 0.208424    
2023-04-26 22:38:04,581 - Epoch: [111][  300/  518]    Overall Loss 2.932305    Objective Loss 2.932305                                        LR 0.000125    Time 0.207641    
2023-04-26 22:38:14,766 - Epoch: [111][  350/  518]    Overall Loss 2.928144    Objective Loss 2.928144                                        LR 0.000125    Time 0.207071    
2023-04-26 22:38:24,996 - Epoch: [111][  400/  518]    Overall Loss 2.921384    Objective Loss 2.921384                                        LR 0.000125    Time 0.206760    
2023-04-26 22:38:35,188 - Epoch: [111][  450/  518]    Overall Loss 2.926482    Objective Loss 2.926482                                        LR 0.000125    Time 0.206432    
2023-04-26 22:38:45,426 - Epoch: [111][  500/  518]    Overall Loss 2.922987    Objective Loss 2.922987                                        LR 0.000125    Time 0.206261    
2023-04-26 22:38:48,953 - Epoch: [111][  518/  518]    Overall Loss 2.923567    Objective Loss 2.923567                                        LR 0.000125    Time 0.205902    
2023-04-26 22:38:49,026 - --- validate (epoch=111)-----------
2023-04-26 22:38:49,026 - 4952 samples (32 per mini-batch)
2023-04-26 22:38:55,793 - Epoch: [111][   50/  155]    Loss 3.213983    mAP 0.443900    
2023-04-26 22:39:02,295 - Epoch: [111][  100/  155]    Loss 3.208088    mAP 0.442705    
2023-04-26 22:39:08,679 - Epoch: [111][  150/  155]    Loss 3.193134    mAP 0.441128    
2023-04-26 22:39:09,262 - Epoch: [111][  155/  155]    Loss 3.192463    mAP 0.443365    
2023-04-26 22:39:09,331 - ==> mAP: 0.44336    Loss: 3.192

2023-04-26 22:39:09,335 - ==> Best [mAP: 0.443686   vloss: 3.197665   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-26 22:39:09,335 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:39:09,372 - 

2023-04-26 22:39:09,372 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:39:20,169 - Epoch: [112][   50/  518]    Overall Loss 2.869364    Objective Loss 2.869364                                        LR 0.000125    Time 0.215871    
2023-04-26 22:39:30,350 - Epoch: [112][  100/  518]    Overall Loss 2.889222    Objective Loss 2.889222                                        LR 0.000125    Time 0.209731    
2023-04-26 22:39:40,547 - Epoch: [112][  150/  518]    Overall Loss 2.902128    Objective Loss 2.902128                                        LR 0.000125    Time 0.207788    
2023-04-26 22:39:50,795 - Epoch: [112][  200/  518]    Overall Loss 2.894141    Objective Loss 2.894141                                        LR 0.000125    Time 0.207072    
2023-04-26 22:40:01,012 - Epoch: [112][  250/  518]    Overall Loss 2.898469    Objective Loss 2.898469                                        LR 0.000125    Time 0.206519    
2023-04-26 22:40:11,153 - Epoch: [112][  300/  518]    Overall Loss 2.902567    Objective Loss 2.902567                                        LR 0.000125    Time 0.205897    
2023-04-26 22:40:21,282 - Epoch: [112][  350/  518]    Overall Loss 2.908702    Objective Loss 2.908702                                        LR 0.000125    Time 0.205419    
2023-04-26 22:40:31,497 - Epoch: [112][  400/  518]    Overall Loss 2.911730    Objective Loss 2.911730                                        LR 0.000125    Time 0.205274    
2023-04-26 22:40:41,756 - Epoch: [112][  450/  518]    Overall Loss 2.918423    Objective Loss 2.918423                                        LR 0.000125    Time 0.205260    
2023-04-26 22:40:51,951 - Epoch: [112][  500/  518]    Overall Loss 2.922526    Objective Loss 2.922526                                        LR 0.000125    Time 0.205122    
2023-04-26 22:40:55,524 - Epoch: [112][  518/  518]    Overall Loss 2.926335    Objective Loss 2.926335                                        LR 0.000125    Time 0.204891    
2023-04-26 22:40:55,595 - --- validate (epoch=112)-----------
2023-04-26 22:40:55,596 - 4952 samples (32 per mini-batch)
2023-04-26 22:41:02,411 - Epoch: [112][   50/  155]    Loss 3.176458    mAP 0.434286    
2023-04-26 22:41:08,859 - Epoch: [112][  100/  155]    Loss 3.199114    mAP 0.433602    
2023-04-26 22:41:15,252 - Epoch: [112][  150/  155]    Loss 3.190080    mAP 0.442437    
2023-04-26 22:41:15,822 - Epoch: [112][  155/  155]    Loss 3.191066    mAP 0.442297    
2023-04-26 22:41:15,893 - ==> mAP: 0.44230    Loss: 3.191

2023-04-26 22:41:15,897 - ==> Best [mAP: 0.443686   vloss: 3.197665   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-26 22:41:15,897 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:41:15,935 - 

2023-04-26 22:41:15,935 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:41:26,868 - Epoch: [113][   50/  518]    Overall Loss 2.903749    Objective Loss 2.903749                                        LR 0.000125    Time 0.218602    
2023-04-26 22:41:37,075 - Epoch: [113][  100/  518]    Overall Loss 2.880212    Objective Loss 2.880212                                        LR 0.000125    Time 0.211354    
2023-04-26 22:41:47,194 - Epoch: [113][  150/  518]    Overall Loss 2.891344    Objective Loss 2.891344                                        LR 0.000125    Time 0.208352    
2023-04-26 22:41:57,350 - Epoch: [113][  200/  518]    Overall Loss 2.894628    Objective Loss 2.894628                                        LR 0.000125    Time 0.207035    
2023-04-26 22:42:07,650 - Epoch: [113][  250/  518]    Overall Loss 2.912572    Objective Loss 2.912572                                        LR 0.000125    Time 0.206822    
2023-04-26 22:42:17,842 - Epoch: [113][  300/  518]    Overall Loss 2.919297    Objective Loss 2.919297                                        LR 0.000125    Time 0.206321    
2023-04-26 22:42:28,073 - Epoch: [113][  350/  518]    Overall Loss 2.923986    Objective Loss 2.923986                                        LR 0.000125    Time 0.206074    
2023-04-26 22:42:38,328 - Epoch: [113][  400/  518]    Overall Loss 2.925886    Objective Loss 2.925886                                        LR 0.000125    Time 0.205946    
2023-04-26 22:42:48,561 - Epoch: [113][  450/  518]    Overall Loss 2.925356    Objective Loss 2.925356                                        LR 0.000125    Time 0.205800    
2023-04-26 22:42:58,703 - Epoch: [113][  500/  518]    Overall Loss 2.921685    Objective Loss 2.921685                                        LR 0.000125    Time 0.205501    
2023-04-26 22:43:02,269 - Epoch: [113][  518/  518]    Overall Loss 2.921095    Objective Loss 2.921095                                        LR 0.000125    Time 0.205244    
2023-04-26 22:43:02,342 - --- validate (epoch=113)-----------
2023-04-26 22:43:02,343 - 4952 samples (32 per mini-batch)
2023-04-26 22:43:09,224 - Epoch: [113][   50/  155]    Loss 3.193860    mAP 0.413256    
2023-04-26 22:43:15,622 - Epoch: [113][  100/  155]    Loss 3.182669    mAP 0.426424    
2023-04-26 22:43:22,047 - Epoch: [113][  150/  155]    Loss 3.183294    mAP 0.429468    
2023-04-26 22:43:22,612 - Epoch: [113][  155/  155]    Loss 3.186067    mAP 0.429833    
2023-04-26 22:43:22,684 - ==> mAP: 0.42983    Loss: 3.186

2023-04-26 22:43:22,687 - ==> Best [mAP: 0.443686   vloss: 3.197665   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-26 22:43:22,688 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:43:22,726 - 

2023-04-26 22:43:22,726 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:43:33,608 - Epoch: [114][   50/  518]    Overall Loss 2.836483    Objective Loss 2.836483                                        LR 0.000125    Time 0.217575    
2023-04-26 22:43:43,899 - Epoch: [114][  100/  518]    Overall Loss 2.871926    Objective Loss 2.871926                                        LR 0.000125    Time 0.211686    
2023-04-26 22:43:54,122 - Epoch: [114][  150/  518]    Overall Loss 2.899273    Objective Loss 2.899273                                        LR 0.000125    Time 0.209266    
2023-04-26 22:44:04,339 - Epoch: [114][  200/  518]    Overall Loss 2.897280    Objective Loss 2.897280                                        LR 0.000125    Time 0.208025    
2023-04-26 22:44:14,539 - Epoch: [114][  250/  518]    Overall Loss 2.903058    Objective Loss 2.903058                                        LR 0.000125    Time 0.207211    
2023-04-26 22:44:24,752 - Epoch: [114][  300/  518]    Overall Loss 2.901948    Objective Loss 2.901948                                        LR 0.000125    Time 0.206715    
2023-04-26 22:44:35,019 - Epoch: [114][  350/  518]    Overall Loss 2.896801    Objective Loss 2.896801                                        LR 0.000125    Time 0.206514    
2023-04-26 22:44:45,189 - Epoch: [114][  400/  518]    Overall Loss 2.901325    Objective Loss 2.901325                                        LR 0.000125    Time 0.206120    
2023-04-26 22:44:55,430 - Epoch: [114][  450/  518]    Overall Loss 2.904894    Objective Loss 2.904894                                        LR 0.000125    Time 0.205972    
2023-04-26 22:45:05,751 - Epoch: [114][  500/  518]    Overall Loss 2.907291    Objective Loss 2.907291                                        LR 0.000125    Time 0.206014    
2023-04-26 22:45:09,284 - Epoch: [114][  518/  518]    Overall Loss 2.907482    Objective Loss 2.907482                                        LR 0.000125    Time 0.205675    
2023-04-26 22:45:09,356 - --- validate (epoch=114)-----------
2023-04-26 22:45:09,356 - 4952 samples (32 per mini-batch)
2023-04-26 22:45:16,055 - Epoch: [114][   50/  155]    Loss 3.199652    mAP 0.432874    
2023-04-26 22:45:22,514 - Epoch: [114][  100/  155]    Loss 3.195378    mAP 0.431717    
2023-04-26 22:45:28,891 - Epoch: [114][  150/  155]    Loss 3.188928    mAP 0.438720    
2023-04-26 22:45:29,458 - Epoch: [114][  155/  155]    Loss 3.189205    mAP 0.438739    
2023-04-26 22:45:29,529 - ==> mAP: 0.43874    Loss: 3.189

2023-04-26 22:45:29,533 - ==> Best [mAP: 0.443686   vloss: 3.197665   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-26 22:45:29,533 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:45:29,570 - 

2023-04-26 22:45:29,570 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:45:40,450 - Epoch: [115][   50/  518]    Overall Loss 2.917484    Objective Loss 2.917484                                        LR 0.000125    Time 0.217531    
2023-04-26 22:45:50,690 - Epoch: [115][  100/  518]    Overall Loss 2.921559    Objective Loss 2.921559                                        LR 0.000125    Time 0.211150    
2023-04-26 22:46:00,980 - Epoch: [115][  150/  518]    Overall Loss 2.924151    Objective Loss 2.924151                                        LR 0.000125    Time 0.209357    
2023-04-26 22:46:11,158 - Epoch: [115][  200/  518]    Overall Loss 2.916861    Objective Loss 2.916861                                        LR 0.000125    Time 0.207903    
2023-04-26 22:46:21,452 - Epoch: [115][  250/  518]    Overall Loss 2.923786    Objective Loss 2.923786                                        LR 0.000125    Time 0.207488    
2023-04-26 22:46:31,694 - Epoch: [115][  300/  518]    Overall Loss 2.907690    Objective Loss 2.907690                                        LR 0.000125    Time 0.207042    
2023-04-26 22:46:41,910 - Epoch: [115][  350/  518]    Overall Loss 2.915019    Objective Loss 2.915019                                        LR 0.000125    Time 0.206650    
2023-04-26 22:46:52,154 - Epoch: [115][  400/  518]    Overall Loss 2.913875    Objective Loss 2.913875                                        LR 0.000125    Time 0.206425    
2023-04-26 22:47:02,355 - Epoch: [115][  450/  518]    Overall Loss 2.917450    Objective Loss 2.917450                                        LR 0.000125    Time 0.206153    
2023-04-26 22:47:12,620 - Epoch: [115][  500/  518]    Overall Loss 2.918872    Objective Loss 2.918872                                        LR 0.000125    Time 0.206065    
2023-04-26 22:47:16,196 - Epoch: [115][  518/  518]    Overall Loss 2.919340    Objective Loss 2.919340                                        LR 0.000125    Time 0.205806    
2023-04-26 22:47:16,268 - --- validate (epoch=115)-----------
2023-04-26 22:47:16,268 - 4952 samples (32 per mini-batch)
2023-04-26 22:47:23,050 - Epoch: [115][   50/  155]    Loss 3.189922    mAP 0.424767    
2023-04-26 22:47:29,478 - Epoch: [115][  100/  155]    Loss 3.196640    mAP 0.431650    
2023-04-26 22:47:35,896 - Epoch: [115][  150/  155]    Loss 3.194007    mAP 0.432363    
2023-04-26 22:47:36,474 - Epoch: [115][  155/  155]    Loss 3.194570    mAP 0.432961    
2023-04-26 22:47:36,545 - ==> mAP: 0.43296    Loss: 3.195

2023-04-26 22:47:36,549 - ==> Best [mAP: 0.443686   vloss: 3.197665   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-26 22:47:36,550 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:47:36,588 - 

2023-04-26 22:47:36,588 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:47:47,582 - Epoch: [116][   50/  518]    Overall Loss 2.941806    Objective Loss 2.941806                                        LR 0.000125    Time 0.219819    
2023-04-26 22:47:57,677 - Epoch: [116][  100/  518]    Overall Loss 2.904355    Objective Loss 2.904355                                        LR 0.000125    Time 0.210846    
2023-04-26 22:48:07,964 - Epoch: [116][  150/  518]    Overall Loss 2.890671    Objective Loss 2.890671                                        LR 0.000125    Time 0.209136    
2023-04-26 22:48:18,124 - Epoch: [116][  200/  518]    Overall Loss 2.907977    Objective Loss 2.907977                                        LR 0.000125    Time 0.207643    
2023-04-26 22:48:28,336 - Epoch: [116][  250/  518]    Overall Loss 2.925239    Objective Loss 2.925239                                        LR 0.000125    Time 0.206955    
2023-04-26 22:48:38,516 - Epoch: [116][  300/  518]    Overall Loss 2.925776    Objective Loss 2.925776                                        LR 0.000125    Time 0.206390    
2023-04-26 22:48:48,768 - Epoch: [116][  350/  518]    Overall Loss 2.923010    Objective Loss 2.923010                                        LR 0.000125    Time 0.206192    
2023-04-26 22:48:58,984 - Epoch: [116][  400/  518]    Overall Loss 2.925184    Objective Loss 2.925184                                        LR 0.000125    Time 0.205954    
2023-04-26 22:49:09,199 - Epoch: [116][  450/  518]    Overall Loss 2.917055    Objective Loss 2.917055                                        LR 0.000125    Time 0.205767    
2023-04-26 22:49:19,342 - Epoch: [116][  500/  518]    Overall Loss 2.919737    Objective Loss 2.919737                                        LR 0.000125    Time 0.205472    
2023-04-26 22:49:22,903 - Epoch: [116][  518/  518]    Overall Loss 2.920775    Objective Loss 2.920775                                        LR 0.000125    Time 0.205206    
2023-04-26 22:49:22,975 - --- validate (epoch=116)-----------
2023-04-26 22:49:22,975 - 4952 samples (32 per mini-batch)
2023-04-26 22:49:29,725 - Epoch: [116][   50/  155]    Loss 3.211632    mAP 0.434540    
2023-04-26 22:49:36,114 - Epoch: [116][  100/  155]    Loss 3.199567    mAP 0.432340    
2023-04-26 22:49:42,463 - Epoch: [116][  150/  155]    Loss 3.200918    mAP 0.428761    
2023-04-26 22:49:43,038 - Epoch: [116][  155/  155]    Loss 3.193116    mAP 0.429912    
2023-04-26 22:49:43,106 - ==> mAP: 0.42991    Loss: 3.193

2023-04-26 22:49:43,109 - ==> Best [mAP: 0.443686   vloss: 3.197665   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-26 22:49:43,110 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:49:43,147 - 

2023-04-26 22:49:43,147 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:49:54,208 - Epoch: [117][   50/  518]    Overall Loss 2.881834    Objective Loss 2.881834                                        LR 0.000125    Time 0.221161    
2023-04-26 22:50:04,483 - Epoch: [117][  100/  518]    Overall Loss 2.886334    Objective Loss 2.886334                                        LR 0.000125    Time 0.213318    
2023-04-26 22:50:14,699 - Epoch: [117][  150/  518]    Overall Loss 2.893793    Objective Loss 2.893793                                        LR 0.000125    Time 0.210306    
2023-04-26 22:50:24,980 - Epoch: [117][  200/  518]    Overall Loss 2.906813    Objective Loss 2.906813                                        LR 0.000125    Time 0.209125    
2023-04-26 22:50:35,150 - Epoch: [117][  250/  518]    Overall Loss 2.927121    Objective Loss 2.927121                                        LR 0.000125    Time 0.207974    
2023-04-26 22:50:45,313 - Epoch: [117][  300/  518]    Overall Loss 2.924688    Objective Loss 2.924688                                        LR 0.000125    Time 0.207184    
2023-04-26 22:50:55,433 - Epoch: [117][  350/  518]    Overall Loss 2.919182    Objective Loss 2.919182                                        LR 0.000125    Time 0.206496    
2023-04-26 22:51:05,622 - Epoch: [117][  400/  518]    Overall Loss 2.916924    Objective Loss 2.916924                                        LR 0.000125    Time 0.206153    
2023-04-26 22:51:15,808 - Epoch: [117][  450/  518]    Overall Loss 2.912598    Objective Loss 2.912598                                        LR 0.000125    Time 0.205877    
2023-04-26 22:51:25,880 - Epoch: [117][  500/  518]    Overall Loss 2.916221    Objective Loss 2.916221                                        LR 0.000125    Time 0.205431    
2023-04-26 22:51:29,447 - Epoch: [117][  518/  518]    Overall Loss 2.917868    Objective Loss 2.917868                                        LR 0.000125    Time 0.205178    
2023-04-26 22:51:29,519 - --- validate (epoch=117)-----------
2023-04-26 22:51:29,520 - 4952 samples (32 per mini-batch)
2023-04-26 22:51:36,238 - Epoch: [117][   50/  155]    Loss 3.168992    mAP 0.438299    
2023-04-26 22:51:42,631 - Epoch: [117][  100/  155]    Loss 3.159211    mAP 0.435356    
2023-04-26 22:51:48,999 - Epoch: [117][  150/  155]    Loss 3.178312    mAP 0.437114    
2023-04-26 22:51:49,563 - Epoch: [117][  155/  155]    Loss 3.178656    mAP 0.437934    
2023-04-26 22:51:49,635 - ==> mAP: 0.43793    Loss: 3.179

2023-04-26 22:51:49,639 - ==> Best [mAP: 0.443686   vloss: 3.197665   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-26 22:51:49,639 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:51:49,676 - 

2023-04-26 22:51:49,676 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:52:00,544 - Epoch: [118][   50/  518]    Overall Loss 2.919194    Objective Loss 2.919194                                        LR 0.000125    Time 0.217297    
2023-04-26 22:52:10,656 - Epoch: [118][  100/  518]    Overall Loss 2.920198    Objective Loss 2.920198                                        LR 0.000125    Time 0.209754    
2023-04-26 22:52:20,713 - Epoch: [118][  150/  518]    Overall Loss 2.910351    Objective Loss 2.910351                                        LR 0.000125    Time 0.206872    
2023-04-26 22:52:30,905 - Epoch: [118][  200/  518]    Overall Loss 2.922631    Objective Loss 2.922631                                        LR 0.000125    Time 0.206104    
2023-04-26 22:52:40,985 - Epoch: [118][  250/  518]    Overall Loss 2.917984    Objective Loss 2.917984                                        LR 0.000125    Time 0.205197    
2023-04-26 22:52:51,159 - Epoch: [118][  300/  518]    Overall Loss 2.922881    Objective Loss 2.922881                                        LR 0.000125    Time 0.204907    
2023-04-26 22:53:01,342 - Epoch: [118][  350/  518]    Overall Loss 2.926382    Objective Loss 2.926382                                        LR 0.000125    Time 0.204723    
2023-04-26 22:53:11,415 - Epoch: [118][  400/  518]    Overall Loss 2.923335    Objective Loss 2.923335                                        LR 0.000125    Time 0.204312    
2023-04-26 22:53:21,530 - Epoch: [118][  450/  518]    Overall Loss 2.918106    Objective Loss 2.918106                                        LR 0.000125    Time 0.204085    
2023-04-26 22:53:31,633 - Epoch: [118][  500/  518]    Overall Loss 2.912914    Objective Loss 2.912914                                        LR 0.000125    Time 0.203879    
2023-04-26 22:53:35,158 - Epoch: [118][  518/  518]    Overall Loss 2.914147    Objective Loss 2.914147                                        LR 0.000125    Time 0.203598    
2023-04-26 22:53:35,229 - --- validate (epoch=118)-----------
2023-04-26 22:53:35,229 - 4952 samples (32 per mini-batch)
2023-04-26 22:53:42,067 - Epoch: [118][   50/  155]    Loss 3.181161    mAP 0.422856    
2023-04-26 22:53:48,432 - Epoch: [118][  100/  155]    Loss 3.186637    mAP 0.432238    
2023-04-26 22:53:54,785 - Epoch: [118][  150/  155]    Loss 3.186519    mAP 0.435314    
2023-04-26 22:53:55,366 - Epoch: [118][  155/  155]    Loss 3.185973    mAP 0.435061    
2023-04-26 22:53:55,439 - ==> mAP: 0.43506    Loss: 3.186

2023-04-26 22:53:55,442 - ==> Best [mAP: 0.443686   vloss: 3.197665   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-26 22:53:55,442 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:53:55,479 - 

2023-04-26 22:53:55,479 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:54:06,250 - Epoch: [119][   50/  518]    Overall Loss 2.896351    Objective Loss 2.896351                                        LR 0.000125    Time 0.215358    
2023-04-26 22:54:16,437 - Epoch: [119][  100/  518]    Overall Loss 2.896053    Objective Loss 2.896053                                        LR 0.000125    Time 0.209530    
2023-04-26 22:54:26,625 - Epoch: [119][  150/  518]    Overall Loss 2.913593    Objective Loss 2.913593                                        LR 0.000125    Time 0.207598    
2023-04-26 22:54:36,712 - Epoch: [119][  200/  518]    Overall Loss 2.896698    Objective Loss 2.896698                                        LR 0.000125    Time 0.206123    
2023-04-26 22:54:46,876 - Epoch: [119][  250/  518]    Overall Loss 2.902839    Objective Loss 2.902839                                        LR 0.000125    Time 0.205548    
2023-04-26 22:54:57,099 - Epoch: [119][  300/  518]    Overall Loss 2.906199    Objective Loss 2.906199                                        LR 0.000125    Time 0.205361    
2023-04-26 22:55:07,302 - Epoch: [119][  350/  518]    Overall Loss 2.907656    Objective Loss 2.907656                                        LR 0.000125    Time 0.205171    
2023-04-26 22:55:17,486 - Epoch: [119][  400/  518]    Overall Loss 2.910213    Objective Loss 2.910213                                        LR 0.000125    Time 0.204982    
2023-04-26 22:55:27,624 - Epoch: [119][  450/  518]    Overall Loss 2.906425    Objective Loss 2.906425                                        LR 0.000125    Time 0.204731    
2023-04-26 22:55:37,787 - Epoch: [119][  500/  518]    Overall Loss 2.907846    Objective Loss 2.907846                                        LR 0.000125    Time 0.204581    
2023-04-26 22:55:41,360 - Epoch: [119][  518/  518]    Overall Loss 2.907140    Objective Loss 2.907140                                        LR 0.000125    Time 0.204369    
2023-04-26 22:55:41,431 - --- validate (epoch=119)-----------
2023-04-26 22:55:41,431 - 4952 samples (32 per mini-batch)
2023-04-26 22:55:48,170 - Epoch: [119][   50/  155]    Loss 3.168309    mAP 0.430602    
2023-04-26 22:55:54,663 - Epoch: [119][  100/  155]    Loss 3.184838    mAP 0.444549    
2023-04-26 22:56:01,043 - Epoch: [119][  150/  155]    Loss 3.182031    mAP 0.444019    
2023-04-26 22:56:01,629 - Epoch: [119][  155/  155]    Loss 3.185144    mAP 0.444519    
2023-04-26 22:56:01,706 - ==> mAP: 0.44452    Loss: 3.185

2023-04-26 22:56:01,710 - ==> Best [mAP: 0.444519   vloss: 3.185144   Sparsity:0.00   Params: 2177088 on epoch: 119]
2023-04-26 22:56:01,710 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:56:01,762 - 

2023-04-26 22:56:01,762 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:56:12,543 - Epoch: [120][   50/  518]    Overall Loss 2.943367    Objective Loss 2.943367                                        LR 0.000125    Time 0.215576    
2023-04-26 22:56:22,684 - Epoch: [120][  100/  518]    Overall Loss 2.926299    Objective Loss 2.926299                                        LR 0.000125    Time 0.209182    
2023-04-26 22:56:32,799 - Epoch: [120][  150/  518]    Overall Loss 2.933093    Objective Loss 2.933093                                        LR 0.000125    Time 0.206876    
2023-04-26 22:56:43,009 - Epoch: [120][  200/  518]    Overall Loss 2.938256    Objective Loss 2.938256                                        LR 0.000125    Time 0.206197    
2023-04-26 22:56:53,229 - Epoch: [120][  250/  518]    Overall Loss 2.932413    Objective Loss 2.932413                                        LR 0.000125    Time 0.205830    
2023-04-26 22:57:03,395 - Epoch: [120][  300/  518]    Overall Loss 2.926886    Objective Loss 2.926886                                        LR 0.000125    Time 0.205407    
2023-04-26 22:57:13,585 - Epoch: [120][  350/  518]    Overall Loss 2.923822    Objective Loss 2.923822                                        LR 0.000125    Time 0.205173    
2023-04-26 22:57:23,704 - Epoch: [120][  400/  518]    Overall Loss 2.917111    Objective Loss 2.917111                                        LR 0.000125    Time 0.204820    
2023-04-26 22:57:33,876 - Epoch: [120][  450/  518]    Overall Loss 2.911975    Objective Loss 2.911975                                        LR 0.000125    Time 0.204663    
2023-04-26 22:57:43,992 - Epoch: [120][  500/  518]    Overall Loss 2.908717    Objective Loss 2.908717                                        LR 0.000125    Time 0.204426    
2023-04-26 22:57:47,556 - Epoch: [120][  518/  518]    Overall Loss 2.909626    Objective Loss 2.909626                                        LR 0.000125    Time 0.204200    
2023-04-26 22:57:47,627 - --- validate (epoch=120)-----------
2023-04-26 22:57:47,627 - 4952 samples (32 per mini-batch)
2023-04-26 22:57:54,411 - Epoch: [120][   50/  155]    Loss 3.197746    mAP 0.442143    
2023-04-26 22:58:00,810 - Epoch: [120][  100/  155]    Loss 3.182623    mAP 0.440350    
2023-04-26 22:58:07,189 - Epoch: [120][  150/  155]    Loss 3.175535    mAP 0.446550    
2023-04-26 22:58:07,762 - Epoch: [120][  155/  155]    Loss 3.177059    mAP 0.444792    
2023-04-26 22:58:07,825 - ==> mAP: 0.44479    Loss: 3.177

2023-04-26 22:58:07,829 - ==> Best [mAP: 0.444792   vloss: 3.177059   Sparsity:0.00   Params: 2177088 on epoch: 120]
2023-04-26 22:58:07,829 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 22:58:07,883 - 

2023-04-26 22:58:07,883 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 22:58:18,752 - Epoch: [121][   50/  518]    Overall Loss 2.967805    Objective Loss 2.967805                                        LR 0.000125    Time 0.217315    
2023-04-26 22:58:28,897 - Epoch: [121][  100/  518]    Overall Loss 2.929491    Objective Loss 2.929491                                        LR 0.000125    Time 0.210098    
2023-04-26 22:58:39,043 - Epoch: [121][  150/  518]    Overall Loss 2.927062    Objective Loss 2.927062                                        LR 0.000125    Time 0.207690    
2023-04-26 22:58:49,140 - Epoch: [121][  200/  518]    Overall Loss 2.926414    Objective Loss 2.926414                                        LR 0.000125    Time 0.206244    
2023-04-26 22:58:59,236 - Epoch: [121][  250/  518]    Overall Loss 2.926153    Objective Loss 2.926153                                        LR 0.000125    Time 0.205375    
2023-04-26 22:59:09,409 - Epoch: [121][  300/  518]    Overall Loss 2.930051    Objective Loss 2.930051                                        LR 0.000125    Time 0.205051    
2023-04-26 22:59:19,507 - Epoch: [121][  350/  518]    Overall Loss 2.923620    Objective Loss 2.923620                                        LR 0.000125    Time 0.204604    
2023-04-26 22:59:29,636 - Epoch: [121][  400/  518]    Overall Loss 2.920346    Objective Loss 2.920346                                        LR 0.000125    Time 0.204346    
2023-04-26 22:59:39,748 - Epoch: [121][  450/  518]    Overall Loss 2.921177    Objective Loss 2.921177                                        LR 0.000125    Time 0.204108    
2023-04-26 22:59:49,864 - Epoch: [121][  500/  518]    Overall Loss 2.918115    Objective Loss 2.918115                                        LR 0.000125    Time 0.203927    
2023-04-26 22:59:53,476 - Epoch: [121][  518/  518]    Overall Loss 2.916028    Objective Loss 2.916028                                        LR 0.000125    Time 0.203811    
2023-04-26 22:59:53,548 - --- validate (epoch=121)-----------
2023-04-26 22:59:53,549 - 4952 samples (32 per mini-batch)
2023-04-26 23:00:00,245 - Epoch: [121][   50/  155]    Loss 3.251105    mAP 0.427340    
2023-04-26 23:00:06,618 - Epoch: [121][  100/  155]    Loss 3.211445    mAP 0.441664    
2023-04-26 23:00:12,945 - Epoch: [121][  150/  155]    Loss 3.198006    mAP 0.443231    
2023-04-26 23:00:13,510 - Epoch: [121][  155/  155]    Loss 3.199776    mAP 0.443764    
2023-04-26 23:00:13,580 - ==> mAP: 0.44376    Loss: 3.200

2023-04-26 23:00:13,583 - ==> Best [mAP: 0.444792   vloss: 3.177059   Sparsity:0.00   Params: 2177088 on epoch: 120]
2023-04-26 23:00:13,583 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:00:13,621 - 

2023-04-26 23:00:13,621 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:00:24,465 - Epoch: [122][   50/  518]    Overall Loss 2.853038    Objective Loss 2.853038                                        LR 0.000125    Time 0.216814    
2023-04-26 23:00:34,612 - Epoch: [122][  100/  518]    Overall Loss 2.841857    Objective Loss 2.841857                                        LR 0.000125    Time 0.209867    
2023-04-26 23:00:44,736 - Epoch: [122][  150/  518]    Overall Loss 2.865407    Objective Loss 2.865407                                        LR 0.000125    Time 0.207389    
2023-04-26 23:00:54,865 - Epoch: [122][  200/  518]    Overall Loss 2.878950    Objective Loss 2.878950                                        LR 0.000125    Time 0.206179    
2023-04-26 23:01:05,068 - Epoch: [122][  250/  518]    Overall Loss 2.891779    Objective Loss 2.891779                                        LR 0.000125    Time 0.205751    
2023-04-26 23:01:15,261 - Epoch: [122][  300/  518]    Overall Loss 2.898091    Objective Loss 2.898091                                        LR 0.000125    Time 0.205430    
2023-04-26 23:01:25,576 - Epoch: [122][  350/  518]    Overall Loss 2.904451    Objective Loss 2.904451                                        LR 0.000125    Time 0.205549    
2023-04-26 23:01:35,735 - Epoch: [122][  400/  518]    Overall Loss 2.899193    Objective Loss 2.899193                                        LR 0.000125    Time 0.205249    
2023-04-26 23:01:45,945 - Epoch: [122][  450/  518]    Overall Loss 2.898732    Objective Loss 2.898732                                        LR 0.000125    Time 0.205129    
2023-04-26 23:01:56,091 - Epoch: [122][  500/  518]    Overall Loss 2.901927    Objective Loss 2.901927                                        LR 0.000125    Time 0.204904    
2023-04-26 23:01:59,638 - Epoch: [122][  518/  518]    Overall Loss 2.906528    Objective Loss 2.906528                                        LR 0.000125    Time 0.204631    
2023-04-26 23:01:59,710 - --- validate (epoch=122)-----------
2023-04-26 23:01:59,711 - 4952 samples (32 per mini-batch)
2023-04-26 23:02:06,541 - Epoch: [122][   50/  155]    Loss 3.195539    mAP 0.455466    
2023-04-26 23:02:12,990 - Epoch: [122][  100/  155]    Loss 3.202402    mAP 0.446390    
2023-04-26 23:02:19,430 - Epoch: [122][  150/  155]    Loss 3.193195    mAP 0.445236    
2023-04-26 23:02:19,991 - Epoch: [122][  155/  155]    Loss 3.191894    mAP 0.442439    
2023-04-26 23:02:20,060 - ==> mAP: 0.44244    Loss: 3.192

2023-04-26 23:02:20,064 - ==> Best [mAP: 0.444792   vloss: 3.177059   Sparsity:0.00   Params: 2177088 on epoch: 120]
2023-04-26 23:02:20,064 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:02:20,103 - 

2023-04-26 23:02:20,103 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:02:30,950 - Epoch: [123][   50/  518]    Overall Loss 2.908392    Objective Loss 2.908392                                        LR 0.000125    Time 0.216881    
2023-04-26 23:02:41,100 - Epoch: [123][  100/  518]    Overall Loss 2.915244    Objective Loss 2.915244                                        LR 0.000125    Time 0.209919    
2023-04-26 23:02:51,226 - Epoch: [123][  150/  518]    Overall Loss 2.915848    Objective Loss 2.915848                                        LR 0.000125    Time 0.207444    
2023-04-26 23:03:01,401 - Epoch: [123][  200/  518]    Overall Loss 2.913296    Objective Loss 2.913296                                        LR 0.000125    Time 0.206450    
2023-04-26 23:03:11,577 - Epoch: [123][  250/  518]    Overall Loss 2.920180    Objective Loss 2.920180                                        LR 0.000125    Time 0.205856    
2023-04-26 23:03:21,807 - Epoch: [123][  300/  518]    Overall Loss 2.926891    Objective Loss 2.926891                                        LR 0.000125    Time 0.205642    
2023-04-26 23:03:31,996 - Epoch: [123][  350/  518]    Overall Loss 2.922864    Objective Loss 2.922864                                        LR 0.000125    Time 0.205372    
2023-04-26 23:03:42,201 - Epoch: [123][  400/  518]    Overall Loss 2.921913    Objective Loss 2.921913                                        LR 0.000125    Time 0.205208    
2023-04-26 23:03:52,340 - Epoch: [123][  450/  518]    Overall Loss 2.919783    Objective Loss 2.919783                                        LR 0.000125    Time 0.204936    
2023-04-26 23:04:02,522 - Epoch: [123][  500/  518]    Overall Loss 2.912766    Objective Loss 2.912766                                        LR 0.000125    Time 0.204803    
2023-04-26 23:04:06,053 - Epoch: [123][  518/  518]    Overall Loss 2.908665    Objective Loss 2.908665                                        LR 0.000125    Time 0.204501    
2023-04-26 23:04:06,124 - --- validate (epoch=123)-----------
2023-04-26 23:04:06,124 - 4952 samples (32 per mini-batch)
2023-04-26 23:04:12,812 - Epoch: [123][   50/  155]    Loss 3.213200    mAP 0.406803    
2023-04-26 23:04:19,155 - Epoch: [123][  100/  155]    Loss 3.175614    mAP 0.436899    
2023-04-26 23:04:25,545 - Epoch: [123][  150/  155]    Loss 3.183179    mAP 0.439113    
2023-04-26 23:04:26,111 - Epoch: [123][  155/  155]    Loss 3.179718    mAP 0.438296    
2023-04-26 23:04:26,193 - ==> mAP: 0.43830    Loss: 3.180

2023-04-26 23:04:26,197 - ==> Best [mAP: 0.444792   vloss: 3.177059   Sparsity:0.00   Params: 2177088 on epoch: 120]
2023-04-26 23:04:26,197 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:04:26,232 - 

2023-04-26 23:04:26,233 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:04:37,100 - Epoch: [124][   50/  518]    Overall Loss 2.897357    Objective Loss 2.897357                                        LR 0.000125    Time 0.217294    
2023-04-26 23:04:47,161 - Epoch: [124][  100/  518]    Overall Loss 2.927078    Objective Loss 2.927078                                        LR 0.000125    Time 0.209241    
2023-04-26 23:04:57,364 - Epoch: [124][  150/  518]    Overall Loss 2.938392    Objective Loss 2.938392                                        LR 0.000125    Time 0.207502    
2023-04-26 23:05:07,558 - Epoch: [124][  200/  518]    Overall Loss 2.926473    Objective Loss 2.926473                                        LR 0.000125    Time 0.206586    
2023-04-26 23:05:17,775 - Epoch: [124][  250/  518]    Overall Loss 2.923227    Objective Loss 2.923227                                        LR 0.000125    Time 0.206130    
2023-04-26 23:05:27,959 - Epoch: [124][  300/  518]    Overall Loss 2.918449    Objective Loss 2.918449                                        LR 0.000125    Time 0.205716    
2023-04-26 23:05:38,110 - Epoch: [124][  350/  518]    Overall Loss 2.907833    Objective Loss 2.907833                                        LR 0.000125    Time 0.205328    
2023-04-26 23:05:48,277 - Epoch: [124][  400/  518]    Overall Loss 2.909160    Objective Loss 2.909160                                        LR 0.000125    Time 0.205074    
2023-04-26 23:05:58,383 - Epoch: [124][  450/  518]    Overall Loss 2.904970    Objective Loss 2.904970                                        LR 0.000125    Time 0.204744    
2023-04-26 23:06:08,568 - Epoch: [124][  500/  518]    Overall Loss 2.901965    Objective Loss 2.901965                                        LR 0.000125    Time 0.204636    
2023-04-26 23:06:12,133 - Epoch: [124][  518/  518]    Overall Loss 2.902696    Objective Loss 2.902696                                        LR 0.000125    Time 0.204406    
2023-04-26 23:06:12,205 - --- validate (epoch=124)-----------
2023-04-26 23:06:12,205 - 4952 samples (32 per mini-batch)
2023-04-26 23:06:18,925 - Epoch: [124][   50/  155]    Loss 3.200543    mAP 0.433967    
2023-04-26 23:06:25,339 - Epoch: [124][  100/  155]    Loss 3.211464    mAP 0.438403    
2023-04-26 23:06:31,691 - Epoch: [124][  150/  155]    Loss 3.193217    mAP 0.438088    
2023-04-26 23:06:32,257 - Epoch: [124][  155/  155]    Loss 3.191534    mAP 0.435759    
2023-04-26 23:06:32,329 - ==> mAP: 0.43576    Loss: 3.192

2023-04-26 23:06:32,333 - ==> Best [mAP: 0.444792   vloss: 3.177059   Sparsity:0.00   Params: 2177088 on epoch: 120]
2023-04-26 23:06:32,333 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:06:32,371 - 

2023-04-26 23:06:32,371 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:06:43,400 - Epoch: [125][   50/  518]    Overall Loss 2.947678    Objective Loss 2.947678                                        LR 0.000125    Time 0.220528    
2023-04-26 23:06:53,497 - Epoch: [125][  100/  518]    Overall Loss 2.890054    Objective Loss 2.890054                                        LR 0.000125    Time 0.211220    
2023-04-26 23:07:03,687 - Epoch: [125][  150/  518]    Overall Loss 2.907004    Objective Loss 2.907004                                        LR 0.000125    Time 0.208733    
2023-04-26 23:07:13,971 - Epoch: [125][  200/  518]    Overall Loss 2.914566    Objective Loss 2.914566                                        LR 0.000125    Time 0.207959    
2023-04-26 23:07:24,205 - Epoch: [125][  250/  518]    Overall Loss 2.907095    Objective Loss 2.907095                                        LR 0.000125    Time 0.207296    
2023-04-26 23:07:34,359 - Epoch: [125][  300/  518]    Overall Loss 2.906013    Objective Loss 2.906013                                        LR 0.000125    Time 0.206588    
2023-04-26 23:07:44,557 - Epoch: [125][  350/  518]    Overall Loss 2.904027    Objective Loss 2.904027                                        LR 0.000125    Time 0.206210    
2023-04-26 23:07:54,742 - Epoch: [125][  400/  518]    Overall Loss 2.904905    Objective Loss 2.904905                                        LR 0.000125    Time 0.205891    
2023-04-26 23:08:04,861 - Epoch: [125][  450/  518]    Overall Loss 2.909675    Objective Loss 2.909675                                        LR 0.000125    Time 0.205498    
2023-04-26 23:08:15,024 - Epoch: [125][  500/  518]    Overall Loss 2.907513    Objective Loss 2.907513                                        LR 0.000125    Time 0.205271    
2023-04-26 23:08:18,516 - Epoch: [125][  518/  518]    Overall Loss 2.907920    Objective Loss 2.907920                                        LR 0.000125    Time 0.204877    
2023-04-26 23:08:18,587 - --- validate (epoch=125)-----------
2023-04-26 23:08:18,587 - 4952 samples (32 per mini-batch)
2023-04-26 23:08:25,299 - Epoch: [125][   50/  155]    Loss 3.149050    mAP 0.450414    
2023-04-26 23:08:31,677 - Epoch: [125][  100/  155]    Loss 3.160620    mAP 0.446773    
2023-04-26 23:08:37,967 - Epoch: [125][  150/  155]    Loss 3.187466    mAP 0.445971    
2023-04-26 23:08:38,534 - Epoch: [125][  155/  155]    Loss 3.188677    mAP 0.446227    
2023-04-26 23:08:38,599 - ==> mAP: 0.44623    Loss: 3.189

2023-04-26 23:08:38,602 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:08:38,603 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:08:38,655 - 

2023-04-26 23:08:38,656 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:08:49,768 - Epoch: [126][   50/  518]    Overall Loss 2.917473    Objective Loss 2.917473                                        LR 0.000125    Time 0.222198    
2023-04-26 23:08:59,988 - Epoch: [126][  100/  518]    Overall Loss 2.908843    Objective Loss 2.908843                                        LR 0.000125    Time 0.213279    
2023-04-26 23:09:10,158 - Epoch: [126][  150/  518]    Overall Loss 2.913200    Objective Loss 2.913200                                        LR 0.000125    Time 0.209976    
2023-04-26 23:09:20,356 - Epoch: [126][  200/  518]    Overall Loss 2.905576    Objective Loss 2.905576                                        LR 0.000125    Time 0.208465    
2023-04-26 23:09:30,468 - Epoch: [126][  250/  518]    Overall Loss 2.901701    Objective Loss 2.901701                                        LR 0.000125    Time 0.207212    
2023-04-26 23:09:40,732 - Epoch: [126][  300/  518]    Overall Loss 2.898020    Objective Loss 2.898020                                        LR 0.000125    Time 0.206884    
2023-04-26 23:09:50,941 - Epoch: [126][  350/  518]    Overall Loss 2.910145    Objective Loss 2.910145                                        LR 0.000125    Time 0.206494    
2023-04-26 23:10:01,062 - Epoch: [126][  400/  518]    Overall Loss 2.903188    Objective Loss 2.903188                                        LR 0.000125    Time 0.205981    
2023-04-26 23:10:11,196 - Epoch: [126][  450/  518]    Overall Loss 2.908347    Objective Loss 2.908347                                        LR 0.000125    Time 0.205610    
2023-04-26 23:10:21,374 - Epoch: [126][  500/  518]    Overall Loss 2.905211    Objective Loss 2.905211                                        LR 0.000125    Time 0.205400    
2023-04-26 23:10:24,904 - Epoch: [126][  518/  518]    Overall Loss 2.906404    Objective Loss 2.906404                                        LR 0.000125    Time 0.205077    
2023-04-26 23:10:24,975 - --- validate (epoch=126)-----------
2023-04-26 23:10:24,976 - 4952 samples (32 per mini-batch)
2023-04-26 23:10:31,692 - Epoch: [126][   50/  155]    Loss 3.192915    mAP 0.442077    
2023-04-26 23:10:38,072 - Epoch: [126][  100/  155]    Loss 3.174701    mAP 0.446622    
2023-04-26 23:10:44,431 - Epoch: [126][  150/  155]    Loss 3.187233    mAP 0.440059    
2023-04-26 23:10:45,014 - Epoch: [126][  155/  155]    Loss 3.188544    mAP 0.439979    
2023-04-26 23:10:45,100 - ==> mAP: 0.43998    Loss: 3.189

2023-04-26 23:10:45,103 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:10:45,103 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:10:45,141 - 

2023-04-26 23:10:45,141 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:10:55,944 - Epoch: [127][   50/  518]    Overall Loss 2.882536    Objective Loss 2.882536                                        LR 0.000125    Time 0.216003    
2023-04-26 23:11:06,114 - Epoch: [127][  100/  518]    Overall Loss 2.889875    Objective Loss 2.889875                                        LR 0.000125    Time 0.209684    
2023-04-26 23:11:16,267 - Epoch: [127][  150/  518]    Overall Loss 2.869519    Objective Loss 2.869519                                        LR 0.000125    Time 0.207467    
2023-04-26 23:11:26,421 - Epoch: [127][  200/  518]    Overall Loss 2.875803    Objective Loss 2.875803                                        LR 0.000125    Time 0.206361    
2023-04-26 23:11:36,461 - Epoch: [127][  250/  518]    Overall Loss 2.886981    Objective Loss 2.886981                                        LR 0.000125    Time 0.205242    
2023-04-26 23:11:46,607 - Epoch: [127][  300/  518]    Overall Loss 2.891038    Objective Loss 2.891038                                        LR 0.000125    Time 0.204850    
2023-04-26 23:11:56,779 - Epoch: [127][  350/  518]    Overall Loss 2.887155    Objective Loss 2.887155                                        LR 0.000125    Time 0.204645    
2023-04-26 23:12:06,895 - Epoch: [127][  400/  518]    Overall Loss 2.894924    Objective Loss 2.894924                                        LR 0.000125    Time 0.204349    
2023-04-26 23:12:16,969 - Epoch: [127][  450/  518]    Overall Loss 2.894949    Objective Loss 2.894949                                        LR 0.000125    Time 0.204026    
2023-04-26 23:12:27,100 - Epoch: [127][  500/  518]    Overall Loss 2.891978    Objective Loss 2.891978                                        LR 0.000125    Time 0.203883    
2023-04-26 23:12:30,601 - Epoch: [127][  518/  518]    Overall Loss 2.892776    Objective Loss 2.892776                                        LR 0.000125    Time 0.203557    
2023-04-26 23:12:30,675 - --- validate (epoch=127)-----------
2023-04-26 23:12:30,675 - 4952 samples (32 per mini-batch)
2023-04-26 23:12:37,387 - Epoch: [127][   50/  155]    Loss 3.223478    mAP 0.449058    
2023-04-26 23:12:43,743 - Epoch: [127][  100/  155]    Loss 3.191005    mAP 0.439838    
2023-04-26 23:12:50,111 - Epoch: [127][  150/  155]    Loss 3.187441    mAP 0.443035    
2023-04-26 23:12:50,680 - Epoch: [127][  155/  155]    Loss 3.190509    mAP 0.441940    
2023-04-26 23:12:50,739 - ==> mAP: 0.44194    Loss: 3.191

2023-04-26 23:12:50,743 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:12:50,743 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:12:50,780 - 

2023-04-26 23:12:50,780 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:13:01,669 - Epoch: [128][   50/  518]    Overall Loss 2.948812    Objective Loss 2.948812                                        LR 0.000125    Time 0.217722    
2023-04-26 23:13:11,781 - Epoch: [128][  100/  518]    Overall Loss 2.932231    Objective Loss 2.932231                                        LR 0.000125    Time 0.209961    
2023-04-26 23:13:21,974 - Epoch: [128][  150/  518]    Overall Loss 2.931930    Objective Loss 2.931930                                        LR 0.000125    Time 0.207917    
2023-04-26 23:13:32,098 - Epoch: [128][  200/  518]    Overall Loss 2.929752    Objective Loss 2.929752                                        LR 0.000125    Time 0.206548    
2023-04-26 23:13:42,224 - Epoch: [128][  250/  518]    Overall Loss 2.927081    Objective Loss 2.927081                                        LR 0.000125    Time 0.205736    
2023-04-26 23:13:52,358 - Epoch: [128][  300/  518]    Overall Loss 2.910337    Objective Loss 2.910337                                        LR 0.000125    Time 0.205221    
2023-04-26 23:14:02,519 - Epoch: [128][  350/  518]    Overall Loss 2.904491    Objective Loss 2.904491                                        LR 0.000125    Time 0.204933    
2023-04-26 23:14:12,653 - Epoch: [128][  400/  518]    Overall Loss 2.900435    Objective Loss 2.900435                                        LR 0.000125    Time 0.204645    
2023-04-26 23:14:22,807 - Epoch: [128][  450/  518]    Overall Loss 2.901876    Objective Loss 2.901876                                        LR 0.000125    Time 0.204467    
2023-04-26 23:14:32,904 - Epoch: [128][  500/  518]    Overall Loss 2.904005    Objective Loss 2.904005                                        LR 0.000125    Time 0.204213    
2023-04-26 23:14:36,490 - Epoch: [128][  518/  518]    Overall Loss 2.905557    Objective Loss 2.905557                                        LR 0.000125    Time 0.204038    
2023-04-26 23:14:36,559 - --- validate (epoch=128)-----------
2023-04-26 23:14:36,560 - 4952 samples (32 per mini-batch)
2023-04-26 23:14:43,228 - Epoch: [128][   50/  155]    Loss 3.161318    mAP 0.440770    
2023-04-26 23:14:49,576 - Epoch: [128][  100/  155]    Loss 3.189616    mAP 0.439280    
2023-04-26 23:14:55,951 - Epoch: [128][  150/  155]    Loss 3.177463    mAP 0.441827    
2023-04-26 23:14:56,518 - Epoch: [128][  155/  155]    Loss 3.181931    mAP 0.439098    
2023-04-26 23:14:56,589 - ==> mAP: 0.43910    Loss: 3.182

2023-04-26 23:14:56,593 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:14:56,593 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:14:56,630 - 

2023-04-26 23:14:56,630 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:15:07,510 - Epoch: [129][   50/  518]    Overall Loss 2.874962    Objective Loss 2.874962                                        LR 0.000125    Time 0.217541    
2023-04-26 23:15:17,646 - Epoch: [129][  100/  518]    Overall Loss 2.880596    Objective Loss 2.880596                                        LR 0.000125    Time 0.210108    
2023-04-26 23:15:27,827 - Epoch: [129][  150/  518]    Overall Loss 2.889922    Objective Loss 2.889922                                        LR 0.000125    Time 0.207939    
2023-04-26 23:15:37,988 - Epoch: [129][  200/  518]    Overall Loss 2.892614    Objective Loss 2.892614                                        LR 0.000125    Time 0.206750    
2023-04-26 23:15:48,169 - Epoch: [129][  250/  518]    Overall Loss 2.900635    Objective Loss 2.900635                                        LR 0.000125    Time 0.206116    
2023-04-26 23:15:58,239 - Epoch: [129][  300/  518]    Overall Loss 2.908663    Objective Loss 2.908663                                        LR 0.000125    Time 0.205326    
2023-04-26 23:16:08,424 - Epoch: [129][  350/  518]    Overall Loss 2.909969    Objective Loss 2.909969                                        LR 0.000125    Time 0.205090    
2023-04-26 23:16:18,595 - Epoch: [129][  400/  518]    Overall Loss 2.912397    Objective Loss 2.912397                                        LR 0.000125    Time 0.204877    
2023-04-26 23:16:28,785 - Epoch: [129][  450/  518]    Overall Loss 2.908418    Objective Loss 2.908418                                        LR 0.000125    Time 0.204753    
2023-04-26 23:16:38,958 - Epoch: [129][  500/  518]    Overall Loss 2.909119    Objective Loss 2.909119                                        LR 0.000125    Time 0.204620    
2023-04-26 23:16:42,454 - Epoch: [129][  518/  518]    Overall Loss 2.904011    Objective Loss 2.904011                                        LR 0.000125    Time 0.204257    
2023-04-26 23:16:42,525 - --- validate (epoch=129)-----------
2023-04-26 23:16:42,525 - 4952 samples (32 per mini-batch)
2023-04-26 23:16:49,231 - Epoch: [129][   50/  155]    Loss 3.139637    mAP 0.436292    
2023-04-26 23:16:55,670 - Epoch: [129][  100/  155]    Loss 3.193122    mAP 0.438963    
2023-04-26 23:17:01,993 - Epoch: [129][  150/  155]    Loss 3.187237    mAP 0.440782    
2023-04-26 23:17:02,553 - Epoch: [129][  155/  155]    Loss 3.186359    mAP 0.438577    
2023-04-26 23:17:02,628 - ==> mAP: 0.43858    Loss: 3.186

2023-04-26 23:17:02,632 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:17:02,632 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:17:02,670 - 

2023-04-26 23:17:02,671 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:17:13,703 - Epoch: [130][   50/  518]    Overall Loss 2.861448    Objective Loss 2.861448                                        LR 0.000125    Time 0.220602    
2023-04-26 23:17:23,892 - Epoch: [130][  100/  518]    Overall Loss 2.875857    Objective Loss 2.875857                                        LR 0.000125    Time 0.212168    
2023-04-26 23:17:33,946 - Epoch: [130][  150/  518]    Overall Loss 2.882995    Objective Loss 2.882995                                        LR 0.000125    Time 0.208464    
2023-04-26 23:17:44,079 - Epoch: [130][  200/  518]    Overall Loss 2.881760    Objective Loss 2.881760                                        LR 0.000125    Time 0.207001    
2023-04-26 23:17:54,231 - Epoch: [130][  250/  518]    Overall Loss 2.881900    Objective Loss 2.881900                                        LR 0.000125    Time 0.206203    
2023-04-26 23:18:04,381 - Epoch: [130][  300/  518]    Overall Loss 2.883692    Objective Loss 2.883692                                        LR 0.000125    Time 0.205664    
2023-04-26 23:18:14,524 - Epoch: [130][  350/  518]    Overall Loss 2.894724    Objective Loss 2.894724                                        LR 0.000125    Time 0.205260    
2023-04-26 23:18:24,808 - Epoch: [130][  400/  518]    Overall Loss 2.886840    Objective Loss 2.886840                                        LR 0.000125    Time 0.205309    
2023-04-26 23:18:34,946 - Epoch: [130][  450/  518]    Overall Loss 2.895490    Objective Loss 2.895490                                        LR 0.000125    Time 0.205021    
2023-04-26 23:18:45,125 - Epoch: [130][  500/  518]    Overall Loss 2.891382    Objective Loss 2.891382                                        LR 0.000125    Time 0.204873    
2023-04-26 23:18:48,636 - Epoch: [130][  518/  518]    Overall Loss 2.894802    Objective Loss 2.894802                                        LR 0.000125    Time 0.204532    
2023-04-26 23:18:48,707 - --- validate (epoch=130)-----------
2023-04-26 23:18:48,708 - 4952 samples (32 per mini-batch)
2023-04-26 23:18:55,374 - Epoch: [130][   50/  155]    Loss 3.220281    mAP 0.435835    
2023-04-26 23:19:01,733 - Epoch: [130][  100/  155]    Loss 3.187851    mAP 0.445150    
2023-04-26 23:19:07,997 - Epoch: [130][  150/  155]    Loss 3.181334    mAP 0.443139    
2023-04-26 23:19:08,562 - Epoch: [130][  155/  155]    Loss 3.178568    mAP 0.444932    
2023-04-26 23:19:08,624 - ==> mAP: 0.44493    Loss: 3.179

2023-04-26 23:19:08,628 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:19:08,628 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:19:08,665 - 

2023-04-26 23:19:08,665 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:19:19,674 - Epoch: [131][   50/  518]    Overall Loss 2.966268    Objective Loss 2.966268                                        LR 0.000125    Time 0.220107    
2023-04-26 23:19:29,686 - Epoch: [131][  100/  518]    Overall Loss 2.902331    Objective Loss 2.902331                                        LR 0.000125    Time 0.210158    
2023-04-26 23:19:39,831 - Epoch: [131][  150/  518]    Overall Loss 2.894120    Objective Loss 2.894120                                        LR 0.000125    Time 0.207729    
2023-04-26 23:19:50,010 - Epoch: [131][  200/  518]    Overall Loss 2.903982    Objective Loss 2.903982                                        LR 0.000125    Time 0.206684    
2023-04-26 23:20:00,088 - Epoch: [131][  250/  518]    Overall Loss 2.896000    Objective Loss 2.896000                                        LR 0.000125    Time 0.205651    
2023-04-26 23:20:10,241 - Epoch: [131][  300/  518]    Overall Loss 2.897446    Objective Loss 2.897446                                        LR 0.000125    Time 0.205215    
2023-04-26 23:20:20,434 - Epoch: [131][  350/  518]    Overall Loss 2.898201    Objective Loss 2.898201                                        LR 0.000125    Time 0.205017    
2023-04-26 23:20:30,627 - Epoch: [131][  400/  518]    Overall Loss 2.895005    Objective Loss 2.895005                                        LR 0.000125    Time 0.204869    
2023-04-26 23:20:40,813 - Epoch: [131][  450/  518]    Overall Loss 2.892279    Objective Loss 2.892279                                        LR 0.000125    Time 0.204737    
2023-04-26 23:20:50,923 - Epoch: [131][  500/  518]    Overall Loss 2.902919    Objective Loss 2.902919                                        LR 0.000125    Time 0.204479    
2023-04-26 23:20:54,461 - Epoch: [131][  518/  518]    Overall Loss 2.904172    Objective Loss 2.904172                                        LR 0.000125    Time 0.204203    
2023-04-26 23:20:54,533 - --- validate (epoch=131)-----------
2023-04-26 23:20:54,533 - 4952 samples (32 per mini-batch)
2023-04-26 23:21:01,260 - Epoch: [131][   50/  155]    Loss 3.180971    mAP 0.437716    
2023-04-26 23:21:07,571 - Epoch: [131][  100/  155]    Loss 3.194589    mAP 0.432402    
2023-04-26 23:21:13,913 - Epoch: [131][  150/  155]    Loss 3.193535    mAP 0.433209    
2023-04-26 23:21:14,484 - Epoch: [131][  155/  155]    Loss 3.191293    mAP 0.433944    
2023-04-26 23:21:14,557 - ==> mAP: 0.43394    Loss: 3.191

2023-04-26 23:21:14,561 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:21:14,561 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:21:14,599 - 

2023-04-26 23:21:14,599 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:21:25,589 - Epoch: [132][   50/  518]    Overall Loss 2.922586    Objective Loss 2.922586                                        LR 0.000125    Time 0.219749    
2023-04-26 23:21:35,820 - Epoch: [132][  100/  518]    Overall Loss 2.925658    Objective Loss 2.925658                                        LR 0.000125    Time 0.212164    
2023-04-26 23:21:45,976 - Epoch: [132][  150/  518]    Overall Loss 2.909697    Objective Loss 2.909697                                        LR 0.000125    Time 0.209142    
2023-04-26 23:21:56,121 - Epoch: [132][  200/  518]    Overall Loss 2.909289    Objective Loss 2.909289                                        LR 0.000125    Time 0.207572    
2023-04-26 23:22:06,300 - Epoch: [132][  250/  518]    Overall Loss 2.905048    Objective Loss 2.905048                                        LR 0.000125    Time 0.206768    
2023-04-26 23:22:16,470 - Epoch: [132][  300/  518]    Overall Loss 2.897088    Objective Loss 2.897088                                        LR 0.000125    Time 0.206199    
2023-04-26 23:22:26,705 - Epoch: [132][  350/  518]    Overall Loss 2.894005    Objective Loss 2.894005                                        LR 0.000125    Time 0.205980    
2023-04-26 23:22:36,826 - Epoch: [132][  400/  518]    Overall Loss 2.893536    Objective Loss 2.893536                                        LR 0.000125    Time 0.205532    
2023-04-26 23:22:46,968 - Epoch: [132][  450/  518]    Overall Loss 2.898477    Objective Loss 2.898477                                        LR 0.000125    Time 0.205229    
2023-04-26 23:22:57,102 - Epoch: [132][  500/  518]    Overall Loss 2.896883    Objective Loss 2.896883                                        LR 0.000125    Time 0.204971    
2023-04-26 23:23:00,697 - Epoch: [132][  518/  518]    Overall Loss 2.899410    Objective Loss 2.899410                                        LR 0.000125    Time 0.204788    
2023-04-26 23:23:00,772 - --- validate (epoch=132)-----------
2023-04-26 23:23:00,773 - 4952 samples (32 per mini-batch)
2023-04-26 23:23:07,472 - Epoch: [132][   50/  155]    Loss 3.159480    mAP 0.441577    
2023-04-26 23:23:13,844 - Epoch: [132][  100/  155]    Loss 3.142394    mAP 0.441092    
2023-04-26 23:23:20,178 - Epoch: [132][  150/  155]    Loss 3.171609    mAP 0.440602    
2023-04-26 23:23:20,738 - Epoch: [132][  155/  155]    Loss 3.179739    mAP 0.438030    
2023-04-26 23:23:20,804 - ==> mAP: 0.43803    Loss: 3.180

2023-04-26 23:23:20,808 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:23:20,808 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:23:20,845 - 

2023-04-26 23:23:20,845 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:23:31,640 - Epoch: [133][   50/  518]    Overall Loss 2.850403    Objective Loss 2.850403                                        LR 0.000125    Time 0.215834    
2023-04-26 23:23:41,797 - Epoch: [133][  100/  518]    Overall Loss 2.882865    Objective Loss 2.882865                                        LR 0.000125    Time 0.209473    
2023-04-26 23:23:51,923 - Epoch: [133][  150/  518]    Overall Loss 2.901139    Objective Loss 2.901139                                        LR 0.000125    Time 0.207146    
2023-04-26 23:24:02,024 - Epoch: [133][  200/  518]    Overall Loss 2.891388    Objective Loss 2.891388                                        LR 0.000125    Time 0.205853    
2023-04-26 23:24:12,149 - Epoch: [133][  250/  518]    Overall Loss 2.884736    Objective Loss 2.884736                                        LR 0.000125    Time 0.205180    
2023-04-26 23:24:22,304 - Epoch: [133][  300/  518]    Overall Loss 2.877716    Objective Loss 2.877716                                        LR 0.000125    Time 0.204827    
2023-04-26 23:24:32,391 - Epoch: [133][  350/  518]    Overall Loss 2.884575    Objective Loss 2.884575                                        LR 0.000125    Time 0.204381    
2023-04-26 23:24:42,526 - Epoch: [133][  400/  518]    Overall Loss 2.884642    Objective Loss 2.884642                                        LR 0.000125    Time 0.204165    
2023-04-26 23:24:52,621 - Epoch: [133][  450/  518]    Overall Loss 2.883995    Objective Loss 2.883995                                        LR 0.000125    Time 0.203911    
2023-04-26 23:25:02,744 - Epoch: [133][  500/  518]    Overall Loss 2.887995    Objective Loss 2.887995                                        LR 0.000125    Time 0.203763    
2023-04-26 23:25:06,278 - Epoch: [133][  518/  518]    Overall Loss 2.887635    Objective Loss 2.887635                                        LR 0.000125    Time 0.203504    
2023-04-26 23:25:06,350 - --- validate (epoch=133)-----------
2023-04-26 23:25:06,350 - 4952 samples (32 per mini-batch)
2023-04-26 23:25:13,106 - Epoch: [133][   50/  155]    Loss 3.193475    mAP 0.438755    
2023-04-26 23:25:19,511 - Epoch: [133][  100/  155]    Loss 3.192928    mAP 0.442787    
2023-04-26 23:25:25,882 - Epoch: [133][  150/  155]    Loss 3.171250    mAP 0.442434    
2023-04-26 23:25:26,456 - Epoch: [133][  155/  155]    Loss 3.172496    mAP 0.442463    
2023-04-26 23:25:26,527 - ==> mAP: 0.44246    Loss: 3.172

2023-04-26 23:25:26,599 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:25:26,599 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:25:26,657 - 

2023-04-26 23:25:26,657 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:25:37,464 - Epoch: [134][   50/  518]    Overall Loss 2.904332    Objective Loss 2.904332                                        LR 0.000125    Time 0.216064    
2023-04-26 23:25:47,680 - Epoch: [134][  100/  518]    Overall Loss 2.901034    Objective Loss 2.901034                                        LR 0.000125    Time 0.210177    
2023-04-26 23:25:57,769 - Epoch: [134][  150/  518]    Overall Loss 2.919642    Objective Loss 2.919642                                        LR 0.000125    Time 0.207365    
2023-04-26 23:26:07,915 - Epoch: [134][  200/  518]    Overall Loss 2.910755    Objective Loss 2.910755                                        LR 0.000125    Time 0.206244    
2023-04-26 23:26:18,077 - Epoch: [134][  250/  518]    Overall Loss 2.902385    Objective Loss 2.902385                                        LR 0.000125    Time 0.205638    
2023-04-26 23:26:28,274 - Epoch: [134][  300/  518]    Overall Loss 2.903022    Objective Loss 2.903022                                        LR 0.000125    Time 0.205351    
2023-04-26 23:26:38,336 - Epoch: [134][  350/  518]    Overall Loss 2.908430    Objective Loss 2.908430                                        LR 0.000125    Time 0.204758    
2023-04-26 23:26:48,452 - Epoch: [134][  400/  518]    Overall Loss 2.908565    Objective Loss 2.908565                                        LR 0.000125    Time 0.204450    
2023-04-26 23:26:58,584 - Epoch: [134][  450/  518]    Overall Loss 2.905697    Objective Loss 2.905697                                        LR 0.000125    Time 0.204244    
2023-04-26 23:27:08,832 - Epoch: [134][  500/  518]    Overall Loss 2.900057    Objective Loss 2.900057                                        LR 0.000125    Time 0.204312    
2023-04-26 23:27:12,367 - Epoch: [134][  518/  518]    Overall Loss 2.903662    Objective Loss 2.903662                                        LR 0.000125    Time 0.204036    
2023-04-26 23:27:12,437 - --- validate (epoch=134)-----------
2023-04-26 23:27:12,438 - 4952 samples (32 per mini-batch)
2023-04-26 23:27:19,159 - Epoch: [134][   50/  155]    Loss 3.188677    mAP 0.425764    
2023-04-26 23:27:25,501 - Epoch: [134][  100/  155]    Loss 3.183038    mAP 0.431069    
2023-04-26 23:27:31,870 - Epoch: [134][  150/  155]    Loss 3.187964    mAP 0.432074    
2023-04-26 23:27:32,449 - Epoch: [134][  155/  155]    Loss 3.185733    mAP 0.433301    
2023-04-26 23:27:32,513 - ==> mAP: 0.43330    Loss: 3.186

2023-04-26 23:27:32,517 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:27:32,517 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:27:32,555 - 

2023-04-26 23:27:32,555 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:27:43,606 - Epoch: [135][   50/  518]    Overall Loss 2.876271    Objective Loss 2.876271                                        LR 0.000125    Time 0.220971    
2023-04-26 23:27:53,812 - Epoch: [135][  100/  518]    Overall Loss 2.846703    Objective Loss 2.846703                                        LR 0.000125    Time 0.212522    
2023-04-26 23:28:04,004 - Epoch: [135][  150/  518]    Overall Loss 2.854338    Objective Loss 2.854338                                        LR 0.000125    Time 0.209619    
2023-04-26 23:28:14,129 - Epoch: [135][  200/  518]    Overall Loss 2.860962    Objective Loss 2.860962                                        LR 0.000125    Time 0.207830    
2023-04-26 23:28:24,308 - Epoch: [135][  250/  518]    Overall Loss 2.860566    Objective Loss 2.860566                                        LR 0.000125    Time 0.206974    
2023-04-26 23:28:34,388 - Epoch: [135][  300/  518]    Overall Loss 2.867928    Objective Loss 2.867928                                        LR 0.000125    Time 0.206075    
2023-04-26 23:28:44,518 - Epoch: [135][  350/  518]    Overall Loss 2.876480    Objective Loss 2.876480                                        LR 0.000125    Time 0.205573    
2023-04-26 23:28:54,635 - Epoch: [135][  400/  518]    Overall Loss 2.878730    Objective Loss 2.878730                                        LR 0.000125    Time 0.205164    
2023-04-26 23:29:04,821 - Epoch: [135][  450/  518]    Overall Loss 2.881674    Objective Loss 2.881674                                        LR 0.000125    Time 0.205001    
2023-04-26 23:29:14,984 - Epoch: [135][  500/  518]    Overall Loss 2.884367    Objective Loss 2.884367                                        LR 0.000125    Time 0.204822    
2023-04-26 23:29:18,480 - Epoch: [135][  518/  518]    Overall Loss 2.885386    Objective Loss 2.885386                                        LR 0.000125    Time 0.204454    
2023-04-26 23:29:18,552 - --- validate (epoch=135)-----------
2023-04-26 23:29:18,552 - 4952 samples (32 per mini-batch)
2023-04-26 23:29:25,313 - Epoch: [135][   50/  155]    Loss 3.178278    mAP 0.445913    
2023-04-26 23:29:31,669 - Epoch: [135][  100/  155]    Loss 3.183741    mAP 0.441370    
2023-04-26 23:29:38,048 - Epoch: [135][  150/  155]    Loss 3.189325    mAP 0.436737    
2023-04-26 23:29:38,618 - Epoch: [135][  155/  155]    Loss 3.187994    mAP 0.437677    
2023-04-26 23:29:38,685 - ==> mAP: 0.43768    Loss: 3.188

2023-04-26 23:29:38,689 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:29:38,689 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:29:38,727 - 

2023-04-26 23:29:38,727 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:29:49,662 - Epoch: [136][   50/  518]    Overall Loss 2.937126    Objective Loss 2.937126                                        LR 0.000125    Time 0.218634    
2023-04-26 23:30:00,036 - Epoch: [136][  100/  518]    Overall Loss 2.898272    Objective Loss 2.898272                                        LR 0.000125    Time 0.213041    
2023-04-26 23:30:10,137 - Epoch: [136][  150/  518]    Overall Loss 2.901033    Objective Loss 2.901033                                        LR 0.000125    Time 0.209356    
2023-04-26 23:30:20,298 - Epoch: [136][  200/  518]    Overall Loss 2.897521    Objective Loss 2.897521                                        LR 0.000125    Time 0.207815    
2023-04-26 23:30:30,511 - Epoch: [136][  250/  518]    Overall Loss 2.890426    Objective Loss 2.890426                                        LR 0.000125    Time 0.207097    
2023-04-26 23:30:40,601 - Epoch: [136][  300/  518]    Overall Loss 2.894054    Objective Loss 2.894054                                        LR 0.000125    Time 0.206209    
2023-04-26 23:30:50,806 - Epoch: [136][  350/  518]    Overall Loss 2.893476    Objective Loss 2.893476                                        LR 0.000125    Time 0.205904    
2023-04-26 23:31:00,922 - Epoch: [136][  400/  518]    Overall Loss 2.897902    Objective Loss 2.897902                                        LR 0.000125    Time 0.205450    
2023-04-26 23:31:11,139 - Epoch: [136][  450/  518]    Overall Loss 2.900246    Objective Loss 2.900246                                        LR 0.000125    Time 0.205323    
2023-04-26 23:31:21,278 - Epoch: [136][  500/  518]    Overall Loss 2.901921    Objective Loss 2.901921                                        LR 0.000125    Time 0.205067    
2023-04-26 23:31:24,797 - Epoch: [136][  518/  518]    Overall Loss 2.903626    Objective Loss 2.903626                                        LR 0.000125    Time 0.204732    
2023-04-26 23:31:24,867 - --- validate (epoch=136)-----------
2023-04-26 23:31:24,867 - 4952 samples (32 per mini-batch)
2023-04-26 23:31:31,591 - Epoch: [136][   50/  155]    Loss 3.200618    mAP 0.444785    
2023-04-26 23:31:38,002 - Epoch: [136][  100/  155]    Loss 3.182733    mAP 0.443873    
2023-04-26 23:31:44,356 - Epoch: [136][  150/  155]    Loss 3.182879    mAP 0.441096    
2023-04-26 23:31:44,934 - Epoch: [136][  155/  155]    Loss 3.180840    mAP 0.441017    
2023-04-26 23:31:44,997 - ==> mAP: 0.44102    Loss: 3.181

2023-04-26 23:31:45,002 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:31:45,002 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:31:45,039 - 

2023-04-26 23:31:45,039 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:31:55,888 - Epoch: [137][   50/  518]    Overall Loss 2.817964    Objective Loss 2.817964                                        LR 0.000125    Time 0.216922    
2023-04-26 23:32:06,127 - Epoch: [137][  100/  518]    Overall Loss 2.843213    Objective Loss 2.843213                                        LR 0.000125    Time 0.210832    
2023-04-26 23:32:16,413 - Epoch: [137][  150/  518]    Overall Loss 2.847887    Objective Loss 2.847887                                        LR 0.000125    Time 0.209115    
2023-04-26 23:32:26,582 - Epoch: [137][  200/  518]    Overall Loss 2.850504    Objective Loss 2.850504                                        LR 0.000125    Time 0.207675    
2023-04-26 23:32:36,633 - Epoch: [137][  250/  518]    Overall Loss 2.863676    Objective Loss 2.863676                                        LR 0.000125    Time 0.206338    
2023-04-26 23:32:46,764 - Epoch: [137][  300/  518]    Overall Loss 2.861106    Objective Loss 2.861106                                        LR 0.000125    Time 0.205713    
2023-04-26 23:32:56,947 - Epoch: [137][  350/  518]    Overall Loss 2.863598    Objective Loss 2.863598                                        LR 0.000125    Time 0.205415    
2023-04-26 23:33:07,108 - Epoch: [137][  400/  518]    Overall Loss 2.863338    Objective Loss 2.863338                                        LR 0.000125    Time 0.205136    
2023-04-26 23:33:17,257 - Epoch: [137][  450/  518]    Overall Loss 2.868683    Objective Loss 2.868683                                        LR 0.000125    Time 0.204893    
2023-04-26 23:33:27,382 - Epoch: [137][  500/  518]    Overall Loss 2.871645    Objective Loss 2.871645                                        LR 0.000125    Time 0.204651    
2023-04-26 23:33:30,888 - Epoch: [137][  518/  518]    Overall Loss 2.872958    Objective Loss 2.872958                                        LR 0.000125    Time 0.204305    
2023-04-26 23:33:30,960 - --- validate (epoch=137)-----------
2023-04-26 23:33:30,960 - 4952 samples (32 per mini-batch)
2023-04-26 23:33:37,618 - Epoch: [137][   50/  155]    Loss 3.209897    mAP 0.429714    
2023-04-26 23:33:43,996 - Epoch: [137][  100/  155]    Loss 3.201362    mAP 0.433744    
2023-04-26 23:33:50,321 - Epoch: [137][  150/  155]    Loss 3.181252    mAP 0.439718    
2023-04-26 23:33:50,865 - Epoch: [137][  155/  155]    Loss 3.177871    mAP 0.438239    
2023-04-26 23:33:50,929 - ==> mAP: 0.43824    Loss: 3.178

2023-04-26 23:33:50,933 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:33:50,933 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:33:50,969 - 

2023-04-26 23:33:50,970 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:34:01,775 - Epoch: [138][   50/  518]    Overall Loss 2.881354    Objective Loss 2.881354                                        LR 0.000125    Time 0.216054    
2023-04-26 23:34:11,877 - Epoch: [138][  100/  518]    Overall Loss 2.865926    Objective Loss 2.865926                                        LR 0.000125    Time 0.209033    
2023-04-26 23:34:22,008 - Epoch: [138][  150/  518]    Overall Loss 2.879884    Objective Loss 2.879884                                        LR 0.000125    Time 0.206880    
2023-04-26 23:34:32,172 - Epoch: [138][  200/  518]    Overall Loss 2.885522    Objective Loss 2.885522                                        LR 0.000125    Time 0.205975    
2023-04-26 23:34:42,455 - Epoch: [138][  250/  518]    Overall Loss 2.873540    Objective Loss 2.873540                                        LR 0.000125    Time 0.205903    
2023-04-26 23:34:52,585 - Epoch: [138][  300/  518]    Overall Loss 2.879638    Objective Loss 2.879638                                        LR 0.000125    Time 0.205349    
2023-04-26 23:35:02,737 - Epoch: [138][  350/  518]    Overall Loss 2.884532    Objective Loss 2.884532                                        LR 0.000125    Time 0.205012    
2023-04-26 23:35:12,914 - Epoch: [138][  400/  518]    Overall Loss 2.881629    Objective Loss 2.881629                                        LR 0.000125    Time 0.204825    
2023-04-26 23:35:23,047 - Epoch: [138][  450/  518]    Overall Loss 2.879006    Objective Loss 2.879006                                        LR 0.000125    Time 0.204580    
2023-04-26 23:35:33,217 - Epoch: [138][  500/  518]    Overall Loss 2.876914    Objective Loss 2.876914                                        LR 0.000125    Time 0.204460    
2023-04-26 23:35:36,769 - Epoch: [138][  518/  518]    Overall Loss 2.879732    Objective Loss 2.879732                                        LR 0.000125    Time 0.204210    
2023-04-26 23:35:36,840 - --- validate (epoch=138)-----------
2023-04-26 23:35:36,840 - 4952 samples (32 per mini-batch)
2023-04-26 23:35:43,526 - Epoch: [138][   50/  155]    Loss 3.136394    mAP 0.445216    
2023-04-26 23:35:49,863 - Epoch: [138][  100/  155]    Loss 3.187799    mAP 0.436535    
2023-04-26 23:35:56,121 - Epoch: [138][  150/  155]    Loss 3.177046    mAP 0.429041    
2023-04-26 23:35:56,685 - Epoch: [138][  155/  155]    Loss 3.179765    mAP 0.428293    
2023-04-26 23:35:56,756 - ==> mAP: 0.42829    Loss: 3.180

2023-04-26 23:35:56,760 - ==> Best [mAP: 0.446227   vloss: 3.188677   Sparsity:0.00   Params: 2177088 on epoch: 125]
2023-04-26 23:35:56,760 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:35:56,798 - 

2023-04-26 23:35:56,798 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:36:07,696 - Epoch: [139][   50/  518]    Overall Loss 2.841489    Objective Loss 2.841489                                        LR 0.000125    Time 0.217906    
2023-04-26 23:36:17,802 - Epoch: [139][  100/  518]    Overall Loss 2.888974    Objective Loss 2.888974                                        LR 0.000125    Time 0.209994    
2023-04-26 23:36:27,978 - Epoch: [139][  150/  518]    Overall Loss 2.879251    Objective Loss 2.879251                                        LR 0.000125    Time 0.207824    
2023-04-26 23:36:38,131 - Epoch: [139][  200/  518]    Overall Loss 2.890135    Objective Loss 2.890135                                        LR 0.000125    Time 0.206626    
2023-04-26 23:36:48,202 - Epoch: [139][  250/  518]    Overall Loss 2.876262    Objective Loss 2.876262                                        LR 0.000125    Time 0.205580    
2023-04-26 23:36:58,375 - Epoch: [139][  300/  518]    Overall Loss 2.883139    Objective Loss 2.883139                                        LR 0.000125    Time 0.205221    
2023-04-26 23:37:08,469 - Epoch: [139][  350/  518]    Overall Loss 2.878188    Objective Loss 2.878188                                        LR 0.000125    Time 0.204737    
2023-04-26 23:37:18,616 - Epoch: [139][  400/  518]    Overall Loss 2.883284    Objective Loss 2.883284                                        LR 0.000125    Time 0.204508    
2023-04-26 23:37:28,854 - Epoch: [139][  450/  518]    Overall Loss 2.881315    Objective Loss 2.881315                                        LR 0.000125    Time 0.204534    
2023-04-26 23:37:39,009 - Epoch: [139][  500/  518]    Overall Loss 2.887564    Objective Loss 2.887564                                        LR 0.000125    Time 0.204386    
2023-04-26 23:37:42,545 - Epoch: [139][  518/  518]    Overall Loss 2.888706    Objective Loss 2.888706                                        LR 0.000125    Time 0.204110    
2023-04-26 23:37:42,616 - --- validate (epoch=139)-----------
2023-04-26 23:37:42,616 - 4952 samples (32 per mini-batch)
2023-04-26 23:37:49,432 - Epoch: [139][   50/  155]    Loss 3.203988    mAP 0.450257    
2023-04-26 23:37:55,797 - Epoch: [139][  100/  155]    Loss 3.198155    mAP 0.451481    
2023-04-26 23:38:02,136 - Epoch: [139][  150/  155]    Loss 3.184437    mAP 0.449628    
2023-04-26 23:38:02,704 - Epoch: [139][  155/  155]    Loss 3.186491    mAP 0.448273    
2023-04-26 23:38:02,775 - ==> mAP: 0.44827    Loss: 3.186

2023-04-26 23:38:02,779 - ==> Best [mAP: 0.448273   vloss: 3.186491   Sparsity:0.00   Params: 2177088 on epoch: 139]
2023-04-26 23:38:02,779 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:38:02,832 - 

2023-04-26 23:38:02,832 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:38:13,751 - Epoch: [140][   50/  518]    Overall Loss 2.886107    Objective Loss 2.886107                                        LR 0.000125    Time 0.218318    
2023-04-26 23:38:23,925 - Epoch: [140][  100/  518]    Overall Loss 2.895902    Objective Loss 2.895902                                        LR 0.000125    Time 0.210891    
2023-04-26 23:38:34,077 - Epoch: [140][  150/  518]    Overall Loss 2.907755    Objective Loss 2.907755                                        LR 0.000125    Time 0.208259    
2023-04-26 23:38:44,216 - Epoch: [140][  200/  518]    Overall Loss 2.907743    Objective Loss 2.907743                                        LR 0.000125    Time 0.206881    
2023-04-26 23:38:54,378 - Epoch: [140][  250/  518]    Overall Loss 2.898124    Objective Loss 2.898124                                        LR 0.000125    Time 0.206145    
2023-04-26 23:39:04,524 - Epoch: [140][  300/  518]    Overall Loss 2.907145    Objective Loss 2.907145                                        LR 0.000125    Time 0.205603    
2023-04-26 23:39:14,672 - Epoch: [140][  350/  518]    Overall Loss 2.903951    Objective Loss 2.903951                                        LR 0.000125    Time 0.205220    
2023-04-26 23:39:24,870 - Epoch: [140][  400/  518]    Overall Loss 2.892586    Objective Loss 2.892586                                        LR 0.000125    Time 0.205060    
2023-04-26 23:39:34,976 - Epoch: [140][  450/  518]    Overall Loss 2.893525    Objective Loss 2.893525                                        LR 0.000125    Time 0.204728    
2023-04-26 23:39:45,162 - Epoch: [140][  500/  518]    Overall Loss 2.895128    Objective Loss 2.895128                                        LR 0.000125    Time 0.204624    
2023-04-26 23:39:48,686 - Epoch: [140][  518/  518]    Overall Loss 2.895633    Objective Loss 2.895633                                        LR 0.000125    Time 0.204317    
2023-04-26 23:39:48,759 - --- validate (epoch=140)-----------
2023-04-26 23:39:48,760 - 4952 samples (32 per mini-batch)
2023-04-26 23:39:55,571 - Epoch: [140][   50/  155]    Loss 3.174632    mAP 0.450027    
2023-04-26 23:40:01,959 - Epoch: [140][  100/  155]    Loss 3.174361    mAP 0.454595    
2023-04-26 23:40:08,363 - Epoch: [140][  150/  155]    Loss 3.181934    mAP 0.448097    
2023-04-26 23:40:08,936 - Epoch: [140][  155/  155]    Loss 3.181567    mAP 0.446846    
2023-04-26 23:40:09,006 - ==> mAP: 0.44685    Loss: 3.182

2023-04-26 23:40:09,009 - ==> Best [mAP: 0.448273   vloss: 3.186491   Sparsity:0.00   Params: 2177088 on epoch: 139]
2023-04-26 23:40:09,009 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:40:09,047 - 

2023-04-26 23:40:09,047 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:40:19,944 - Epoch: [141][   50/  518]    Overall Loss 2.905253    Objective Loss 2.905253                                        LR 0.000125    Time 0.217874    
2023-04-26 23:40:30,096 - Epoch: [141][  100/  518]    Overall Loss 2.907708    Objective Loss 2.907708                                        LR 0.000125    Time 0.210442    
2023-04-26 23:40:40,281 - Epoch: [141][  150/  518]    Overall Loss 2.890114    Objective Loss 2.890114                                        LR 0.000125    Time 0.208187    
2023-04-26 23:40:50,436 - Epoch: [141][  200/  518]    Overall Loss 2.898481    Objective Loss 2.898481                                        LR 0.000125    Time 0.206903    
2023-04-26 23:41:00,575 - Epoch: [141][  250/  518]    Overall Loss 2.887159    Objective Loss 2.887159                                        LR 0.000125    Time 0.206072    
2023-04-26 23:41:10,731 - Epoch: [141][  300/  518]    Overall Loss 2.885791    Objective Loss 2.885791                                        LR 0.000125    Time 0.205577    
2023-04-26 23:41:20,915 - Epoch: [141][  350/  518]    Overall Loss 2.885747    Objective Loss 2.885747                                        LR 0.000125    Time 0.205301    
2023-04-26 23:41:31,073 - Epoch: [141][  400/  518]    Overall Loss 2.883521    Objective Loss 2.883521                                        LR 0.000125    Time 0.205028    
2023-04-26 23:41:41,227 - Epoch: [141][  450/  518]    Overall Loss 2.884306    Objective Loss 2.884306                                        LR 0.000125    Time 0.204808    
2023-04-26 23:41:51,310 - Epoch: [141][  500/  518]    Overall Loss 2.883433    Objective Loss 2.883433                                        LR 0.000125    Time 0.204491    
2023-04-26 23:41:54,844 - Epoch: [141][  518/  518]    Overall Loss 2.885886    Objective Loss 2.885886                                        LR 0.000125    Time 0.204205    
2023-04-26 23:41:54,915 - --- validate (epoch=141)-----------
2023-04-26 23:41:54,915 - 4952 samples (32 per mini-batch)
2023-04-26 23:42:01,581 - Epoch: [141][   50/  155]    Loss 3.126947    mAP 0.434433    
2023-04-26 23:42:07,984 - Epoch: [141][  100/  155]    Loss 3.141725    mAP 0.448234    
2023-04-26 23:42:14,333 - Epoch: [141][  150/  155]    Loss 3.163740    mAP 0.444503    
2023-04-26 23:42:14,899 - Epoch: [141][  155/  155]    Loss 3.161330    mAP 0.446125    
2023-04-26 23:42:14,970 - ==> mAP: 0.44612    Loss: 3.161

2023-04-26 23:42:14,973 - ==> Best [mAP: 0.448273   vloss: 3.186491   Sparsity:0.00   Params: 2177088 on epoch: 139]
2023-04-26 23:42:14,973 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:42:15,011 - 

2023-04-26 23:42:15,011 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:42:25,931 - Epoch: [142][   50/  518]    Overall Loss 2.891305    Objective Loss 2.891305                                        LR 0.000125    Time 0.218349    
2023-04-26 23:42:36,081 - Epoch: [142][  100/  518]    Overall Loss 2.891355    Objective Loss 2.891355                                        LR 0.000125    Time 0.210652    
2023-04-26 23:42:46,199 - Epoch: [142][  150/  518]    Overall Loss 2.880251    Objective Loss 2.880251                                        LR 0.000125    Time 0.207880    
2023-04-26 23:42:56,343 - Epoch: [142][  200/  518]    Overall Loss 2.878873    Objective Loss 2.878873                                        LR 0.000125    Time 0.206621    
2023-04-26 23:43:06,528 - Epoch: [142][  250/  518]    Overall Loss 2.882732    Objective Loss 2.882732                                        LR 0.000125    Time 0.206032    
2023-04-26 23:43:16,641 - Epoch: [142][  300/  518]    Overall Loss 2.888642    Objective Loss 2.888642                                        LR 0.000125    Time 0.205397    
2023-04-26 23:43:26,774 - Epoch: [142][  350/  518]    Overall Loss 2.889424    Objective Loss 2.889424                                        LR 0.000125    Time 0.205002    
2023-04-26 23:43:36,919 - Epoch: [142][  400/  518]    Overall Loss 2.885389    Objective Loss 2.885389                                        LR 0.000125    Time 0.204734    
2023-04-26 23:43:47,031 - Epoch: [142][  450/  518]    Overall Loss 2.887114    Objective Loss 2.887114                                        LR 0.000125    Time 0.204454    
2023-04-26 23:43:57,221 - Epoch: [142][  500/  518]    Overall Loss 2.888162    Objective Loss 2.888162                                        LR 0.000125    Time 0.204386    
2023-04-26 23:44:00,803 - Epoch: [142][  518/  518]    Overall Loss 2.889634    Objective Loss 2.889634                                        LR 0.000125    Time 0.204198    
2023-04-26 23:44:00,875 - --- validate (epoch=142)-----------
2023-04-26 23:44:00,875 - 4952 samples (32 per mini-batch)
2023-04-26 23:44:07,597 - Epoch: [142][   50/  155]    Loss 3.206886    mAP 0.438774    
2023-04-26 23:44:13,932 - Epoch: [142][  100/  155]    Loss 3.178444    mAP 0.439797    
2023-04-26 23:44:20,258 - Epoch: [142][  150/  155]    Loss 3.175899    mAP 0.438917    
2023-04-26 23:44:20,826 - Epoch: [142][  155/  155]    Loss 3.175253    mAP 0.438402    
2023-04-26 23:44:20,899 - ==> mAP: 0.43840    Loss: 3.175

2023-04-26 23:44:20,903 - ==> Best [mAP: 0.448273   vloss: 3.186491   Sparsity:0.00   Params: 2177088 on epoch: 139]
2023-04-26 23:44:20,903 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:44:20,939 - 

2023-04-26 23:44:20,939 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:44:31,757 - Epoch: [143][   50/  518]    Overall Loss 2.863049    Objective Loss 2.863049                                        LR 0.000125    Time 0.216297    
2023-04-26 23:44:41,886 - Epoch: [143][  100/  518]    Overall Loss 2.872220    Objective Loss 2.872220                                        LR 0.000125    Time 0.209422    
2023-04-26 23:44:52,166 - Epoch: [143][  150/  518]    Overall Loss 2.874588    Objective Loss 2.874588                                        LR 0.000125    Time 0.208138    
2023-04-26 23:45:02,245 - Epoch: [143][  200/  518]    Overall Loss 2.888555    Objective Loss 2.888555                                        LR 0.000125    Time 0.206488    
2023-04-26 23:45:12,468 - Epoch: [143][  250/  518]    Overall Loss 2.904762    Objective Loss 2.904762                                        LR 0.000125    Time 0.206080    
2023-04-26 23:45:22,581 - Epoch: [143][  300/  518]    Overall Loss 2.900860    Objective Loss 2.900860                                        LR 0.000125    Time 0.205438    
2023-04-26 23:45:32,720 - Epoch: [143][  350/  518]    Overall Loss 2.894714    Objective Loss 2.894714                                        LR 0.000125    Time 0.205053    
2023-04-26 23:45:42,823 - Epoch: [143][  400/  518]    Overall Loss 2.895617    Objective Loss 2.895617                                        LR 0.000125    Time 0.204673    
2023-04-26 23:45:52,975 - Epoch: [143][  450/  518]    Overall Loss 2.893229    Objective Loss 2.893229                                        LR 0.000125    Time 0.204488    
2023-04-26 23:46:03,268 - Epoch: [143][  500/  518]    Overall Loss 2.892966    Objective Loss 2.892966                                        LR 0.000125    Time 0.204623    
2023-04-26 23:46:06,786 - Epoch: [143][  518/  518]    Overall Loss 2.889831    Objective Loss 2.889831                                        LR 0.000125    Time 0.204304    
2023-04-26 23:46:06,857 - --- validate (epoch=143)-----------
2023-04-26 23:46:06,857 - 4952 samples (32 per mini-batch)
2023-04-26 23:46:13,600 - Epoch: [143][   50/  155]    Loss 3.163149    mAP 0.444924    
2023-04-26 23:46:19,949 - Epoch: [143][  100/  155]    Loss 3.182330    mAP 0.434648    
2023-04-26 23:46:26,203 - Epoch: [143][  150/  155]    Loss 3.173671    mAP 0.437509    
2023-04-26 23:46:26,764 - Epoch: [143][  155/  155]    Loss 3.169328    mAP 0.438246    
2023-04-26 23:46:26,833 - ==> mAP: 0.43825    Loss: 3.169

2023-04-26 23:46:26,838 - ==> Best [mAP: 0.448273   vloss: 3.186491   Sparsity:0.00   Params: 2177088 on epoch: 139]
2023-04-26 23:46:26,838 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:46:26,875 - 

2023-04-26 23:46:26,875 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:46:37,816 - Epoch: [144][   50/  518]    Overall Loss 2.908705    Objective Loss 2.908705                                        LR 0.000125    Time 0.218754    
2023-04-26 23:46:47,989 - Epoch: [144][  100/  518]    Overall Loss 2.889222    Objective Loss 2.889222                                        LR 0.000125    Time 0.211089    
2023-04-26 23:46:58,082 - Epoch: [144][  150/  518]    Overall Loss 2.897286    Objective Loss 2.897286                                        LR 0.000125    Time 0.208001    
2023-04-26 23:47:08,232 - Epoch: [144][  200/  518]    Overall Loss 2.887360    Objective Loss 2.887360                                        LR 0.000125    Time 0.206747    
2023-04-26 23:47:18,302 - Epoch: [144][  250/  518]    Overall Loss 2.888758    Objective Loss 2.888758                                        LR 0.000125    Time 0.205671    
2023-04-26 23:47:28,505 - Epoch: [144][  300/  518]    Overall Loss 2.888178    Objective Loss 2.888178                                        LR 0.000125    Time 0.205397    
2023-04-26 23:47:38,680 - Epoch: [144][  350/  518]    Overall Loss 2.884738    Objective Loss 2.884738                                        LR 0.000125    Time 0.205119    
2023-04-26 23:47:48,831 - Epoch: [144][  400/  518]    Overall Loss 2.881456    Objective Loss 2.881456                                        LR 0.000125    Time 0.204853    
2023-04-26 23:47:58,976 - Epoch: [144][  450/  518]    Overall Loss 2.877843    Objective Loss 2.877843                                        LR 0.000125    Time 0.204632    
2023-04-26 23:48:09,111 - Epoch: [144][  500/  518]    Overall Loss 2.880208    Objective Loss 2.880208                                        LR 0.000125    Time 0.204436    
2023-04-26 23:48:12,640 - Epoch: [144][  518/  518]    Overall Loss 2.881438    Objective Loss 2.881438                                        LR 0.000125    Time 0.204144    
2023-04-26 23:48:12,710 - --- validate (epoch=144)-----------
2023-04-26 23:48:12,710 - 4952 samples (32 per mini-batch)
2023-04-26 23:48:19,326 - Epoch: [144][   50/  155]    Loss 3.167701    mAP 0.422944    
2023-04-26 23:48:25,666 - Epoch: [144][  100/  155]    Loss 3.168999    mAP 0.427461    
2023-04-26 23:48:32,040 - Epoch: [144][  150/  155]    Loss 3.172585    mAP 0.435169    
2023-04-26 23:48:32,625 - Epoch: [144][  155/  155]    Loss 3.170249    mAP 0.437575    
2023-04-26 23:48:32,692 - ==> mAP: 0.43757    Loss: 3.170

2023-04-26 23:48:32,697 - ==> Best [mAP: 0.448273   vloss: 3.186491   Sparsity:0.00   Params: 2177088 on epoch: 139]
2023-04-26 23:48:32,697 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:48:32,734 - 

2023-04-26 23:48:32,734 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:48:43,524 - Epoch: [145][   50/  518]    Overall Loss 2.896976    Objective Loss 2.896976                                        LR 0.000125    Time 0.215734    
2023-04-26 23:48:53,751 - Epoch: [145][  100/  518]    Overall Loss 2.890204    Objective Loss 2.890204                                        LR 0.000125    Time 0.210124    
2023-04-26 23:49:03,990 - Epoch: [145][  150/  518]    Overall Loss 2.883764    Objective Loss 2.883764                                        LR 0.000125    Time 0.208335    
2023-04-26 23:49:14,113 - Epoch: [145][  200/  518]    Overall Loss 2.882266    Objective Loss 2.882266                                        LR 0.000125    Time 0.206857    
2023-04-26 23:49:24,338 - Epoch: [145][  250/  518]    Overall Loss 2.889557    Objective Loss 2.889557                                        LR 0.000125    Time 0.206378    
2023-04-26 23:49:34,506 - Epoch: [145][  300/  518]    Overall Loss 2.888468    Objective Loss 2.888468                                        LR 0.000125    Time 0.205870    
2023-04-26 23:49:44,741 - Epoch: [145][  350/  518]    Overall Loss 2.891097    Objective Loss 2.891097                                        LR 0.000125    Time 0.205698    
2023-04-26 23:49:54,888 - Epoch: [145][  400/  518]    Overall Loss 2.895299    Objective Loss 2.895299                                        LR 0.000125    Time 0.205349    
2023-04-26 23:50:05,041 - Epoch: [145][  450/  518]    Overall Loss 2.899003    Objective Loss 2.899003                                        LR 0.000125    Time 0.205090    
2023-04-26 23:50:15,238 - Epoch: [145][  500/  518]    Overall Loss 2.897335    Objective Loss 2.897335                                        LR 0.000125    Time 0.204972    
2023-04-26 23:50:18,784 - Epoch: [145][  518/  518]    Overall Loss 2.897996    Objective Loss 2.897996                                        LR 0.000125    Time 0.204695    
2023-04-26 23:50:18,857 - --- validate (epoch=145)-----------
2023-04-26 23:50:18,857 - 4952 samples (32 per mini-batch)
2023-04-26 23:50:25,560 - Epoch: [145][   50/  155]    Loss 3.201118    mAP 0.440703    
2023-04-26 23:50:31,971 - Epoch: [145][  100/  155]    Loss 3.190007    mAP 0.437428    
2023-04-26 23:50:38,297 - Epoch: [145][  150/  155]    Loss 3.180871    mAP 0.436075    
2023-04-26 23:50:38,877 - Epoch: [145][  155/  155]    Loss 3.179963    mAP 0.437717    
2023-04-26 23:50:38,936 - ==> mAP: 0.43772    Loss: 3.180

2023-04-26 23:50:38,940 - ==> Best [mAP: 0.448273   vloss: 3.186491   Sparsity:0.00   Params: 2177088 on epoch: 139]
2023-04-26 23:50:38,940 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:50:38,978 - 

2023-04-26 23:50:38,978 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:50:49,940 - Epoch: [146][   50/  518]    Overall Loss 2.905931    Objective Loss 2.905931                                        LR 0.000125    Time 0.219179    
2023-04-26 23:51:00,086 - Epoch: [146][  100/  518]    Overall Loss 2.887328    Objective Loss 2.887328                                        LR 0.000125    Time 0.211037    
2023-04-26 23:51:10,222 - Epoch: [146][  150/  518]    Overall Loss 2.866246    Objective Loss 2.866246                                        LR 0.000125    Time 0.208253    
2023-04-26 23:51:20,488 - Epoch: [146][  200/  518]    Overall Loss 2.867901    Objective Loss 2.867901                                        LR 0.000125    Time 0.207512    
2023-04-26 23:51:30,574 - Epoch: [146][  250/  518]    Overall Loss 2.872727    Objective Loss 2.872727                                        LR 0.000125    Time 0.206348    
2023-04-26 23:51:40,752 - Epoch: [146][  300/  518]    Overall Loss 2.880870    Objective Loss 2.880870                                        LR 0.000125    Time 0.205877    
2023-04-26 23:51:50,893 - Epoch: [146][  350/  518]    Overall Loss 2.878139    Objective Loss 2.878139                                        LR 0.000125    Time 0.205436    
2023-04-26 23:52:01,070 - Epoch: [146][  400/  518]    Overall Loss 2.877339    Objective Loss 2.877339                                        LR 0.000125    Time 0.205194    
2023-04-26 23:52:11,260 - Epoch: [146][  450/  518]    Overall Loss 2.881913    Objective Loss 2.881913                                        LR 0.000125    Time 0.205035    
2023-04-26 23:52:21,406 - Epoch: [146][  500/  518]    Overall Loss 2.884553    Objective Loss 2.884553                                        LR 0.000125    Time 0.204821    
2023-04-26 23:52:24,946 - Epoch: [146][  518/  518]    Overall Loss 2.882600    Objective Loss 2.882600                                        LR 0.000125    Time 0.204536    
2023-04-26 23:52:25,017 - --- validate (epoch=146)-----------
2023-04-26 23:52:25,018 - 4952 samples (32 per mini-batch)
2023-04-26 23:52:31,777 - Epoch: [146][   50/  155]    Loss 3.176014    mAP 0.440752    
2023-04-26 23:52:38,183 - Epoch: [146][  100/  155]    Loss 3.170115    mAP 0.440259    
2023-04-26 23:52:44,583 - Epoch: [146][  150/  155]    Loss 3.163430    mAP 0.443460    
2023-04-26 23:52:45,159 - Epoch: [146][  155/  155]    Loss 3.166209    mAP 0.443818    
2023-04-26 23:52:45,225 - ==> mAP: 0.44382    Loss: 3.166

2023-04-26 23:52:45,229 - ==> Best [mAP: 0.448273   vloss: 3.186491   Sparsity:0.00   Params: 2177088 on epoch: 139]
2023-04-26 23:52:45,229 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:52:45,267 - 

2023-04-26 23:52:45,267 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:52:56,181 - Epoch: [147][   50/  518]    Overall Loss 2.864511    Objective Loss 2.864511                                        LR 0.000125    Time 0.218226    
2023-04-26 23:53:06,238 - Epoch: [147][  100/  518]    Overall Loss 2.867423    Objective Loss 2.867423                                        LR 0.000125    Time 0.209657    
2023-04-26 23:53:16,372 - Epoch: [147][  150/  518]    Overall Loss 2.869349    Objective Loss 2.869349                                        LR 0.000125    Time 0.207326    
2023-04-26 23:53:26,565 - Epoch: [147][  200/  518]    Overall Loss 2.879709    Objective Loss 2.879709                                        LR 0.000125    Time 0.206452    
2023-04-26 23:53:36,733 - Epoch: [147][  250/  518]    Overall Loss 2.885629    Objective Loss 2.885629                                        LR 0.000125    Time 0.205824    
2023-04-26 23:53:46,876 - Epoch: [147][  300/  518]    Overall Loss 2.877354    Objective Loss 2.877354                                        LR 0.000125    Time 0.205325    
2023-04-26 23:53:57,123 - Epoch: [147][  350/  518]    Overall Loss 2.877451    Objective Loss 2.877451                                        LR 0.000125    Time 0.205265    
2023-04-26 23:54:07,319 - Epoch: [147][  400/  518]    Overall Loss 2.881916    Objective Loss 2.881916                                        LR 0.000125    Time 0.205092    
2023-04-26 23:54:17,619 - Epoch: [147][  450/  518]    Overall Loss 2.883229    Objective Loss 2.883229                                        LR 0.000125    Time 0.205190    
2023-04-26 23:54:27,752 - Epoch: [147][  500/  518]    Overall Loss 2.882732    Objective Loss 2.882732                                        LR 0.000125    Time 0.204934    
2023-04-26 23:54:31,325 - Epoch: [147][  518/  518]    Overall Loss 2.884835    Objective Loss 2.884835                                        LR 0.000125    Time 0.204709    
2023-04-26 23:54:31,398 - --- validate (epoch=147)-----------
2023-04-26 23:54:31,398 - 4952 samples (32 per mini-batch)
2023-04-26 23:54:38,144 - Epoch: [147][   50/  155]    Loss 3.207219    mAP 0.459640    
2023-04-26 23:54:44,557 - Epoch: [147][  100/  155]    Loss 3.189772    mAP 0.451736    
2023-04-26 23:54:50,919 - Epoch: [147][  150/  155]    Loss 3.171729    mAP 0.451290    
2023-04-26 23:54:51,505 - Epoch: [147][  155/  155]    Loss 3.166752    mAP 0.452634    
2023-04-26 23:54:51,572 - ==> mAP: 0.45263    Loss: 3.167

2023-04-26 23:54:51,575 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-26 23:54:51,575 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:54:51,625 - 

2023-04-26 23:54:51,626 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:55:02,529 - Epoch: [148][   50/  518]    Overall Loss 2.901927    Objective Loss 2.901927                                        LR 0.000125    Time 0.218020    
2023-04-26 23:55:12,729 - Epoch: [148][  100/  518]    Overall Loss 2.883188    Objective Loss 2.883188                                        LR 0.000125    Time 0.210993    
2023-04-26 23:55:22,886 - Epoch: [148][  150/  518]    Overall Loss 2.878624    Objective Loss 2.878624                                        LR 0.000125    Time 0.208365    
2023-04-26 23:55:33,079 - Epoch: [148][  200/  518]    Overall Loss 2.880564    Objective Loss 2.880564                                        LR 0.000125    Time 0.207230    
2023-04-26 23:55:43,188 - Epoch: [148][  250/  518]    Overall Loss 2.883250    Objective Loss 2.883250                                        LR 0.000125    Time 0.206212    
2023-04-26 23:55:53,469 - Epoch: [148][  300/  518]    Overall Loss 2.879393    Objective Loss 2.879393                                        LR 0.000125    Time 0.206110    
2023-04-26 23:56:03,568 - Epoch: [148][  350/  518]    Overall Loss 2.880160    Objective Loss 2.880160                                        LR 0.000125    Time 0.205513    
2023-04-26 23:56:13,804 - Epoch: [148][  400/  518]    Overall Loss 2.882914    Objective Loss 2.882914                                        LR 0.000125    Time 0.205411    
2023-04-26 23:56:23,912 - Epoch: [148][  450/  518]    Overall Loss 2.883456    Objective Loss 2.883456                                        LR 0.000125    Time 0.205046    
2023-04-26 23:56:34,053 - Epoch: [148][  500/  518]    Overall Loss 2.883821    Objective Loss 2.883821                                        LR 0.000125    Time 0.204820    
2023-04-26 23:56:37,594 - Epoch: [148][  518/  518]    Overall Loss 2.883758    Objective Loss 2.883758                                        LR 0.000125    Time 0.204538    
2023-04-26 23:56:37,666 - --- validate (epoch=148)-----------
2023-04-26 23:56:37,667 - 4952 samples (32 per mini-batch)
2023-04-26 23:56:44,426 - Epoch: [148][   50/  155]    Loss 3.179925    mAP 0.443432    
2023-04-26 23:56:50,840 - Epoch: [148][  100/  155]    Loss 3.186947    mAP 0.447412    
2023-04-26 23:56:57,173 - Epoch: [148][  150/  155]    Loss 3.177256    mAP 0.444664    
2023-04-26 23:56:57,742 - Epoch: [148][  155/  155]    Loss 3.175674    mAP 0.445015    
2023-04-26 23:56:57,813 - ==> mAP: 0.44502    Loss: 3.176

2023-04-26 23:56:57,816 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-26 23:56:57,817 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:56:57,854 - 

2023-04-26 23:56:57,854 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:57:08,956 - Epoch: [149][   50/  518]    Overall Loss 2.913762    Objective Loss 2.913762                                        LR 0.000125    Time 0.221979    
2023-04-26 23:57:19,175 - Epoch: [149][  100/  518]    Overall Loss 2.899700    Objective Loss 2.899700                                        LR 0.000125    Time 0.213163    
2023-04-26 23:57:29,316 - Epoch: [149][  150/  518]    Overall Loss 2.887263    Objective Loss 2.887263                                        LR 0.000125    Time 0.209709    
2023-04-26 23:57:39,481 - Epoch: [149][  200/  518]    Overall Loss 2.892838    Objective Loss 2.892838                                        LR 0.000125    Time 0.208099    
2023-04-26 23:57:49,676 - Epoch: [149][  250/  518]    Overall Loss 2.890130    Objective Loss 2.890130                                        LR 0.000125    Time 0.207253    
2023-04-26 23:57:59,819 - Epoch: [149][  300/  518]    Overall Loss 2.886694    Objective Loss 2.886694                                        LR 0.000125    Time 0.206514    
2023-04-26 23:58:09,963 - Epoch: [149][  350/  518]    Overall Loss 2.883478    Objective Loss 2.883478                                        LR 0.000125    Time 0.205991    
2023-04-26 23:58:20,080 - Epoch: [149][  400/  518]    Overall Loss 2.881678    Objective Loss 2.881678                                        LR 0.000125    Time 0.205531    
2023-04-26 23:58:30,199 - Epoch: [149][  450/  518]    Overall Loss 2.884703    Objective Loss 2.884703                                        LR 0.000125    Time 0.205176    
2023-04-26 23:58:40,391 - Epoch: [149][  500/  518]    Overall Loss 2.885953    Objective Loss 2.885953                                        LR 0.000125    Time 0.205040    
2023-04-26 23:58:43,943 - Epoch: [149][  518/  518]    Overall Loss 2.891217    Objective Loss 2.891217                                        LR 0.000125    Time 0.204771    
2023-04-26 23:58:44,015 - --- validate (epoch=149)-----------
2023-04-26 23:58:44,015 - 4952 samples (32 per mini-batch)
2023-04-26 23:58:50,734 - Epoch: [149][   50/  155]    Loss 3.155173    mAP 0.459914    
2023-04-26 23:58:57,115 - Epoch: [149][  100/  155]    Loss 3.147307    mAP 0.456810    
2023-04-26 23:59:03,493 - Epoch: [149][  150/  155]    Loss 3.159855    mAP 0.450226    
2023-04-26 23:59:04,063 - Epoch: [149][  155/  155]    Loss 3.160437    mAP 0.448896    
2023-04-26 23:59:04,142 - ==> mAP: 0.44890    Loss: 3.160

2023-04-26 23:59:04,145 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-26 23:59:04,146 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-26 23:59:04,183 - 

2023-04-26 23:59:04,183 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-26 23:59:15,008 - Epoch: [150][   50/  518]    Overall Loss 2.862238    Objective Loss 2.862238                                        LR 0.000031    Time 0.216426    
2023-04-26 23:59:25,126 - Epoch: [150][  100/  518]    Overall Loss 2.855522    Objective Loss 2.855522                                        LR 0.000031    Time 0.209382    
2023-04-26 23:59:35,372 - Epoch: [150][  150/  518]    Overall Loss 2.847380    Objective Loss 2.847380                                        LR 0.000031    Time 0.207881    
2023-04-26 23:59:45,492 - Epoch: [150][  200/  518]    Overall Loss 2.867577    Objective Loss 2.867577                                        LR 0.000031    Time 0.206504    
2023-04-26 23:59:55,552 - Epoch: [150][  250/  518]    Overall Loss 2.869510    Objective Loss 2.869510                                        LR 0.000031    Time 0.205438    
2023-04-27 00:00:05,769 - Epoch: [150][  300/  518]    Overall Loss 2.865114    Objective Loss 2.865114                                        LR 0.000031    Time 0.205248    
2023-04-27 00:00:15,902 - Epoch: [150][  350/  518]    Overall Loss 2.860736    Objective Loss 2.860736                                        LR 0.000031    Time 0.204873    
2023-04-27 00:00:26,018 - Epoch: [150][  400/  518]    Overall Loss 2.863382    Objective Loss 2.863382                                        LR 0.000031    Time 0.204549    
2023-04-27 00:00:36,165 - Epoch: [150][  450/  518]    Overall Loss 2.866192    Objective Loss 2.866192                                        LR 0.000031    Time 0.204368    
2023-04-27 00:00:46,332 - Epoch: [150][  500/  518]    Overall Loss 2.865029    Objective Loss 2.865029                                        LR 0.000031    Time 0.204261    
2023-04-27 00:00:49,822 - Epoch: [150][  518/  518]    Overall Loss 2.868395    Objective Loss 2.868395                                        LR 0.000031    Time 0.203901    
2023-04-27 00:00:49,895 - --- validate (epoch=150)-----------
2023-04-27 00:00:49,895 - 4952 samples (32 per mini-batch)
2023-04-27 00:00:56,567 - Epoch: [150][   50/  155]    Loss 3.145302    mAP 0.436955    
2023-04-27 00:01:02,935 - Epoch: [150][  100/  155]    Loss 3.153357    mAP 0.450051    
2023-04-27 00:01:09,349 - Epoch: [150][  150/  155]    Loss 3.151659    mAP 0.452531    
2023-04-27 00:01:09,911 - Epoch: [150][  155/  155]    Loss 3.158624    mAP 0.450083    
2023-04-27 00:01:09,976 - ==> mAP: 0.45008    Loss: 3.159

2023-04-27 00:01:09,980 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-27 00:01:09,980 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:01:10,018 - 

2023-04-27 00:01:10,018 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:01:20,856 - Epoch: [151][   50/  518]    Overall Loss 2.905828    Objective Loss 2.905828                                        LR 0.000031    Time 0.216704    
2023-04-27 00:01:31,042 - Epoch: [151][  100/  518]    Overall Loss 2.895686    Objective Loss 2.895686                                        LR 0.000031    Time 0.210198    
2023-04-27 00:01:41,245 - Epoch: [151][  150/  518]    Overall Loss 2.873868    Objective Loss 2.873868                                        LR 0.000031    Time 0.208138    
2023-04-27 00:01:51,415 - Epoch: [151][  200/  518]    Overall Loss 2.871029    Objective Loss 2.871029                                        LR 0.000031    Time 0.206949    
2023-04-27 00:02:01,585 - Epoch: [151][  250/  518]    Overall Loss 2.864720    Objective Loss 2.864720                                        LR 0.000031    Time 0.206233    
2023-04-27 00:02:11,723 - Epoch: [151][  300/  518]    Overall Loss 2.855685    Objective Loss 2.855685                                        LR 0.000031    Time 0.205648    
2023-04-27 00:02:21,860 - Epoch: [151][  350/  518]    Overall Loss 2.854722    Objective Loss 2.854722                                        LR 0.000031    Time 0.205228    
2023-04-27 00:02:32,080 - Epoch: [151][  400/  518]    Overall Loss 2.853272    Objective Loss 2.853272                                        LR 0.000031    Time 0.205119    
2023-04-27 00:02:42,375 - Epoch: [151][  450/  518]    Overall Loss 2.853580    Objective Loss 2.853580                                        LR 0.000031    Time 0.205203    
2023-04-27 00:02:52,525 - Epoch: [151][  500/  518]    Overall Loss 2.857822    Objective Loss 2.857822                                        LR 0.000031    Time 0.204980    
2023-04-27 00:02:56,100 - Epoch: [151][  518/  518]    Overall Loss 2.854862    Objective Loss 2.854862                                        LR 0.000031    Time 0.204757    
2023-04-27 00:02:56,170 - --- validate (epoch=151)-----------
2023-04-27 00:02:56,171 - 4952 samples (32 per mini-batch)
2023-04-27 00:03:02,918 - Epoch: [151][   50/  155]    Loss 3.155741    mAP 0.453053    
2023-04-27 00:03:09,393 - Epoch: [151][  100/  155]    Loss 3.157797    mAP 0.450122    
2023-04-27 00:03:15,786 - Epoch: [151][  150/  155]    Loss 3.154181    mAP 0.446455    
2023-04-27 00:03:16,356 - Epoch: [151][  155/  155]    Loss 3.155173    mAP 0.445101    
2023-04-27 00:03:16,439 - ==> mAP: 0.44510    Loss: 3.155

2023-04-27 00:03:16,443 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-27 00:03:16,443 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:03:16,480 - 

2023-04-27 00:03:16,480 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:03:27,552 - Epoch: [152][   50/  518]    Overall Loss 2.865492    Objective Loss 2.865492                                        LR 0.000031    Time 0.221384    
2023-04-27 00:03:37,673 - Epoch: [152][  100/  518]    Overall Loss 2.872873    Objective Loss 2.872873                                        LR 0.000031    Time 0.211884    
2023-04-27 00:03:47,864 - Epoch: [152][  150/  518]    Overall Loss 2.856630    Objective Loss 2.856630                                        LR 0.000031    Time 0.209186    
2023-04-27 00:03:57,988 - Epoch: [152][  200/  518]    Overall Loss 2.850954    Objective Loss 2.850954                                        LR 0.000031    Time 0.207497    
2023-04-27 00:04:08,194 - Epoch: [152][  250/  518]    Overall Loss 2.854195    Objective Loss 2.854195                                        LR 0.000031    Time 0.206815    
2023-04-27 00:04:18,314 - Epoch: [152][  300/  518]    Overall Loss 2.857736    Objective Loss 2.857736                                        LR 0.000031    Time 0.206074    
2023-04-27 00:04:28,445 - Epoch: [152][  350/  518]    Overall Loss 2.856356    Objective Loss 2.856356                                        LR 0.000031    Time 0.205577    
2023-04-27 00:04:38,627 - Epoch: [152][  400/  518]    Overall Loss 2.859385    Objective Loss 2.859385                                        LR 0.000031    Time 0.205331    
2023-04-27 00:04:48,810 - Epoch: [152][  450/  518]    Overall Loss 2.861490    Objective Loss 2.861490                                        LR 0.000031    Time 0.205142    
2023-04-27 00:04:58,914 - Epoch: [152][  500/  518]    Overall Loss 2.866743    Objective Loss 2.866743                                        LR 0.000031    Time 0.204832    
2023-04-27 00:05:02,490 - Epoch: [152][  518/  518]    Overall Loss 2.866530    Objective Loss 2.866530                                        LR 0.000031    Time 0.204617    
2023-04-27 00:05:02,561 - --- validate (epoch=152)-----------
2023-04-27 00:05:02,562 - 4952 samples (32 per mini-batch)
2023-04-27 00:05:09,299 - Epoch: [152][   50/  155]    Loss 3.160888    mAP 0.441504    
2023-04-27 00:05:15,737 - Epoch: [152][  100/  155]    Loss 3.147758    mAP 0.449812    
2023-04-27 00:05:22,072 - Epoch: [152][  150/  155]    Loss 3.156457    mAP 0.449706    
2023-04-27 00:05:22,645 - Epoch: [152][  155/  155]    Loss 3.155320    mAP 0.450545    
2023-04-27 00:05:22,711 - ==> mAP: 0.45054    Loss: 3.155

2023-04-27 00:05:22,715 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-27 00:05:22,715 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:05:22,752 - 

2023-04-27 00:05:22,752 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:05:33,675 - Epoch: [153][   50/  518]    Overall Loss 2.750504    Objective Loss 2.750504                                        LR 0.000031    Time 0.218391    
2023-04-27 00:05:43,793 - Epoch: [153][  100/  518]    Overall Loss 2.839751    Objective Loss 2.839751                                        LR 0.000031    Time 0.210360    
2023-04-27 00:05:53,988 - Epoch: [153][  150/  518]    Overall Loss 2.843288    Objective Loss 2.843288                                        LR 0.000031    Time 0.208195    
2023-04-27 00:06:04,176 - Epoch: [153][  200/  518]    Overall Loss 2.851549    Objective Loss 2.851549                                        LR 0.000031    Time 0.207080    
2023-04-27 00:06:14,308 - Epoch: [153][  250/  518]    Overall Loss 2.858437    Objective Loss 2.858437                                        LR 0.000031    Time 0.206186    
2023-04-27 00:06:24,552 - Epoch: [153][  300/  518]    Overall Loss 2.859086    Objective Loss 2.859086                                        LR 0.000031    Time 0.205961    
2023-04-27 00:06:34,716 - Epoch: [153][  350/  518]    Overall Loss 2.861413    Objective Loss 2.861413                                        LR 0.000031    Time 0.205574    
2023-04-27 00:06:44,912 - Epoch: [153][  400/  518]    Overall Loss 2.863841    Objective Loss 2.863841                                        LR 0.000031    Time 0.205363    
2023-04-27 00:06:55,085 - Epoch: [153][  450/  518]    Overall Loss 2.862602    Objective Loss 2.862602                                        LR 0.000031    Time 0.205148    
2023-04-27 00:07:05,284 - Epoch: [153][  500/  518]    Overall Loss 2.862408    Objective Loss 2.862408                                        LR 0.000031    Time 0.205028    
2023-04-27 00:07:08,836 - Epoch: [153][  518/  518]    Overall Loss 2.864821    Objective Loss 2.864821                                        LR 0.000031    Time 0.204759    
2023-04-27 00:07:08,908 - --- validate (epoch=153)-----------
2023-04-27 00:07:08,908 - 4952 samples (32 per mini-batch)
2023-04-27 00:07:15,640 - Epoch: [153][   50/  155]    Loss 3.155023    mAP 0.448841    
2023-04-27 00:07:22,031 - Epoch: [153][  100/  155]    Loss 3.165727    mAP 0.448886    
2023-04-27 00:07:28,371 - Epoch: [153][  150/  155]    Loss 3.159222    mAP 0.449860    
2023-04-27 00:07:28,943 - Epoch: [153][  155/  155]    Loss 3.154548    mAP 0.451284    
2023-04-27 00:07:29,007 - ==> mAP: 0.45128    Loss: 3.155

2023-04-27 00:07:29,011 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-27 00:07:29,011 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:07:29,048 - 

2023-04-27 00:07:29,048 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:07:40,006 - Epoch: [154][   50/  518]    Overall Loss 2.827449    Objective Loss 2.827449                                        LR 0.000031    Time 0.219094    
2023-04-27 00:07:50,167 - Epoch: [154][  100/  518]    Overall Loss 2.847826    Objective Loss 2.847826                                        LR 0.000031    Time 0.211139    
2023-04-27 00:08:00,262 - Epoch: [154][  150/  518]    Overall Loss 2.834072    Objective Loss 2.834072                                        LR 0.000031    Time 0.208051    
2023-04-27 00:08:10,476 - Epoch: [154][  200/  518]    Overall Loss 2.843022    Objective Loss 2.843022                                        LR 0.000031    Time 0.207101    
2023-04-27 00:08:20,662 - Epoch: [154][  250/  518]    Overall Loss 2.849187    Objective Loss 2.849187                                        LR 0.000031    Time 0.206416    
2023-04-27 00:08:30,839 - Epoch: [154][  300/  518]    Overall Loss 2.845864    Objective Loss 2.845864                                        LR 0.000031    Time 0.205932    
2023-04-27 00:08:40,965 - Epoch: [154][  350/  518]    Overall Loss 2.845608    Objective Loss 2.845608                                        LR 0.000031    Time 0.205439    
2023-04-27 00:08:51,157 - Epoch: [154][  400/  518]    Overall Loss 2.847182    Objective Loss 2.847182                                        LR 0.000031    Time 0.205235    
2023-04-27 00:09:01,384 - Epoch: [154][  450/  518]    Overall Loss 2.845374    Objective Loss 2.845374                                        LR 0.000031    Time 0.205155    
2023-04-27 00:09:11,482 - Epoch: [154][  500/  518]    Overall Loss 2.849932    Objective Loss 2.849932                                        LR 0.000031    Time 0.204831    
2023-04-27 00:09:14,981 - Epoch: [154][  518/  518]    Overall Loss 2.847845    Objective Loss 2.847845                                        LR 0.000031    Time 0.204467    
2023-04-27 00:09:15,052 - --- validate (epoch=154)-----------
2023-04-27 00:09:15,052 - 4952 samples (32 per mini-batch)
2023-04-27 00:09:21,798 - Epoch: [154][   50/  155]    Loss 3.132762    mAP 0.449348    
2023-04-27 00:09:28,144 - Epoch: [154][  100/  155]    Loss 3.136802    mAP 0.444984    
2023-04-27 00:09:34,479 - Epoch: [154][  150/  155]    Loss 3.154044    mAP 0.447157    
2023-04-27 00:09:35,051 - Epoch: [154][  155/  155]    Loss 3.159106    mAP 0.447774    
2023-04-27 00:09:35,123 - ==> mAP: 0.44777    Loss: 3.159

2023-04-27 00:09:35,127 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-27 00:09:35,127 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:09:35,165 - 

2023-04-27 00:09:35,165 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:09:46,060 - Epoch: [155][   50/  518]    Overall Loss 2.832081    Objective Loss 2.832081                                        LR 0.000031    Time 0.217845    
2023-04-27 00:09:56,283 - Epoch: [155][  100/  518]    Overall Loss 2.857264    Objective Loss 2.857264                                        LR 0.000031    Time 0.211142    
2023-04-27 00:10:06,464 - Epoch: [155][  150/  518]    Overall Loss 2.858422    Objective Loss 2.858422                                        LR 0.000031    Time 0.208620    
2023-04-27 00:10:16,615 - Epoch: [155][  200/  518]    Overall Loss 2.859262    Objective Loss 2.859262                                        LR 0.000031    Time 0.207213    
2023-04-27 00:10:26,783 - Epoch: [155][  250/  518]    Overall Loss 2.865163    Objective Loss 2.865163                                        LR 0.000031    Time 0.206437    
2023-04-27 00:10:36,940 - Epoch: [155][  300/  518]    Overall Loss 2.865458    Objective Loss 2.865458                                        LR 0.000031    Time 0.205881    
2023-04-27 00:10:47,021 - Epoch: [155][  350/  518]    Overall Loss 2.858682    Objective Loss 2.858682                                        LR 0.000031    Time 0.205269    
2023-04-27 00:10:57,219 - Epoch: [155][  400/  518]    Overall Loss 2.865378    Objective Loss 2.865378                                        LR 0.000031    Time 0.205100    
2023-04-27 00:11:07,392 - Epoch: [155][  450/  518]    Overall Loss 2.861244    Objective Loss 2.861244                                        LR 0.000031    Time 0.204913    
2023-04-27 00:11:17,559 - Epoch: [155][  500/  518]    Overall Loss 2.861629    Objective Loss 2.861629                                        LR 0.000031    Time 0.204753    
2023-04-27 00:11:21,079 - Epoch: [155][  518/  518]    Overall Loss 2.864626    Objective Loss 2.864626                                        LR 0.000031    Time 0.204432    
2023-04-27 00:11:21,151 - --- validate (epoch=155)-----------
2023-04-27 00:11:21,152 - 4952 samples (32 per mini-batch)
2023-04-27 00:11:27,907 - Epoch: [155][   50/  155]    Loss 3.136369    mAP 0.449966    
2023-04-27 00:11:34,245 - Epoch: [155][  100/  155]    Loss 3.160944    mAP 0.446453    
2023-04-27 00:11:40,635 - Epoch: [155][  150/  155]    Loss 3.165235    mAP 0.444553    
2023-04-27 00:11:41,196 - Epoch: [155][  155/  155]    Loss 3.161665    mAP 0.444145    
2023-04-27 00:11:41,266 - ==> mAP: 0.44414    Loss: 3.162

2023-04-27 00:11:41,270 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-27 00:11:41,270 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:11:41,306 - 

2023-04-27 00:11:41,307 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:11:52,191 - Epoch: [156][   50/  518]    Overall Loss 2.839193    Objective Loss 2.839193                                        LR 0.000031    Time 0.217636    
2023-04-27 00:12:02,411 - Epoch: [156][  100/  518]    Overall Loss 2.856150    Objective Loss 2.856150                                        LR 0.000031    Time 0.210999    
2023-04-27 00:12:12,637 - Epoch: [156][  150/  518]    Overall Loss 2.842504    Objective Loss 2.842504                                        LR 0.000031    Time 0.208828    
2023-04-27 00:12:22,798 - Epoch: [156][  200/  518]    Overall Loss 2.853985    Objective Loss 2.853985                                        LR 0.000031    Time 0.207417    
2023-04-27 00:12:32,956 - Epoch: [156][  250/  518]    Overall Loss 2.852790    Objective Loss 2.852790                                        LR 0.000031    Time 0.206560    
2023-04-27 00:12:43,115 - Epoch: [156][  300/  518]    Overall Loss 2.855700    Objective Loss 2.855700                                        LR 0.000031    Time 0.205991    
2023-04-27 00:12:53,276 - Epoch: [156][  350/  518]    Overall Loss 2.856010    Objective Loss 2.856010                                        LR 0.000031    Time 0.205591    
2023-04-27 00:13:03,523 - Epoch: [156][  400/  518]    Overall Loss 2.855968    Objective Loss 2.855968                                        LR 0.000031    Time 0.205506    
2023-04-27 00:13:13,660 - Epoch: [156][  450/  518]    Overall Loss 2.855650    Objective Loss 2.855650                                        LR 0.000031    Time 0.205195    
2023-04-27 00:13:23,808 - Epoch: [156][  500/  518]    Overall Loss 2.853758    Objective Loss 2.853758                                        LR 0.000031    Time 0.204968    
2023-04-27 00:13:27,323 - Epoch: [156][  518/  518]    Overall Loss 2.852859    Objective Loss 2.852859                                        LR 0.000031    Time 0.204630    
2023-04-27 00:13:27,395 - --- validate (epoch=156)-----------
2023-04-27 00:13:27,396 - 4952 samples (32 per mini-batch)
2023-04-27 00:13:34,160 - Epoch: [156][   50/  155]    Loss 3.191339    mAP 0.433896    
2023-04-27 00:13:40,552 - Epoch: [156][  100/  155]    Loss 3.169294    mAP 0.435512    
2023-04-27 00:13:46,911 - Epoch: [156][  150/  155]    Loss 3.161826    mAP 0.446374    
2023-04-27 00:13:47,487 - Epoch: [156][  155/  155]    Loss 3.156768    mAP 0.447201    
2023-04-27 00:13:47,550 - ==> mAP: 0.44720    Loss: 3.157

2023-04-27 00:13:47,553 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-27 00:13:47,553 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:13:47,590 - 

2023-04-27 00:13:47,590 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:13:58,503 - Epoch: [157][   50/  518]    Overall Loss 2.878328    Objective Loss 2.878328                                        LR 0.000031    Time 0.218209    
2023-04-27 00:14:08,617 - Epoch: [157][  100/  518]    Overall Loss 2.849456    Objective Loss 2.849456                                        LR 0.000031    Time 0.210221    
2023-04-27 00:14:18,741 - Epoch: [157][  150/  518]    Overall Loss 2.836358    Objective Loss 2.836358                                        LR 0.000031    Time 0.207635    
2023-04-27 00:14:28,932 - Epoch: [157][  200/  518]    Overall Loss 2.849585    Objective Loss 2.849585                                        LR 0.000031    Time 0.206669    
2023-04-27 00:14:39,119 - Epoch: [157][  250/  518]    Overall Loss 2.855950    Objective Loss 2.855950                                        LR 0.000031    Time 0.206077    
2023-04-27 00:14:49,276 - Epoch: [157][  300/  518]    Overall Loss 2.854037    Objective Loss 2.854037                                        LR 0.000031    Time 0.205582    
2023-04-27 00:14:59,417 - Epoch: [157][  350/  518]    Overall Loss 2.851163    Objective Loss 2.851163                                        LR 0.000031    Time 0.205183    
2023-04-27 00:15:09,518 - Epoch: [157][  400/  518]    Overall Loss 2.858830    Objective Loss 2.858830                                        LR 0.000031    Time 0.204785    
2023-04-27 00:15:19,662 - Epoch: [157][  450/  518]    Overall Loss 2.852975    Objective Loss 2.852975                                        LR 0.000031    Time 0.204568    
2023-04-27 00:15:29,822 - Epoch: [157][  500/  518]    Overall Loss 2.849682    Objective Loss 2.849682                                        LR 0.000031    Time 0.204430    
2023-04-27 00:15:33,338 - Epoch: [157][  518/  518]    Overall Loss 2.850612    Objective Loss 2.850612                                        LR 0.000031    Time 0.204112    
2023-04-27 00:15:33,411 - --- validate (epoch=157)-----------
2023-04-27 00:15:33,411 - 4952 samples (32 per mini-batch)
2023-04-27 00:15:40,192 - Epoch: [157][   50/  155]    Loss 3.152102    mAP 0.448333    
2023-04-27 00:15:46,563 - Epoch: [157][  100/  155]    Loss 3.144684    mAP 0.453296    
2023-04-27 00:15:52,956 - Epoch: [157][  150/  155]    Loss 3.162286    mAP 0.444936    
2023-04-27 00:15:53,515 - Epoch: [157][  155/  155]    Loss 3.158339    mAP 0.445789    
2023-04-27 00:15:53,584 - ==> mAP: 0.44579    Loss: 3.158

2023-04-27 00:15:53,587 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-27 00:15:53,588 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:15:53,625 - 

2023-04-27 00:15:53,625 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:16:04,561 - Epoch: [158][   50/  518]    Overall Loss 2.860401    Objective Loss 2.860401                                        LR 0.000031    Time 0.218667    
2023-04-27 00:16:14,688 - Epoch: [158][  100/  518]    Overall Loss 2.861722    Objective Loss 2.861722                                        LR 0.000031    Time 0.210583    
2023-04-27 00:16:24,829 - Epoch: [158][  150/  518]    Overall Loss 2.877528    Objective Loss 2.877528                                        LR 0.000031    Time 0.207984    
2023-04-27 00:16:34,984 - Epoch: [158][  200/  518]    Overall Loss 2.865730    Objective Loss 2.865730                                        LR 0.000031    Time 0.206756    
2023-04-27 00:16:45,101 - Epoch: [158][  250/  518]    Overall Loss 2.860225    Objective Loss 2.860225                                        LR 0.000031    Time 0.205866    
2023-04-27 00:16:55,227 - Epoch: [158][  300/  518]    Overall Loss 2.857134    Objective Loss 2.857134                                        LR 0.000031    Time 0.205304    
2023-04-27 00:17:05,311 - Epoch: [158][  350/  518]    Overall Loss 2.857141    Objective Loss 2.857141                                        LR 0.000031    Time 0.204780    
2023-04-27 00:17:15,544 - Epoch: [158][  400/  518]    Overall Loss 2.852238    Objective Loss 2.852238                                        LR 0.000031    Time 0.204762    
2023-04-27 00:17:25,693 - Epoch: [158][  450/  518]    Overall Loss 2.852865    Objective Loss 2.852865                                        LR 0.000031    Time 0.204560    
2023-04-27 00:17:35,805 - Epoch: [158][  500/  518]    Overall Loss 2.853772    Objective Loss 2.853772                                        LR 0.000031    Time 0.204324    
2023-04-27 00:17:39,317 - Epoch: [158][  518/  518]    Overall Loss 2.856359    Objective Loss 2.856359                                        LR 0.000031    Time 0.204003    
2023-04-27 00:17:39,389 - --- validate (epoch=158)-----------
2023-04-27 00:17:39,389 - 4952 samples (32 per mini-batch)
2023-04-27 00:17:46,150 - Epoch: [158][   50/  155]    Loss 3.177163    mAP 0.441906    
2023-04-27 00:17:52,522 - Epoch: [158][  100/  155]    Loss 3.150256    mAP 0.443979    
2023-04-27 00:17:58,906 - Epoch: [158][  150/  155]    Loss 3.148855    mAP 0.443603    
2023-04-27 00:17:59,472 - Epoch: [158][  155/  155]    Loss 3.153740    mAP 0.443867    
2023-04-27 00:17:59,543 - ==> mAP: 0.44387    Loss: 3.154

2023-04-27 00:17:59,547 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-27 00:17:59,547 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:17:59,584 - 

2023-04-27 00:17:59,584 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:18:10,554 - Epoch: [159][   50/  518]    Overall Loss 2.879464    Objective Loss 2.879464                                        LR 0.000031    Time 0.219341    
2023-04-27 00:18:20,639 - Epoch: [159][  100/  518]    Overall Loss 2.876903    Objective Loss 2.876903                                        LR 0.000031    Time 0.210505    
2023-04-27 00:18:30,789 - Epoch: [159][  150/  518]    Overall Loss 2.858082    Objective Loss 2.858082                                        LR 0.000031    Time 0.207990    
2023-04-27 00:18:40,942 - Epoch: [159][  200/  518]    Overall Loss 2.849643    Objective Loss 2.849643                                        LR 0.000031    Time 0.206752    
2023-04-27 00:18:51,060 - Epoch: [159][  250/  518]    Overall Loss 2.862305    Objective Loss 2.862305                                        LR 0.000031    Time 0.205867    
2023-04-27 00:19:01,242 - Epoch: [159][  300/  518]    Overall Loss 2.865535    Objective Loss 2.865535                                        LR 0.000031    Time 0.205489    
2023-04-27 00:19:11,446 - Epoch: [159][  350/  518]    Overall Loss 2.867448    Objective Loss 2.867448                                        LR 0.000031    Time 0.205283    
2023-04-27 00:19:21,563 - Epoch: [159][  400/  518]    Overall Loss 2.869771    Objective Loss 2.869771                                        LR 0.000031    Time 0.204910    
2023-04-27 00:19:31,745 - Epoch: [159][  450/  518]    Overall Loss 2.873826    Objective Loss 2.873826                                        LR 0.000031    Time 0.204767    
2023-04-27 00:19:41,851 - Epoch: [159][  500/  518]    Overall Loss 2.872849    Objective Loss 2.872849                                        LR 0.000031    Time 0.204499    
2023-04-27 00:19:45,376 - Epoch: [159][  518/  518]    Overall Loss 2.871776    Objective Loss 2.871776                                        LR 0.000031    Time 0.204196    
2023-04-27 00:19:45,447 - --- validate (epoch=159)-----------
2023-04-27 00:19:45,447 - 4952 samples (32 per mini-batch)
2023-04-27 00:19:52,141 - Epoch: [159][   50/  155]    Loss 3.191313    mAP 0.435922    
2023-04-27 00:19:58,610 - Epoch: [159][  100/  155]    Loss 3.166448    mAP 0.446666    
2023-04-27 00:20:04,980 - Epoch: [159][  150/  155]    Loss 3.163580    mAP 0.451067    
2023-04-27 00:20:05,554 - Epoch: [159][  155/  155]    Loss 3.161166    mAP 0.451449    
2023-04-27 00:20:05,637 - ==> mAP: 0.45145    Loss: 3.161

2023-04-27 00:20:05,641 - ==> Best [mAP: 0.452634   vloss: 3.166752   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-27 00:20:05,641 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:20:05,679 - 

2023-04-27 00:20:05,679 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:20:16,620 - Epoch: [160][   50/  518]    Overall Loss 2.911208    Objective Loss 2.911208                                        LR 0.000031    Time 0.218777    
2023-04-27 00:20:26,843 - Epoch: [160][  100/  518]    Overall Loss 2.867972    Objective Loss 2.867972                                        LR 0.000031    Time 0.211595    
2023-04-27 00:20:36,990 - Epoch: [160][  150/  518]    Overall Loss 2.884520    Objective Loss 2.884520                                        LR 0.000031    Time 0.208698    
2023-04-27 00:20:47,123 - Epoch: [160][  200/  518]    Overall Loss 2.867161    Objective Loss 2.867161                                        LR 0.000031    Time 0.207180    
2023-04-27 00:20:57,257 - Epoch: [160][  250/  518]    Overall Loss 2.874411    Objective Loss 2.874411                                        LR 0.000031    Time 0.206275    
2023-04-27 00:21:07,437 - Epoch: [160][  300/  518]    Overall Loss 2.869192    Objective Loss 2.869192                                        LR 0.000031    Time 0.205825    
2023-04-27 00:21:17,478 - Epoch: [160][  350/  518]    Overall Loss 2.874329    Objective Loss 2.874329                                        LR 0.000031    Time 0.205104    
2023-04-27 00:21:27,583 - Epoch: [160][  400/  518]    Overall Loss 2.873660    Objective Loss 2.873660                                        LR 0.000031    Time 0.204726    
2023-04-27 00:21:37,759 - Epoch: [160][  450/  518]    Overall Loss 2.875457    Objective Loss 2.875457                                        LR 0.000031    Time 0.204587    
2023-04-27 00:21:47,946 - Epoch: [160][  500/  518]    Overall Loss 2.877673    Objective Loss 2.877673                                        LR 0.000031    Time 0.204500    
2023-04-27 00:21:51,478 - Epoch: [160][  518/  518]    Overall Loss 2.876922    Objective Loss 2.876922                                        LR 0.000031    Time 0.204212    
2023-04-27 00:21:51,549 - --- validate (epoch=160)-----------
2023-04-27 00:21:51,550 - 4952 samples (32 per mini-batch)
2023-04-27 00:21:58,291 - Epoch: [160][   50/  155]    Loss 3.115938    mAP 0.446150    
2023-04-27 00:22:04,679 - Epoch: [160][  100/  155]    Loss 3.142149    mAP 0.447514    
2023-04-27 00:22:11,047 - Epoch: [160][  150/  155]    Loss 3.154637    mAP 0.452682    
2023-04-27 00:22:11,633 - Epoch: [160][  155/  155]    Loss 3.159736    mAP 0.454181    
2023-04-27 00:22:11,703 - ==> mAP: 0.45418    Loss: 3.160

2023-04-27 00:22:11,706 - ==> Best [mAP: 0.454181   vloss: 3.159736   Sparsity:0.00   Params: 2177088 on epoch: 160]
2023-04-27 00:22:11,706 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:22:11,760 - 

2023-04-27 00:22:11,760 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:22:22,775 - Epoch: [161][   50/  518]    Overall Loss 2.850727    Objective Loss 2.850727                                        LR 0.000031    Time 0.220239    
2023-04-27 00:22:32,925 - Epoch: [161][  100/  518]    Overall Loss 2.843908    Objective Loss 2.843908                                        LR 0.000031    Time 0.211610    
2023-04-27 00:22:43,100 - Epoch: [161][  150/  518]    Overall Loss 2.846468    Objective Loss 2.846468                                        LR 0.000031    Time 0.208893    
2023-04-27 00:22:53,267 - Epoch: [161][  200/  518]    Overall Loss 2.866637    Objective Loss 2.866637                                        LR 0.000031    Time 0.207498    
2023-04-27 00:23:03,428 - Epoch: [161][  250/  518]    Overall Loss 2.860275    Objective Loss 2.860275                                        LR 0.000031    Time 0.206635    
2023-04-27 00:23:13,623 - Epoch: [161][  300/  518]    Overall Loss 2.859653    Objective Loss 2.859653                                        LR 0.000031    Time 0.206174    
2023-04-27 00:23:23,757 - Epoch: [161][  350/  518]    Overall Loss 2.867411    Objective Loss 2.867411                                        LR 0.000031    Time 0.205671    
2023-04-27 00:23:33,970 - Epoch: [161][  400/  518]    Overall Loss 2.858389    Objective Loss 2.858389                                        LR 0.000031    Time 0.205491    
2023-04-27 00:23:44,144 - Epoch: [161][  450/  518]    Overall Loss 2.862072    Objective Loss 2.862072                                        LR 0.000031    Time 0.205264    
2023-04-27 00:23:54,291 - Epoch: [161][  500/  518]    Overall Loss 2.865480    Objective Loss 2.865480                                        LR 0.000031    Time 0.205027    
2023-04-27 00:23:57,826 - Epoch: [161][  518/  518]    Overall Loss 2.867138    Objective Loss 2.867138                                        LR 0.000031    Time 0.204726    
2023-04-27 00:23:57,898 - --- validate (epoch=161)-----------
2023-04-27 00:23:57,899 - 4952 samples (32 per mini-batch)
2023-04-27 00:24:04,659 - Epoch: [161][   50/  155]    Loss 3.144797    mAP 0.450954    
2023-04-27 00:24:10,990 - Epoch: [161][  100/  155]    Loss 3.164495    mAP 0.450318    
2023-04-27 00:24:17,344 - Epoch: [161][  150/  155]    Loss 3.162160    mAP 0.449719    
2023-04-27 00:24:17,924 - Epoch: [161][  155/  155]    Loss 3.160033    mAP 0.449768    
2023-04-27 00:24:17,999 - ==> mAP: 0.44977    Loss: 3.160

2023-04-27 00:24:18,003 - ==> Best [mAP: 0.454181   vloss: 3.159736   Sparsity:0.00   Params: 2177088 on epoch: 160]
2023-04-27 00:24:18,003 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:24:18,040 - 

2023-04-27 00:24:18,040 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:24:28,870 - Epoch: [162][   50/  518]    Overall Loss 2.841349    Objective Loss 2.841349                                        LR 0.000031    Time 0.216547    
2023-04-27 00:24:38,948 - Epoch: [162][  100/  518]    Overall Loss 2.850787    Objective Loss 2.850787                                        LR 0.000031    Time 0.209033    
2023-04-27 00:24:49,118 - Epoch: [162][  150/  518]    Overall Loss 2.858706    Objective Loss 2.858706                                        LR 0.000031    Time 0.207150    
2023-04-27 00:24:59,322 - Epoch: [162][  200/  518]    Overall Loss 2.843096    Objective Loss 2.843096                                        LR 0.000031    Time 0.206371    
2023-04-27 00:25:09,502 - Epoch: [162][  250/  518]    Overall Loss 2.848480    Objective Loss 2.848480                                        LR 0.000031    Time 0.205812    
2023-04-27 00:25:19,585 - Epoch: [162][  300/  518]    Overall Loss 2.847302    Objective Loss 2.847302                                        LR 0.000031    Time 0.205115    
2023-04-27 00:25:29,720 - Epoch: [162][  350/  518]    Overall Loss 2.852264    Objective Loss 2.852264                                        LR 0.000031    Time 0.204764    
2023-04-27 00:25:39,885 - Epoch: [162][  400/  518]    Overall Loss 2.851433    Objective Loss 2.851433                                        LR 0.000031    Time 0.204577    
2023-04-27 00:25:50,024 - Epoch: [162][  450/  518]    Overall Loss 2.846246    Objective Loss 2.846246                                        LR 0.000031    Time 0.204374    
2023-04-27 00:26:00,118 - Epoch: [162][  500/  518]    Overall Loss 2.854426    Objective Loss 2.854426                                        LR 0.000031    Time 0.204120    
2023-04-27 00:26:03,653 - Epoch: [162][  518/  518]    Overall Loss 2.855377    Objective Loss 2.855377                                        LR 0.000031    Time 0.203851    
2023-04-27 00:26:03,724 - --- validate (epoch=162)-----------
2023-04-27 00:26:03,724 - 4952 samples (32 per mini-batch)
2023-04-27 00:26:10,530 - Epoch: [162][   50/  155]    Loss 3.156674    mAP 0.449069    
2023-04-27 00:26:17,014 - Epoch: [162][  100/  155]    Loss 3.161960    mAP 0.455262    
2023-04-27 00:26:23,370 - Epoch: [162][  150/  155]    Loss 3.152652    mAP 0.451041    
2023-04-27 00:26:23,951 - Epoch: [162][  155/  155]    Loss 3.154368    mAP 0.452228    
2023-04-27 00:26:24,023 - ==> mAP: 0.45223    Loss: 3.154

2023-04-27 00:26:24,027 - ==> Best [mAP: 0.454181   vloss: 3.159736   Sparsity:0.00   Params: 2177088 on epoch: 160]
2023-04-27 00:26:24,027 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:26:24,089 - 

2023-04-27 00:26:24,089 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:26:34,956 - Epoch: [163][   50/  518]    Overall Loss 2.858901    Objective Loss 2.858901                                        LR 0.000031    Time 0.217251    
2023-04-27 00:26:45,071 - Epoch: [163][  100/  518]    Overall Loss 2.813803    Objective Loss 2.813803                                        LR 0.000031    Time 0.209761    
2023-04-27 00:26:55,290 - Epoch: [163][  150/  518]    Overall Loss 2.828465    Objective Loss 2.828465                                        LR 0.000031    Time 0.207954    
2023-04-27 00:27:05,437 - Epoch: [163][  200/  518]    Overall Loss 2.830300    Objective Loss 2.830300                                        LR 0.000031    Time 0.206692    
2023-04-27 00:27:15,552 - Epoch: [163][  250/  518]    Overall Loss 2.840843    Objective Loss 2.840843                                        LR 0.000031    Time 0.205807    
2023-04-27 00:27:25,768 - Epoch: [163][  300/  518]    Overall Loss 2.849568    Objective Loss 2.849568                                        LR 0.000031    Time 0.205553    
2023-04-27 00:27:35,895 - Epoch: [163][  350/  518]    Overall Loss 2.853397    Objective Loss 2.853397                                        LR 0.000031    Time 0.205120    
2023-04-27 00:27:45,968 - Epoch: [163][  400/  518]    Overall Loss 2.850322    Objective Loss 2.850322                                        LR 0.000031    Time 0.204659    
2023-04-27 00:27:56,127 - Epoch: [163][  450/  518]    Overall Loss 2.850313    Objective Loss 2.850313                                        LR 0.000031    Time 0.204490    
2023-04-27 00:28:06,300 - Epoch: [163][  500/  518]    Overall Loss 2.853050    Objective Loss 2.853050                                        LR 0.000031    Time 0.204384    
2023-04-27 00:28:09,817 - Epoch: [163][  518/  518]    Overall Loss 2.859321    Objective Loss 2.859321                                        LR 0.000031    Time 0.204070    
2023-04-27 00:28:09,888 - --- validate (epoch=163)-----------
2023-04-27 00:28:09,888 - 4952 samples (32 per mini-batch)
2023-04-27 00:28:16,645 - Epoch: [163][   50/  155]    Loss 3.161769    mAP 0.441542    
2023-04-27 00:28:23,008 - Epoch: [163][  100/  155]    Loss 3.141011    mAP 0.448379    
2023-04-27 00:28:29,373 - Epoch: [163][  150/  155]    Loss 3.154760    mAP 0.446650    
2023-04-27 00:28:29,942 - Epoch: [163][  155/  155]    Loss 3.157784    mAP 0.446149    
2023-04-27 00:28:30,013 - ==> mAP: 0.44615    Loss: 3.158

2023-04-27 00:28:30,017 - ==> Best [mAP: 0.454181   vloss: 3.159736   Sparsity:0.00   Params: 2177088 on epoch: 160]
2023-04-27 00:28:30,017 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:28:30,054 - 

2023-04-27 00:28:30,054 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:28:41,148 - Epoch: [164][   50/  518]    Overall Loss 2.835639    Objective Loss 2.835639                                        LR 0.000031    Time 0.221816    
2023-04-27 00:28:51,361 - Epoch: [164][  100/  518]    Overall Loss 2.831179    Objective Loss 2.831179                                        LR 0.000031    Time 0.213022    
2023-04-27 00:29:01,489 - Epoch: [164][  150/  518]    Overall Loss 2.834430    Objective Loss 2.834430                                        LR 0.000031    Time 0.209523    
2023-04-27 00:29:11,707 - Epoch: [164][  200/  518]    Overall Loss 2.852728    Objective Loss 2.852728                                        LR 0.000031    Time 0.208227    
2023-04-27 00:29:21,862 - Epoch: [164][  250/  518]    Overall Loss 2.860053    Objective Loss 2.860053                                        LR 0.000031    Time 0.207195    
2023-04-27 00:29:32,098 - Epoch: [164][  300/  518]    Overall Loss 2.867550    Objective Loss 2.867550                                        LR 0.000031    Time 0.206776    
2023-04-27 00:29:42,254 - Epoch: [164][  350/  518]    Overall Loss 2.858886    Objective Loss 2.858886                                        LR 0.000031    Time 0.206249    
2023-04-27 00:29:52,445 - Epoch: [164][  400/  518]    Overall Loss 2.860879    Objective Loss 2.860879                                        LR 0.000031    Time 0.205940    
2023-04-27 00:30:02,577 - Epoch: [164][  450/  518]    Overall Loss 2.857075    Objective Loss 2.857075                                        LR 0.000031    Time 0.205571    
2023-04-27 00:30:12,677 - Epoch: [164][  500/  518]    Overall Loss 2.859253    Objective Loss 2.859253                                        LR 0.000031    Time 0.205211    
2023-04-27 00:30:16,177 - Epoch: [164][  518/  518]    Overall Loss 2.857679    Objective Loss 2.857679                                        LR 0.000031    Time 0.204836    
2023-04-27 00:30:16,247 - --- validate (epoch=164)-----------
2023-04-27 00:30:16,247 - 4952 samples (32 per mini-batch)
2023-04-27 00:30:22,912 - Epoch: [164][   50/  155]    Loss 3.130228    mAP 0.449059    
2023-04-27 00:30:29,312 - Epoch: [164][  100/  155]    Loss 3.150129    mAP 0.452025    
2023-04-27 00:30:35,605 - Epoch: [164][  150/  155]    Loss 3.151751    mAP 0.451099    
2023-04-27 00:30:36,166 - Epoch: [164][  155/  155]    Loss 3.154516    mAP 0.450116    
2023-04-27 00:30:36,237 - ==> mAP: 0.45012    Loss: 3.155

2023-04-27 00:30:36,241 - ==> Best [mAP: 0.454181   vloss: 3.159736   Sparsity:0.00   Params: 2177088 on epoch: 160]
2023-04-27 00:30:36,241 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:30:36,278 - 

2023-04-27 00:30:36,278 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:30:47,200 - Epoch: [165][   50/  518]    Overall Loss 2.857006    Objective Loss 2.857006                                        LR 0.000031    Time 0.218375    
2023-04-27 00:30:57,340 - Epoch: [165][  100/  518]    Overall Loss 2.840210    Objective Loss 2.840210                                        LR 0.000031    Time 0.210573    
2023-04-27 00:31:07,616 - Epoch: [165][  150/  518]    Overall Loss 2.842085    Objective Loss 2.842085                                        LR 0.000031    Time 0.208878    
2023-04-27 00:31:17,790 - Epoch: [165][  200/  518]    Overall Loss 2.860172    Objective Loss 2.860172                                        LR 0.000031    Time 0.207523    
2023-04-27 00:31:27,909 - Epoch: [165][  250/  518]    Overall Loss 2.865786    Objective Loss 2.865786                                        LR 0.000031    Time 0.206487    
2023-04-27 00:31:38,053 - Epoch: [165][  300/  518]    Overall Loss 2.871700    Objective Loss 2.871700                                        LR 0.000031    Time 0.205880    
2023-04-27 00:31:48,203 - Epoch: [165][  350/  518]    Overall Loss 2.870087    Objective Loss 2.870087                                        LR 0.000031    Time 0.205463    
2023-04-27 00:31:58,335 - Epoch: [165][  400/  518]    Overall Loss 2.863076    Objective Loss 2.863076                                        LR 0.000031    Time 0.205106    
2023-04-27 00:32:08,437 - Epoch: [165][  450/  518]    Overall Loss 2.859500    Objective Loss 2.859500                                        LR 0.000031    Time 0.204762    
2023-04-27 00:32:18,544 - Epoch: [165][  500/  518]    Overall Loss 2.863149    Objective Loss 2.863149                                        LR 0.000031    Time 0.204497    
2023-04-27 00:32:22,069 - Epoch: [165][  518/  518]    Overall Loss 2.858591    Objective Loss 2.858591                                        LR 0.000031    Time 0.204195    
2023-04-27 00:32:22,143 - --- validate (epoch=165)-----------
2023-04-27 00:32:22,143 - 4952 samples (32 per mini-batch)
2023-04-27 00:32:28,895 - Epoch: [165][   50/  155]    Loss 3.141234    mAP 0.448034    
2023-04-27 00:32:35,267 - Epoch: [165][  100/  155]    Loss 3.143262    mAP 0.443395    
2023-04-27 00:32:41,640 - Epoch: [165][  150/  155]    Loss 3.157058    mAP 0.447408    
2023-04-27 00:32:42,209 - Epoch: [165][  155/  155]    Loss 3.155883    mAP 0.446977    
2023-04-27 00:32:42,276 - ==> mAP: 0.44698    Loss: 3.156

2023-04-27 00:32:42,280 - ==> Best [mAP: 0.454181   vloss: 3.159736   Sparsity:0.00   Params: 2177088 on epoch: 160]
2023-04-27 00:32:42,280 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:32:42,317 - 

2023-04-27 00:32:42,317 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:32:53,173 - Epoch: [166][   50/  518]    Overall Loss 2.807568    Objective Loss 2.807568                                        LR 0.000031    Time 0.217063    
2023-04-27 00:33:03,404 - Epoch: [166][  100/  518]    Overall Loss 2.835082    Objective Loss 2.835082                                        LR 0.000031    Time 0.210821    
2023-04-27 00:33:13,559 - Epoch: [166][  150/  518]    Overall Loss 2.826795    Objective Loss 2.826795                                        LR 0.000031    Time 0.208237    
2023-04-27 00:33:23,694 - Epoch: [166][  200/  518]    Overall Loss 2.838625    Objective Loss 2.838625                                        LR 0.000031    Time 0.206844    
2023-04-27 00:33:33,782 - Epoch: [166][  250/  518]    Overall Loss 2.841549    Objective Loss 2.841549                                        LR 0.000031    Time 0.205822    
2023-04-27 00:33:44,054 - Epoch: [166][  300/  518]    Overall Loss 2.842067    Objective Loss 2.842067                                        LR 0.000031    Time 0.205751    
2023-04-27 00:33:54,166 - Epoch: [166][  350/  518]    Overall Loss 2.845806    Objective Loss 2.845806                                        LR 0.000031    Time 0.205247    
2023-04-27 00:34:04,234 - Epoch: [166][  400/  518]    Overall Loss 2.853028    Objective Loss 2.853028                                        LR 0.000031    Time 0.204756    
2023-04-27 00:34:14,412 - Epoch: [166][  450/  518]    Overall Loss 2.855978    Objective Loss 2.855978                                        LR 0.000031    Time 0.204620    
2023-04-27 00:34:24,588 - Epoch: [166][  500/  518]    Overall Loss 2.860554    Objective Loss 2.860554                                        LR 0.000031    Time 0.204507    
2023-04-27 00:34:28,100 - Epoch: [166][  518/  518]    Overall Loss 2.858554    Objective Loss 2.858554                                        LR 0.000031    Time 0.204178    
2023-04-27 00:34:28,171 - --- validate (epoch=166)-----------
2023-04-27 00:34:28,171 - 4952 samples (32 per mini-batch)
2023-04-27 00:34:34,908 - Epoch: [166][   50/  155]    Loss 3.138660    mAP 0.441576    
2023-04-27 00:34:41,250 - Epoch: [166][  100/  155]    Loss 3.144442    mAP 0.447110    
2023-04-27 00:34:47,625 - Epoch: [166][  150/  155]    Loss 3.155461    mAP 0.445329    
2023-04-27 00:34:48,209 - Epoch: [166][  155/  155]    Loss 3.155332    mAP 0.445581    
2023-04-27 00:34:48,279 - ==> mAP: 0.44558    Loss: 3.155

2023-04-27 00:34:48,283 - ==> Best [mAP: 0.454181   vloss: 3.159736   Sparsity:0.00   Params: 2177088 on epoch: 160]
2023-04-27 00:34:48,283 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:34:48,320 - 

2023-04-27 00:34:48,320 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:34:59,219 - Epoch: [167][   50/  518]    Overall Loss 2.803489    Objective Loss 2.803489                                        LR 0.000031    Time 0.217916    
2023-04-27 00:35:09,395 - Epoch: [167][  100/  518]    Overall Loss 2.847794    Objective Loss 2.847794                                        LR 0.000031    Time 0.210703    
2023-04-27 00:35:19,606 - Epoch: [167][  150/  518]    Overall Loss 2.856434    Objective Loss 2.856434                                        LR 0.000031    Time 0.208534    
2023-04-27 00:35:29,792 - Epoch: [167][  200/  518]    Overall Loss 2.852460    Objective Loss 2.852460                                        LR 0.000031    Time 0.207319    
2023-04-27 00:35:39,899 - Epoch: [167][  250/  518]    Overall Loss 2.853619    Objective Loss 2.853619                                        LR 0.000031    Time 0.206278    
2023-04-27 00:35:50,077 - Epoch: [167][  300/  518]    Overall Loss 2.857180    Objective Loss 2.857180                                        LR 0.000031    Time 0.205820    
2023-04-27 00:36:00,196 - Epoch: [167][  350/  518]    Overall Loss 2.856976    Objective Loss 2.856976                                        LR 0.000031    Time 0.205323    
2023-04-27 00:36:10,362 - Epoch: [167][  400/  518]    Overall Loss 2.857799    Objective Loss 2.857799                                        LR 0.000031    Time 0.205070    
2023-04-27 00:36:20,535 - Epoch: [167][  450/  518]    Overall Loss 2.855267    Objective Loss 2.855267                                        LR 0.000031    Time 0.204886    
2023-04-27 00:36:30,678 - Epoch: [167][  500/  518]    Overall Loss 2.861540    Objective Loss 2.861540                                        LR 0.000031    Time 0.204680    
2023-04-27 00:36:34,213 - Epoch: [167][  518/  518]    Overall Loss 2.859988    Objective Loss 2.859988                                        LR 0.000031    Time 0.204391    
2023-04-27 00:36:34,285 - --- validate (epoch=167)-----------
2023-04-27 00:36:34,285 - 4952 samples (32 per mini-batch)
2023-04-27 00:36:40,963 - Epoch: [167][   50/  155]    Loss 3.165576    mAP 0.441557    
2023-04-27 00:36:47,373 - Epoch: [167][  100/  155]    Loss 3.166564    mAP 0.454865    
2023-04-27 00:36:53,702 - Epoch: [167][  150/  155]    Loss 3.151835    mAP 0.454654    
2023-04-27 00:36:54,277 - Epoch: [167][  155/  155]    Loss 3.152132    mAP 0.452565    
2023-04-27 00:36:54,347 - ==> mAP: 0.45257    Loss: 3.152

2023-04-27 00:36:54,351 - ==> Best [mAP: 0.454181   vloss: 3.159736   Sparsity:0.00   Params: 2177088 on epoch: 160]
2023-04-27 00:36:54,351 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:36:54,388 - 

2023-04-27 00:36:54,388 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:37:05,315 - Epoch: [168][   50/  518]    Overall Loss 2.845920    Objective Loss 2.845920                                        LR 0.000031    Time 0.218487    
2023-04-27 00:37:15,451 - Epoch: [168][  100/  518]    Overall Loss 2.851537    Objective Loss 2.851537                                        LR 0.000031    Time 0.210585    
2023-04-27 00:37:25,601 - Epoch: [168][  150/  518]    Overall Loss 2.849907    Objective Loss 2.849907                                        LR 0.000031    Time 0.208044    
2023-04-27 00:37:35,770 - Epoch: [168][  200/  518]    Overall Loss 2.857140    Objective Loss 2.857140                                        LR 0.000031    Time 0.206871    
2023-04-27 00:37:45,953 - Epoch: [168][  250/  518]    Overall Loss 2.858097    Objective Loss 2.858097                                        LR 0.000031    Time 0.206221    
2023-04-27 00:37:56,040 - Epoch: [168][  300/  518]    Overall Loss 2.857136    Objective Loss 2.857136                                        LR 0.000031    Time 0.205470    
2023-04-27 00:38:06,223 - Epoch: [168][  350/  518]    Overall Loss 2.858030    Objective Loss 2.858030                                        LR 0.000031    Time 0.205207    
2023-04-27 00:38:16,332 - Epoch: [168][  400/  518]    Overall Loss 2.858022    Objective Loss 2.858022                                        LR 0.000031    Time 0.204825    
2023-04-27 00:38:26,477 - Epoch: [168][  450/  518]    Overall Loss 2.856679    Objective Loss 2.856679                                        LR 0.000031    Time 0.204607    
2023-04-27 00:38:36,592 - Epoch: [168][  500/  518]    Overall Loss 2.855530    Objective Loss 2.855530                                        LR 0.000031    Time 0.204374    
2023-04-27 00:38:40,133 - Epoch: [168][  518/  518]    Overall Loss 2.857787    Objective Loss 2.857787                                        LR 0.000031    Time 0.204106    
2023-04-27 00:38:40,203 - --- validate (epoch=168)-----------
2023-04-27 00:38:40,204 - 4952 samples (32 per mini-batch)
2023-04-27 00:38:46,939 - Epoch: [168][   50/  155]    Loss 3.164496    mAP 0.457708    
2023-04-27 00:38:53,342 - Epoch: [168][  100/  155]    Loss 3.156144    mAP 0.453287    
2023-04-27 00:38:59,703 - Epoch: [168][  150/  155]    Loss 3.151699    mAP 0.457004    
2023-04-27 00:39:00,280 - Epoch: [168][  155/  155]    Loss 3.151359    mAP 0.457598    
2023-04-27 00:39:00,351 - ==> mAP: 0.45760    Loss: 3.151

2023-04-27 00:39:00,355 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 00:39:00,355 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:39:00,408 - 

2023-04-27 00:39:00,408 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:39:11,385 - Epoch: [169][   50/  518]    Overall Loss 2.888846    Objective Loss 2.888846                                        LR 0.000031    Time 0.219489    
2023-04-27 00:39:21,555 - Epoch: [169][  100/  518]    Overall Loss 2.864906    Objective Loss 2.864906                                        LR 0.000031    Time 0.211424    
2023-04-27 00:39:31,694 - Epoch: [169][  150/  518]    Overall Loss 2.867120    Objective Loss 2.867120                                        LR 0.000031    Time 0.208533    
2023-04-27 00:39:41,803 - Epoch: [169][  200/  518]    Overall Loss 2.875372    Objective Loss 2.875372                                        LR 0.000031    Time 0.206935    
2023-04-27 00:39:52,052 - Epoch: [169][  250/  518]    Overall Loss 2.869170    Objective Loss 2.869170                                        LR 0.000031    Time 0.206539    
2023-04-27 00:40:02,165 - Epoch: [169][  300/  518]    Overall Loss 2.872670    Objective Loss 2.872670                                        LR 0.000031    Time 0.205821    
2023-04-27 00:40:12,375 - Epoch: [169][  350/  518]    Overall Loss 2.870152    Objective Loss 2.870152                                        LR 0.000031    Time 0.205585    
2023-04-27 00:40:22,455 - Epoch: [169][  400/  518]    Overall Loss 2.868705    Objective Loss 2.868705                                        LR 0.000031    Time 0.205082    
2023-04-27 00:40:32,609 - Epoch: [169][  450/  518]    Overall Loss 2.854357    Objective Loss 2.854357                                        LR 0.000031    Time 0.204856    
2023-04-27 00:40:42,684 - Epoch: [169][  500/  518]    Overall Loss 2.850419    Objective Loss 2.850419                                        LR 0.000031    Time 0.204518    
2023-04-27 00:40:46,214 - Epoch: [169][  518/  518]    Overall Loss 2.852384    Objective Loss 2.852384                                        LR 0.000031    Time 0.204224    
2023-04-27 00:40:46,286 - --- validate (epoch=169)-----------
2023-04-27 00:40:46,287 - 4952 samples (32 per mini-batch)
2023-04-27 00:40:52,994 - Epoch: [169][   50/  155]    Loss 3.144399    mAP 0.444134    
2023-04-27 00:40:59,323 - Epoch: [169][  100/  155]    Loss 3.137222    mAP 0.444477    
2023-04-27 00:41:05,665 - Epoch: [169][  150/  155]    Loss 3.157119    mAP 0.440898    
2023-04-27 00:41:06,238 - Epoch: [169][  155/  155]    Loss 3.152611    mAP 0.440601    
2023-04-27 00:41:06,301 - ==> mAP: 0.44060    Loss: 3.153

2023-04-27 00:41:06,306 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 00:41:06,306 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:41:06,343 - 

2023-04-27 00:41:06,343 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:41:17,201 - Epoch: [170][   50/  518]    Overall Loss 2.839039    Objective Loss 2.839039                                        LR 0.000031    Time 0.217108    
2023-04-27 00:41:27,336 - Epoch: [170][  100/  518]    Overall Loss 2.846259    Objective Loss 2.846259                                        LR 0.000031    Time 0.209886    
2023-04-27 00:41:37,485 - Epoch: [170][  150/  518]    Overall Loss 2.840455    Objective Loss 2.840455                                        LR 0.000031    Time 0.207572    
2023-04-27 00:41:47,630 - Epoch: [170][  200/  518]    Overall Loss 2.851489    Objective Loss 2.851489                                        LR 0.000031    Time 0.206397    
2023-04-27 00:41:57,711 - Epoch: [170][  250/  518]    Overall Loss 2.849784    Objective Loss 2.849784                                        LR 0.000031    Time 0.205432    
2023-04-27 00:42:07,875 - Epoch: [170][  300/  518]    Overall Loss 2.848639    Objective Loss 2.848639                                        LR 0.000031    Time 0.205068    
2023-04-27 00:42:17,947 - Epoch: [170][  350/  518]    Overall Loss 2.844181    Objective Loss 2.844181                                        LR 0.000031    Time 0.204546    
2023-04-27 00:42:28,075 - Epoch: [170][  400/  518]    Overall Loss 2.844152    Objective Loss 2.844152                                        LR 0.000031    Time 0.204294    
2023-04-27 00:42:38,225 - Epoch: [170][  450/  518]    Overall Loss 2.839913    Objective Loss 2.839913                                        LR 0.000031    Time 0.204147    
2023-04-27 00:42:48,463 - Epoch: [170][  500/  518]    Overall Loss 2.843605    Objective Loss 2.843605                                        LR 0.000031    Time 0.204204    
2023-04-27 00:42:52,008 - Epoch: [170][  518/  518]    Overall Loss 2.843284    Objective Loss 2.843284                                        LR 0.000031    Time 0.203952    
2023-04-27 00:42:52,079 - --- validate (epoch=170)-----------
2023-04-27 00:42:52,079 - 4952 samples (32 per mini-batch)
2023-04-27 00:42:58,763 - Epoch: [170][   50/  155]    Loss 3.144961    mAP 0.436328    
2023-04-27 00:43:05,168 - Epoch: [170][  100/  155]    Loss 3.161740    mAP 0.441800    
2023-04-27 00:43:11,534 - Epoch: [170][  150/  155]    Loss 3.160455    mAP 0.437091    
2023-04-27 00:43:12,107 - Epoch: [170][  155/  155]    Loss 3.157406    mAP 0.438111    
2023-04-27 00:43:12,175 - ==> mAP: 0.43811    Loss: 3.157

2023-04-27 00:43:12,179 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 00:43:12,179 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:43:12,216 - 

2023-04-27 00:43:12,217 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:43:23,085 - Epoch: [171][   50/  518]    Overall Loss 2.862185    Objective Loss 2.862185                                        LR 0.000031    Time 0.217312    
2023-04-27 00:43:33,178 - Epoch: [171][  100/  518]    Overall Loss 2.839396    Objective Loss 2.839396                                        LR 0.000031    Time 0.209564    
2023-04-27 00:43:43,303 - Epoch: [171][  150/  518]    Overall Loss 2.837212    Objective Loss 2.837212                                        LR 0.000031    Time 0.207201    
2023-04-27 00:43:53,470 - Epoch: [171][  200/  518]    Overall Loss 2.850501    Objective Loss 2.850501                                        LR 0.000031    Time 0.206228    
2023-04-27 00:44:03,624 - Epoch: [171][  250/  518]    Overall Loss 2.855030    Objective Loss 2.855030                                        LR 0.000031    Time 0.205591    
2023-04-27 00:44:13,796 - Epoch: [171][  300/  518]    Overall Loss 2.853232    Objective Loss 2.853232                                        LR 0.000031    Time 0.205229    
2023-04-27 00:44:23,996 - Epoch: [171][  350/  518]    Overall Loss 2.850696    Objective Loss 2.850696                                        LR 0.000031    Time 0.205047    
2023-04-27 00:44:34,180 - Epoch: [171][  400/  518]    Overall Loss 2.855420    Objective Loss 2.855420                                        LR 0.000031    Time 0.204873    
2023-04-27 00:44:44,345 - Epoch: [171][  450/  518]    Overall Loss 2.848515    Objective Loss 2.848515                                        LR 0.000031    Time 0.204693    
2023-04-27 00:44:54,491 - Epoch: [171][  500/  518]    Overall Loss 2.853095    Objective Loss 2.853095                                        LR 0.000031    Time 0.204513    
2023-04-27 00:44:58,038 - Epoch: [171][  518/  518]    Overall Loss 2.852798    Objective Loss 2.852798                                        LR 0.000031    Time 0.204252    
2023-04-27 00:44:58,109 - --- validate (epoch=171)-----------
2023-04-27 00:44:58,109 - 4952 samples (32 per mini-batch)
2023-04-27 00:45:04,886 - Epoch: [171][   50/  155]    Loss 3.144199    mAP 0.462704    
2023-04-27 00:45:11,291 - Epoch: [171][  100/  155]    Loss 3.155053    mAP 0.453770    
2023-04-27 00:45:17,687 - Epoch: [171][  150/  155]    Loss 3.156220    mAP 0.451157    
2023-04-27 00:45:18,255 - Epoch: [171][  155/  155]    Loss 3.153890    mAP 0.451720    
2023-04-27 00:45:18,325 - ==> mAP: 0.45172    Loss: 3.154

2023-04-27 00:45:18,329 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 00:45:18,329 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:45:18,366 - 

2023-04-27 00:45:18,366 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:45:29,254 - Epoch: [172][   50/  518]    Overall Loss 2.808546    Objective Loss 2.808546                                        LR 0.000031    Time 0.217712    
2023-04-27 00:45:39,393 - Epoch: [172][  100/  518]    Overall Loss 2.828036    Objective Loss 2.828036                                        LR 0.000031    Time 0.210226    
2023-04-27 00:45:49,536 - Epoch: [172][  150/  518]    Overall Loss 2.841280    Objective Loss 2.841280                                        LR 0.000031    Time 0.207762    
2023-04-27 00:45:59,810 - Epoch: [172][  200/  518]    Overall Loss 2.850216    Objective Loss 2.850216                                        LR 0.000031    Time 0.207182    
2023-04-27 00:46:09,930 - Epoch: [172][  250/  518]    Overall Loss 2.861730    Objective Loss 2.861730                                        LR 0.000031    Time 0.206220    
2023-04-27 00:46:20,068 - Epoch: [172][  300/  518]    Overall Loss 2.844378    Objective Loss 2.844378                                        LR 0.000031    Time 0.205636    
2023-04-27 00:46:30,178 - Epoch: [172][  350/  518]    Overall Loss 2.846242    Objective Loss 2.846242                                        LR 0.000031    Time 0.205141    
2023-04-27 00:46:40,295 - Epoch: [172][  400/  518]    Overall Loss 2.850922    Objective Loss 2.850922                                        LR 0.000031    Time 0.204786    
2023-04-27 00:46:50,420 - Epoch: [172][  450/  518]    Overall Loss 2.855720    Objective Loss 2.855720                                        LR 0.000031    Time 0.204529    
2023-04-27 00:47:00,612 - Epoch: [172][  500/  518]    Overall Loss 2.852985    Objective Loss 2.852985                                        LR 0.000031    Time 0.204457    
2023-04-27 00:47:04,168 - Epoch: [172][  518/  518]    Overall Loss 2.850571    Objective Loss 2.850571                                        LR 0.000031    Time 0.204216    
2023-04-27 00:47:04,239 - --- validate (epoch=172)-----------
2023-04-27 00:47:04,240 - 4952 samples (32 per mini-batch)
2023-04-27 00:47:10,998 - Epoch: [172][   50/  155]    Loss 3.165273    mAP 0.454323    
2023-04-27 00:47:17,361 - Epoch: [172][  100/  155]    Loss 3.163832    mAP 0.445922    
2023-04-27 00:47:23,751 - Epoch: [172][  150/  155]    Loss 3.162536    mAP 0.450693    
2023-04-27 00:47:24,321 - Epoch: [172][  155/  155]    Loss 3.155610    mAP 0.451582    
2023-04-27 00:47:24,391 - ==> mAP: 0.45158    Loss: 3.156

2023-04-27 00:47:24,395 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 00:47:24,395 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:47:24,432 - 

2023-04-27 00:47:24,432 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:47:35,381 - Epoch: [173][   50/  518]    Overall Loss 2.837142    Objective Loss 2.837142                                        LR 0.000031    Time 0.218914    
2023-04-27 00:47:45,491 - Epoch: [173][  100/  518]    Overall Loss 2.857301    Objective Loss 2.857301                                        LR 0.000031    Time 0.210545    
2023-04-27 00:47:55,603 - Epoch: [173][  150/  518]    Overall Loss 2.873301    Objective Loss 2.873301                                        LR 0.000031    Time 0.207765    
2023-04-27 00:48:05,781 - Epoch: [173][  200/  518]    Overall Loss 2.851107    Objective Loss 2.851107                                        LR 0.000031    Time 0.206703    
2023-04-27 00:48:15,947 - Epoch: [173][  250/  518]    Overall Loss 2.839771    Objective Loss 2.839771                                        LR 0.000031    Time 0.206020    
2023-04-27 00:48:26,118 - Epoch: [173][  300/  518]    Overall Loss 2.836157    Objective Loss 2.836157                                        LR 0.000031    Time 0.205584    
2023-04-27 00:48:36,281 - Epoch: [173][  350/  518]    Overall Loss 2.833630    Objective Loss 2.833630                                        LR 0.000031    Time 0.205245    
2023-04-27 00:48:46,453 - Epoch: [173][  400/  518]    Overall Loss 2.842963    Objective Loss 2.842963                                        LR 0.000031    Time 0.205016    
2023-04-27 00:48:56,553 - Epoch: [173][  450/  518]    Overall Loss 2.846643    Objective Loss 2.846643                                        LR 0.000031    Time 0.204677    
2023-04-27 00:49:06,761 - Epoch: [173][  500/  518]    Overall Loss 2.849285    Objective Loss 2.849285                                        LR 0.000031    Time 0.204623    
2023-04-27 00:49:10,292 - Epoch: [173][  518/  518]    Overall Loss 2.853034    Objective Loss 2.853034                                        LR 0.000031    Time 0.204328    
2023-04-27 00:49:10,364 - --- validate (epoch=173)-----------
2023-04-27 00:49:10,364 - 4952 samples (32 per mini-batch)
2023-04-27 00:49:17,127 - Epoch: [173][   50/  155]    Loss 3.155101    mAP 0.451752    
2023-04-27 00:49:23,467 - Epoch: [173][  100/  155]    Loss 3.158489    mAP 0.445015    
2023-04-27 00:49:29,839 - Epoch: [173][  150/  155]    Loss 3.146680    mAP 0.444556    
2023-04-27 00:49:30,408 - Epoch: [173][  155/  155]    Loss 3.151280    mAP 0.444441    
2023-04-27 00:49:30,479 - ==> mAP: 0.44444    Loss: 3.151

2023-04-27 00:49:30,483 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 00:49:30,483 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:49:30,521 - 

2023-04-27 00:49:30,521 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:49:41,336 - Epoch: [174][   50/  518]    Overall Loss 2.858481    Objective Loss 2.858481                                        LR 0.000031    Time 0.216239    
2023-04-27 00:49:51,547 - Epoch: [174][  100/  518]    Overall Loss 2.812947    Objective Loss 2.812947                                        LR 0.000031    Time 0.210219    
2023-04-27 00:50:01,713 - Epoch: [174][  150/  518]    Overall Loss 2.821116    Objective Loss 2.821116                                        LR 0.000031    Time 0.207909    
2023-04-27 00:50:11,889 - Epoch: [174][  200/  518]    Overall Loss 2.832866    Objective Loss 2.832866                                        LR 0.000031    Time 0.206803    
2023-04-27 00:50:22,072 - Epoch: [174][  250/  518]    Overall Loss 2.833703    Objective Loss 2.833703                                        LR 0.000031    Time 0.206169    
2023-04-27 00:50:32,189 - Epoch: [174][  300/  518]    Overall Loss 2.840062    Objective Loss 2.840062                                        LR 0.000031    Time 0.205525    
2023-04-27 00:50:42,314 - Epoch: [174][  350/  518]    Overall Loss 2.839347    Objective Loss 2.839347                                        LR 0.000031    Time 0.205086    
2023-04-27 00:50:52,434 - Epoch: [174][  400/  518]    Overall Loss 2.842846    Objective Loss 2.842846                                        LR 0.000031    Time 0.204746    
2023-04-27 00:51:02,571 - Epoch: [174][  450/  518]    Overall Loss 2.846188    Objective Loss 2.846188                                        LR 0.000031    Time 0.204521    
2023-04-27 00:51:12,670 - Epoch: [174][  500/  518]    Overall Loss 2.845268    Objective Loss 2.845268                                        LR 0.000031    Time 0.204264    
2023-04-27 00:51:16,181 - Epoch: [174][  518/  518]    Overall Loss 2.847802    Objective Loss 2.847802                                        LR 0.000031    Time 0.203942    
2023-04-27 00:51:16,252 - --- validate (epoch=174)-----------
2023-04-27 00:51:16,253 - 4952 samples (32 per mini-batch)
2023-04-27 00:51:22,938 - Epoch: [174][   50/  155]    Loss 3.117370    mAP 0.436337    
2023-04-27 00:51:29,328 - Epoch: [174][  100/  155]    Loss 3.144142    mAP 0.438554    
2023-04-27 00:51:35,727 - Epoch: [174][  150/  155]    Loss 3.160601    mAP 0.438156    
2023-04-27 00:51:36,285 - Epoch: [174][  155/  155]    Loss 3.156397    mAP 0.436472    
2023-04-27 00:51:36,365 - ==> mAP: 0.43647    Loss: 3.156

2023-04-27 00:51:36,369 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 00:51:36,369 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:51:36,406 - 

2023-04-27 00:51:36,406 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:51:47,246 - Epoch: [175][   50/  518]    Overall Loss 2.839689    Objective Loss 2.839689                                        LR 0.000031    Time 0.216739    
2023-04-27 00:51:57,428 - Epoch: [175][  100/  518]    Overall Loss 2.854767    Objective Loss 2.854767                                        LR 0.000031    Time 0.210172    
2023-04-27 00:52:07,446 - Epoch: [175][  150/  518]    Overall Loss 2.848810    Objective Loss 2.848810                                        LR 0.000031    Time 0.206892    
2023-04-27 00:52:17,540 - Epoch: [175][  200/  518]    Overall Loss 2.861578    Objective Loss 2.861578                                        LR 0.000031    Time 0.205631    
2023-04-27 00:52:27,781 - Epoch: [175][  250/  518]    Overall Loss 2.860024    Objective Loss 2.860024                                        LR 0.000031    Time 0.205463    
2023-04-27 00:52:37,893 - Epoch: [175][  300/  518]    Overall Loss 2.856373    Objective Loss 2.856373                                        LR 0.000031    Time 0.204919    
2023-04-27 00:52:48,076 - Epoch: [175][  350/  518]    Overall Loss 2.860245    Objective Loss 2.860245                                        LR 0.000031    Time 0.204734    
2023-04-27 00:52:58,269 - Epoch: [175][  400/  518]    Overall Loss 2.852913    Objective Loss 2.852913                                        LR 0.000031    Time 0.204620    
2023-04-27 00:53:08,418 - Epoch: [175][  450/  518]    Overall Loss 2.852823    Objective Loss 2.852823                                        LR 0.000031    Time 0.204436    
2023-04-27 00:53:18,504 - Epoch: [175][  500/  518]    Overall Loss 2.850238    Objective Loss 2.850238                                        LR 0.000031    Time 0.204160    
2023-04-27 00:53:22,034 - Epoch: [175][  518/  518]    Overall Loss 2.850722    Objective Loss 2.850722                                        LR 0.000031    Time 0.203879    
2023-04-27 00:53:22,107 - --- validate (epoch=175)-----------
2023-04-27 00:53:22,108 - 4952 samples (32 per mini-batch)
2023-04-27 00:53:28,821 - Epoch: [175][   50/  155]    Loss 3.177828    mAP 0.448367    
2023-04-27 00:53:35,191 - Epoch: [175][  100/  155]    Loss 3.177447    mAP 0.446042    
2023-04-27 00:53:41,492 - Epoch: [175][  150/  155]    Loss 3.152630    mAP 0.451076    
2023-04-27 00:53:42,064 - Epoch: [175][  155/  155]    Loss 3.154214    mAP 0.451349    
2023-04-27 00:53:42,135 - ==> mAP: 0.45135    Loss: 3.154

2023-04-27 00:53:42,139 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 00:53:42,139 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:53:42,176 - 

2023-04-27 00:53:42,176 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:53:52,989 - Epoch: [176][   50/  518]    Overall Loss 2.875472    Objective Loss 2.875472                                        LR 0.000031    Time 0.216200    
2023-04-27 00:54:03,097 - Epoch: [176][  100/  518]    Overall Loss 2.874252    Objective Loss 2.874252                                        LR 0.000031    Time 0.209162    
2023-04-27 00:54:13,203 - Epoch: [176][  150/  518]    Overall Loss 2.857343    Objective Loss 2.857343                                        LR 0.000031    Time 0.206804    
2023-04-27 00:54:23,408 - Epoch: [176][  200/  518]    Overall Loss 2.861214    Objective Loss 2.861214                                        LR 0.000031    Time 0.206118    
2023-04-27 00:54:33,566 - Epoch: [176][  250/  518]    Overall Loss 2.865233    Objective Loss 2.865233                                        LR 0.000031    Time 0.205518    
2023-04-27 00:54:43,656 - Epoch: [176][  300/  518]    Overall Loss 2.864304    Objective Loss 2.864304                                        LR 0.000031    Time 0.204892    
2023-04-27 00:54:53,858 - Epoch: [176][  350/  518]    Overall Loss 2.852848    Objective Loss 2.852848                                        LR 0.000031    Time 0.204768    
2023-04-27 00:55:03,967 - Epoch: [176][  400/  518]    Overall Loss 2.841926    Objective Loss 2.841926                                        LR 0.000031    Time 0.204440    
2023-04-27 00:55:14,116 - Epoch: [176][  450/  518]    Overall Loss 2.843482    Objective Loss 2.843482                                        LR 0.000031    Time 0.204274    
2023-04-27 00:55:24,319 - Epoch: [176][  500/  518]    Overall Loss 2.847808    Objective Loss 2.847808                                        LR 0.000031    Time 0.204249    
2023-04-27 00:55:27,827 - Epoch: [176][  518/  518]    Overall Loss 2.849151    Objective Loss 2.849151                                        LR 0.000031    Time 0.203922    
2023-04-27 00:55:27,898 - --- validate (epoch=176)-----------
2023-04-27 00:55:27,898 - 4952 samples (32 per mini-batch)
2023-04-27 00:55:34,694 - Epoch: [176][   50/  155]    Loss 3.139897    mAP 0.441269    
2023-04-27 00:55:41,140 - Epoch: [176][  100/  155]    Loss 3.154784    mAP 0.436179    
2023-04-27 00:55:47,547 - Epoch: [176][  150/  155]    Loss 3.154133    mAP 0.443637    
2023-04-27 00:55:48,116 - Epoch: [176][  155/  155]    Loss 3.153621    mAP 0.444955    
2023-04-27 00:55:48,195 - ==> mAP: 0.44496    Loss: 3.154

2023-04-27 00:55:48,199 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 00:55:48,199 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:55:48,236 - 

2023-04-27 00:55:48,236 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:55:59,119 - Epoch: [177][   50/  518]    Overall Loss 2.892882    Objective Loss 2.892882                                        LR 0.000031    Time 0.217589    
2023-04-27 00:56:09,307 - Epoch: [177][  100/  518]    Overall Loss 2.881696    Objective Loss 2.881696                                        LR 0.000031    Time 0.210663    
2023-04-27 00:56:19,451 - Epoch: [177][  150/  518]    Overall Loss 2.856772    Objective Loss 2.856772                                        LR 0.000031    Time 0.208055    
2023-04-27 00:56:29,600 - Epoch: [177][  200/  518]    Overall Loss 2.848390    Objective Loss 2.848390                                        LR 0.000031    Time 0.206782    
2023-04-27 00:56:39,711 - Epoch: [177][  250/  518]    Overall Loss 2.850863    Objective Loss 2.850863                                        LR 0.000031    Time 0.205863    
2023-04-27 00:56:49,773 - Epoch: [177][  300/  518]    Overall Loss 2.852361    Objective Loss 2.852361                                        LR 0.000031    Time 0.205085    
2023-04-27 00:56:59,916 - Epoch: [177][  350/  518]    Overall Loss 2.853101    Objective Loss 2.853101                                        LR 0.000031    Time 0.204761    
2023-04-27 00:57:10,097 - Epoch: [177][  400/  518]    Overall Loss 2.849402    Objective Loss 2.849402                                        LR 0.000031    Time 0.204617    
2023-04-27 00:57:20,260 - Epoch: [177][  450/  518]    Overall Loss 2.848345    Objective Loss 2.848345                                        LR 0.000031    Time 0.204462    
2023-04-27 00:57:30,514 - Epoch: [177][  500/  518]    Overall Loss 2.854337    Objective Loss 2.854337                                        LR 0.000031    Time 0.204520    
2023-04-27 00:57:34,028 - Epoch: [177][  518/  518]    Overall Loss 2.856589    Objective Loss 2.856589                                        LR 0.000031    Time 0.204196    
2023-04-27 00:57:34,100 - --- validate (epoch=177)-----------
2023-04-27 00:57:34,100 - 4952 samples (32 per mini-batch)
2023-04-27 00:57:40,894 - Epoch: [177][   50/  155]    Loss 3.177972    mAP 0.457768    
2023-04-27 00:57:47,295 - Epoch: [177][  100/  155]    Loss 3.154313    mAP 0.459177    
2023-04-27 00:57:53,622 - Epoch: [177][  150/  155]    Loss 3.159434    mAP 0.451917    
2023-04-27 00:57:54,195 - Epoch: [177][  155/  155]    Loss 3.154004    mAP 0.452733    
2023-04-27 00:57:54,274 - ==> mAP: 0.45273    Loss: 3.154

2023-04-27 00:57:54,278 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 00:57:54,278 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 00:57:54,316 - 

2023-04-27 00:57:54,316 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 00:58:05,120 - Epoch: [178][   50/  518]    Overall Loss 2.839772    Objective Loss 2.839772                                        LR 0.000031    Time 0.216025    
2023-04-27 00:58:15,311 - Epoch: [178][  100/  518]    Overall Loss 2.829271    Objective Loss 2.829271                                        LR 0.000031    Time 0.209910    
2023-04-27 00:58:25,501 - Epoch: [178][  150/  518]    Overall Loss 2.837304    Objective Loss 2.837304                                        LR 0.000031    Time 0.207859    
2023-04-27 00:58:35,644 - Epoch: [178][  200/  518]    Overall Loss 2.848324    Objective Loss 2.848324                                        LR 0.000031    Time 0.206601    
2023-04-27 00:58:45,789 - Epoch: [178][  250/  518]    Overall Loss 2.843283    Objective Loss 2.843283                                        LR 0.000031    Time 0.205855    
2023-04-27 00:58:55,996 - Epoch: [178][  300/  518]    Overall Loss 2.844621    Objective Loss 2.844621                                        LR 0.000031    Time 0.205562    
2023-04-27 00:59:06,183 - Epoch: [178][  350/  518]    Overall Loss 2.845546    Objective Loss 2.845546                                        LR 0.000031    Time 0.205298    
2023-04-27 00:59:16,283 - Epoch: [178][  400/  518]    Overall Loss 2.851094    Objective Loss 2.851094                                        LR 0.000031    Time 0.204881    
2023-04-27 00:59:26,462 - Epoch: [178][  450/  518]    Overall Loss 2.846385    Objective Loss 2.846385                                        LR 0.000031    Time 0.204733    
2023-04-27 00:59:36,710 - Epoch: [178][  500/  518]    Overall Loss 2.842960    Objective Loss 2.842960                                        LR 0.000031    Time 0.204753    
2023-04-27 00:59:40,270 - Epoch: [178][  518/  518]    Overall Loss 2.846643    Objective Loss 2.846643                                        LR 0.000031    Time 0.204509    
2023-04-27 00:59:40,343 - --- validate (epoch=178)-----------
2023-04-27 00:59:40,344 - 4952 samples (32 per mini-batch)
2023-04-27 00:59:47,117 - Epoch: [178][   50/  155]    Loss 3.147992    mAP 0.449395    
2023-04-27 00:59:53,545 - Epoch: [178][  100/  155]    Loss 3.154691    mAP 0.456374    
2023-04-27 00:59:59,953 - Epoch: [178][  150/  155]    Loss 3.157242    mAP 0.455650    
2023-04-27 01:00:00,531 - Epoch: [178][  155/  155]    Loss 3.158572    mAP 0.455131    
2023-04-27 01:00:00,591 - ==> mAP: 0.45513    Loss: 3.159

2023-04-27 01:00:00,595 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 01:00:00,595 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:00:00,632 - 

2023-04-27 01:00:00,632 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:00:11,692 - Epoch: [179][   50/  518]    Overall Loss 2.891975    Objective Loss 2.891975                                        LR 0.000031    Time 0.221142    
2023-04-27 01:00:21,819 - Epoch: [179][  100/  518]    Overall Loss 2.859409    Objective Loss 2.859409                                        LR 0.000031    Time 0.211820    
2023-04-27 01:00:31,923 - Epoch: [179][  150/  518]    Overall Loss 2.852555    Objective Loss 2.852555                                        LR 0.000031    Time 0.208567    
2023-04-27 01:00:42,115 - Epoch: [179][  200/  518]    Overall Loss 2.842469    Objective Loss 2.842469                                        LR 0.000031    Time 0.207375    
2023-04-27 01:00:52,231 - Epoch: [179][  250/  518]    Overall Loss 2.849682    Objective Loss 2.849682                                        LR 0.000031    Time 0.206355    
2023-04-27 01:01:02,433 - Epoch: [179][  300/  518]    Overall Loss 2.840946    Objective Loss 2.840946                                        LR 0.000031    Time 0.205966    
2023-04-27 01:01:12,604 - Epoch: [179][  350/  518]    Overall Loss 2.840138    Objective Loss 2.840138                                        LR 0.000031    Time 0.205598    
2023-04-27 01:01:22,748 - Epoch: [179][  400/  518]    Overall Loss 2.847532    Objective Loss 2.847532                                        LR 0.000031    Time 0.205253    
2023-04-27 01:01:32,841 - Epoch: [179][  450/  518]    Overall Loss 2.850035    Objective Loss 2.850035                                        LR 0.000031    Time 0.204872    
2023-04-27 01:01:42,935 - Epoch: [179][  500/  518]    Overall Loss 2.846841    Objective Loss 2.846841                                        LR 0.000031    Time 0.204570    
2023-04-27 01:01:46,470 - Epoch: [179][  518/  518]    Overall Loss 2.847783    Objective Loss 2.847783                                        LR 0.000031    Time 0.204285    
2023-04-27 01:01:46,541 - --- validate (epoch=179)-----------
2023-04-27 01:01:46,542 - 4952 samples (32 per mini-batch)
2023-04-27 01:01:53,297 - Epoch: [179][   50/  155]    Loss 3.136510    mAP 0.456279    
2023-04-27 01:01:59,677 - Epoch: [179][  100/  155]    Loss 3.144357    mAP 0.450723    
2023-04-27 01:02:06,049 - Epoch: [179][  150/  155]    Loss 3.156402    mAP 0.446476    
2023-04-27 01:02:06,603 - Epoch: [179][  155/  155]    Loss 3.154249    mAP 0.447559    
2023-04-27 01:02:06,670 - ==> mAP: 0.44756    Loss: 3.154

2023-04-27 01:02:06,675 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 01:02:06,675 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:02:06,713 - 

2023-04-27 01:02:06,713 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:02:17,727 - Epoch: [180][   50/  518]    Overall Loss 2.878138    Objective Loss 2.878138                                        LR 0.000031    Time 0.220227    
2023-04-27 01:02:27,862 - Epoch: [180][  100/  518]    Overall Loss 2.855433    Objective Loss 2.855433                                        LR 0.000031    Time 0.211444    
2023-04-27 01:02:38,006 - Epoch: [180][  150/  518]    Overall Loss 2.861258    Objective Loss 2.861258                                        LR 0.000031    Time 0.208579    
2023-04-27 01:02:48,141 - Epoch: [180][  200/  518]    Overall Loss 2.872487    Objective Loss 2.872487                                        LR 0.000031    Time 0.207104    
2023-04-27 01:02:58,384 - Epoch: [180][  250/  518]    Overall Loss 2.860555    Objective Loss 2.860555                                        LR 0.000031    Time 0.206648    
2023-04-27 01:03:08,528 - Epoch: [180][  300/  518]    Overall Loss 2.858964    Objective Loss 2.858964                                        LR 0.000031    Time 0.206015    
2023-04-27 01:03:18,670 - Epoch: [180][  350/  518]    Overall Loss 2.859067    Objective Loss 2.859067                                        LR 0.000031    Time 0.205555    
2023-04-27 01:03:28,856 - Epoch: [180][  400/  518]    Overall Loss 2.853989    Objective Loss 2.853989                                        LR 0.000031    Time 0.205321    
2023-04-27 01:03:39,004 - Epoch: [180][  450/  518]    Overall Loss 2.851173    Objective Loss 2.851173                                        LR 0.000031    Time 0.205056    
2023-04-27 01:03:49,133 - Epoch: [180][  500/  518]    Overall Loss 2.847819    Objective Loss 2.847819                                        LR 0.000031    Time 0.204804    
2023-04-27 01:03:52,653 - Epoch: [180][  518/  518]    Overall Loss 2.847417    Objective Loss 2.847417                                        LR 0.000031    Time 0.204482    
2023-04-27 01:03:52,723 - --- validate (epoch=180)-----------
2023-04-27 01:03:52,724 - 4952 samples (32 per mini-batch)
2023-04-27 01:03:59,504 - Epoch: [180][   50/  155]    Loss 3.153533    mAP 0.449393    
2023-04-27 01:04:05,843 - Epoch: [180][  100/  155]    Loss 3.151324    mAP 0.438318    
2023-04-27 01:04:12,207 - Epoch: [180][  150/  155]    Loss 3.153269    mAP 0.443711    
2023-04-27 01:04:12,779 - Epoch: [180][  155/  155]    Loss 3.155839    mAP 0.442074    
2023-04-27 01:04:12,847 - ==> mAP: 0.44207    Loss: 3.156

2023-04-27 01:04:12,851 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 01:04:12,851 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:04:12,888 - 

2023-04-27 01:04:12,888 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:04:23,714 - Epoch: [181][   50/  518]    Overall Loss 2.869825    Objective Loss 2.869825                                        LR 0.000031    Time 0.216457    
2023-04-27 01:04:33,824 - Epoch: [181][  100/  518]    Overall Loss 2.852747    Objective Loss 2.852747                                        LR 0.000031    Time 0.209311    
2023-04-27 01:04:44,007 - Epoch: [181][  150/  518]    Overall Loss 2.850897    Objective Loss 2.850897                                        LR 0.000031    Time 0.207416    
2023-04-27 01:04:54,238 - Epoch: [181][  200/  518]    Overall Loss 2.851266    Objective Loss 2.851266                                        LR 0.000031    Time 0.206713    
2023-04-27 01:05:04,460 - Epoch: [181][  250/  518]    Overall Loss 2.858597    Objective Loss 2.858597                                        LR 0.000031    Time 0.206248    
2023-04-27 01:05:14,715 - Epoch: [181][  300/  518]    Overall Loss 2.860817    Objective Loss 2.860817                                        LR 0.000031    Time 0.206053    
2023-04-27 01:05:24,907 - Epoch: [181][  350/  518]    Overall Loss 2.861054    Objective Loss 2.861054                                        LR 0.000031    Time 0.205732    
2023-04-27 01:05:35,093 - Epoch: [181][  400/  518]    Overall Loss 2.860628    Objective Loss 2.860628                                        LR 0.000031    Time 0.205477    
2023-04-27 01:05:45,232 - Epoch: [181][  450/  518]    Overall Loss 2.854948    Objective Loss 2.854948                                        LR 0.000031    Time 0.205173    
2023-04-27 01:05:55,404 - Epoch: [181][  500/  518]    Overall Loss 2.855661    Objective Loss 2.855661                                        LR 0.000031    Time 0.204996    
2023-04-27 01:05:58,898 - Epoch: [181][  518/  518]    Overall Loss 2.857159    Objective Loss 2.857159                                        LR 0.000031    Time 0.204617    
2023-04-27 01:05:58,968 - --- validate (epoch=181)-----------
2023-04-27 01:05:58,969 - 4952 samples (32 per mini-batch)
2023-04-27 01:06:05,708 - Epoch: [181][   50/  155]    Loss 3.195268    mAP 0.442645    
2023-04-27 01:06:12,134 - Epoch: [181][  100/  155]    Loss 3.154019    mAP 0.456952    
2023-04-27 01:06:18,519 - Epoch: [181][  150/  155]    Loss 3.163407    mAP 0.453724    
2023-04-27 01:06:19,090 - Epoch: [181][  155/  155]    Loss 3.160857    mAP 0.454575    
2023-04-27 01:06:19,166 - ==> mAP: 0.45457    Loss: 3.161

2023-04-27 01:06:19,170 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 01:06:19,170 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:06:19,207 - 

2023-04-27 01:06:19,207 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:06:30,155 - Epoch: [182][   50/  518]    Overall Loss 2.871212    Objective Loss 2.871212                                        LR 0.000031    Time 0.218883    
2023-04-27 01:06:40,299 - Epoch: [182][  100/  518]    Overall Loss 2.885053    Objective Loss 2.885053                                        LR 0.000031    Time 0.210871    
2023-04-27 01:06:50,578 - Epoch: [182][  150/  518]    Overall Loss 2.871093    Objective Loss 2.871093                                        LR 0.000031    Time 0.209096    
2023-04-27 01:07:00,709 - Epoch: [182][  200/  518]    Overall Loss 2.846563    Objective Loss 2.846563                                        LR 0.000031    Time 0.207469    
2023-04-27 01:07:10,875 - Epoch: [182][  250/  518]    Overall Loss 2.851370    Objective Loss 2.851370                                        LR 0.000031    Time 0.206633    
2023-04-27 01:07:20,983 - Epoch: [182][  300/  518]    Overall Loss 2.846879    Objective Loss 2.846879                                        LR 0.000031    Time 0.205882    
2023-04-27 01:07:31,101 - Epoch: [182][  350/  518]    Overall Loss 2.849107    Objective Loss 2.849107                                        LR 0.000031    Time 0.205374    
2023-04-27 01:07:41,243 - Epoch: [182][  400/  518]    Overall Loss 2.848077    Objective Loss 2.848077                                        LR 0.000031    Time 0.205051    
2023-04-27 01:07:51,356 - Epoch: [182][  450/  518]    Overall Loss 2.852545    Objective Loss 2.852545                                        LR 0.000031    Time 0.204740    
2023-04-27 01:08:01,471 - Epoch: [182][  500/  518]    Overall Loss 2.854116    Objective Loss 2.854116                                        LR 0.000031    Time 0.204491    
2023-04-27 01:08:04,988 - Epoch: [182][  518/  518]    Overall Loss 2.854065    Objective Loss 2.854065                                        LR 0.000031    Time 0.204174    
2023-04-27 01:08:05,058 - --- validate (epoch=182)-----------
2023-04-27 01:08:05,058 - 4952 samples (32 per mini-batch)
2023-04-27 01:08:11,810 - Epoch: [182][   50/  155]    Loss 3.152971    mAP 0.451391    
2023-04-27 01:08:18,182 - Epoch: [182][  100/  155]    Loss 3.154191    mAP 0.450487    
2023-04-27 01:08:24,549 - Epoch: [182][  150/  155]    Loss 3.153627    mAP 0.447665    
2023-04-27 01:08:25,110 - Epoch: [182][  155/  155]    Loss 3.149786    mAP 0.446610    
2023-04-27 01:08:25,177 - ==> mAP: 0.44661    Loss: 3.150

2023-04-27 01:08:25,181 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 01:08:25,181 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:08:25,219 - 

2023-04-27 01:08:25,219 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:08:36,190 - Epoch: [183][   50/  518]    Overall Loss 2.846082    Objective Loss 2.846082                                        LR 0.000031    Time 0.219352    
2023-04-27 01:08:46,341 - Epoch: [183][  100/  518]    Overall Loss 2.830887    Objective Loss 2.830887                                        LR 0.000031    Time 0.211172    
2023-04-27 01:08:56,476 - Epoch: [183][  150/  518]    Overall Loss 2.826195    Objective Loss 2.826195                                        LR 0.000031    Time 0.208339    
2023-04-27 01:09:06,633 - Epoch: [183][  200/  518]    Overall Loss 2.842986    Objective Loss 2.842986                                        LR 0.000031    Time 0.207029    
2023-04-27 01:09:16,823 - Epoch: [183][  250/  518]    Overall Loss 2.836924    Objective Loss 2.836924                                        LR 0.000031    Time 0.206377    
2023-04-27 01:09:27,035 - Epoch: [183][  300/  518]    Overall Loss 2.837913    Objective Loss 2.837913                                        LR 0.000031    Time 0.206015    
2023-04-27 01:09:37,175 - Epoch: [183][  350/  518]    Overall Loss 2.840553    Objective Loss 2.840553                                        LR 0.000031    Time 0.205551    
2023-04-27 01:09:47,358 - Epoch: [183][  400/  518]    Overall Loss 2.843695    Objective Loss 2.843695                                        LR 0.000031    Time 0.205310    
2023-04-27 01:09:57,480 - Epoch: [183][  450/  518]    Overall Loss 2.848939    Objective Loss 2.848939                                        LR 0.000031    Time 0.204989    
2023-04-27 01:10:07,757 - Epoch: [183][  500/  518]    Overall Loss 2.849630    Objective Loss 2.849630                                        LR 0.000031    Time 0.205040    
2023-04-27 01:10:11,289 - Epoch: [183][  518/  518]    Overall Loss 2.849810    Objective Loss 2.849810                                        LR 0.000031    Time 0.204732    
2023-04-27 01:10:11,360 - --- validate (epoch=183)-----------
2023-04-27 01:10:11,361 - 4952 samples (32 per mini-batch)
2023-04-27 01:10:18,124 - Epoch: [183][   50/  155]    Loss 3.201459    mAP 0.440809    
2023-04-27 01:10:24,484 - Epoch: [183][  100/  155]    Loss 3.172445    mAP 0.451911    
2023-04-27 01:10:30,830 - Epoch: [183][  150/  155]    Loss 3.151166    mAP 0.453323    
2023-04-27 01:10:31,410 - Epoch: [183][  155/  155]    Loss 3.152169    mAP 0.452763    
2023-04-27 01:10:31,491 - ==> mAP: 0.45276    Loss: 3.152

2023-04-27 01:10:31,495 - ==> Best [mAP: 0.457598   vloss: 3.151359   Sparsity:0.00   Params: 2177088 on epoch: 168]
2023-04-27 01:10:31,495 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:10:31,532 - 

2023-04-27 01:10:31,532 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:10:42,384 - Epoch: [184][   50/  518]    Overall Loss 2.893280    Objective Loss 2.893280                                        LR 0.000031    Time 0.216984    
2023-04-27 01:10:52,553 - Epoch: [184][  100/  518]    Overall Loss 2.853276    Objective Loss 2.853276                                        LR 0.000031    Time 0.210164    
2023-04-27 01:11:02,713 - Epoch: [184][  150/  518]    Overall Loss 2.863886    Objective Loss 2.863886                                        LR 0.000031    Time 0.207831    
2023-04-27 01:11:12,885 - Epoch: [184][  200/  518]    Overall Loss 2.854734    Objective Loss 2.854734                                        LR 0.000031    Time 0.206729    
2023-04-27 01:11:23,037 - Epoch: [184][  250/  518]    Overall Loss 2.855534    Objective Loss 2.855534                                        LR 0.000031    Time 0.205984    
2023-04-27 01:11:33,173 - Epoch: [184][  300/  518]    Overall Loss 2.859732    Objective Loss 2.859732                                        LR 0.000031    Time 0.205433    
2023-04-27 01:11:43,391 - Epoch: [184][  350/  518]    Overall Loss 2.857136    Objective Loss 2.857136                                        LR 0.000031    Time 0.205276    
2023-04-27 01:11:53,536 - Epoch: [184][  400/  518]    Overall Loss 2.853813    Objective Loss 2.853813                                        LR 0.000031    Time 0.204975    
2023-04-27 01:12:03,659 - Epoch: [184][  450/  518]    Overall Loss 2.854137    Objective Loss 2.854137                                        LR 0.000031    Time 0.204692    
2023-04-27 01:12:13,822 - Epoch: [184][  500/  518]    Overall Loss 2.853566    Objective Loss 2.853566                                        LR 0.000031    Time 0.204545    
2023-04-27 01:12:17,367 - Epoch: [184][  518/  518]    Overall Loss 2.855378    Objective Loss 2.855378                                        LR 0.000031    Time 0.204279    
2023-04-27 01:12:17,438 - --- validate (epoch=184)-----------
2023-04-27 01:12:17,438 - 4952 samples (32 per mini-batch)
2023-04-27 01:12:24,220 - Epoch: [184][   50/  155]    Loss 3.151207    mAP 0.450805    
2023-04-27 01:12:30,674 - Epoch: [184][  100/  155]    Loss 3.152210    mAP 0.460296    
2023-04-27 01:12:37,064 - Epoch: [184][  150/  155]    Loss 3.154473    mAP 0.461911    
2023-04-27 01:12:37,633 - Epoch: [184][  155/  155]    Loss 3.158213    mAP 0.461909    
2023-04-27 01:12:37,704 - ==> mAP: 0.46191    Loss: 3.158

2023-04-27 01:12:37,708 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:12:37,708 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:12:37,761 - 

2023-04-27 01:12:37,761 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:12:48,631 - Epoch: [185][   50/  518]    Overall Loss 2.837221    Objective Loss 2.837221                                        LR 0.000031    Time 0.217330    
2023-04-27 01:12:58,797 - Epoch: [185][  100/  518]    Overall Loss 2.851356    Objective Loss 2.851356                                        LR 0.000031    Time 0.210311    
2023-04-27 01:13:09,094 - Epoch: [185][  150/  518]    Overall Loss 2.851809    Objective Loss 2.851809                                        LR 0.000031    Time 0.208845    
2023-04-27 01:13:19,194 - Epoch: [185][  200/  518]    Overall Loss 2.841139    Objective Loss 2.841139                                        LR 0.000031    Time 0.207124    
2023-04-27 01:13:29,453 - Epoch: [185][  250/  518]    Overall Loss 2.848882    Objective Loss 2.848882                                        LR 0.000031    Time 0.206727    
2023-04-27 01:13:39,715 - Epoch: [185][  300/  518]    Overall Loss 2.851980    Objective Loss 2.851980                                        LR 0.000031    Time 0.206475    
2023-04-27 01:13:49,794 - Epoch: [185][  350/  518]    Overall Loss 2.852715    Objective Loss 2.852715                                        LR 0.000031    Time 0.205772    
2023-04-27 01:14:00,023 - Epoch: [185][  400/  518]    Overall Loss 2.860233    Objective Loss 2.860233                                        LR 0.000031    Time 0.205619    
2023-04-27 01:14:10,194 - Epoch: [185][  450/  518]    Overall Loss 2.856591    Objective Loss 2.856591                                        LR 0.000031    Time 0.205371    
2023-04-27 01:14:20,395 - Epoch: [185][  500/  518]    Overall Loss 2.854191    Objective Loss 2.854191                                        LR 0.000031    Time 0.205233    
2023-04-27 01:14:23,970 - Epoch: [185][  518/  518]    Overall Loss 2.856522    Objective Loss 2.856522                                        LR 0.000031    Time 0.205001    
2023-04-27 01:14:24,044 - --- validate (epoch=185)-----------
2023-04-27 01:14:24,044 - 4952 samples (32 per mini-batch)
2023-04-27 01:14:30,840 - Epoch: [185][   50/  155]    Loss 3.111425    mAP 0.466269    
2023-04-27 01:14:37,241 - Epoch: [185][  100/  155]    Loss 3.133747    mAP 0.453389    
2023-04-27 01:14:43,569 - Epoch: [185][  150/  155]    Loss 3.146134    mAP 0.453663    
2023-04-27 01:14:44,139 - Epoch: [185][  155/  155]    Loss 3.144814    mAP 0.452907    
2023-04-27 01:14:44,217 - ==> mAP: 0.45291    Loss: 3.145

2023-04-27 01:14:44,221 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:14:44,221 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:14:44,259 - 

2023-04-27 01:14:44,260 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:14:55,299 - Epoch: [186][   50/  518]    Overall Loss 2.886301    Objective Loss 2.886301                                        LR 0.000031    Time 0.220734    
2023-04-27 01:15:05,491 - Epoch: [186][  100/  518]    Overall Loss 2.876928    Objective Loss 2.876928                                        LR 0.000031    Time 0.212265    
2023-04-27 01:15:15,739 - Epoch: [186][  150/  518]    Overall Loss 2.867832    Objective Loss 2.867832                                        LR 0.000031    Time 0.209825    
2023-04-27 01:15:25,950 - Epoch: [186][  200/  518]    Overall Loss 2.860819    Objective Loss 2.860819                                        LR 0.000031    Time 0.208414    
2023-04-27 01:15:36,162 - Epoch: [186][  250/  518]    Overall Loss 2.863076    Objective Loss 2.863076                                        LR 0.000031    Time 0.207571    
2023-04-27 01:15:46,268 - Epoch: [186][  300/  518]    Overall Loss 2.862186    Objective Loss 2.862186                                        LR 0.000031    Time 0.206658    
2023-04-27 01:15:56,404 - Epoch: [186][  350/  518]    Overall Loss 2.864558    Objective Loss 2.864558                                        LR 0.000031    Time 0.206091    
2023-04-27 01:16:06,559 - Epoch: [186][  400/  518]    Overall Loss 2.864644    Objective Loss 2.864644                                        LR 0.000031    Time 0.205712    
2023-04-27 01:16:16,707 - Epoch: [186][  450/  518]    Overall Loss 2.855868    Objective Loss 2.855868                                        LR 0.000031    Time 0.205404    
2023-04-27 01:16:26,877 - Epoch: [186][  500/  518]    Overall Loss 2.859231    Objective Loss 2.859231                                        LR 0.000031    Time 0.205200    
2023-04-27 01:16:30,410 - Epoch: [186][  518/  518]    Overall Loss 2.857032    Objective Loss 2.857032                                        LR 0.000031    Time 0.204889    
2023-04-27 01:16:30,483 - --- validate (epoch=186)-----------
2023-04-27 01:16:30,483 - 4952 samples (32 per mini-batch)
2023-04-27 01:16:37,284 - Epoch: [186][   50/  155]    Loss 3.131826    mAP 0.473306    
2023-04-27 01:16:43,673 - Epoch: [186][  100/  155]    Loss 3.141429    mAP 0.463318    
2023-04-27 01:16:50,029 - Epoch: [186][  150/  155]    Loss 3.151530    mAP 0.457005    
2023-04-27 01:16:50,600 - Epoch: [186][  155/  155]    Loss 3.146144    mAP 0.457250    
2023-04-27 01:16:50,669 - ==> mAP: 0.45725    Loss: 3.146

2023-04-27 01:16:50,672 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:16:50,672 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:16:50,710 - 

2023-04-27 01:16:50,710 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:17:01,712 - Epoch: [187][   50/  518]    Overall Loss 2.844389    Objective Loss 2.844389                                        LR 0.000031    Time 0.219975    
2023-04-27 01:17:11,857 - Epoch: [187][  100/  518]    Overall Loss 2.846278    Objective Loss 2.846278                                        LR 0.000031    Time 0.211429    
2023-04-27 01:17:22,040 - Epoch: [187][  150/  518]    Overall Loss 2.852587    Objective Loss 2.852587                                        LR 0.000031    Time 0.208824    
2023-04-27 01:17:32,159 - Epoch: [187][  200/  518]    Overall Loss 2.840308    Objective Loss 2.840308                                        LR 0.000031    Time 0.207207    
2023-04-27 01:17:42,371 - Epoch: [187][  250/  518]    Overall Loss 2.848249    Objective Loss 2.848249                                        LR 0.000031    Time 0.206606    
2023-04-27 01:17:52,560 - Epoch: [187][  300/  518]    Overall Loss 2.844085    Objective Loss 2.844085                                        LR 0.000031    Time 0.206131    
2023-04-27 01:18:02,780 - Epoch: [187][  350/  518]    Overall Loss 2.849883    Objective Loss 2.849883                                        LR 0.000031    Time 0.205879    
2023-04-27 01:18:12,951 - Epoch: [187][  400/  518]    Overall Loss 2.847591    Objective Loss 2.847591                                        LR 0.000031    Time 0.205567    
2023-04-27 01:18:23,041 - Epoch: [187][  450/  518]    Overall Loss 2.845680    Objective Loss 2.845680                                        LR 0.000031    Time 0.205144    
2023-04-27 01:18:33,221 - Epoch: [187][  500/  518]    Overall Loss 2.851157    Objective Loss 2.851157                                        LR 0.000031    Time 0.204987    
2023-04-27 01:18:36,753 - Epoch: [187][  518/  518]    Overall Loss 2.850489    Objective Loss 2.850489                                        LR 0.000031    Time 0.204682    
2023-04-27 01:18:36,825 - --- validate (epoch=187)-----------
2023-04-27 01:18:36,826 - 4952 samples (32 per mini-batch)
2023-04-27 01:18:43,526 - Epoch: [187][   50/  155]    Loss 3.153069    mAP 0.462421    
2023-04-27 01:18:49,905 - Epoch: [187][  100/  155]    Loss 3.144052    mAP 0.454471    
2023-04-27 01:18:56,224 - Epoch: [187][  150/  155]    Loss 3.151966    mAP 0.451016    
2023-04-27 01:18:56,793 - Epoch: [187][  155/  155]    Loss 3.152565    mAP 0.450277    
2023-04-27 01:18:56,855 - ==> mAP: 0.45028    Loss: 3.153

2023-04-27 01:18:56,859 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:18:56,859 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:18:56,897 - 

2023-04-27 01:18:56,897 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:19:07,742 - Epoch: [188][   50/  518]    Overall Loss 2.931894    Objective Loss 2.931894                                        LR 0.000031    Time 0.216848    
2023-04-27 01:19:17,869 - Epoch: [188][  100/  518]    Overall Loss 2.892878    Objective Loss 2.892878                                        LR 0.000031    Time 0.209679    
2023-04-27 01:19:27,986 - Epoch: [188][  150/  518]    Overall Loss 2.862235    Objective Loss 2.862235                                        LR 0.000031    Time 0.207217    
2023-04-27 01:19:38,135 - Epoch: [188][  200/  518]    Overall Loss 2.865723    Objective Loss 2.865723                                        LR 0.000031    Time 0.206153    
2023-04-27 01:19:48,367 - Epoch: [188][  250/  518]    Overall Loss 2.866684    Objective Loss 2.866684                                        LR 0.000031    Time 0.205843    
2023-04-27 01:19:58,477 - Epoch: [188][  300/  518]    Overall Loss 2.866082    Objective Loss 2.866082                                        LR 0.000031    Time 0.205231    
2023-04-27 01:20:08,650 - Epoch: [188][  350/  518]    Overall Loss 2.854587    Objective Loss 2.854587                                        LR 0.000031    Time 0.204973    
2023-04-27 01:20:18,720 - Epoch: [188][  400/  518]    Overall Loss 2.853529    Objective Loss 2.853529                                        LR 0.000031    Time 0.204523    
2023-04-27 01:20:28,844 - Epoch: [188][  450/  518]    Overall Loss 2.850120    Objective Loss 2.850120                                        LR 0.000031    Time 0.204291    
2023-04-27 01:20:38,978 - Epoch: [188][  500/  518]    Overall Loss 2.850032    Objective Loss 2.850032                                        LR 0.000031    Time 0.204127    
2023-04-27 01:20:42,531 - Epoch: [188][  518/  518]    Overall Loss 2.851702    Objective Loss 2.851702                                        LR 0.000031    Time 0.203891    
2023-04-27 01:20:42,602 - --- validate (epoch=188)-----------
2023-04-27 01:20:42,602 - 4952 samples (32 per mini-batch)
2023-04-27 01:20:49,295 - Epoch: [188][   50/  155]    Loss 3.172165    mAP 0.446324    
2023-04-27 01:20:55,646 - Epoch: [188][  100/  155]    Loss 3.172619    mAP 0.452452    
2023-04-27 01:21:02,011 - Epoch: [188][  150/  155]    Loss 3.160474    mAP 0.453511    
2023-04-27 01:21:02,595 - Epoch: [188][  155/  155]    Loss 3.152344    mAP 0.455549    
2023-04-27 01:21:02,664 - ==> mAP: 0.45555    Loss: 3.152

2023-04-27 01:21:02,667 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:21:02,668 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:21:02,705 - 

2023-04-27 01:21:02,706 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:21:13,657 - Epoch: [189][   50/  518]    Overall Loss 2.804240    Objective Loss 2.804240                                        LR 0.000031    Time 0.218979    
2023-04-27 01:21:23,860 - Epoch: [189][  100/  518]    Overall Loss 2.837194    Objective Loss 2.837194                                        LR 0.000031    Time 0.211494    
2023-04-27 01:21:34,011 - Epoch: [189][  150/  518]    Overall Loss 2.838094    Objective Loss 2.838094                                        LR 0.000031    Time 0.208663    
2023-04-27 01:21:44,162 - Epoch: [189][  200/  518]    Overall Loss 2.834400    Objective Loss 2.834400                                        LR 0.000031    Time 0.207245    
2023-04-27 01:21:54,333 - Epoch: [189][  250/  518]    Overall Loss 2.837773    Objective Loss 2.837773                                        LR 0.000031    Time 0.206473    
2023-04-27 01:22:04,495 - Epoch: [189][  300/  518]    Overall Loss 2.840652    Objective Loss 2.840652                                        LR 0.000031    Time 0.205929    
2023-04-27 01:22:14,693 - Epoch: [189][  350/  518]    Overall Loss 2.845474    Objective Loss 2.845474                                        LR 0.000031    Time 0.205642    
2023-04-27 01:22:24,826 - Epoch: [189][  400/  518]    Overall Loss 2.834355    Objective Loss 2.834355                                        LR 0.000031    Time 0.205264    
2023-04-27 01:22:34,977 - Epoch: [189][  450/  518]    Overall Loss 2.833199    Objective Loss 2.833199                                        LR 0.000031    Time 0.205013    
2023-04-27 01:22:45,140 - Epoch: [189][  500/  518]    Overall Loss 2.838412    Objective Loss 2.838412                                        LR 0.000031    Time 0.204834    
2023-04-27 01:22:48,689 - Epoch: [189][  518/  518]    Overall Loss 2.841608    Objective Loss 2.841608                                        LR 0.000031    Time 0.204565    
2023-04-27 01:22:48,761 - --- validate (epoch=189)-----------
2023-04-27 01:22:48,762 - 4952 samples (32 per mini-batch)
2023-04-27 01:22:55,457 - Epoch: [189][   50/  155]    Loss 3.166775    mAP 0.436071    
2023-04-27 01:23:01,887 - Epoch: [189][  100/  155]    Loss 3.168454    mAP 0.444101    
2023-04-27 01:23:08,235 - Epoch: [189][  150/  155]    Loss 3.155470    mAP 0.444436    
2023-04-27 01:23:08,801 - Epoch: [189][  155/  155]    Loss 3.151289    mAP 0.444036    
2023-04-27 01:23:08,892 - ==> mAP: 0.44404    Loss: 3.151

2023-04-27 01:23:08,896 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:23:08,896 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:23:08,934 - 

2023-04-27 01:23:08,934 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:23:19,919 - Epoch: [190][   50/  518]    Overall Loss 2.895856    Objective Loss 2.895856                                        LR 0.000031    Time 0.219659    
2023-04-27 01:23:30,113 - Epoch: [190][  100/  518]    Overall Loss 2.871577    Objective Loss 2.871577                                        LR 0.000031    Time 0.211747    
2023-04-27 01:23:40,212 - Epoch: [190][  150/  518]    Overall Loss 2.842779    Objective Loss 2.842779                                        LR 0.000031    Time 0.208479    
2023-04-27 01:23:50,397 - Epoch: [190][  200/  518]    Overall Loss 2.842301    Objective Loss 2.842301                                        LR 0.000031    Time 0.207275    
2023-04-27 01:24:00,603 - Epoch: [190][  250/  518]    Overall Loss 2.851153    Objective Loss 2.851153                                        LR 0.000031    Time 0.206639    
2023-04-27 01:24:10,751 - Epoch: [190][  300/  518]    Overall Loss 2.855142    Objective Loss 2.855142                                        LR 0.000031    Time 0.206020    
2023-04-27 01:24:20,936 - Epoch: [190][  350/  518]    Overall Loss 2.846511    Objective Loss 2.846511                                        LR 0.000031    Time 0.205683    
2023-04-27 01:24:31,199 - Epoch: [190][  400/  518]    Overall Loss 2.851191    Objective Loss 2.851191                                        LR 0.000031    Time 0.205626    
2023-04-27 01:24:41,369 - Epoch: [190][  450/  518]    Overall Loss 2.851951    Objective Loss 2.851951                                        LR 0.000031    Time 0.205376    
2023-04-27 01:24:51,483 - Epoch: [190][  500/  518]    Overall Loss 2.849957    Objective Loss 2.849957                                        LR 0.000031    Time 0.205062    
2023-04-27 01:24:55,004 - Epoch: [190][  518/  518]    Overall Loss 2.846914    Objective Loss 2.846914                                        LR 0.000031    Time 0.204734    
2023-04-27 01:24:55,076 - --- validate (epoch=190)-----------
2023-04-27 01:24:55,077 - 4952 samples (32 per mini-batch)
2023-04-27 01:25:01,798 - Epoch: [190][   50/  155]    Loss 3.179151    mAP 0.438920    
2023-04-27 01:25:08,157 - Epoch: [190][  100/  155]    Loss 3.151781    mAP 0.439905    
2023-04-27 01:25:14,509 - Epoch: [190][  150/  155]    Loss 3.158272    mAP 0.444665    
2023-04-27 01:25:15,075 - Epoch: [190][  155/  155]    Loss 3.152659    mAP 0.448002    
2023-04-27 01:25:15,141 - ==> mAP: 0.44800    Loss: 3.153

2023-04-27 01:25:15,145 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:25:15,145 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:25:15,182 - 

2023-04-27 01:25:15,182 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:25:26,143 - Epoch: [191][   50/  518]    Overall Loss 2.922661    Objective Loss 2.922661                                        LR 0.000031    Time 0.219162    
2023-04-27 01:25:36,297 - Epoch: [191][  100/  518]    Overall Loss 2.879362    Objective Loss 2.879362                                        LR 0.000031    Time 0.211099    
2023-04-27 01:25:46,356 - Epoch: [191][  150/  518]    Overall Loss 2.875701    Objective Loss 2.875701                                        LR 0.000031    Time 0.207779    
2023-04-27 01:25:56,496 - Epoch: [191][  200/  518]    Overall Loss 2.880409    Objective Loss 2.880409                                        LR 0.000031    Time 0.206531    
2023-04-27 01:26:06,701 - Epoch: [191][  250/  518]    Overall Loss 2.878463    Objective Loss 2.878463                                        LR 0.000031    Time 0.206036    
2023-04-27 01:26:16,906 - Epoch: [191][  300/  518]    Overall Loss 2.879858    Objective Loss 2.879858                                        LR 0.000031    Time 0.205706    
2023-04-27 01:26:27,136 - Epoch: [191][  350/  518]    Overall Loss 2.875452    Objective Loss 2.875452                                        LR 0.000031    Time 0.205544    
2023-04-27 01:26:37,342 - Epoch: [191][  400/  518]    Overall Loss 2.870660    Objective Loss 2.870660                                        LR 0.000031    Time 0.205363    
2023-04-27 01:26:47,467 - Epoch: [191][  450/  518]    Overall Loss 2.865997    Objective Loss 2.865997                                        LR 0.000031    Time 0.205041    
2023-04-27 01:26:57,658 - Epoch: [191][  500/  518]    Overall Loss 2.862210    Objective Loss 2.862210                                        LR 0.000031    Time 0.204916    
2023-04-27 01:27:01,187 - Epoch: [191][  518/  518]    Overall Loss 2.858150    Objective Loss 2.858150                                        LR 0.000031    Time 0.204603    
2023-04-27 01:27:01,259 - --- validate (epoch=191)-----------
2023-04-27 01:27:01,259 - 4952 samples (32 per mini-batch)
2023-04-27 01:27:07,988 - Epoch: [191][   50/  155]    Loss 3.133891    mAP 0.455387    
2023-04-27 01:27:14,304 - Epoch: [191][  100/  155]    Loss 3.132436    mAP 0.449379    
2023-04-27 01:27:20,671 - Epoch: [191][  150/  155]    Loss 3.152535    mAP 0.451503    
2023-04-27 01:27:21,237 - Epoch: [191][  155/  155]    Loss 3.156425    mAP 0.450695    
2023-04-27 01:27:21,306 - ==> mAP: 0.45069    Loss: 3.156

2023-04-27 01:27:21,310 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:27:21,310 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:27:21,346 - 

2023-04-27 01:27:21,346 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:27:32,163 - Epoch: [192][   50/  518]    Overall Loss 2.851368    Objective Loss 2.851368                                        LR 0.000031    Time 0.216270    
2023-04-27 01:27:42,222 - Epoch: [192][  100/  518]    Overall Loss 2.830917    Objective Loss 2.830917                                        LR 0.000031    Time 0.208713    
2023-04-27 01:27:52,368 - Epoch: [192][  150/  518]    Overall Loss 2.844201    Objective Loss 2.844201                                        LR 0.000031    Time 0.206769    
2023-04-27 01:28:02,529 - Epoch: [192][  200/  518]    Overall Loss 2.835183    Objective Loss 2.835183                                        LR 0.000031    Time 0.205873    
2023-04-27 01:28:12,660 - Epoch: [192][  250/  518]    Overall Loss 2.833196    Objective Loss 2.833196                                        LR 0.000031    Time 0.205215    
2023-04-27 01:28:22,815 - Epoch: [192][  300/  518]    Overall Loss 2.840903    Objective Loss 2.840903                                        LR 0.000031    Time 0.204857    
2023-04-27 01:28:32,970 - Epoch: [192][  350/  518]    Overall Loss 2.838638    Objective Loss 2.838638                                        LR 0.000031    Time 0.204602    
2023-04-27 01:28:43,225 - Epoch: [192][  400/  518]    Overall Loss 2.846859    Objective Loss 2.846859                                        LR 0.000031    Time 0.204660    
2023-04-27 01:28:53,417 - Epoch: [192][  450/  518]    Overall Loss 2.847085    Objective Loss 2.847085                                        LR 0.000031    Time 0.204565    
2023-04-27 01:29:03,617 - Epoch: [192][  500/  518]    Overall Loss 2.846199    Objective Loss 2.846199                                        LR 0.000031    Time 0.204506    
2023-04-27 01:29:07,144 - Epoch: [192][  518/  518]    Overall Loss 2.845869    Objective Loss 2.845869                                        LR 0.000031    Time 0.204206    
2023-04-27 01:29:07,219 - --- validate (epoch=192)-----------
2023-04-27 01:29:07,219 - 4952 samples (32 per mini-batch)
2023-04-27 01:29:13,951 - Epoch: [192][   50/  155]    Loss 3.145129    mAP 0.436973    
2023-04-27 01:29:20,367 - Epoch: [192][  100/  155]    Loss 3.171665    mAP 0.448441    
2023-04-27 01:29:26,685 - Epoch: [192][  150/  155]    Loss 3.154648    mAP 0.444636    
2023-04-27 01:29:27,264 - Epoch: [192][  155/  155]    Loss 3.155434    mAP 0.444159    
2023-04-27 01:29:27,334 - ==> mAP: 0.44416    Loss: 3.155

2023-04-27 01:29:27,338 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:29:27,338 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:29:27,376 - 

2023-04-27 01:29:27,376 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:29:38,409 - Epoch: [193][   50/  518]    Overall Loss 2.850758    Objective Loss 2.850758                                        LR 0.000031    Time 0.220608    
2023-04-27 01:29:48,508 - Epoch: [193][  100/  518]    Overall Loss 2.847089    Objective Loss 2.847089                                        LR 0.000031    Time 0.211281    
2023-04-27 01:29:58,749 - Epoch: [193][  150/  518]    Overall Loss 2.846376    Objective Loss 2.846376                                        LR 0.000031    Time 0.209116    
2023-04-27 01:30:08,830 - Epoch: [193][  200/  518]    Overall Loss 2.853427    Objective Loss 2.853427                                        LR 0.000031    Time 0.207234    
2023-04-27 01:30:19,011 - Epoch: [193][  250/  518]    Overall Loss 2.845374    Objective Loss 2.845374                                        LR 0.000031    Time 0.206505    
2023-04-27 01:30:29,101 - Epoch: [193][  300/  518]    Overall Loss 2.852757    Objective Loss 2.852757                                        LR 0.000031    Time 0.205713    
2023-04-27 01:30:39,273 - Epoch: [193][  350/  518]    Overall Loss 2.845641    Objective Loss 2.845641                                        LR 0.000031    Time 0.205383    
2023-04-27 01:30:49,348 - Epoch: [193][  400/  518]    Overall Loss 2.849585    Objective Loss 2.849585                                        LR 0.000031    Time 0.204894    
2023-04-27 01:30:59,486 - Epoch: [193][  450/  518]    Overall Loss 2.846900    Objective Loss 2.846900                                        LR 0.000031    Time 0.204653    
2023-04-27 01:31:09,647 - Epoch: [193][  500/  518]    Overall Loss 2.847202    Objective Loss 2.847202                                        LR 0.000031    Time 0.204508    
2023-04-27 01:31:13,166 - Epoch: [193][  518/  518]    Overall Loss 2.849824    Objective Loss 2.849824                                        LR 0.000031    Time 0.204193    
2023-04-27 01:31:13,237 - --- validate (epoch=193)-----------
2023-04-27 01:31:13,237 - 4952 samples (32 per mini-batch)
2023-04-27 01:31:19,945 - Epoch: [193][   50/  155]    Loss 3.174259    mAP 0.432159    
2023-04-27 01:31:26,358 - Epoch: [193][  100/  155]    Loss 3.143492    mAP 0.448132    
2023-04-27 01:31:32,719 - Epoch: [193][  150/  155]    Loss 3.152541    mAP 0.453739    
2023-04-27 01:31:33,292 - Epoch: [193][  155/  155]    Loss 3.152665    mAP 0.453489    
2023-04-27 01:31:33,361 - ==> mAP: 0.45349    Loss: 3.153

2023-04-27 01:31:33,365 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:31:33,365 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:31:33,403 - 

2023-04-27 01:31:33,403 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:31:44,283 - Epoch: [194][   50/  518]    Overall Loss 2.846080    Objective Loss 2.846080                                        LR 0.000031    Time 0.217545    
2023-04-27 01:31:54,519 - Epoch: [194][  100/  518]    Overall Loss 2.846407    Objective Loss 2.846407                                        LR 0.000031    Time 0.211120    
2023-04-27 01:32:04,743 - Epoch: [194][  150/  518]    Overall Loss 2.833758    Objective Loss 2.833758                                        LR 0.000031    Time 0.208891    
2023-04-27 01:32:14,941 - Epoch: [194][  200/  518]    Overall Loss 2.820361    Objective Loss 2.820361                                        LR 0.000031    Time 0.207649    
2023-04-27 01:32:25,160 - Epoch: [194][  250/  518]    Overall Loss 2.832167    Objective Loss 2.832167                                        LR 0.000031    Time 0.206992    
2023-04-27 01:32:35,327 - Epoch: [194][  300/  518]    Overall Loss 2.831883    Objective Loss 2.831883                                        LR 0.000031    Time 0.206376    
2023-04-27 01:32:45,465 - Epoch: [194][  350/  518]    Overall Loss 2.837512    Objective Loss 2.837512                                        LR 0.000031    Time 0.205854    
2023-04-27 01:32:55,595 - Epoch: [194][  400/  518]    Overall Loss 2.837655    Objective Loss 2.837655                                        LR 0.000031    Time 0.205445    
2023-04-27 01:33:05,724 - Epoch: [194][  450/  518]    Overall Loss 2.842819    Objective Loss 2.842819                                        LR 0.000031    Time 0.205123    
2023-04-27 01:33:15,851 - Epoch: [194][  500/  518]    Overall Loss 2.841317    Objective Loss 2.841317                                        LR 0.000031    Time 0.204861    
2023-04-27 01:33:19,389 - Epoch: [194][  518/  518]    Overall Loss 2.845710    Objective Loss 2.845710                                        LR 0.000031    Time 0.204571    
2023-04-27 01:33:19,460 - --- validate (epoch=194)-----------
2023-04-27 01:33:19,460 - 4952 samples (32 per mini-batch)
2023-04-27 01:33:26,194 - Epoch: [194][   50/  155]    Loss 3.137425    mAP 0.459755    
2023-04-27 01:33:32,619 - Epoch: [194][  100/  155]    Loss 3.125061    mAP 0.470568    
2023-04-27 01:33:39,076 - Epoch: [194][  150/  155]    Loss 3.152531    mAP 0.458668    
2023-04-27 01:33:39,646 - Epoch: [194][  155/  155]    Loss 3.154230    mAP 0.458363    
2023-04-27 01:33:39,724 - ==> mAP: 0.45836    Loss: 3.154

2023-04-27 01:33:39,727 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:33:39,727 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:33:39,765 - 

2023-04-27 01:33:39,765 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:33:50,830 - Epoch: [195][   50/  518]    Overall Loss 2.826105    Objective Loss 2.826105                                        LR 0.000031    Time 0.221246    
2023-04-27 01:34:01,033 - Epoch: [195][  100/  518]    Overall Loss 2.843848    Objective Loss 2.843848                                        LR 0.000031    Time 0.212633    
2023-04-27 01:34:11,222 - Epoch: [195][  150/  518]    Overall Loss 2.841005    Objective Loss 2.841005                                        LR 0.000031    Time 0.209668    
2023-04-27 01:34:21,405 - Epoch: [195][  200/  518]    Overall Loss 2.843097    Objective Loss 2.843097                                        LR 0.000031    Time 0.208161    
2023-04-27 01:34:31,484 - Epoch: [195][  250/  518]    Overall Loss 2.839411    Objective Loss 2.839411                                        LR 0.000031    Time 0.206838    
2023-04-27 01:34:41,717 - Epoch: [195][  300/  518]    Overall Loss 2.840822    Objective Loss 2.840822                                        LR 0.000031    Time 0.206469    
2023-04-27 01:34:51,886 - Epoch: [195][  350/  518]    Overall Loss 2.838113    Objective Loss 2.838113                                        LR 0.000031    Time 0.206023    
2023-04-27 01:35:02,064 - Epoch: [195][  400/  518]    Overall Loss 2.844344    Objective Loss 2.844344                                        LR 0.000031    Time 0.205712    
2023-04-27 01:35:12,176 - Epoch: [195][  450/  518]    Overall Loss 2.848754    Objective Loss 2.848754                                        LR 0.000031    Time 0.205321    
2023-04-27 01:35:22,322 - Epoch: [195][  500/  518]    Overall Loss 2.844441    Objective Loss 2.844441                                        LR 0.000031    Time 0.205077    
2023-04-27 01:35:25,845 - Epoch: [195][  518/  518]    Overall Loss 2.850044    Objective Loss 2.850044                                        LR 0.000031    Time 0.204752    
2023-04-27 01:35:25,917 - --- validate (epoch=195)-----------
2023-04-27 01:35:25,917 - 4952 samples (32 per mini-batch)
2023-04-27 01:35:32,661 - Epoch: [195][   50/  155]    Loss 3.128942    mAP 0.442595    
2023-04-27 01:35:39,028 - Epoch: [195][  100/  155]    Loss 3.127459    mAP 0.443198    
2023-04-27 01:35:45,404 - Epoch: [195][  150/  155]    Loss 3.140874    mAP 0.444937    
2023-04-27 01:35:45,965 - Epoch: [195][  155/  155]    Loss 3.142307    mAP 0.443640    
2023-04-27 01:35:46,054 - ==> mAP: 0.44364    Loss: 3.142

2023-04-27 01:35:46,058 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:35:46,058 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:35:46,095 - 

2023-04-27 01:35:46,095 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:35:56,917 - Epoch: [196][   50/  518]    Overall Loss 2.922650    Objective Loss 2.922650                                        LR 0.000031    Time 0.216383    
2023-04-27 01:36:07,055 - Epoch: [196][  100/  518]    Overall Loss 2.865078    Objective Loss 2.865078                                        LR 0.000031    Time 0.209556    
2023-04-27 01:36:17,149 - Epoch: [196][  150/  518]    Overall Loss 2.828801    Objective Loss 2.828801                                        LR 0.000031    Time 0.206985    
2023-04-27 01:36:27,342 - Epoch: [196][  200/  518]    Overall Loss 2.826317    Objective Loss 2.826317                                        LR 0.000031    Time 0.206196    
2023-04-27 01:36:37,469 - Epoch: [196][  250/  518]    Overall Loss 2.831596    Objective Loss 2.831596                                        LR 0.000031    Time 0.205456    
2023-04-27 01:36:47,747 - Epoch: [196][  300/  518]    Overall Loss 2.837360    Objective Loss 2.837360                                        LR 0.000031    Time 0.205469    
2023-04-27 01:36:57,894 - Epoch: [196][  350/  518]    Overall Loss 2.837445    Objective Loss 2.837445                                        LR 0.000031    Time 0.205103    
2023-04-27 01:37:07,983 - Epoch: [196][  400/  518]    Overall Loss 2.838191    Objective Loss 2.838191                                        LR 0.000031    Time 0.204682    
2023-04-27 01:37:18,163 - Epoch: [196][  450/  518]    Overall Loss 2.834695    Objective Loss 2.834695                                        LR 0.000031    Time 0.204559    
2023-04-27 01:37:28,254 - Epoch: [196][  500/  518]    Overall Loss 2.837245    Objective Loss 2.837245                                        LR 0.000031    Time 0.204283    
2023-04-27 01:37:31,777 - Epoch: [196][  518/  518]    Overall Loss 2.840966    Objective Loss 2.840966                                        LR 0.000031    Time 0.203984    
2023-04-27 01:37:31,848 - --- validate (epoch=196)-----------
2023-04-27 01:37:31,848 - 4952 samples (32 per mini-batch)
2023-04-27 01:37:38,600 - Epoch: [196][   50/  155]    Loss 3.144156    mAP 0.455038    
2023-04-27 01:37:44,997 - Epoch: [196][  100/  155]    Loss 3.165642    mAP 0.458116    
2023-04-27 01:37:51,385 - Epoch: [196][  150/  155]    Loss 3.149983    mAP 0.455706    
2023-04-27 01:37:51,972 - Epoch: [196][  155/  155]    Loss 3.148419    mAP 0.455973    
2023-04-27 01:37:52,048 - ==> mAP: 0.45597    Loss: 3.148

2023-04-27 01:37:52,051 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:37:52,051 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:37:52,089 - 

2023-04-27 01:37:52,089 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:38:03,036 - Epoch: [197][   50/  518]    Overall Loss 2.855136    Objective Loss 2.855136                                        LR 0.000031    Time 0.218869    
2023-04-27 01:38:13,125 - Epoch: [197][  100/  518]    Overall Loss 2.848036    Objective Loss 2.848036                                        LR 0.000031    Time 0.210314    
2023-04-27 01:38:23,335 - Epoch: [197][  150/  518]    Overall Loss 2.855982    Objective Loss 2.855982                                        LR 0.000031    Time 0.208261    
2023-04-27 01:38:33,504 - Epoch: [197][  200/  518]    Overall Loss 2.862925    Objective Loss 2.862925                                        LR 0.000031    Time 0.207036    
2023-04-27 01:38:43,580 - Epoch: [197][  250/  518]    Overall Loss 2.855966    Objective Loss 2.855966                                        LR 0.000031    Time 0.205925    
2023-04-27 01:38:53,759 - Epoch: [197][  300/  518]    Overall Loss 2.857722    Objective Loss 2.857722                                        LR 0.000031    Time 0.205528    
2023-04-27 01:39:03,929 - Epoch: [197][  350/  518]    Overall Loss 2.866644    Objective Loss 2.866644                                        LR 0.000031    Time 0.205219    
2023-04-27 01:39:14,092 - Epoch: [197][  400/  518]    Overall Loss 2.856798    Objective Loss 2.856798                                        LR 0.000031    Time 0.204972    
2023-04-27 01:39:24,268 - Epoch: [197][  450/  518]    Overall Loss 2.852562    Objective Loss 2.852562                                        LR 0.000031    Time 0.204807    
2023-04-27 01:39:34,440 - Epoch: [197][  500/  518]    Overall Loss 2.854808    Objective Loss 2.854808                                        LR 0.000031    Time 0.204665    
2023-04-27 01:39:37,995 - Epoch: [197][  518/  518]    Overall Loss 2.855284    Objective Loss 2.855284                                        LR 0.000031    Time 0.204416    
2023-04-27 01:39:38,069 - --- validate (epoch=197)-----------
2023-04-27 01:39:38,069 - 4952 samples (32 per mini-batch)
2023-04-27 01:39:44,806 - Epoch: [197][   50/  155]    Loss 3.135218    mAP 0.448708    
2023-04-27 01:39:51,234 - Epoch: [197][  100/  155]    Loss 3.151671    mAP 0.455679    
2023-04-27 01:39:57,572 - Epoch: [197][  150/  155]    Loss 3.149193    mAP 0.448841    
2023-04-27 01:39:58,143 - Epoch: [197][  155/  155]    Loss 3.145818    mAP 0.449170    
2023-04-27 01:39:58,215 - ==> mAP: 0.44917    Loss: 3.146

2023-04-27 01:39:58,219 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:39:58,219 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:39:58,256 - 

2023-04-27 01:39:58,256 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:40:09,167 - Epoch: [198][   50/  518]    Overall Loss 2.852484    Objective Loss 2.852484                                        LR 0.000031    Time 0.218155    
2023-04-27 01:40:19,326 - Epoch: [198][  100/  518]    Overall Loss 2.859505    Objective Loss 2.859505                                        LR 0.000031    Time 0.210654    
2023-04-27 01:40:29,452 - Epoch: [198][  150/  518]    Overall Loss 2.851443    Objective Loss 2.851443                                        LR 0.000031    Time 0.207929    
2023-04-27 01:40:39,670 - Epoch: [198][  200/  518]    Overall Loss 2.849354    Objective Loss 2.849354                                        LR 0.000031    Time 0.207030    
2023-04-27 01:40:49,841 - Epoch: [198][  250/  518]    Overall Loss 2.850264    Objective Loss 2.850264                                        LR 0.000031    Time 0.206299    
2023-04-27 01:41:00,063 - Epoch: [198][  300/  518]    Overall Loss 2.852455    Objective Loss 2.852455                                        LR 0.000031    Time 0.205983    
2023-04-27 01:41:10,230 - Epoch: [198][  350/  518]    Overall Loss 2.859647    Objective Loss 2.859647                                        LR 0.000031    Time 0.205603    
2023-04-27 01:41:20,407 - Epoch: [198][  400/  518]    Overall Loss 2.854912    Objective Loss 2.854912                                        LR 0.000031    Time 0.205339    
2023-04-27 01:41:30,591 - Epoch: [198][  450/  518]    Overall Loss 2.855713    Objective Loss 2.855713                                        LR 0.000031    Time 0.205152    
2023-04-27 01:41:40,667 - Epoch: [198][  500/  518]    Overall Loss 2.849669    Objective Loss 2.849669                                        LR 0.000031    Time 0.204786    
2023-04-27 01:41:44,182 - Epoch: [198][  518/  518]    Overall Loss 2.850225    Objective Loss 2.850225                                        LR 0.000031    Time 0.204454    
2023-04-27 01:41:44,252 - --- validate (epoch=198)-----------
2023-04-27 01:41:44,253 - 4952 samples (32 per mini-batch)
2023-04-27 01:41:51,053 - Epoch: [198][   50/  155]    Loss 3.122188    mAP 0.472561    
2023-04-27 01:41:57,474 - Epoch: [198][  100/  155]    Loss 3.117730    mAP 0.465418    
2023-04-27 01:42:03,856 - Epoch: [198][  150/  155]    Loss 3.146209    mAP 0.454948    
2023-04-27 01:42:04,423 - Epoch: [198][  155/  155]    Loss 3.147852    mAP 0.453342    
2023-04-27 01:42:04,503 - ==> mAP: 0.45334    Loss: 3.148

2023-04-27 01:42:04,507 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:42:04,507 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:42:04,545 - 

2023-04-27 01:42:04,545 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:42:15,447 - Epoch: [199][   50/  518]    Overall Loss 2.861491    Objective Loss 2.861491                                        LR 0.000031    Time 0.217981    
2023-04-27 01:42:25,606 - Epoch: [199][  100/  518]    Overall Loss 2.855142    Objective Loss 2.855142                                        LR 0.000031    Time 0.210568    
2023-04-27 01:42:35,718 - Epoch: [199][  150/  518]    Overall Loss 2.853309    Objective Loss 2.853309                                        LR 0.000031    Time 0.207780    
2023-04-27 01:42:45,912 - Epoch: [199][  200/  518]    Overall Loss 2.852752    Objective Loss 2.852752                                        LR 0.000031    Time 0.206796    
2023-04-27 01:42:56,094 - Epoch: [199][  250/  518]    Overall Loss 2.860316    Objective Loss 2.860316                                        LR 0.000031    Time 0.206158    
2023-04-27 01:43:06,223 - Epoch: [199][  300/  518]    Overall Loss 2.858533    Objective Loss 2.858533                                        LR 0.000031    Time 0.205557    
2023-04-27 01:43:16,366 - Epoch: [199][  350/  518]    Overall Loss 2.862983    Objective Loss 2.862983                                        LR 0.000031    Time 0.205167    
2023-04-27 01:43:26,522 - Epoch: [199][  400/  518]    Overall Loss 2.858039    Objective Loss 2.858039                                        LR 0.000031    Time 0.204907    
2023-04-27 01:43:36,672 - Epoch: [199][  450/  518]    Overall Loss 2.865517    Objective Loss 2.865517                                        LR 0.000031    Time 0.204691    
2023-04-27 01:43:46,804 - Epoch: [199][  500/  518]    Overall Loss 2.863693    Objective Loss 2.863693                                        LR 0.000031    Time 0.204484    
2023-04-27 01:43:50,322 - Epoch: [199][  518/  518]    Overall Loss 2.862876    Objective Loss 2.862876                                        LR 0.000031    Time 0.204169    
2023-04-27 01:43:50,393 - --- validate (epoch=199)-----------
2023-04-27 01:43:50,393 - 4952 samples (32 per mini-batch)
2023-04-27 01:43:57,097 - Epoch: [199][   50/  155]    Loss 3.185084    mAP 0.448203    
2023-04-27 01:44:03,468 - Epoch: [199][  100/  155]    Loss 3.147566    mAP 0.458632    
2023-04-27 01:44:09,857 - Epoch: [199][  150/  155]    Loss 3.143502    mAP 0.452454    
2023-04-27 01:44:10,438 - Epoch: [199][  155/  155]    Loss 3.144061    mAP 0.453641    
2023-04-27 01:44:10,509 - ==> mAP: 0.45364    Loss: 3.144

2023-04-27 01:44:10,513 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:44:10,513 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:44:10,551 - 

2023-04-27 01:44:10,551 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:44:21,509 - Epoch: [200][   50/  518]    Overall Loss 2.832907    Objective Loss 2.832907                                        LR 0.000008    Time 0.219112    
2023-04-27 01:44:31,636 - Epoch: [200][  100/  518]    Overall Loss 2.838178    Objective Loss 2.838178                                        LR 0.000008    Time 0.210805    
2023-04-27 01:44:41,797 - Epoch: [200][  150/  518]    Overall Loss 2.831309    Objective Loss 2.831309                                        LR 0.000008    Time 0.208265    
2023-04-27 01:44:51,978 - Epoch: [200][  200/  518]    Overall Loss 2.833170    Objective Loss 2.833170                                        LR 0.000008    Time 0.207097    
2023-04-27 01:45:02,204 - Epoch: [200][  250/  518]    Overall Loss 2.835221    Objective Loss 2.835221                                        LR 0.000008    Time 0.206576    
2023-04-27 01:45:12,377 - Epoch: [200][  300/  518]    Overall Loss 2.837161    Objective Loss 2.837161                                        LR 0.000008    Time 0.206052    
2023-04-27 01:45:22,539 - Epoch: [200][  350/  518]    Overall Loss 2.837229    Objective Loss 2.837229                                        LR 0.000008    Time 0.205645    
2023-04-27 01:45:32,631 - Epoch: [200][  400/  518]    Overall Loss 2.835586    Objective Loss 2.835586                                        LR 0.000008    Time 0.205164    
2023-04-27 01:45:42,762 - Epoch: [200][  450/  518]    Overall Loss 2.841851    Objective Loss 2.841851                                        LR 0.000008    Time 0.204879    
2023-04-27 01:45:52,967 - Epoch: [200][  500/  518]    Overall Loss 2.851637    Objective Loss 2.851637                                        LR 0.000008    Time 0.204796    
2023-04-27 01:45:56,525 - Epoch: [200][  518/  518]    Overall Loss 2.852527    Objective Loss 2.852527                                        LR 0.000008    Time 0.204549    
2023-04-27 01:45:56,598 - --- validate (epoch=200)-----------
2023-04-27 01:45:56,598 - 4952 samples (32 per mini-batch)
2023-04-27 01:46:03,390 - Epoch: [200][   50/  155]    Loss 3.187804    mAP 0.444355    
2023-04-27 01:46:09,772 - Epoch: [200][  100/  155]    Loss 3.157387    mAP 0.448424    
2023-04-27 01:46:16,100 - Epoch: [200][  150/  155]    Loss 3.149844    mAP 0.444953    
2023-04-27 01:46:16,668 - Epoch: [200][  155/  155]    Loss 3.148346    mAP 0.444812    
2023-04-27 01:46:16,737 - ==> mAP: 0.44481    Loss: 3.148

2023-04-27 01:46:16,740 - ==> Best [mAP: 0.461909   vloss: 3.158213   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-27 01:46:16,740 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:46:16,778 - 

2023-04-27 01:46:16,778 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:46:27,712 - Epoch: [201][   50/  518]    Overall Loss 2.906920    Objective Loss 2.906920                                        LR 0.000008    Time 0.218622    
2023-04-27 01:46:37,862 - Epoch: [201][  100/  518]    Overall Loss 2.891210    Objective Loss 2.891210                                        LR 0.000008    Time 0.210798    
2023-04-27 01:46:48,040 - Epoch: [201][  150/  518]    Overall Loss 2.863199    Objective Loss 2.863199                                        LR 0.000008    Time 0.208369    
2023-04-27 01:46:58,118 - Epoch: [201][  200/  518]    Overall Loss 2.857947    Objective Loss 2.857947                                        LR 0.000008    Time 0.206660    
2023-04-27 01:47:08,256 - Epoch: [201][  250/  518]    Overall Loss 2.856573    Objective Loss 2.856573                                        LR 0.000008    Time 0.205875    
2023-04-27 01:47:18,362 - Epoch: [201][  300/  518]    Overall Loss 2.862379    Objective Loss 2.862379                                        LR 0.000008    Time 0.205243    
2023-04-27 01:47:28,535 - Epoch: [201][  350/  518]    Overall Loss 2.856918    Objective Loss 2.856918                                        LR 0.000008    Time 0.204984    
2023-04-27 01:47:38,779 - Epoch: [201][  400/  518]    Overall Loss 2.857995    Objective Loss 2.857995                                        LR 0.000008    Time 0.204968    
2023-04-27 01:47:48,955 - Epoch: [201][  450/  518]    Overall Loss 2.855076    Objective Loss 2.855076                                        LR 0.000008    Time 0.204803    
2023-04-27 01:47:59,162 - Epoch: [201][  500/  518]    Overall Loss 2.846404    Objective Loss 2.846404                                        LR 0.000008    Time 0.204734    
2023-04-27 01:48:02,706 - Epoch: [201][  518/  518]    Overall Loss 2.850152    Objective Loss 2.850152                                        LR 0.000008    Time 0.204460    
2023-04-27 01:48:02,778 - --- validate (epoch=201)-----------
2023-04-27 01:48:02,778 - 4952 samples (32 per mini-batch)
2023-04-27 01:48:09,557 - Epoch: [201][   50/  155]    Loss 3.203125    mAP 0.466786    
2023-04-27 01:48:16,000 - Epoch: [201][  100/  155]    Loss 3.175466    mAP 0.462138    
2023-04-27 01:48:22,398 - Epoch: [201][  150/  155]    Loss 3.142282    mAP 0.460868    
2023-04-27 01:48:22,971 - Epoch: [201][  155/  155]    Loss 3.144180    mAP 0.462889    
2023-04-27 01:48:23,054 - ==> mAP: 0.46289    Loss: 3.144

2023-04-27 01:48:23,058 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 01:48:23,058 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:48:23,111 - 

2023-04-27 01:48:23,112 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:48:33,965 - Epoch: [202][   50/  518]    Overall Loss 2.787363    Objective Loss 2.787363                                        LR 0.000008    Time 0.217018    
2023-04-27 01:48:44,191 - Epoch: [202][  100/  518]    Overall Loss 2.819730    Objective Loss 2.819730                                        LR 0.000008    Time 0.210753    
2023-04-27 01:48:54,351 - Epoch: [202][  150/  518]    Overall Loss 2.846302    Objective Loss 2.846302                                        LR 0.000008    Time 0.208221    
2023-04-27 01:49:04,510 - Epoch: [202][  200/  518]    Overall Loss 2.837304    Objective Loss 2.837304                                        LR 0.000008    Time 0.206953    
2023-04-27 01:49:14,660 - Epoch: [202][  250/  518]    Overall Loss 2.836076    Objective Loss 2.836076                                        LR 0.000008    Time 0.206155    
2023-04-27 01:49:24,805 - Epoch: [202][  300/  518]    Overall Loss 2.834939    Objective Loss 2.834939                                        LR 0.000008    Time 0.205608    
2023-04-27 01:49:34,989 - Epoch: [202][  350/  518]    Overall Loss 2.841616    Objective Loss 2.841616                                        LR 0.000008    Time 0.205327    
2023-04-27 01:49:45,140 - Epoch: [202][  400/  518]    Overall Loss 2.845711    Objective Loss 2.845711                                        LR 0.000008    Time 0.205035    
2023-04-27 01:49:55,280 - Epoch: [202][  450/  518]    Overall Loss 2.844847    Objective Loss 2.844847                                        LR 0.000008    Time 0.204784    
2023-04-27 01:50:05,475 - Epoch: [202][  500/  518]    Overall Loss 2.844469    Objective Loss 2.844469                                        LR 0.000008    Time 0.204692    
2023-04-27 01:50:09,013 - Epoch: [202][  518/  518]    Overall Loss 2.845097    Objective Loss 2.845097                                        LR 0.000008    Time 0.204409    
2023-04-27 01:50:09,084 - --- validate (epoch=202)-----------
2023-04-27 01:50:09,085 - 4952 samples (32 per mini-batch)
2023-04-27 01:50:15,816 - Epoch: [202][   50/  155]    Loss 3.134071    mAP 0.466268    
2023-04-27 01:50:22,202 - Epoch: [202][  100/  155]    Loss 3.153222    mAP 0.446024    
2023-04-27 01:50:28,581 - Epoch: [202][  150/  155]    Loss 3.158046    mAP 0.447742    
2023-04-27 01:50:29,133 - Epoch: [202][  155/  155]    Loss 3.154738    mAP 0.445502    
2023-04-27 01:50:29,204 - ==> mAP: 0.44550    Loss: 3.155

2023-04-27 01:50:29,209 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 01:50:29,209 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:50:29,247 - 

2023-04-27 01:50:29,247 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:50:40,140 - Epoch: [203][   50/  518]    Overall Loss 2.882840    Objective Loss 2.882840                                        LR 0.000008    Time 0.217799    
2023-04-27 01:50:50,240 - Epoch: [203][  100/  518]    Overall Loss 2.886663    Objective Loss 2.886663                                        LR 0.000008    Time 0.209883    
2023-04-27 01:51:00,429 - Epoch: [203][  150/  518]    Overall Loss 2.900961    Objective Loss 2.900961                                        LR 0.000008    Time 0.207841    
2023-04-27 01:51:10,628 - Epoch: [203][  200/  518]    Overall Loss 2.875661    Objective Loss 2.875661                                        LR 0.000008    Time 0.206864    
2023-04-27 01:51:20,780 - Epoch: [203][  250/  518]    Overall Loss 2.856198    Objective Loss 2.856198                                        LR 0.000008    Time 0.206094    
2023-04-27 01:51:30,897 - Epoch: [203][  300/  518]    Overall Loss 2.855655    Objective Loss 2.855655                                        LR 0.000008    Time 0.205462    
2023-04-27 01:51:41,091 - Epoch: [203][  350/  518]    Overall Loss 2.856877    Objective Loss 2.856877                                        LR 0.000008    Time 0.205234    
2023-04-27 01:51:51,215 - Epoch: [203][  400/  518]    Overall Loss 2.852828    Objective Loss 2.852828                                        LR 0.000008    Time 0.204885    
2023-04-27 01:52:01,277 - Epoch: [203][  450/  518]    Overall Loss 2.851454    Objective Loss 2.851454                                        LR 0.000008    Time 0.204475    
2023-04-27 01:52:11,428 - Epoch: [203][  500/  518]    Overall Loss 2.849040    Objective Loss 2.849040                                        LR 0.000008    Time 0.204327    
2023-04-27 01:52:15,008 - Epoch: [203][  518/  518]    Overall Loss 2.853260    Objective Loss 2.853260                                        LR 0.000008    Time 0.204136    
2023-04-27 01:52:15,079 - --- validate (epoch=203)-----------
2023-04-27 01:52:15,079 - 4952 samples (32 per mini-batch)
2023-04-27 01:52:21,822 - Epoch: [203][   50/  155]    Loss 3.158198    mAP 0.444907    
2023-04-27 01:52:28,248 - Epoch: [203][  100/  155]    Loss 3.159702    mAP 0.450578    
2023-04-27 01:52:34,607 - Epoch: [203][  150/  155]    Loss 3.148838    mAP 0.454994    
2023-04-27 01:52:35,194 - Epoch: [203][  155/  155]    Loss 3.149908    mAP 0.454410    
2023-04-27 01:52:35,257 - ==> mAP: 0.45441    Loss: 3.150

2023-04-27 01:52:35,261 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 01:52:35,261 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:52:35,298 - 

2023-04-27 01:52:35,299 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:52:46,327 - Epoch: [204][   50/  518]    Overall Loss 2.806552    Objective Loss 2.806552                                        LR 0.000008    Time 0.220509    
2023-04-27 01:52:56,539 - Epoch: [204][  100/  518]    Overall Loss 2.801955    Objective Loss 2.801955                                        LR 0.000008    Time 0.212356    
2023-04-27 01:53:06,724 - Epoch: [204][  150/  518]    Overall Loss 2.816842    Objective Loss 2.816842                                        LR 0.000008    Time 0.209459    
2023-04-27 01:53:16,939 - Epoch: [204][  200/  518]    Overall Loss 2.828980    Objective Loss 2.828980                                        LR 0.000008    Time 0.208164    
2023-04-27 01:53:27,122 - Epoch: [204][  250/  518]    Overall Loss 2.839316    Objective Loss 2.839316                                        LR 0.000008    Time 0.207256    
2023-04-27 01:53:37,238 - Epoch: [204][  300/  518]    Overall Loss 2.843983    Objective Loss 2.843983                                        LR 0.000008    Time 0.206428    
2023-04-27 01:53:47,401 - Epoch: [204][  350/  518]    Overall Loss 2.835111    Objective Loss 2.835111                                        LR 0.000008    Time 0.205971    
2023-04-27 01:53:57,596 - Epoch: [204][  400/  518]    Overall Loss 2.837476    Objective Loss 2.837476                                        LR 0.000008    Time 0.205708    
2023-04-27 01:54:07,797 - Epoch: [204][  450/  518]    Overall Loss 2.840676    Objective Loss 2.840676                                        LR 0.000008    Time 0.205517    
2023-04-27 01:54:17,945 - Epoch: [204][  500/  518]    Overall Loss 2.839648    Objective Loss 2.839648                                        LR 0.000008    Time 0.205257    
2023-04-27 01:54:21,472 - Epoch: [204][  518/  518]    Overall Loss 2.843657    Objective Loss 2.843657                                        LR 0.000008    Time 0.204932    
2023-04-27 01:54:21,543 - --- validate (epoch=204)-----------
2023-04-27 01:54:21,543 - 4952 samples (32 per mini-batch)
2023-04-27 01:54:28,303 - Epoch: [204][   50/  155]    Loss 3.208688    mAP 0.431542    
2023-04-27 01:54:34,725 - Epoch: [204][  100/  155]    Loss 3.154551    mAP 0.439614    
2023-04-27 01:54:41,084 - Epoch: [204][  150/  155]    Loss 3.143855    mAP 0.440210    
2023-04-27 01:54:41,655 - Epoch: [204][  155/  155]    Loss 3.145772    mAP 0.438684    
2023-04-27 01:54:41,734 - ==> mAP: 0.43868    Loss: 3.146

2023-04-27 01:54:41,738 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 01:54:41,738 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:54:41,776 - 

2023-04-27 01:54:41,776 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:54:52,645 - Epoch: [205][   50/  518]    Overall Loss 2.861848    Objective Loss 2.861848                                        LR 0.000008    Time 0.217313    
2023-04-27 01:55:02,802 - Epoch: [205][  100/  518]    Overall Loss 2.860854    Objective Loss 2.860854                                        LR 0.000008    Time 0.210214    
2023-04-27 01:55:12,937 - Epoch: [205][  150/  518]    Overall Loss 2.850033    Objective Loss 2.850033                                        LR 0.000008    Time 0.207697    
2023-04-27 01:55:23,039 - Epoch: [205][  200/  518]    Overall Loss 2.842458    Objective Loss 2.842458                                        LR 0.000008    Time 0.206272    
2023-04-27 01:55:33,233 - Epoch: [205][  250/  518]    Overall Loss 2.836829    Objective Loss 2.836829                                        LR 0.000008    Time 0.205790    
2023-04-27 01:55:43,359 - Epoch: [205][  300/  518]    Overall Loss 2.843336    Objective Loss 2.843336                                        LR 0.000008    Time 0.205239    
2023-04-27 01:55:53,454 - Epoch: [205][  350/  518]    Overall Loss 2.836511    Objective Loss 2.836511                                        LR 0.000008    Time 0.204758    
2023-04-27 01:56:03,582 - Epoch: [205][  400/  518]    Overall Loss 2.835854    Objective Loss 2.835854                                        LR 0.000008    Time 0.204478    
2023-04-27 01:56:13,716 - Epoch: [205][  450/  518]    Overall Loss 2.831625    Objective Loss 2.831625                                        LR 0.000008    Time 0.204275    
2023-04-27 01:56:23,897 - Epoch: [205][  500/  518]    Overall Loss 2.830622    Objective Loss 2.830622                                        LR 0.000008    Time 0.204207    
2023-04-27 01:56:27,431 - Epoch: [205][  518/  518]    Overall Loss 2.834043    Objective Loss 2.834043                                        LR 0.000008    Time 0.203932    
2023-04-27 01:56:27,501 - --- validate (epoch=205)-----------
2023-04-27 01:56:27,502 - 4952 samples (32 per mini-batch)
2023-04-27 01:56:34,256 - Epoch: [205][   50/  155]    Loss 3.191742    mAP 0.431427    
2023-04-27 01:56:40,738 - Epoch: [205][  100/  155]    Loss 3.144393    mAP 0.452077    
2023-04-27 01:56:47,114 - Epoch: [205][  150/  155]    Loss 3.141941    mAP 0.455001    
2023-04-27 01:56:47,683 - Epoch: [205][  155/  155]    Loss 3.142018    mAP 0.453725    
2023-04-27 01:56:47,753 - ==> mAP: 0.45373    Loss: 3.142

2023-04-27 01:56:47,758 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 01:56:47,758 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:56:47,796 - 

2023-04-27 01:56:47,796 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:56:58,502 - Epoch: [206][   50/  518]    Overall Loss 2.899592    Objective Loss 2.899592                                        LR 0.000008    Time 0.214060    
2023-04-27 01:57:08,775 - Epoch: [206][  100/  518]    Overall Loss 2.864573    Objective Loss 2.864573                                        LR 0.000008    Time 0.209741    
2023-04-27 01:57:18,899 - Epoch: [206][  150/  518]    Overall Loss 2.853285    Objective Loss 2.853285                                        LR 0.000008    Time 0.207309    
2023-04-27 01:57:28,955 - Epoch: [206][  200/  518]    Overall Loss 2.855956    Objective Loss 2.855956                                        LR 0.000008    Time 0.205755    
2023-04-27 01:57:39,174 - Epoch: [206][  250/  518]    Overall Loss 2.856143    Objective Loss 2.856143                                        LR 0.000008    Time 0.205476    
2023-04-27 01:57:49,333 - Epoch: [206][  300/  518]    Overall Loss 2.853209    Objective Loss 2.853209                                        LR 0.000008    Time 0.205085    
2023-04-27 01:57:59,550 - Epoch: [206][  350/  518]    Overall Loss 2.845665    Objective Loss 2.845665                                        LR 0.000008    Time 0.204975    
2023-04-27 01:58:09,695 - Epoch: [206][  400/  518]    Overall Loss 2.835114    Objective Loss 2.835114                                        LR 0.000008    Time 0.204711    
2023-04-27 01:58:19,938 - Epoch: [206][  450/  518]    Overall Loss 2.838851    Objective Loss 2.838851                                        LR 0.000008    Time 0.204724    
2023-04-27 01:58:30,057 - Epoch: [206][  500/  518]    Overall Loss 2.835141    Objective Loss 2.835141                                        LR 0.000008    Time 0.204486    
2023-04-27 01:58:33,579 - Epoch: [206][  518/  518]    Overall Loss 2.834190    Objective Loss 2.834190                                        LR 0.000008    Time 0.204179    
2023-04-27 01:58:33,650 - --- validate (epoch=206)-----------
2023-04-27 01:58:33,650 - 4952 samples (32 per mini-batch)
2023-04-27 01:58:40,401 - Epoch: [206][   50/  155]    Loss 3.214658    mAP 0.423781    
2023-04-27 01:58:46,778 - Epoch: [206][  100/  155]    Loss 3.162507    mAP 0.449039    
2023-04-27 01:58:53,034 - Epoch: [206][  150/  155]    Loss 3.151341    mAP 0.443933    
2023-04-27 01:58:53,607 - Epoch: [206][  155/  155]    Loss 3.150310    mAP 0.444036    
2023-04-27 01:58:53,676 - ==> mAP: 0.44404    Loss: 3.150

2023-04-27 01:58:53,681 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 01:58:53,681 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 01:58:53,718 - 

2023-04-27 01:58:53,718 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 01:59:04,677 - Epoch: [207][   50/  518]    Overall Loss 2.866719    Objective Loss 2.866719                                        LR 0.000008    Time 0.219128    
2023-04-27 01:59:14,854 - Epoch: [207][  100/  518]    Overall Loss 2.832479    Objective Loss 2.832479                                        LR 0.000008    Time 0.211313    
2023-04-27 01:59:25,023 - Epoch: [207][  150/  518]    Overall Loss 2.823128    Objective Loss 2.823128                                        LR 0.000008    Time 0.208656    
2023-04-27 01:59:35,244 - Epoch: [207][  200/  518]    Overall Loss 2.837521    Objective Loss 2.837521                                        LR 0.000008    Time 0.207589    
2023-04-27 01:59:45,364 - Epoch: [207][  250/  518]    Overall Loss 2.846883    Objective Loss 2.846883                                        LR 0.000008    Time 0.206544    
2023-04-27 01:59:55,530 - Epoch: [207][  300/  518]    Overall Loss 2.852238    Objective Loss 2.852238                                        LR 0.000008    Time 0.206003    
2023-04-27 02:00:05,714 - Epoch: [207][  350/  518]    Overall Loss 2.858479    Objective Loss 2.858479                                        LR 0.000008    Time 0.205667    
2023-04-27 02:00:15,812 - Epoch: [207][  400/  518]    Overall Loss 2.853312    Objective Loss 2.853312                                        LR 0.000008    Time 0.205198    
2023-04-27 02:00:25,935 - Epoch: [207][  450/  518]    Overall Loss 2.852032    Objective Loss 2.852032                                        LR 0.000008    Time 0.204892    
2023-04-27 02:00:36,044 - Epoch: [207][  500/  518]    Overall Loss 2.850500    Objective Loss 2.850500                                        LR 0.000008    Time 0.204617    
2023-04-27 02:00:39,614 - Epoch: [207][  518/  518]    Overall Loss 2.847104    Objective Loss 2.847104                                        LR 0.000008    Time 0.204397    
2023-04-27 02:00:39,686 - --- validate (epoch=207)-----------
2023-04-27 02:00:39,687 - 4952 samples (32 per mini-batch)
2023-04-27 02:00:46,482 - Epoch: [207][   50/  155]    Loss 3.124932    mAP 0.466031    
2023-04-27 02:00:52,902 - Epoch: [207][  100/  155]    Loss 3.148475    mAP 0.457380    
2023-04-27 02:00:59,217 - Epoch: [207][  150/  155]    Loss 3.140854    mAP 0.449591    
2023-04-27 02:00:59,783 - Epoch: [207][  155/  155]    Loss 3.145049    mAP 0.448747    
2023-04-27 02:00:59,854 - ==> mAP: 0.44875    Loss: 3.145

2023-04-27 02:00:59,858 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:00:59,858 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:00:59,895 - 

2023-04-27 02:00:59,895 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:01:10,951 - Epoch: [208][   50/  518]    Overall Loss 2.843577    Objective Loss 2.843577                                        LR 0.000008    Time 0.221052    
2023-04-27 02:01:21,086 - Epoch: [208][  100/  518]    Overall Loss 2.866989    Objective Loss 2.866989                                        LR 0.000008    Time 0.211862    
2023-04-27 02:01:31,254 - Epoch: [208][  150/  518]    Overall Loss 2.838379    Objective Loss 2.838379                                        LR 0.000008    Time 0.209019    
2023-04-27 02:01:41,425 - Epoch: [208][  200/  518]    Overall Loss 2.852985    Objective Loss 2.852985                                        LR 0.000008    Time 0.207611    
2023-04-27 02:01:51,503 - Epoch: [208][  250/  518]    Overall Loss 2.855428    Objective Loss 2.855428                                        LR 0.000008    Time 0.206394    
2023-04-27 02:02:01,664 - Epoch: [208][  300/  518]    Overall Loss 2.852739    Objective Loss 2.852739                                        LR 0.000008    Time 0.205860    
2023-04-27 02:02:11,899 - Epoch: [208][  350/  518]    Overall Loss 2.848797    Objective Loss 2.848797                                        LR 0.000008    Time 0.205687    
2023-04-27 02:02:22,044 - Epoch: [208][  400/  518]    Overall Loss 2.842083    Objective Loss 2.842083                                        LR 0.000008    Time 0.205337    
2023-04-27 02:02:32,175 - Epoch: [208][  450/  518]    Overall Loss 2.845232    Objective Loss 2.845232                                        LR 0.000008    Time 0.205030    
2023-04-27 02:02:42,323 - Epoch: [208][  500/  518]    Overall Loss 2.847248    Objective Loss 2.847248                                        LR 0.000008    Time 0.204819    
2023-04-27 02:02:45,818 - Epoch: [208][  518/  518]    Overall Loss 2.843784    Objective Loss 2.843784                                        LR 0.000008    Time 0.204449    
2023-04-27 02:02:45,888 - --- validate (epoch=208)-----------
2023-04-27 02:02:45,888 - 4952 samples (32 per mini-batch)
2023-04-27 02:02:52,679 - Epoch: [208][   50/  155]    Loss 3.164061    mAP 0.448384    
2023-04-27 02:02:59,051 - Epoch: [208][  100/  155]    Loss 3.151726    mAP 0.451904    
2023-04-27 02:03:05,432 - Epoch: [208][  150/  155]    Loss 3.152316    mAP 0.449900    
2023-04-27 02:03:05,998 - Epoch: [208][  155/  155]    Loss 3.146979    mAP 0.451829    
2023-04-27 02:03:06,057 - ==> mAP: 0.45183    Loss: 3.147

2023-04-27 02:03:06,062 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:03:06,062 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:03:06,099 - 

2023-04-27 02:03:06,099 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:03:16,930 - Epoch: [209][   50/  518]    Overall Loss 2.849534    Objective Loss 2.849534                                        LR 0.000008    Time 0.216552    
2023-04-27 02:03:27,146 - Epoch: [209][  100/  518]    Overall Loss 2.881888    Objective Loss 2.881888                                        LR 0.000008    Time 0.210427    
2023-04-27 02:03:37,303 - Epoch: [209][  150/  518]    Overall Loss 2.869578    Objective Loss 2.869578                                        LR 0.000008    Time 0.207985    
2023-04-27 02:03:47,445 - Epoch: [209][  200/  518]    Overall Loss 2.857097    Objective Loss 2.857097                                        LR 0.000008    Time 0.206690    
2023-04-27 02:03:57,504 - Epoch: [209][  250/  518]    Overall Loss 2.846677    Objective Loss 2.846677                                        LR 0.000008    Time 0.205581    
2023-04-27 02:04:07,638 - Epoch: [209][  300/  518]    Overall Loss 2.842274    Objective Loss 2.842274                                        LR 0.000008    Time 0.205091    
2023-04-27 02:04:17,694 - Epoch: [209][  350/  518]    Overall Loss 2.839896    Objective Loss 2.839896                                        LR 0.000008    Time 0.204521    
2023-04-27 02:04:27,854 - Epoch: [209][  400/  518]    Overall Loss 2.838154    Objective Loss 2.838154                                        LR 0.000008    Time 0.204351    
2023-04-27 02:04:37,983 - Epoch: [209][  450/  518]    Overall Loss 2.842082    Objective Loss 2.842082                                        LR 0.000008    Time 0.204150    
2023-04-27 02:04:48,048 - Epoch: [209][  500/  518]    Overall Loss 2.846956    Objective Loss 2.846956                                        LR 0.000008    Time 0.203862    
2023-04-27 02:04:51,615 - Epoch: [209][  518/  518]    Overall Loss 2.844704    Objective Loss 2.844704                                        LR 0.000008    Time 0.203663    
2023-04-27 02:04:51,684 - --- validate (epoch=209)-----------
2023-04-27 02:04:51,685 - 4952 samples (32 per mini-batch)
2023-04-27 02:04:58,421 - Epoch: [209][   50/  155]    Loss 3.171391    mAP 0.458560    
2023-04-27 02:05:04,828 - Epoch: [209][  100/  155]    Loss 3.163077    mAP 0.457324    
2023-04-27 02:05:11,165 - Epoch: [209][  150/  155]    Loss 3.155708    mAP 0.458696    
2023-04-27 02:05:11,732 - Epoch: [209][  155/  155]    Loss 3.151107    mAP 0.457557    
2023-04-27 02:05:11,798 - ==> mAP: 0.45756    Loss: 3.151

2023-04-27 02:05:11,802 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:05:11,802 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:05:11,840 - 

2023-04-27 02:05:11,840 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:05:22,680 - Epoch: [210][   50/  518]    Overall Loss 2.838443    Objective Loss 2.838443                                        LR 0.000008    Time 0.216737    
2023-04-27 02:05:32,858 - Epoch: [210][  100/  518]    Overall Loss 2.833992    Objective Loss 2.833992                                        LR 0.000008    Time 0.210136    
2023-04-27 02:05:42,980 - Epoch: [210][  150/  518]    Overall Loss 2.818161    Objective Loss 2.818161                                        LR 0.000008    Time 0.207558    
2023-04-27 02:05:53,147 - Epoch: [210][  200/  518]    Overall Loss 2.832158    Objective Loss 2.832158                                        LR 0.000008    Time 0.206496    
2023-04-27 02:06:03,232 - Epoch: [210][  250/  518]    Overall Loss 2.832250    Objective Loss 2.832250                                        LR 0.000008    Time 0.205530    
2023-04-27 02:06:13,375 - Epoch: [210][  300/  518]    Overall Loss 2.832318    Objective Loss 2.832318                                        LR 0.000008    Time 0.205079    
2023-04-27 02:06:23,483 - Epoch: [210][  350/  518]    Overall Loss 2.829410    Objective Loss 2.829410                                        LR 0.000008    Time 0.204656    
2023-04-27 02:06:33,692 - Epoch: [210][  400/  518]    Overall Loss 2.833859    Objective Loss 2.833859                                        LR 0.000008    Time 0.204594    
2023-04-27 02:06:43,875 - Epoch: [210][  450/  518]    Overall Loss 2.834790    Objective Loss 2.834790                                        LR 0.000008    Time 0.204485    
2023-04-27 02:06:54,065 - Epoch: [210][  500/  518]    Overall Loss 2.837574    Objective Loss 2.837574                                        LR 0.000008    Time 0.204415    
2023-04-27 02:06:57,614 - Epoch: [210][  518/  518]    Overall Loss 2.836361    Objective Loss 2.836361                                        LR 0.000008    Time 0.204162    
2023-04-27 02:06:57,687 - --- validate (epoch=210)-----------
2023-04-27 02:06:57,687 - 4952 samples (32 per mini-batch)
2023-04-27 02:07:04,412 - Epoch: [210][   50/  155]    Loss 3.126536    mAP 0.454473    
2023-04-27 02:07:11,122 - Epoch: [210][  100/  155]    Loss 3.144298    mAP 0.453569    
2023-04-27 02:07:17,450 - Epoch: [210][  150/  155]    Loss 3.150127    mAP 0.445546    
2023-04-27 02:07:18,015 - Epoch: [210][  155/  155]    Loss 3.147970    mAP 0.447558    
2023-04-27 02:07:18,089 - ==> mAP: 0.44756    Loss: 3.148

2023-04-27 02:07:18,093 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:07:18,093 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:07:18,130 - 

2023-04-27 02:07:18,130 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:07:28,963 - Epoch: [211][   50/  518]    Overall Loss 2.823180    Objective Loss 2.823180                                        LR 0.000008    Time 0.216605    
2023-04-27 02:07:39,202 - Epoch: [211][  100/  518]    Overall Loss 2.841527    Objective Loss 2.841527                                        LR 0.000008    Time 0.210671    
2023-04-27 02:07:49,381 - Epoch: [211][  150/  518]    Overall Loss 2.832451    Objective Loss 2.832451                                        LR 0.000008    Time 0.208301    
2023-04-27 02:07:59,522 - Epoch: [211][  200/  518]    Overall Loss 2.830016    Objective Loss 2.830016                                        LR 0.000008    Time 0.206922    
2023-04-27 02:08:09,692 - Epoch: [211][  250/  518]    Overall Loss 2.840034    Objective Loss 2.840034                                        LR 0.000008    Time 0.206210    
2023-04-27 02:08:19,971 - Epoch: [211][  300/  518]    Overall Loss 2.845732    Objective Loss 2.845732                                        LR 0.000008    Time 0.206100    
2023-04-27 02:08:30,082 - Epoch: [211][  350/  518]    Overall Loss 2.842037    Objective Loss 2.842037                                        LR 0.000008    Time 0.205540    
2023-04-27 02:08:40,308 - Epoch: [211][  400/  518]    Overall Loss 2.833241    Objective Loss 2.833241                                        LR 0.000008    Time 0.205408    
2023-04-27 02:08:50,478 - Epoch: [211][  450/  518]    Overall Loss 2.826757    Objective Loss 2.826757                                        LR 0.000008    Time 0.205181    
2023-04-27 02:09:00,676 - Epoch: [211][  500/  518]    Overall Loss 2.832119    Objective Loss 2.832119                                        LR 0.000008    Time 0.205057    
2023-04-27 02:09:04,235 - Epoch: [211][  518/  518]    Overall Loss 2.830947    Objective Loss 2.830947                                        LR 0.000008    Time 0.204800    
2023-04-27 02:09:04,311 - --- validate (epoch=211)-----------
2023-04-27 02:09:04,312 - 4952 samples (32 per mini-batch)
2023-04-27 02:09:11,056 - Epoch: [211][   50/  155]    Loss 3.176895    mAP 0.445190    
2023-04-27 02:09:17,426 - Epoch: [211][  100/  155]    Loss 3.153623    mAP 0.451836    
2023-04-27 02:09:23,782 - Epoch: [211][  150/  155]    Loss 3.154288    mAP 0.452671    
2023-04-27 02:09:24,345 - Epoch: [211][  155/  155]    Loss 3.149285    mAP 0.453059    
2023-04-27 02:09:24,421 - ==> mAP: 0.45306    Loss: 3.149

2023-04-27 02:09:24,425 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:09:24,425 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:09:24,462 - 

2023-04-27 02:09:24,462 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:09:35,302 - Epoch: [212][   50/  518]    Overall Loss 2.845255    Objective Loss 2.845255                                        LR 0.000008    Time 0.216735    
2023-04-27 02:09:45,454 - Epoch: [212][  100/  518]    Overall Loss 2.827825    Objective Loss 2.827825                                        LR 0.000008    Time 0.209872    
2023-04-27 02:09:55,643 - Epoch: [212][  150/  518]    Overall Loss 2.834259    Objective Loss 2.834259                                        LR 0.000008    Time 0.207835    
2023-04-27 02:10:05,810 - Epoch: [212][  200/  518]    Overall Loss 2.847568    Objective Loss 2.847568                                        LR 0.000008    Time 0.206698    
2023-04-27 02:10:15,994 - Epoch: [212][  250/  518]    Overall Loss 2.845861    Objective Loss 2.845861                                        LR 0.000008    Time 0.206092    
2023-04-27 02:10:26,110 - Epoch: [212][  300/  518]    Overall Loss 2.841164    Objective Loss 2.841164                                        LR 0.000008    Time 0.205458    
2023-04-27 02:10:36,198 - Epoch: [212][  350/  518]    Overall Loss 2.845795    Objective Loss 2.845795                                        LR 0.000008    Time 0.204923    
2023-04-27 02:10:46,402 - Epoch: [212][  400/  518]    Overall Loss 2.849638    Objective Loss 2.849638                                        LR 0.000008    Time 0.204815    
2023-04-27 02:10:56,689 - Epoch: [212][  450/  518]    Overall Loss 2.849271    Objective Loss 2.849271                                        LR 0.000008    Time 0.204914    
2023-04-27 02:11:06,893 - Epoch: [212][  500/  518]    Overall Loss 2.852103    Objective Loss 2.852103                                        LR 0.000008    Time 0.204826    
2023-04-27 02:11:10,425 - Epoch: [212][  518/  518]    Overall Loss 2.851388    Objective Loss 2.851388                                        LR 0.000008    Time 0.204526    
2023-04-27 02:11:10,501 - --- validate (epoch=212)-----------
2023-04-27 02:11:10,501 - 4952 samples (32 per mini-batch)
2023-04-27 02:11:17,319 - Epoch: [212][   50/  155]    Loss 3.186546    mAP 0.442362    
2023-04-27 02:11:23,731 - Epoch: [212][  100/  155]    Loss 3.137448    mAP 0.447438    
2023-04-27 02:11:30,118 - Epoch: [212][  150/  155]    Loss 3.144988    mAP 0.453704    
2023-04-27 02:11:30,704 - Epoch: [212][  155/  155]    Loss 3.145661    mAP 0.455622    
2023-04-27 02:11:30,780 - ==> mAP: 0.45562    Loss: 3.146

2023-04-27 02:11:30,783 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:11:30,783 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:11:30,821 - 

2023-04-27 02:11:30,821 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:11:41,871 - Epoch: [213][   50/  518]    Overall Loss 2.839166    Objective Loss 2.839166                                        LR 0.000008    Time 0.220957    
2023-04-27 02:11:52,038 - Epoch: [213][  100/  518]    Overall Loss 2.845738    Objective Loss 2.845738                                        LR 0.000008    Time 0.212129    
2023-04-27 02:12:02,258 - Epoch: [213][  150/  518]    Overall Loss 2.856722    Objective Loss 2.856722                                        LR 0.000008    Time 0.209537    
2023-04-27 02:12:12,411 - Epoch: [213][  200/  518]    Overall Loss 2.854780    Objective Loss 2.854780                                        LR 0.000008    Time 0.207912    
2023-04-27 02:12:22,608 - Epoch: [213][  250/  518]    Overall Loss 2.854706    Objective Loss 2.854706                                        LR 0.000008    Time 0.207110    
2023-04-27 02:12:32,780 - Epoch: [213][  300/  518]    Overall Loss 2.848863    Objective Loss 2.848863                                        LR 0.000008    Time 0.206494    
2023-04-27 02:12:42,965 - Epoch: [213][  350/  518]    Overall Loss 2.849405    Objective Loss 2.849405                                        LR 0.000008    Time 0.206089    
2023-04-27 02:12:53,098 - Epoch: [213][  400/  518]    Overall Loss 2.844046    Objective Loss 2.844046                                        LR 0.000008    Time 0.205658    
2023-04-27 02:13:03,268 - Epoch: [213][  450/  518]    Overall Loss 2.847025    Objective Loss 2.847025                                        LR 0.000008    Time 0.205402    
2023-04-27 02:13:13,405 - Epoch: [213][  500/  518]    Overall Loss 2.848637    Objective Loss 2.848637                                        LR 0.000008    Time 0.205133    
2023-04-27 02:13:16,900 - Epoch: [213][  518/  518]    Overall Loss 2.849587    Objective Loss 2.849587                                        LR 0.000008    Time 0.204751    
2023-04-27 02:13:16,976 - --- validate (epoch=213)-----------
2023-04-27 02:13:16,976 - 4952 samples (32 per mini-batch)
2023-04-27 02:13:23,718 - Epoch: [213][   50/  155]    Loss 3.116566    mAP 0.438327    
2023-04-27 02:13:30,073 - Epoch: [213][  100/  155]    Loss 3.129347    mAP 0.439854    
2023-04-27 02:13:36,434 - Epoch: [213][  150/  155]    Loss 3.144361    mAP 0.448404    
2023-04-27 02:13:37,002 - Epoch: [213][  155/  155]    Loss 3.144092    mAP 0.448927    
2023-04-27 02:13:37,071 - ==> mAP: 0.44893    Loss: 3.144

2023-04-27 02:13:37,075 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:13:37,075 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:13:37,112 - 

2023-04-27 02:13:37,112 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:13:48,063 - Epoch: [214][   50/  518]    Overall Loss 2.873508    Objective Loss 2.873508                                        LR 0.000008    Time 0.218961    
2023-04-27 02:13:58,233 - Epoch: [214][  100/  518]    Overall Loss 2.881475    Objective Loss 2.881475                                        LR 0.000008    Time 0.211167    
2023-04-27 02:14:08,445 - Epoch: [214][  150/  518]    Overall Loss 2.884083    Objective Loss 2.884083                                        LR 0.000008    Time 0.208848    
2023-04-27 02:14:18,541 - Epoch: [214][  200/  518]    Overall Loss 2.874653    Objective Loss 2.874653                                        LR 0.000008    Time 0.207108    
2023-04-27 02:14:28,770 - Epoch: [214][  250/  518]    Overall Loss 2.870767    Objective Loss 2.870767                                        LR 0.000008    Time 0.206594    
2023-04-27 02:14:38,972 - Epoch: [214][  300/  518]    Overall Loss 2.863197    Objective Loss 2.863197                                        LR 0.000008    Time 0.206163    
2023-04-27 02:14:49,126 - Epoch: [214][  350/  518]    Overall Loss 2.863962    Objective Loss 2.863962                                        LR 0.000008    Time 0.205718    
2023-04-27 02:14:59,311 - Epoch: [214][  400/  518]    Overall Loss 2.860906    Objective Loss 2.860906                                        LR 0.000008    Time 0.205462    
2023-04-27 02:15:09,488 - Epoch: [214][  450/  518]    Overall Loss 2.855031    Objective Loss 2.855031                                        LR 0.000008    Time 0.205245    
2023-04-27 02:15:19,594 - Epoch: [214][  500/  518]    Overall Loss 2.851344    Objective Loss 2.851344                                        LR 0.000008    Time 0.204929    
2023-04-27 02:15:23,132 - Epoch: [214][  518/  518]    Overall Loss 2.852693    Objective Loss 2.852693                                        LR 0.000008    Time 0.204636    
2023-04-27 02:15:23,209 - --- validate (epoch=214)-----------
2023-04-27 02:15:23,209 - 4952 samples (32 per mini-batch)
2023-04-27 02:15:29,982 - Epoch: [214][   50/  155]    Loss 3.136370    mAP 0.447498    
2023-04-27 02:15:36,390 - Epoch: [214][  100/  155]    Loss 3.141205    mAP 0.457661    
2023-04-27 02:15:42,762 - Epoch: [214][  150/  155]    Loss 3.142873    mAP 0.455366    
2023-04-27 02:15:43,334 - Epoch: [214][  155/  155]    Loss 3.144023    mAP 0.454042    
2023-04-27 02:15:43,409 - ==> mAP: 0.45404    Loss: 3.144

2023-04-27 02:15:43,413 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:15:43,413 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:15:43,449 - 

2023-04-27 02:15:43,449 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:15:54,217 - Epoch: [215][   50/  518]    Overall Loss 2.778113    Objective Loss 2.778113                                        LR 0.000008    Time 0.215290    
2023-04-27 02:16:04,403 - Epoch: [215][  100/  518]    Overall Loss 2.800045    Objective Loss 2.800045                                        LR 0.000008    Time 0.209495    
2023-04-27 02:16:14,490 - Epoch: [215][  150/  518]    Overall Loss 2.823687    Objective Loss 2.823687                                        LR 0.000008    Time 0.206894    
2023-04-27 02:16:24,719 - Epoch: [215][  200/  518]    Overall Loss 2.820686    Objective Loss 2.820686                                        LR 0.000008    Time 0.206310    
2023-04-27 02:16:34,864 - Epoch: [215][  250/  518]    Overall Loss 2.821546    Objective Loss 2.821546                                        LR 0.000008    Time 0.205623    
2023-04-27 02:16:45,038 - Epoch: [215][  300/  518]    Overall Loss 2.830602    Objective Loss 2.830602                                        LR 0.000008    Time 0.205258    
2023-04-27 02:16:55,217 - Epoch: [215][  350/  518]    Overall Loss 2.833941    Objective Loss 2.833941                                        LR 0.000008    Time 0.205015    
2023-04-27 02:17:05,336 - Epoch: [215][  400/  518]    Overall Loss 2.836289    Objective Loss 2.836289                                        LR 0.000008    Time 0.204681    
2023-04-27 02:17:15,477 - Epoch: [215][  450/  518]    Overall Loss 2.830951    Objective Loss 2.830951                                        LR 0.000008    Time 0.204471    
2023-04-27 02:17:25,596 - Epoch: [215][  500/  518]    Overall Loss 2.832878    Objective Loss 2.832878                                        LR 0.000008    Time 0.204259    
2023-04-27 02:17:29,142 - Epoch: [215][  518/  518]    Overall Loss 2.831842    Objective Loss 2.831842                                        LR 0.000008    Time 0.204005    
2023-04-27 02:17:29,218 - --- validate (epoch=215)-----------
2023-04-27 02:17:29,218 - 4952 samples (32 per mini-batch)
2023-04-27 02:17:35,951 - Epoch: [215][   50/  155]    Loss 3.112050    mAP 0.462622    
2023-04-27 02:17:42,379 - Epoch: [215][  100/  155]    Loss 3.156629    mAP 0.459010    
2023-04-27 02:17:48,757 - Epoch: [215][  150/  155]    Loss 3.143667    mAP 0.459783    
2023-04-27 02:17:49,329 - Epoch: [215][  155/  155]    Loss 3.144633    mAP 0.458593    
2023-04-27 02:17:49,403 - ==> mAP: 0.45859    Loss: 3.145

2023-04-27 02:17:49,407 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:17:49,407 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:17:49,444 - 

2023-04-27 02:17:49,444 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:18:00,300 - Epoch: [216][   50/  518]    Overall Loss 2.865622    Objective Loss 2.865622                                        LR 0.000008    Time 0.217078    
2023-04-27 02:18:10,461 - Epoch: [216][  100/  518]    Overall Loss 2.876797    Objective Loss 2.876797                                        LR 0.000008    Time 0.210131    
2023-04-27 02:18:20,600 - Epoch: [216][  150/  518]    Overall Loss 2.853204    Objective Loss 2.853204                                        LR 0.000008    Time 0.207667    
2023-04-27 02:18:30,683 - Epoch: [216][  200/  518]    Overall Loss 2.860055    Objective Loss 2.860055                                        LR 0.000008    Time 0.206160    
2023-04-27 02:18:40,787 - Epoch: [216][  250/  518]    Overall Loss 2.853359    Objective Loss 2.853359                                        LR 0.000008    Time 0.205334    
2023-04-27 02:18:50,978 - Epoch: [216][  300/  518]    Overall Loss 2.850698    Objective Loss 2.850698                                        LR 0.000008    Time 0.205078    
2023-04-27 02:19:01,180 - Epoch: [216][  350/  518]    Overall Loss 2.849385    Objective Loss 2.849385                                        LR 0.000008    Time 0.204925    
2023-04-27 02:19:11,372 - Epoch: [216][  400/  518]    Overall Loss 2.851756    Objective Loss 2.851756                                        LR 0.000008    Time 0.204785    
2023-04-27 02:19:21,559 - Epoch: [216][  450/  518]    Overall Loss 2.850067    Objective Loss 2.850067                                        LR 0.000008    Time 0.204666    
2023-04-27 02:19:31,708 - Epoch: [216][  500/  518]    Overall Loss 2.847753    Objective Loss 2.847753                                        LR 0.000008    Time 0.204494    
2023-04-27 02:19:35,255 - Epoch: [216][  518/  518]    Overall Loss 2.842260    Objective Loss 2.842260                                        LR 0.000008    Time 0.204234    
2023-04-27 02:19:35,334 - --- validate (epoch=216)-----------
2023-04-27 02:19:35,334 - 4952 samples (32 per mini-batch)
2023-04-27 02:19:42,221 - Epoch: [216][   50/  155]    Loss 3.166013    mAP 0.456266    
2023-04-27 02:19:48,641 - Epoch: [216][  100/  155]    Loss 3.132877    mAP 0.450977    
2023-04-27 02:19:55,028 - Epoch: [216][  150/  155]    Loss 3.141799    mAP 0.452493    
2023-04-27 02:19:55,593 - Epoch: [216][  155/  155]    Loss 3.138929    mAP 0.451681    
2023-04-27 02:19:55,660 - ==> mAP: 0.45168    Loss: 3.139

2023-04-27 02:19:55,664 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:19:55,665 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:19:55,701 - 

2023-04-27 02:19:55,701 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:20:06,579 - Epoch: [217][   50/  518]    Overall Loss 2.843319    Objective Loss 2.843319                                        LR 0.000008    Time 0.217493    
2023-04-27 02:20:16,734 - Epoch: [217][  100/  518]    Overall Loss 2.835470    Objective Loss 2.835470                                        LR 0.000008    Time 0.210283    
2023-04-27 02:20:26,886 - Epoch: [217][  150/  518]    Overall Loss 2.828563    Objective Loss 2.828563                                        LR 0.000008    Time 0.207858    
2023-04-27 02:20:37,099 - Epoch: [217][  200/  518]    Overall Loss 2.834932    Objective Loss 2.834932                                        LR 0.000008    Time 0.206948    
2023-04-27 02:20:47,261 - Epoch: [217][  250/  518]    Overall Loss 2.825416    Objective Loss 2.825416                                        LR 0.000008    Time 0.206200    
2023-04-27 02:20:57,363 - Epoch: [217][  300/  518]    Overall Loss 2.829735    Objective Loss 2.829735                                        LR 0.000008    Time 0.205502    
2023-04-27 02:21:07,577 - Epoch: [217][  350/  518]    Overall Loss 2.828849    Objective Loss 2.828849                                        LR 0.000008    Time 0.205322    
2023-04-27 02:21:17,701 - Epoch: [217][  400/  518]    Overall Loss 2.826988    Objective Loss 2.826988                                        LR 0.000008    Time 0.204964    
2023-04-27 02:21:27,822 - Epoch: [217][  450/  518]    Overall Loss 2.824717    Objective Loss 2.824717                                        LR 0.000008    Time 0.204678    
2023-04-27 02:21:38,048 - Epoch: [217][  500/  518]    Overall Loss 2.827791    Objective Loss 2.827791                                        LR 0.000008    Time 0.204658    
2023-04-27 02:21:41,580 - Epoch: [217][  518/  518]    Overall Loss 2.829156    Objective Loss 2.829156                                        LR 0.000008    Time 0.204364    
2023-04-27 02:21:41,658 - --- validate (epoch=217)-----------
2023-04-27 02:21:41,658 - 4952 samples (32 per mini-batch)
2023-04-27 02:21:48,424 - Epoch: [217][   50/  155]    Loss 3.080807    mAP 0.446506    
2023-04-27 02:21:54,844 - Epoch: [217][  100/  155]    Loss 3.113131    mAP 0.455380    
2023-04-27 02:22:01,268 - Epoch: [217][  150/  155]    Loss 3.145501    mAP 0.449260    
2023-04-27 02:22:01,845 - Epoch: [217][  155/  155]    Loss 3.143686    mAP 0.447863    
2023-04-27 02:22:01,913 - ==> mAP: 0.44786    Loss: 3.144

2023-04-27 02:22:01,917 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:22:01,917 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:22:01,954 - 

2023-04-27 02:22:01,954 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:22:12,954 - Epoch: [218][   50/  518]    Overall Loss 2.804906    Objective Loss 2.804906                                        LR 0.000008    Time 0.219933    
2023-04-27 02:22:23,083 - Epoch: [218][  100/  518]    Overall Loss 2.799984    Objective Loss 2.799984                                        LR 0.000008    Time 0.211241    
2023-04-27 02:22:33,297 - Epoch: [218][  150/  518]    Overall Loss 2.827940    Objective Loss 2.827940                                        LR 0.000008    Time 0.208913    
2023-04-27 02:22:43,419 - Epoch: [218][  200/  518]    Overall Loss 2.823601    Objective Loss 2.823601                                        LR 0.000008    Time 0.207284    
2023-04-27 02:22:53,682 - Epoch: [218][  250/  518]    Overall Loss 2.829039    Objective Loss 2.829039                                        LR 0.000008    Time 0.206876    
2023-04-27 02:23:03,783 - Epoch: [218][  300/  518]    Overall Loss 2.830125    Objective Loss 2.830125                                        LR 0.000008    Time 0.206060    
2023-04-27 02:23:13,879 - Epoch: [218][  350/  518]    Overall Loss 2.837434    Objective Loss 2.837434                                        LR 0.000008    Time 0.205463    
2023-04-27 02:23:23,956 - Epoch: [218][  400/  518]    Overall Loss 2.838470    Objective Loss 2.838470                                        LR 0.000008    Time 0.204969    
2023-04-27 02:23:34,125 - Epoch: [218][  450/  518]    Overall Loss 2.832557    Objective Loss 2.832557                                        LR 0.000008    Time 0.204788    
2023-04-27 02:23:44,343 - Epoch: [218][  500/  518]    Overall Loss 2.829257    Objective Loss 2.829257                                        LR 0.000008    Time 0.204743    
2023-04-27 02:23:47,862 - Epoch: [218][  518/  518]    Overall Loss 2.830546    Objective Loss 2.830546                                        LR 0.000008    Time 0.204421    
2023-04-27 02:23:47,938 - --- validate (epoch=218)-----------
2023-04-27 02:23:47,939 - 4952 samples (32 per mini-batch)
2023-04-27 02:23:54,685 - Epoch: [218][   50/  155]    Loss 3.130098    mAP 0.445228    
2023-04-27 02:24:01,124 - Epoch: [218][  100/  155]    Loss 3.139987    mAP 0.437544    
2023-04-27 02:24:07,463 - Epoch: [218][  150/  155]    Loss 3.149896    mAP 0.441051    
2023-04-27 02:24:08,032 - Epoch: [218][  155/  155]    Loss 3.145768    mAP 0.442957    
2023-04-27 02:24:08,102 - ==> mAP: 0.44296    Loss: 3.146

2023-04-27 02:24:08,106 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:24:08,106 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:24:08,144 - 

2023-04-27 02:24:08,144 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:24:19,152 - Epoch: [219][   50/  518]    Overall Loss 2.814052    Objective Loss 2.814052                                        LR 0.000008    Time 0.220107    
2023-04-27 02:24:29,210 - Epoch: [219][  100/  518]    Overall Loss 2.838779    Objective Loss 2.838779                                        LR 0.000008    Time 0.210611    
2023-04-27 02:24:39,312 - Epoch: [219][  150/  518]    Overall Loss 2.829193    Objective Loss 2.829193                                        LR 0.000008    Time 0.207745    
2023-04-27 02:24:49,478 - Epoch: [219][  200/  518]    Overall Loss 2.825765    Objective Loss 2.825765                                        LR 0.000008    Time 0.206629    
2023-04-27 02:24:59,661 - Epoch: [219][  250/  518]    Overall Loss 2.828378    Objective Loss 2.828378                                        LR 0.000008    Time 0.206031    
2023-04-27 02:25:09,831 - Epoch: [219][  300/  518]    Overall Loss 2.835557    Objective Loss 2.835557                                        LR 0.000008    Time 0.205585    
2023-04-27 02:25:19,958 - Epoch: [219][  350/  518]    Overall Loss 2.835673    Objective Loss 2.835673                                        LR 0.000008    Time 0.205146    
2023-04-27 02:25:30,093 - Epoch: [219][  400/  518]    Overall Loss 2.836970    Objective Loss 2.836970                                        LR 0.000008    Time 0.204837    
2023-04-27 02:25:40,210 - Epoch: [219][  450/  518]    Overall Loss 2.841905    Objective Loss 2.841905                                        LR 0.000008    Time 0.204555    
2023-04-27 02:25:50,386 - Epoch: [219][  500/  518]    Overall Loss 2.836743    Objective Loss 2.836743                                        LR 0.000008    Time 0.204450    
2023-04-27 02:25:53,926 - Epoch: [219][  518/  518]    Overall Loss 2.835635    Objective Loss 2.835635                                        LR 0.000008    Time 0.204178    
2023-04-27 02:25:54,002 - --- validate (epoch=219)-----------
2023-04-27 02:25:54,002 - 4952 samples (32 per mini-batch)
2023-04-27 02:26:00,806 - Epoch: [219][   50/  155]    Loss 3.171045    mAP 0.450750    
2023-04-27 02:26:07,204 - Epoch: [219][  100/  155]    Loss 3.142162    mAP 0.450939    
2023-04-27 02:26:13,570 - Epoch: [219][  150/  155]    Loss 3.146542    mAP 0.449511    
2023-04-27 02:26:14,141 - Epoch: [219][  155/  155]    Loss 3.148029    mAP 0.451298    
2023-04-27 02:26:14,208 - ==> mAP: 0.45130    Loss: 3.148

2023-04-27 02:26:14,212 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:26:14,212 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:26:14,249 - 

2023-04-27 02:26:14,249 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:26:25,050 - Epoch: [220][   50/  518]    Overall Loss 2.873363    Objective Loss 2.873363                                        LR 0.000008    Time 0.215966    
2023-04-27 02:26:35,319 - Epoch: [220][  100/  518]    Overall Loss 2.845147    Objective Loss 2.845147                                        LR 0.000008    Time 0.210657    
2023-04-27 02:26:45,403 - Epoch: [220][  150/  518]    Overall Loss 2.824270    Objective Loss 2.824270                                        LR 0.000008    Time 0.207654    
2023-04-27 02:26:55,514 - Epoch: [220][  200/  518]    Overall Loss 2.835854    Objective Loss 2.835854                                        LR 0.000008    Time 0.206285    
2023-04-27 02:27:05,697 - Epoch: [220][  250/  518]    Overall Loss 2.841618    Objective Loss 2.841618                                        LR 0.000008    Time 0.205754    
2023-04-27 02:27:15,889 - Epoch: [220][  300/  518]    Overall Loss 2.838614    Objective Loss 2.838614                                        LR 0.000008    Time 0.205432    
2023-04-27 02:27:26,008 - Epoch: [220][  350/  518]    Overall Loss 2.836298    Objective Loss 2.836298                                        LR 0.000008    Time 0.204991    
2023-04-27 02:27:36,250 - Epoch: [220][  400/  518]    Overall Loss 2.828784    Objective Loss 2.828784                                        LR 0.000008    Time 0.204969    
2023-04-27 02:27:46,439 - Epoch: [220][  450/  518]    Overall Loss 2.829132    Objective Loss 2.829132                                        LR 0.000008    Time 0.204832    
2023-04-27 02:27:56,651 - Epoch: [220][  500/  518]    Overall Loss 2.831787    Objective Loss 2.831787                                        LR 0.000008    Time 0.204770    
2023-04-27 02:28:00,197 - Epoch: [220][  518/  518]    Overall Loss 2.831778    Objective Loss 2.831778                                        LR 0.000008    Time 0.204500    
2023-04-27 02:28:00,275 - --- validate (epoch=220)-----------
2023-04-27 02:28:00,275 - 4952 samples (32 per mini-batch)
2023-04-27 02:28:07,023 - Epoch: [220][   50/  155]    Loss 3.146492    mAP 0.436486    
2023-04-27 02:28:13,413 - Epoch: [220][  100/  155]    Loss 3.142854    mAP 0.440813    
2023-04-27 02:28:19,832 - Epoch: [220][  150/  155]    Loss 3.152317    mAP 0.439966    
2023-04-27 02:28:20,398 - Epoch: [220][  155/  155]    Loss 3.145767    mAP 0.442764    
2023-04-27 02:28:20,472 - ==> mAP: 0.44276    Loss: 3.146

2023-04-27 02:28:20,476 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:28:20,476 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:28:20,512 - 

2023-04-27 02:28:20,512 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:28:31,420 - Epoch: [221][   50/  518]    Overall Loss 2.824726    Objective Loss 2.824726                                        LR 0.000008    Time 0.218093    
2023-04-27 02:28:41,563 - Epoch: [221][  100/  518]    Overall Loss 2.840026    Objective Loss 2.840026                                        LR 0.000008    Time 0.210463    
2023-04-27 02:28:51,760 - Epoch: [221][  150/  518]    Overall Loss 2.831188    Objective Loss 2.831188                                        LR 0.000008    Time 0.208273    
2023-04-27 02:29:01,975 - Epoch: [221][  200/  518]    Overall Loss 2.828506    Objective Loss 2.828506                                        LR 0.000008    Time 0.207272    
2023-04-27 02:29:12,179 - Epoch: [221][  250/  518]    Overall Loss 2.826878    Objective Loss 2.826878                                        LR 0.000008    Time 0.206630    
2023-04-27 02:29:22,310 - Epoch: [221][  300/  518]    Overall Loss 2.832307    Objective Loss 2.832307                                        LR 0.000008    Time 0.205955    
2023-04-27 02:29:32,438 - Epoch: [221][  350/  518]    Overall Loss 2.839205    Objective Loss 2.839205                                        LR 0.000008    Time 0.205466    
2023-04-27 02:29:42,603 - Epoch: [221][  400/  518]    Overall Loss 2.841577    Objective Loss 2.841577                                        LR 0.000008    Time 0.205192    
2023-04-27 02:29:52,804 - Epoch: [221][  450/  518]    Overall Loss 2.843710    Objective Loss 2.843710                                        LR 0.000008    Time 0.205057    
2023-04-27 02:30:02,941 - Epoch: [221][  500/  518]    Overall Loss 2.840918    Objective Loss 2.840918                                        LR 0.000008    Time 0.204822    
2023-04-27 02:30:06,520 - Epoch: [221][  518/  518]    Overall Loss 2.841006    Objective Loss 2.841006                                        LR 0.000008    Time 0.204612    
2023-04-27 02:30:06,597 - --- validate (epoch=221)-----------
2023-04-27 02:30:06,597 - 4952 samples (32 per mini-batch)
2023-04-27 02:30:13,329 - Epoch: [221][   50/  155]    Loss 3.121237    mAP 0.470564    
2023-04-27 02:30:19,688 - Epoch: [221][  100/  155]    Loss 3.159309    mAP 0.455097    
2023-04-27 02:30:26,042 - Epoch: [221][  150/  155]    Loss 3.149493    mAP 0.454794    
2023-04-27 02:30:26,623 - Epoch: [221][  155/  155]    Loss 3.149910    mAP 0.454811    
2023-04-27 02:30:26,700 - ==> mAP: 0.45481    Loss: 3.150

2023-04-27 02:30:26,704 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:30:26,704 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:30:26,740 - 

2023-04-27 02:30:26,740 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:30:37,563 - Epoch: [222][   50/  518]    Overall Loss 2.884980    Objective Loss 2.884980                                        LR 0.000008    Time 0.216398    
2023-04-27 02:30:47,714 - Epoch: [222][  100/  518]    Overall Loss 2.854767    Objective Loss 2.854767                                        LR 0.000008    Time 0.209699    
2023-04-27 02:30:57,841 - Epoch: [222][  150/  518]    Overall Loss 2.837080    Objective Loss 2.837080                                        LR 0.000008    Time 0.207302    
2023-04-27 02:31:07,959 - Epoch: [222][  200/  518]    Overall Loss 2.839298    Objective Loss 2.839298                                        LR 0.000008    Time 0.206060    
2023-04-27 02:31:18,040 - Epoch: [222][  250/  518]    Overall Loss 2.837534    Objective Loss 2.837534                                        LR 0.000008    Time 0.205165    
2023-04-27 02:31:28,142 - Epoch: [222][  300/  518]    Overall Loss 2.833342    Objective Loss 2.833342                                        LR 0.000008    Time 0.204637    
2023-04-27 02:31:38,313 - Epoch: [222][  350/  518]    Overall Loss 2.835090    Objective Loss 2.835090                                        LR 0.000008    Time 0.204458    
2023-04-27 02:31:48,557 - Epoch: [222][  400/  518]    Overall Loss 2.835406    Objective Loss 2.835406                                        LR 0.000008    Time 0.204507    
2023-04-27 02:31:58,719 - Epoch: [222][  450/  518]    Overall Loss 2.835215    Objective Loss 2.835215                                        LR 0.000008    Time 0.204364    
2023-04-27 02:32:08,819 - Epoch: [222][  500/  518]    Overall Loss 2.829819    Objective Loss 2.829819                                        LR 0.000008    Time 0.204124    
2023-04-27 02:32:12,340 - Epoch: [222][  518/  518]    Overall Loss 2.834090    Objective Loss 2.834090                                        LR 0.000008    Time 0.203827    
2023-04-27 02:32:12,418 - --- validate (epoch=222)-----------
2023-04-27 02:32:12,418 - 4952 samples (32 per mini-batch)
2023-04-27 02:32:19,250 - Epoch: [222][   50/  155]    Loss 3.128718    mAP 0.449431    
2023-04-27 02:32:25,683 - Epoch: [222][  100/  155]    Loss 3.132788    mAP 0.462313    
2023-04-27 02:32:32,031 - Epoch: [222][  150/  155]    Loss 3.150789    mAP 0.455601    
2023-04-27 02:32:32,596 - Epoch: [222][  155/  155]    Loss 3.145550    mAP 0.455863    
2023-04-27 02:32:32,670 - ==> mAP: 0.45586    Loss: 3.146

2023-04-27 02:32:32,674 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:32:32,674 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:32:32,711 - 

2023-04-27 02:32:32,711 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:32:43,623 - Epoch: [223][   50/  518]    Overall Loss 2.888458    Objective Loss 2.888458                                        LR 0.000008    Time 0.218198    
2023-04-27 02:32:53,710 - Epoch: [223][  100/  518]    Overall Loss 2.830577    Objective Loss 2.830577                                        LR 0.000008    Time 0.209951    
2023-04-27 02:33:03,880 - Epoch: [223][  150/  518]    Overall Loss 2.836017    Objective Loss 2.836017                                        LR 0.000008    Time 0.207756    
2023-04-27 02:33:14,046 - Epoch: [223][  200/  518]    Overall Loss 2.833491    Objective Loss 2.833491                                        LR 0.000008    Time 0.206637    
2023-04-27 02:33:24,146 - Epoch: [223][  250/  518]    Overall Loss 2.830746    Objective Loss 2.830746                                        LR 0.000008    Time 0.205703    
2023-04-27 02:33:34,221 - Epoch: [223][  300/  518]    Overall Loss 2.839087    Objective Loss 2.839087                                        LR 0.000008    Time 0.204998    
2023-04-27 02:33:44,338 - Epoch: [223][  350/  518]    Overall Loss 2.832340    Objective Loss 2.832340                                        LR 0.000008    Time 0.204612    
2023-04-27 02:33:54,555 - Epoch: [223][  400/  518]    Overall Loss 2.838476    Objective Loss 2.838476                                        LR 0.000008    Time 0.204575    
2023-04-27 02:34:04,808 - Epoch: [223][  450/  518]    Overall Loss 2.837566    Objective Loss 2.837566                                        LR 0.000008    Time 0.204625    
2023-04-27 02:34:14,963 - Epoch: [223][  500/  518]    Overall Loss 2.841154    Objective Loss 2.841154                                        LR 0.000008    Time 0.204470    
2023-04-27 02:34:18,520 - Epoch: [223][  518/  518]    Overall Loss 2.842962    Objective Loss 2.842962                                        LR 0.000008    Time 0.204231    
2023-04-27 02:34:18,597 - --- validate (epoch=223)-----------
2023-04-27 02:34:18,597 - 4952 samples (32 per mini-batch)
2023-04-27 02:34:25,365 - Epoch: [223][   50/  155]    Loss 3.163072    mAP 0.453233    
2023-04-27 02:34:31,793 - Epoch: [223][  100/  155]    Loss 3.155975    mAP 0.455115    
2023-04-27 02:34:38,184 - Epoch: [223][  150/  155]    Loss 3.151138    mAP 0.456696    
2023-04-27 02:34:38,748 - Epoch: [223][  155/  155]    Loss 3.147809    mAP 0.457403    
2023-04-27 02:34:38,823 - ==> mAP: 0.45740    Loss: 3.148

2023-04-27 02:34:38,827 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:34:38,827 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:34:38,864 - 

2023-04-27 02:34:38,864 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:34:49,757 - Epoch: [224][   50/  518]    Overall Loss 2.832989    Objective Loss 2.832989                                        LR 0.000008    Time 0.217810    
2023-04-27 02:34:59,906 - Epoch: [224][  100/  518]    Overall Loss 2.835877    Objective Loss 2.835877                                        LR 0.000008    Time 0.210383    
2023-04-27 02:35:09,986 - Epoch: [224][  150/  518]    Overall Loss 2.830155    Objective Loss 2.830155                                        LR 0.000008    Time 0.207440    
2023-04-27 02:35:20,160 - Epoch: [224][  200/  518]    Overall Loss 2.816419    Objective Loss 2.816419                                        LR 0.000008    Time 0.206441    
2023-04-27 02:35:30,274 - Epoch: [224][  250/  518]    Overall Loss 2.816431    Objective Loss 2.816431                                        LR 0.000008    Time 0.205604    
2023-04-27 02:35:40,401 - Epoch: [224][  300/  518]    Overall Loss 2.814538    Objective Loss 2.814538                                        LR 0.000008    Time 0.205087    
2023-04-27 02:35:50,516 - Epoch: [224][  350/  518]    Overall Loss 2.821973    Objective Loss 2.821973                                        LR 0.000008    Time 0.204684    
2023-04-27 02:36:00,718 - Epoch: [224][  400/  518]    Overall Loss 2.824792    Objective Loss 2.824792                                        LR 0.000008    Time 0.204601    
2023-04-27 02:36:10,960 - Epoch: [224][  450/  518]    Overall Loss 2.828365    Objective Loss 2.828365                                        LR 0.000008    Time 0.204624    
2023-04-27 02:36:21,096 - Epoch: [224][  500/  518]    Overall Loss 2.829100    Objective Loss 2.829100                                        LR 0.000008    Time 0.204429    
2023-04-27 02:36:24,626 - Epoch: [224][  518/  518]    Overall Loss 2.830941    Objective Loss 2.830941                                        LR 0.000008    Time 0.204141    
2023-04-27 02:36:24,703 - --- validate (epoch=224)-----------
2023-04-27 02:36:24,704 - 4952 samples (32 per mini-batch)
2023-04-27 02:36:31,459 - Epoch: [224][   50/  155]    Loss 3.172251    mAP 0.443992    
2023-04-27 02:36:37,825 - Epoch: [224][  100/  155]    Loss 3.153487    mAP 0.444766    
2023-04-27 02:36:44,182 - Epoch: [224][  150/  155]    Loss 3.156451    mAP 0.438891    
2023-04-27 02:36:44,759 - Epoch: [224][  155/  155]    Loss 3.149283    mAP 0.439560    
2023-04-27 02:36:44,831 - ==> mAP: 0.43956    Loss: 3.149

2023-04-27 02:36:44,835 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:36:44,835 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:36:44,872 - 

2023-04-27 02:36:44,872 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:36:55,817 - Epoch: [225][   50/  518]    Overall Loss 2.857843    Objective Loss 2.857843                                        LR 0.000008    Time 0.218856    
2023-04-27 02:37:05,885 - Epoch: [225][  100/  518]    Overall Loss 2.859336    Objective Loss 2.859336                                        LR 0.000008    Time 0.210085    
2023-04-27 02:37:16,049 - Epoch: [225][  150/  518]    Overall Loss 2.843288    Objective Loss 2.843288                                        LR 0.000008    Time 0.207811    
2023-04-27 02:37:26,221 - Epoch: [225][  200/  518]    Overall Loss 2.843984    Objective Loss 2.843984                                        LR 0.000008    Time 0.206707    
2023-04-27 02:37:36,378 - Epoch: [225][  250/  518]    Overall Loss 2.857188    Objective Loss 2.857188                                        LR 0.000008    Time 0.205987    
2023-04-27 02:37:46,589 - Epoch: [225][  300/  518]    Overall Loss 2.843422    Objective Loss 2.843422                                        LR 0.000008    Time 0.205689    
2023-04-27 02:37:56,804 - Epoch: [225][  350/  518]    Overall Loss 2.848327    Objective Loss 2.848327                                        LR 0.000008    Time 0.205486    
2023-04-27 02:38:06,986 - Epoch: [225][  400/  518]    Overall Loss 2.843583    Objective Loss 2.843583                                        LR 0.000008    Time 0.205250    
2023-04-27 02:38:17,200 - Epoch: [225][  450/  518]    Overall Loss 2.844764    Objective Loss 2.844764                                        LR 0.000008    Time 0.205138    
2023-04-27 02:38:27,397 - Epoch: [225][  500/  518]    Overall Loss 2.850501    Objective Loss 2.850501                                        LR 0.000008    Time 0.205015    
2023-04-27 02:38:30,921 - Epoch: [225][  518/  518]    Overall Loss 2.851611    Objective Loss 2.851611                                        LR 0.000008    Time 0.204694    
2023-04-27 02:38:30,999 - --- validate (epoch=225)-----------
2023-04-27 02:38:31,000 - 4952 samples (32 per mini-batch)
2023-04-27 02:38:37,723 - Epoch: [225][   50/  155]    Loss 3.126545    mAP 0.449003    
2023-04-27 02:38:44,169 - Epoch: [225][  100/  155]    Loss 3.145622    mAP 0.449000    
2023-04-27 02:38:50,557 - Epoch: [225][  150/  155]    Loss 3.147282    mAP 0.450089    
2023-04-27 02:38:51,137 - Epoch: [225][  155/  155]    Loss 3.148065    mAP 0.449709    
2023-04-27 02:38:51,211 - ==> mAP: 0.44971    Loss: 3.148

2023-04-27 02:38:51,215 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:38:51,215 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:38:51,251 - 

2023-04-27 02:38:51,251 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:39:02,033 - Epoch: [226][   50/  518]    Overall Loss 2.831670    Objective Loss 2.831670                                        LR 0.000008    Time 0.215584    
2023-04-27 02:39:12,135 - Epoch: [226][  100/  518]    Overall Loss 2.838696    Objective Loss 2.838696                                        LR 0.000008    Time 0.208797    
2023-04-27 02:39:22,314 - Epoch: [226][  150/  518]    Overall Loss 2.844421    Objective Loss 2.844421                                        LR 0.000008    Time 0.207048    
2023-04-27 02:39:32,562 - Epoch: [226][  200/  518]    Overall Loss 2.836894    Objective Loss 2.836894                                        LR 0.000008    Time 0.206516    
2023-04-27 02:39:42,779 - Epoch: [226][  250/  518]    Overall Loss 2.838951    Objective Loss 2.838951                                        LR 0.000008    Time 0.206075    
2023-04-27 02:39:52,863 - Epoch: [226][  300/  518]    Overall Loss 2.838262    Objective Loss 2.838262                                        LR 0.000008    Time 0.205336    
2023-04-27 02:40:03,020 - Epoch: [226][  350/  518]    Overall Loss 2.832724    Objective Loss 2.832724                                        LR 0.000008    Time 0.205016    
2023-04-27 02:40:13,149 - Epoch: [226][  400/  518]    Overall Loss 2.832034    Objective Loss 2.832034                                        LR 0.000008    Time 0.204710    
2023-04-27 02:40:23,281 - Epoch: [226][  450/  518]    Overall Loss 2.834972    Objective Loss 2.834972                                        LR 0.000008    Time 0.204476    
2023-04-27 02:40:33,421 - Epoch: [226][  500/  518]    Overall Loss 2.825047    Objective Loss 2.825047                                        LR 0.000008    Time 0.204305    
2023-04-27 02:40:36,930 - Epoch: [226][  518/  518]    Overall Loss 2.827463    Objective Loss 2.827463                                        LR 0.000008    Time 0.203979    
2023-04-27 02:40:37,007 - --- validate (epoch=226)-----------
2023-04-27 02:40:37,007 - 4952 samples (32 per mini-batch)
2023-04-27 02:40:43,786 - Epoch: [226][   50/  155]    Loss 3.124058    mAP 0.443947    
2023-04-27 02:40:50,222 - Epoch: [226][  100/  155]    Loss 3.144361    mAP 0.452168    
2023-04-27 02:40:56,598 - Epoch: [226][  150/  155]    Loss 3.149067    mAP 0.452027    
2023-04-27 02:40:57,164 - Epoch: [226][  155/  155]    Loss 3.148602    mAP 0.453183    
2023-04-27 02:40:57,247 - ==> mAP: 0.45318    Loss: 3.149

2023-04-27 02:40:57,252 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:40:57,252 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:40:57,289 - 

2023-04-27 02:40:57,289 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:41:08,209 - Epoch: [227][   50/  518]    Overall Loss 2.835131    Objective Loss 2.835131                                        LR 0.000008    Time 0.218333    
2023-04-27 02:41:18,328 - Epoch: [227][  100/  518]    Overall Loss 2.834554    Objective Loss 2.834554                                        LR 0.000008    Time 0.210339    
2023-04-27 02:41:28,485 - Epoch: [227][  150/  518]    Overall Loss 2.840147    Objective Loss 2.840147                                        LR 0.000008    Time 0.207928    
2023-04-27 02:41:38,589 - Epoch: [227][  200/  518]    Overall Loss 2.848695    Objective Loss 2.848695                                        LR 0.000008    Time 0.206461    
2023-04-27 02:41:48,754 - Epoch: [227][  250/  518]    Overall Loss 2.844235    Objective Loss 2.844235                                        LR 0.000008    Time 0.205820    
2023-04-27 02:41:59,037 - Epoch: [227][  300/  518]    Overall Loss 2.833315    Objective Loss 2.833315                                        LR 0.000008    Time 0.205789    
2023-04-27 02:42:09,161 - Epoch: [227][  350/  518]    Overall Loss 2.835304    Objective Loss 2.835304                                        LR 0.000008    Time 0.205312    
2023-04-27 02:42:19,200 - Epoch: [227][  400/  518]    Overall Loss 2.837429    Objective Loss 2.837429                                        LR 0.000008    Time 0.204742    
2023-04-27 02:42:29,261 - Epoch: [227][  450/  518]    Overall Loss 2.834536    Objective Loss 2.834536                                        LR 0.000008    Time 0.204347    
2023-04-27 02:42:39,392 - Epoch: [227][  500/  518]    Overall Loss 2.833662    Objective Loss 2.833662                                        LR 0.000008    Time 0.204171    
2023-04-27 02:42:42,917 - Epoch: [227][  518/  518]    Overall Loss 2.834841    Objective Loss 2.834841                                        LR 0.000008    Time 0.203880    
2023-04-27 02:42:42,992 - --- validate (epoch=227)-----------
2023-04-27 02:42:42,992 - 4952 samples (32 per mini-batch)
2023-04-27 02:42:49,832 - Epoch: [227][   50/  155]    Loss 3.080485    mAP 0.462817    
2023-04-27 02:42:56,262 - Epoch: [227][  100/  155]    Loss 3.112923    mAP 0.457571    
2023-04-27 02:43:02,634 - Epoch: [227][  150/  155]    Loss 3.136484    mAP 0.451921    
2023-04-27 02:43:03,204 - Epoch: [227][  155/  155]    Loss 3.138703    mAP 0.451077    
2023-04-27 02:43:03,281 - ==> mAP: 0.45108    Loss: 3.139

2023-04-27 02:43:03,285 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:43:03,285 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:43:03,321 - 

2023-04-27 02:43:03,321 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:43:14,218 - Epoch: [228][   50/  518]    Overall Loss 2.817256    Objective Loss 2.817256                                        LR 0.000008    Time 0.217884    
2023-04-27 02:43:24,367 - Epoch: [228][  100/  518]    Overall Loss 2.809601    Objective Loss 2.809601                                        LR 0.000008    Time 0.210407    
2023-04-27 02:43:34,609 - Epoch: [228][  150/  518]    Overall Loss 2.809390    Objective Loss 2.809390                                        LR 0.000008    Time 0.208546    
2023-04-27 02:43:44,835 - Epoch: [228][  200/  518]    Overall Loss 2.806565    Objective Loss 2.806565                                        LR 0.000008    Time 0.207528    
2023-04-27 02:43:55,034 - Epoch: [228][  250/  518]    Overall Loss 2.817969    Objective Loss 2.817969                                        LR 0.000008    Time 0.206815    
2023-04-27 02:44:05,144 - Epoch: [228][  300/  518]    Overall Loss 2.828194    Objective Loss 2.828194                                        LR 0.000008    Time 0.206040    
2023-04-27 02:44:15,210 - Epoch: [228][  350/  518]    Overall Loss 2.825078    Objective Loss 2.825078                                        LR 0.000008    Time 0.205361    
2023-04-27 02:44:25,362 - Epoch: [228][  400/  518]    Overall Loss 2.831661    Objective Loss 2.831661                                        LR 0.000008    Time 0.205066    
2023-04-27 02:44:35,496 - Epoch: [228][  450/  518]    Overall Loss 2.831269    Objective Loss 2.831269                                        LR 0.000008    Time 0.204799    
2023-04-27 02:44:45,603 - Epoch: [228][  500/  518]    Overall Loss 2.834374    Objective Loss 2.834374                                        LR 0.000008    Time 0.204528    
2023-04-27 02:44:49,124 - Epoch: [228][  518/  518]    Overall Loss 2.833511    Objective Loss 2.833511                                        LR 0.000008    Time 0.204218    
2023-04-27 02:44:49,204 - --- validate (epoch=228)-----------
2023-04-27 02:44:49,204 - 4952 samples (32 per mini-batch)
2023-04-27 02:44:55,996 - Epoch: [228][   50/  155]    Loss 3.156313    mAP 0.467803    
2023-04-27 02:45:02,446 - Epoch: [228][  100/  155]    Loss 3.154921    mAP 0.457131    
2023-04-27 02:45:08,901 - Epoch: [228][  150/  155]    Loss 3.138079    mAP 0.458745    
2023-04-27 02:45:09,474 - Epoch: [228][  155/  155]    Loss 3.141108    mAP 0.456878    
2023-04-27 02:45:09,547 - ==> mAP: 0.45688    Loss: 3.141

2023-04-27 02:45:09,551 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:45:09,551 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:45:09,587 - 

2023-04-27 02:45:09,588 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:45:20,583 - Epoch: [229][   50/  518]    Overall Loss 2.840580    Objective Loss 2.840580                                        LR 0.000008    Time 0.219854    
2023-04-27 02:45:30,686 - Epoch: [229][  100/  518]    Overall Loss 2.835651    Objective Loss 2.835651                                        LR 0.000008    Time 0.210937    
2023-04-27 02:45:40,816 - Epoch: [229][  150/  518]    Overall Loss 2.838428    Objective Loss 2.838428                                        LR 0.000008    Time 0.208150    
2023-04-27 02:45:50,987 - Epoch: [229][  200/  518]    Overall Loss 2.833170    Objective Loss 2.833170                                        LR 0.000008    Time 0.206957    
2023-04-27 02:46:01,088 - Epoch: [229][  250/  518]    Overall Loss 2.824636    Objective Loss 2.824636                                        LR 0.000008    Time 0.205964    
2023-04-27 02:46:11,267 - Epoch: [229][  300/  518]    Overall Loss 2.829443    Objective Loss 2.829443                                        LR 0.000008    Time 0.205561    
2023-04-27 02:46:21,478 - Epoch: [229][  350/  518]    Overall Loss 2.828202    Objective Loss 2.828202                                        LR 0.000008    Time 0.205367    
2023-04-27 02:46:31,663 - Epoch: [229][  400/  518]    Overall Loss 2.824323    Objective Loss 2.824323                                        LR 0.000008    Time 0.205154    
2023-04-27 02:46:41,796 - Epoch: [229][  450/  518]    Overall Loss 2.826068    Objective Loss 2.826068                                        LR 0.000008    Time 0.204872    
2023-04-27 02:46:51,915 - Epoch: [229][  500/  518]    Overall Loss 2.833326    Objective Loss 2.833326                                        LR 0.000008    Time 0.204621    
2023-04-27 02:46:55,417 - Epoch: [229][  518/  518]    Overall Loss 2.834260    Objective Loss 2.834260                                        LR 0.000008    Time 0.204270    
2023-04-27 02:46:55,495 - --- validate (epoch=229)-----------
2023-04-27 02:46:55,495 - 4952 samples (32 per mini-batch)
2023-04-27 02:47:02,296 - Epoch: [229][   50/  155]    Loss 3.147352    mAP 0.468036    
2023-04-27 02:47:08,687 - Epoch: [229][  100/  155]    Loss 3.153649    mAP 0.452870    
2023-04-27 02:47:15,100 - Epoch: [229][  150/  155]    Loss 3.141868    mAP 0.456235    
2023-04-27 02:47:15,671 - Epoch: [229][  155/  155]    Loss 3.142247    mAP 0.456460    
2023-04-27 02:47:15,742 - ==> mAP: 0.45646    Loss: 3.142

2023-04-27 02:47:15,745 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:47:15,745 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:47:15,782 - 

2023-04-27 02:47:15,782 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:47:26,801 - Epoch: [230][   50/  518]    Overall Loss 2.889240    Objective Loss 2.889240                                        LR 0.000008    Time 0.220329    
2023-04-27 02:47:36,867 - Epoch: [230][  100/  518]    Overall Loss 2.848097    Objective Loss 2.848097                                        LR 0.000008    Time 0.210799    
2023-04-27 02:47:46,994 - Epoch: [230][  150/  518]    Overall Loss 2.843613    Objective Loss 2.843613                                        LR 0.000008    Time 0.208035    
2023-04-27 02:47:57,257 - Epoch: [230][  200/  518]    Overall Loss 2.842756    Objective Loss 2.842756                                        LR 0.000008    Time 0.207333    
2023-04-27 02:48:07,403 - Epoch: [230][  250/  518]    Overall Loss 2.829936    Objective Loss 2.829936                                        LR 0.000008    Time 0.206445    
2023-04-27 02:48:17,571 - Epoch: [230][  300/  518]    Overall Loss 2.830174    Objective Loss 2.830174                                        LR 0.000008    Time 0.205925    
2023-04-27 02:48:27,633 - Epoch: [230][  350/  518]    Overall Loss 2.826558    Objective Loss 2.826558                                        LR 0.000008    Time 0.205251    
2023-04-27 02:48:37,795 - Epoch: [230][  400/  518]    Overall Loss 2.825451    Objective Loss 2.825451                                        LR 0.000008    Time 0.204997    
2023-04-27 02:48:47,921 - Epoch: [230][  450/  518]    Overall Loss 2.829304    Objective Loss 2.829304                                        LR 0.000008    Time 0.204718    
2023-04-27 02:48:58,087 - Epoch: [230][  500/  518]    Overall Loss 2.829891    Objective Loss 2.829891                                        LR 0.000008    Time 0.204575    
2023-04-27 02:49:01,601 - Epoch: [230][  518/  518]    Overall Loss 2.827652    Objective Loss 2.827652                                        LR 0.000008    Time 0.204249    
2023-04-27 02:49:01,678 - --- validate (epoch=230)-----------
2023-04-27 02:49:01,679 - 4952 samples (32 per mini-batch)
2023-04-27 02:49:08,399 - Epoch: [230][   50/  155]    Loss 3.141372    mAP 0.446296    
2023-04-27 02:49:14,777 - Epoch: [230][  100/  155]    Loss 3.133139    mAP 0.460085    
2023-04-27 02:49:21,133 - Epoch: [230][  150/  155]    Loss 3.140823    mAP 0.453906    
2023-04-27 02:49:21,709 - Epoch: [230][  155/  155]    Loss 3.144497    mAP 0.452072    
2023-04-27 02:49:21,777 - ==> mAP: 0.45207    Loss: 3.144

2023-04-27 02:49:21,781 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:49:21,781 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:49:21,817 - 

2023-04-27 02:49:21,817 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:49:32,748 - Epoch: [231][   50/  518]    Overall Loss 2.826600    Objective Loss 2.826600                                        LR 0.000008    Time 0.218559    
2023-04-27 02:49:42,931 - Epoch: [231][  100/  518]    Overall Loss 2.810909    Objective Loss 2.810909                                        LR 0.000008    Time 0.211094    
2023-04-27 02:49:53,073 - Epoch: [231][  150/  518]    Overall Loss 2.816656    Objective Loss 2.816656                                        LR 0.000008    Time 0.208332    
2023-04-27 02:50:03,166 - Epoch: [231][  200/  518]    Overall Loss 2.815688    Objective Loss 2.815688                                        LR 0.000008    Time 0.206705    
2023-04-27 02:50:13,310 - Epoch: [231][  250/  518]    Overall Loss 2.828615    Objective Loss 2.828615                                        LR 0.000008    Time 0.205934    
2023-04-27 02:50:23,493 - Epoch: [231][  300/  518]    Overall Loss 2.819677    Objective Loss 2.819677                                        LR 0.000008    Time 0.205550    
2023-04-27 02:50:33,699 - Epoch: [231][  350/  518]    Overall Loss 2.823725    Objective Loss 2.823725                                        LR 0.000008    Time 0.205341    
2023-04-27 02:50:43,791 - Epoch: [231][  400/  518]    Overall Loss 2.823719    Objective Loss 2.823719                                        LR 0.000008    Time 0.204899    
2023-04-27 02:50:53,979 - Epoch: [231][  450/  518]    Overall Loss 2.825193    Objective Loss 2.825193                                        LR 0.000008    Time 0.204768    
2023-04-27 02:51:04,076 - Epoch: [231][  500/  518]    Overall Loss 2.828167    Objective Loss 2.828167                                        LR 0.000008    Time 0.204483    
2023-04-27 02:51:07,604 - Epoch: [231][  518/  518]    Overall Loss 2.833202    Objective Loss 2.833202                                        LR 0.000008    Time 0.204187    
2023-04-27 02:51:07,682 - --- validate (epoch=231)-----------
2023-04-27 02:51:07,682 - 4952 samples (32 per mini-batch)
2023-04-27 02:51:14,487 - Epoch: [231][   50/  155]    Loss 3.223501    mAP 0.454163    
2023-04-27 02:51:20,878 - Epoch: [231][  100/  155]    Loss 3.174030    mAP 0.454638    
2023-04-27 02:51:27,290 - Epoch: [231][  150/  155]    Loss 3.158317    mAP 0.456411    
2023-04-27 02:51:27,867 - Epoch: [231][  155/  155]    Loss 3.154404    mAP 0.456618    
2023-04-27 02:51:27,941 - ==> mAP: 0.45662    Loss: 3.154

2023-04-27 02:51:27,945 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:51:27,945 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:51:27,982 - 

2023-04-27 02:51:27,982 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:51:38,946 - Epoch: [232][   50/  518]    Overall Loss 2.815822    Objective Loss 2.815822                                        LR 0.000008    Time 0.219237    
2023-04-27 02:51:49,109 - Epoch: [232][  100/  518]    Overall Loss 2.805901    Objective Loss 2.805901                                        LR 0.000008    Time 0.211230    
2023-04-27 02:51:59,344 - Epoch: [232][  150/  518]    Overall Loss 2.826777    Objective Loss 2.826777                                        LR 0.000008    Time 0.209041    
2023-04-27 02:52:09,486 - Epoch: [232][  200/  518]    Overall Loss 2.826660    Objective Loss 2.826660                                        LR 0.000008    Time 0.207481    
2023-04-27 02:52:19,603 - Epoch: [232][  250/  518]    Overall Loss 2.821612    Objective Loss 2.821612                                        LR 0.000008    Time 0.206447    
2023-04-27 02:52:29,759 - Epoch: [232][  300/  518]    Overall Loss 2.825684    Objective Loss 2.825684                                        LR 0.000008    Time 0.205887    
2023-04-27 02:52:40,004 - Epoch: [232][  350/  518]    Overall Loss 2.825294    Objective Loss 2.825294                                        LR 0.000008    Time 0.205742    
2023-04-27 02:52:50,111 - Epoch: [232][  400/  518]    Overall Loss 2.825437    Objective Loss 2.825437                                        LR 0.000008    Time 0.205287    
2023-04-27 02:53:00,338 - Epoch: [232][  450/  518]    Overall Loss 2.828188    Objective Loss 2.828188                                        LR 0.000008    Time 0.205201    
2023-04-27 02:53:10,448 - Epoch: [232][  500/  518]    Overall Loss 2.830263    Objective Loss 2.830263                                        LR 0.000008    Time 0.204898    
2023-04-27 02:53:13,969 - Epoch: [232][  518/  518]    Overall Loss 2.830057    Objective Loss 2.830057                                        LR 0.000008    Time 0.204574    
2023-04-27 02:53:14,046 - --- validate (epoch=232)-----------
2023-04-27 02:53:14,046 - 4952 samples (32 per mini-batch)
2023-04-27 02:53:20,804 - Epoch: [232][   50/  155]    Loss 3.177887    mAP 0.449662    
2023-04-27 02:53:27,202 - Epoch: [232][  100/  155]    Loss 3.139085    mAP 0.450522    
2023-04-27 02:53:33,576 - Epoch: [232][  150/  155]    Loss 3.142621    mAP 0.451115    
2023-04-27 02:53:34,160 - Epoch: [232][  155/  155]    Loss 3.140389    mAP 0.450372    
2023-04-27 02:53:34,234 - ==> mAP: 0.45037    Loss: 3.140

2023-04-27 02:53:34,239 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:53:34,239 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:53:34,275 - 

2023-04-27 02:53:34,275 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:53:45,312 - Epoch: [233][   50/  518]    Overall Loss 2.842486    Objective Loss 2.842486                                        LR 0.000008    Time 0.220676    
2023-04-27 02:53:55,443 - Epoch: [233][  100/  518]    Overall Loss 2.871154    Objective Loss 2.871154                                        LR 0.000008    Time 0.211638    
2023-04-27 02:54:05,609 - Epoch: [233][  150/  518]    Overall Loss 2.860183    Objective Loss 2.860183                                        LR 0.000008    Time 0.208850    
2023-04-27 02:54:15,877 - Epoch: [233][  200/  518]    Overall Loss 2.850721    Objective Loss 2.850721                                        LR 0.000008    Time 0.207968    
2023-04-27 02:54:26,031 - Epoch: [233][  250/  518]    Overall Loss 2.859871    Objective Loss 2.859871                                        LR 0.000008    Time 0.206984    
2023-04-27 02:54:36,217 - Epoch: [233][  300/  518]    Overall Loss 2.848508    Objective Loss 2.848508                                        LR 0.000008    Time 0.206435    
2023-04-27 02:54:46,376 - Epoch: [233][  350/  518]    Overall Loss 2.847276    Objective Loss 2.847276                                        LR 0.000008    Time 0.205968    
2023-04-27 02:54:56,605 - Epoch: [233][  400/  518]    Overall Loss 2.840191    Objective Loss 2.840191                                        LR 0.000008    Time 0.205789    
2023-04-27 02:55:06,750 - Epoch: [233][  450/  518]    Overall Loss 2.835313    Objective Loss 2.835313                                        LR 0.000008    Time 0.205465    
2023-04-27 02:55:16,980 - Epoch: [233][  500/  518]    Overall Loss 2.837867    Objective Loss 2.837867                                        LR 0.000008    Time 0.205374    
2023-04-27 02:55:20,516 - Epoch: [233][  518/  518]    Overall Loss 2.836987    Objective Loss 2.836987                                        LR 0.000008    Time 0.205063    
2023-04-27 02:55:20,591 - --- validate (epoch=233)-----------
2023-04-27 02:55:20,592 - 4952 samples (32 per mini-batch)
2023-04-27 02:55:27,412 - Epoch: [233][   50/  155]    Loss 3.140055    mAP 0.463631    
2023-04-27 02:55:33,887 - Epoch: [233][  100/  155]    Loss 3.142752    mAP 0.465154    
2023-04-27 02:55:40,392 - Epoch: [233][  150/  155]    Loss 3.140647    mAP 0.465994    
2023-04-27 02:55:40,952 - Epoch: [233][  155/  155]    Loss 3.140474    mAP 0.462149    
2023-04-27 02:55:41,027 - ==> mAP: 0.46215    Loss: 3.140

2023-04-27 02:55:41,031 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:55:41,031 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:55:41,067 - 

2023-04-27 02:55:41,067 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:55:52,161 - Epoch: [234][   50/  518]    Overall Loss 2.810145    Objective Loss 2.810145                                        LR 0.000008    Time 0.221818    
2023-04-27 02:56:02,328 - Epoch: [234][  100/  518]    Overall Loss 2.827560    Objective Loss 2.827560                                        LR 0.000008    Time 0.212562    
2023-04-27 02:56:12,469 - Epoch: [234][  150/  518]    Overall Loss 2.830668    Objective Loss 2.830668                                        LR 0.000008    Time 0.209303    
2023-04-27 02:56:22,623 - Epoch: [234][  200/  518]    Overall Loss 2.833720    Objective Loss 2.833720                                        LR 0.000008    Time 0.207742    
2023-04-27 02:56:32,769 - Epoch: [234][  250/  518]    Overall Loss 2.833551    Objective Loss 2.833551                                        LR 0.000008    Time 0.206769    
2023-04-27 02:56:42,855 - Epoch: [234][  300/  518]    Overall Loss 2.840598    Objective Loss 2.840598                                        LR 0.000008    Time 0.205923    
2023-04-27 02:56:53,047 - Epoch: [234][  350/  518]    Overall Loss 2.839892    Objective Loss 2.839892                                        LR 0.000008    Time 0.205622    
2023-04-27 02:57:03,250 - Epoch: [234][  400/  518]    Overall Loss 2.845123    Objective Loss 2.845123                                        LR 0.000008    Time 0.205421    
2023-04-27 02:57:13,346 - Epoch: [234][  450/  518]    Overall Loss 2.837178    Objective Loss 2.837178                                        LR 0.000008    Time 0.205028    
2023-04-27 02:57:23,557 - Epoch: [234][  500/  518]    Overall Loss 2.837996    Objective Loss 2.837996                                        LR 0.000008    Time 0.204944    
2023-04-27 02:57:27,116 - Epoch: [234][  518/  518]    Overall Loss 2.837473    Objective Loss 2.837473                                        LR 0.000008    Time 0.204692    
2023-04-27 02:57:27,193 - --- validate (epoch=234)-----------
2023-04-27 02:57:27,193 - 4952 samples (32 per mini-batch)
2023-04-27 02:57:34,010 - Epoch: [234][   50/  155]    Loss 3.096852    mAP 0.437541    
2023-04-27 02:57:40,423 - Epoch: [234][  100/  155]    Loss 3.127265    mAP 0.445690    
2023-04-27 02:57:46,837 - Epoch: [234][  150/  155]    Loss 3.142490    mAP 0.448448    
2023-04-27 02:57:47,420 - Epoch: [234][  155/  155]    Loss 3.144693    mAP 0.448564    
2023-04-27 02:57:47,494 - ==> mAP: 0.44856    Loss: 3.145

2023-04-27 02:57:47,498 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:57:47,498 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:57:47,535 - 

2023-04-27 02:57:47,535 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 02:57:58,436 - Epoch: [235][   50/  518]    Overall Loss 2.903288    Objective Loss 2.903288                                        LR 0.000008    Time 0.217963    
2023-04-27 02:58:08,577 - Epoch: [235][  100/  518]    Overall Loss 2.869203    Objective Loss 2.869203                                        LR 0.000008    Time 0.210366    
2023-04-27 02:58:18,721 - Epoch: [235][  150/  518]    Overall Loss 2.851342    Objective Loss 2.851342                                        LR 0.000008    Time 0.207865    
2023-04-27 02:58:28,833 - Epoch: [235][  200/  518]    Overall Loss 2.841876    Objective Loss 2.841876                                        LR 0.000008    Time 0.206451    
2023-04-27 02:58:38,963 - Epoch: [235][  250/  518]    Overall Loss 2.841126    Objective Loss 2.841126                                        LR 0.000008    Time 0.205673    
2023-04-27 02:58:49,142 - Epoch: [235][  300/  518]    Overall Loss 2.853104    Objective Loss 2.853104                                        LR 0.000008    Time 0.205320    
2023-04-27 02:58:59,202 - Epoch: [235][  350/  518]    Overall Loss 2.852172    Objective Loss 2.852172                                        LR 0.000008    Time 0.204725    
2023-04-27 02:59:09,462 - Epoch: [235][  400/  518]    Overall Loss 2.847677    Objective Loss 2.847677                                        LR 0.000008    Time 0.204782    
2023-04-27 02:59:19,687 - Epoch: [235][  450/  518]    Overall Loss 2.843317    Objective Loss 2.843317                                        LR 0.000008    Time 0.204746    
2023-04-27 02:59:29,802 - Epoch: [235][  500/  518]    Overall Loss 2.851370    Objective Loss 2.851370                                        LR 0.000008    Time 0.204499    
2023-04-27 02:59:33,309 - Epoch: [235][  518/  518]    Overall Loss 2.850990    Objective Loss 2.850990                                        LR 0.000008    Time 0.204162    
2023-04-27 02:59:33,385 - --- validate (epoch=235)-----------
2023-04-27 02:59:33,386 - 4952 samples (32 per mini-batch)
2023-04-27 02:59:40,252 - Epoch: [235][   50/  155]    Loss 3.165168    mAP 0.449129    
2023-04-27 02:59:46,700 - Epoch: [235][  100/  155]    Loss 3.162542    mAP 0.450145    
2023-04-27 02:59:53,052 - Epoch: [235][  150/  155]    Loss 3.148512    mAP 0.449439    
2023-04-27 02:59:53,633 - Epoch: [235][  155/  155]    Loss 3.144292    mAP 0.450877    
2023-04-27 02:59:53,707 - ==> mAP: 0.45088    Loss: 3.144

2023-04-27 02:59:53,711 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 02:59:53,711 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 02:59:53,747 - 

2023-04-27 02:59:53,747 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:00:04,803 - Epoch: [236][   50/  518]    Overall Loss 2.860995    Objective Loss 2.860995                                        LR 0.000008    Time 0.221067    
2023-04-27 03:00:14,911 - Epoch: [236][  100/  518]    Overall Loss 2.849574    Objective Loss 2.849574                                        LR 0.000008    Time 0.211594    
2023-04-27 03:00:25,115 - Epoch: [236][  150/  518]    Overall Loss 2.836780    Objective Loss 2.836780                                        LR 0.000008    Time 0.209082    
2023-04-27 03:00:35,309 - Epoch: [236][  200/  518]    Overall Loss 2.830969    Objective Loss 2.830969                                        LR 0.000008    Time 0.207770    
2023-04-27 03:00:45,475 - Epoch: [236][  250/  518]    Overall Loss 2.837388    Objective Loss 2.837388                                        LR 0.000008    Time 0.206873    
2023-04-27 03:00:55,616 - Epoch: [236][  300/  518]    Overall Loss 2.839230    Objective Loss 2.839230                                        LR 0.000008    Time 0.206195    
2023-04-27 03:01:05,805 - Epoch: [236][  350/  518]    Overall Loss 2.834942    Objective Loss 2.834942                                        LR 0.000008    Time 0.205844    
2023-04-27 03:01:15,831 - Epoch: [236][  400/  518]    Overall Loss 2.835928    Objective Loss 2.835928                                        LR 0.000008    Time 0.205174    
2023-04-27 03:01:25,953 - Epoch: [236][  450/  518]    Overall Loss 2.833137    Objective Loss 2.833137                                        LR 0.000008    Time 0.204866    
2023-04-27 03:01:36,037 - Epoch: [236][  500/  518]    Overall Loss 2.833344    Objective Loss 2.833344                                        LR 0.000008    Time 0.204546    
2023-04-27 03:01:39,594 - Epoch: [236][  518/  518]    Overall Loss 2.830463    Objective Loss 2.830463                                        LR 0.000008    Time 0.204303    
2023-04-27 03:01:39,674 - --- validate (epoch=236)-----------
2023-04-27 03:01:39,674 - 4952 samples (32 per mini-batch)
2023-04-27 03:01:46,404 - Epoch: [236][   50/  155]    Loss 3.139010    mAP 0.460043    
2023-04-27 03:01:52,795 - Epoch: [236][  100/  155]    Loss 3.151171    mAP 0.444363    
2023-04-27 03:01:59,141 - Epoch: [236][  150/  155]    Loss 3.147443    mAP 0.443054    
2023-04-27 03:01:59,714 - Epoch: [236][  155/  155]    Loss 3.143583    mAP 0.443783    
2023-04-27 03:01:59,780 - ==> mAP: 0.44378    Loss: 3.144

2023-04-27 03:01:59,784 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:01:59,784 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:01:59,821 - 

2023-04-27 03:01:59,821 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:02:10,680 - Epoch: [237][   50/  518]    Overall Loss 2.832814    Objective Loss 2.832814                                        LR 0.000008    Time 0.217129    
2023-04-27 03:02:20,866 - Epoch: [237][  100/  518]    Overall Loss 2.825315    Objective Loss 2.825315                                        LR 0.000008    Time 0.210403    
2023-04-27 03:02:31,031 - Epoch: [237][  150/  518]    Overall Loss 2.833361    Objective Loss 2.833361                                        LR 0.000008    Time 0.208026    
2023-04-27 03:02:41,245 - Epoch: [237][  200/  518]    Overall Loss 2.837767    Objective Loss 2.837767                                        LR 0.000008    Time 0.207083    
2023-04-27 03:02:51,468 - Epoch: [237][  250/  518]    Overall Loss 2.831306    Objective Loss 2.831306                                        LR 0.000008    Time 0.206553    
2023-04-27 03:03:01,569 - Epoch: [237][  300/  518]    Overall Loss 2.832573    Objective Loss 2.832573                                        LR 0.000008    Time 0.205792    
2023-04-27 03:03:11,753 - Epoch: [237][  350/  518]    Overall Loss 2.837596    Objective Loss 2.837596                                        LR 0.000008    Time 0.205484    
2023-04-27 03:03:21,883 - Epoch: [237][  400/  518]    Overall Loss 2.836323    Objective Loss 2.836323                                        LR 0.000008    Time 0.205120    
2023-04-27 03:03:32,026 - Epoch: [237][  450/  518]    Overall Loss 2.845728    Objective Loss 2.845728                                        LR 0.000008    Time 0.204864    
2023-04-27 03:03:42,275 - Epoch: [237][  500/  518]    Overall Loss 2.841143    Objective Loss 2.841143                                        LR 0.000008    Time 0.204875    
2023-04-27 03:03:45,808 - Epoch: [237][  518/  518]    Overall Loss 2.838485    Objective Loss 2.838485                                        LR 0.000008    Time 0.204575    
2023-04-27 03:03:45,885 - --- validate (epoch=237)-----------
2023-04-27 03:03:45,885 - 4952 samples (32 per mini-batch)
2023-04-27 03:03:52,765 - Epoch: [237][   50/  155]    Loss 3.119597    mAP 0.452916    
2023-04-27 03:03:59,131 - Epoch: [237][  100/  155]    Loss 3.135302    mAP 0.448452    
2023-04-27 03:04:05,504 - Epoch: [237][  150/  155]    Loss 3.141364    mAP 0.453901    
2023-04-27 03:04:06,067 - Epoch: [237][  155/  155]    Loss 3.147882    mAP 0.450161    
2023-04-27 03:04:06,136 - ==> mAP: 0.45016    Loss: 3.148

2023-04-27 03:04:06,139 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:04:06,139 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:04:06,176 - 

2023-04-27 03:04:06,176 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:04:16,938 - Epoch: [238][   50/  518]    Overall Loss 2.824409    Objective Loss 2.824409                                        LR 0.000008    Time 0.215197    
2023-04-27 03:04:27,151 - Epoch: [238][  100/  518]    Overall Loss 2.850423    Objective Loss 2.850423                                        LR 0.000008    Time 0.209710    
2023-04-27 03:04:37,314 - Epoch: [238][  150/  518]    Overall Loss 2.821306    Objective Loss 2.821306                                        LR 0.000008    Time 0.207549    
2023-04-27 03:04:47,435 - Epoch: [238][  200/  518]    Overall Loss 2.834234    Objective Loss 2.834234                                        LR 0.000008    Time 0.206257    
2023-04-27 03:04:57,608 - Epoch: [238][  250/  518]    Overall Loss 2.841553    Objective Loss 2.841553                                        LR 0.000008    Time 0.205692    
2023-04-27 03:05:07,723 - Epoch: [238][  300/  518]    Overall Loss 2.838626    Objective Loss 2.838626                                        LR 0.000008    Time 0.205121    
2023-04-27 03:05:17,899 - Epoch: [238][  350/  518]    Overall Loss 2.831570    Objective Loss 2.831570                                        LR 0.000008    Time 0.204888    
2023-04-27 03:05:28,056 - Epoch: [238][  400/  518]    Overall Loss 2.835717    Objective Loss 2.835717                                        LR 0.000008    Time 0.204665    
2023-04-27 03:05:38,159 - Epoch: [238][  450/  518]    Overall Loss 2.834643    Objective Loss 2.834643                                        LR 0.000008    Time 0.204372    
2023-04-27 03:05:48,427 - Epoch: [238][  500/  518]    Overall Loss 2.837105    Objective Loss 2.837105                                        LR 0.000008    Time 0.204468    
2023-04-27 03:05:51,930 - Epoch: [238][  518/  518]    Overall Loss 2.835297    Objective Loss 2.835297                                        LR 0.000008    Time 0.204125    
2023-04-27 03:05:52,007 - --- validate (epoch=238)-----------
2023-04-27 03:05:52,007 - 4952 samples (32 per mini-batch)
2023-04-27 03:05:58,812 - Epoch: [238][   50/  155]    Loss 3.168899    mAP 0.430778    
2023-04-27 03:06:05,202 - Epoch: [238][  100/  155]    Loss 3.147241    mAP 0.442345    
2023-04-27 03:06:11,546 - Epoch: [238][  150/  155]    Loss 3.152410    mAP 0.441866    
2023-04-27 03:06:12,113 - Epoch: [238][  155/  155]    Loss 3.150306    mAP 0.439960    
2023-04-27 03:06:12,190 - ==> mAP: 0.43996    Loss: 3.150

2023-04-27 03:06:12,194 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:06:12,194 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:06:12,230 - 

2023-04-27 03:06:12,230 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:06:23,215 - Epoch: [239][   50/  518]    Overall Loss 2.819662    Objective Loss 2.819662                                        LR 0.000008    Time 0.219633    
2023-04-27 03:06:33,355 - Epoch: [239][  100/  518]    Overall Loss 2.822502    Objective Loss 2.822502                                        LR 0.000008    Time 0.211202    
2023-04-27 03:06:43,494 - Epoch: [239][  150/  518]    Overall Loss 2.840246    Objective Loss 2.840246                                        LR 0.000008    Time 0.208384    
2023-04-27 03:06:53,605 - Epoch: [239][  200/  518]    Overall Loss 2.833193    Objective Loss 2.833193                                        LR 0.000008    Time 0.206835    
2023-04-27 03:07:03,759 - Epoch: [239][  250/  518]    Overall Loss 2.827265    Objective Loss 2.827265                                        LR 0.000008    Time 0.206079    
2023-04-27 03:07:13,944 - Epoch: [239][  300/  518]    Overall Loss 2.840620    Objective Loss 2.840620                                        LR 0.000008    Time 0.205675    
2023-04-27 03:07:24,126 - Epoch: [239][  350/  518]    Overall Loss 2.831584    Objective Loss 2.831584                                        LR 0.000008    Time 0.205382    
2023-04-27 03:07:34,244 - Epoch: [239][  400/  518]    Overall Loss 2.837621    Objective Loss 2.837621                                        LR 0.000008    Time 0.205000    
2023-04-27 03:07:44,415 - Epoch: [239][  450/  518]    Overall Loss 2.833852    Objective Loss 2.833852                                        LR 0.000008    Time 0.204821    
2023-04-27 03:07:54,537 - Epoch: [239][  500/  518]    Overall Loss 2.831509    Objective Loss 2.831509                                        LR 0.000008    Time 0.204578    
2023-04-27 03:07:58,062 - Epoch: [239][  518/  518]    Overall Loss 2.834797    Objective Loss 2.834797                                        LR 0.000008    Time 0.204274    
2023-04-27 03:07:58,139 - --- validate (epoch=239)-----------
2023-04-27 03:07:58,140 - 4952 samples (32 per mini-batch)
2023-04-27 03:08:04,987 - Epoch: [239][   50/  155]    Loss 3.156967    mAP 0.463699    
2023-04-27 03:08:11,360 - Epoch: [239][  100/  155]    Loss 3.132672    mAP 0.457244    
2023-04-27 03:08:17,740 - Epoch: [239][  150/  155]    Loss 3.145529    mAP 0.456999    
2023-04-27 03:08:18,309 - Epoch: [239][  155/  155]    Loss 3.143130    mAP 0.457234    
2023-04-27 03:08:18,380 - ==> mAP: 0.45723    Loss: 3.143

2023-04-27 03:08:18,384 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:08:18,385 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:08:18,421 - 

2023-04-27 03:08:18,421 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:08:29,388 - Epoch: [240][   50/  518]    Overall Loss 2.887000    Objective Loss 2.887000                                        LR 0.000008    Time 0.219280    
2023-04-27 03:08:39,642 - Epoch: [240][  100/  518]    Overall Loss 2.856424    Objective Loss 2.856424                                        LR 0.000008    Time 0.212158    
2023-04-27 03:08:49,822 - Epoch: [240][  150/  518]    Overall Loss 2.853056    Objective Loss 2.853056                                        LR 0.000008    Time 0.209300    
2023-04-27 03:08:59,924 - Epoch: [240][  200/  518]    Overall Loss 2.847096    Objective Loss 2.847096                                        LR 0.000008    Time 0.207476    
2023-04-27 03:09:10,087 - Epoch: [240][  250/  518]    Overall Loss 2.849038    Objective Loss 2.849038                                        LR 0.000008    Time 0.206626    
2023-04-27 03:09:20,218 - Epoch: [240][  300/  518]    Overall Loss 2.837657    Objective Loss 2.837657                                        LR 0.000008    Time 0.205954    
2023-04-27 03:09:30,396 - Epoch: [240][  350/  518]    Overall Loss 2.840751    Objective Loss 2.840751                                        LR 0.000008    Time 0.205608    
2023-04-27 03:09:40,537 - Epoch: [240][  400/  518]    Overall Loss 2.839837    Objective Loss 2.839837                                        LR 0.000008    Time 0.205255    
2023-04-27 03:09:50,640 - Epoch: [240][  450/  518]    Overall Loss 2.841903    Objective Loss 2.841903                                        LR 0.000008    Time 0.204896    
2023-04-27 03:10:00,808 - Epoch: [240][  500/  518]    Overall Loss 2.839752    Objective Loss 2.839752                                        LR 0.000008    Time 0.204738    
2023-04-27 03:10:04,340 - Epoch: [240][  518/  518]    Overall Loss 2.839877    Objective Loss 2.839877                                        LR 0.000008    Time 0.204442    
2023-04-27 03:10:04,419 - --- validate (epoch=240)-----------
2023-04-27 03:10:04,419 - 4952 samples (32 per mini-batch)
2023-04-27 03:10:11,220 - Epoch: [240][   50/  155]    Loss 3.168273    mAP 0.456738    
2023-04-27 03:10:17,644 - Epoch: [240][  100/  155]    Loss 3.158077    mAP 0.458359    
2023-04-27 03:10:24,064 - Epoch: [240][  150/  155]    Loss 3.146985    mAP 0.458955    
2023-04-27 03:10:24,644 - Epoch: [240][  155/  155]    Loss 3.150241    mAP 0.458012    
2023-04-27 03:10:24,708 - ==> mAP: 0.45801    Loss: 3.150

2023-04-27 03:10:24,711 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:10:24,711 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:10:24,748 - 

2023-04-27 03:10:24,748 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:10:35,629 - Epoch: [241][   50/  518]    Overall Loss 2.800355    Objective Loss 2.800355                                        LR 0.000008    Time 0.217555    
2023-04-27 03:10:45,745 - Epoch: [241][  100/  518]    Overall Loss 2.851935    Objective Loss 2.851935                                        LR 0.000008    Time 0.209924    
2023-04-27 03:10:55,850 - Epoch: [241][  150/  518]    Overall Loss 2.861797    Objective Loss 2.861797                                        LR 0.000008    Time 0.207307    
2023-04-27 03:11:05,974 - Epoch: [241][  200/  518]    Overall Loss 2.850461    Objective Loss 2.850461                                        LR 0.000008    Time 0.206091    
2023-04-27 03:11:16,157 - Epoch: [241][  250/  518]    Overall Loss 2.846491    Objective Loss 2.846491                                        LR 0.000008    Time 0.205597    
2023-04-27 03:11:26,312 - Epoch: [241][  300/  518]    Overall Loss 2.847881    Objective Loss 2.847881                                        LR 0.000008    Time 0.205174    
2023-04-27 03:11:36,476 - Epoch: [241][  350/  518]    Overall Loss 2.842124    Objective Loss 2.842124                                        LR 0.000008    Time 0.204901    
2023-04-27 03:11:46,608 - Epoch: [241][  400/  518]    Overall Loss 2.842397    Objective Loss 2.842397                                        LR 0.000008    Time 0.204614    
2023-04-27 03:11:56,715 - Epoch: [241][  450/  518]    Overall Loss 2.841824    Objective Loss 2.841824                                        LR 0.000008    Time 0.204335    
2023-04-27 03:12:06,883 - Epoch: [241][  500/  518]    Overall Loss 2.841957    Objective Loss 2.841957                                        LR 0.000008    Time 0.204235    
2023-04-27 03:12:10,394 - Epoch: [241][  518/  518]    Overall Loss 2.844105    Objective Loss 2.844105                                        LR 0.000008    Time 0.203914    
2023-04-27 03:12:10,471 - --- validate (epoch=241)-----------
2023-04-27 03:12:10,471 - 4952 samples (32 per mini-batch)
2023-04-27 03:12:17,347 - Epoch: [241][   50/  155]    Loss 3.117961    mAP 0.458574    
2023-04-27 03:12:23,778 - Epoch: [241][  100/  155]    Loss 3.133963    mAP 0.451674    
2023-04-27 03:12:30,179 - Epoch: [241][  150/  155]    Loss 3.148740    mAP 0.451599    
2023-04-27 03:12:30,739 - Epoch: [241][  155/  155]    Loss 3.141148    mAP 0.452220    
2023-04-27 03:12:30,811 - ==> mAP: 0.45222    Loss: 3.141

2023-04-27 03:12:30,815 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:12:30,815 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:12:30,851 - 

2023-04-27 03:12:30,851 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:12:41,727 - Epoch: [242][   50/  518]    Overall Loss 2.849431    Objective Loss 2.849431                                        LR 0.000008    Time 0.217448    
2023-04-27 03:12:51,892 - Epoch: [242][  100/  518]    Overall Loss 2.853696    Objective Loss 2.853696                                        LR 0.000008    Time 0.210362    
2023-04-27 03:13:01,999 - Epoch: [242][  150/  518]    Overall Loss 2.852114    Objective Loss 2.852114                                        LR 0.000008    Time 0.207610    
2023-04-27 03:13:12,117 - Epoch: [242][  200/  518]    Overall Loss 2.845313    Objective Loss 2.845313                                        LR 0.000008    Time 0.206291    
2023-04-27 03:13:22,257 - Epoch: [242][  250/  518]    Overall Loss 2.848270    Objective Loss 2.848270                                        LR 0.000008    Time 0.205586    
2023-04-27 03:13:32,461 - Epoch: [242][  300/  518]    Overall Loss 2.854972    Objective Loss 2.854972                                        LR 0.000008    Time 0.205329    
2023-04-27 03:13:42,651 - Epoch: [242][  350/  518]    Overall Loss 2.847225    Objective Loss 2.847225                                        LR 0.000008    Time 0.205107    
2023-04-27 03:13:52,877 - Epoch: [242][  400/  518]    Overall Loss 2.841083    Objective Loss 2.841083                                        LR 0.000008    Time 0.205030    
2023-04-27 03:14:03,027 - Epoch: [242][  450/  518]    Overall Loss 2.832297    Objective Loss 2.832297                                        LR 0.000008    Time 0.204800    
2023-04-27 03:14:13,247 - Epoch: [242][  500/  518]    Overall Loss 2.834879    Objective Loss 2.834879                                        LR 0.000008    Time 0.204758    
2023-04-27 03:14:16,784 - Epoch: [242][  518/  518]    Overall Loss 2.836618    Objective Loss 2.836618                                        LR 0.000008    Time 0.204468    
2023-04-27 03:14:16,858 - --- validate (epoch=242)-----------
2023-04-27 03:14:16,858 - 4952 samples (32 per mini-batch)
2023-04-27 03:14:23,639 - Epoch: [242][   50/  155]    Loss 3.157299    mAP 0.443588    
2023-04-27 03:14:30,021 - Epoch: [242][  100/  155]    Loss 3.153577    mAP 0.447783    
2023-04-27 03:14:36,343 - Epoch: [242][  150/  155]    Loss 3.141548    mAP 0.450491    
2023-04-27 03:14:36,935 - Epoch: [242][  155/  155]    Loss 3.141176    mAP 0.449897    
2023-04-27 03:14:37,023 - ==> mAP: 0.44990    Loss: 3.141

2023-04-27 03:14:37,027 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:14:37,027 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:14:37,063 - 

2023-04-27 03:14:37,063 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:14:47,967 - Epoch: [243][   50/  518]    Overall Loss 2.870643    Objective Loss 2.870643                                        LR 0.000008    Time 0.218011    
2023-04-27 03:14:58,084 - Epoch: [243][  100/  518]    Overall Loss 2.865286    Objective Loss 2.865286                                        LR 0.000008    Time 0.210157    
2023-04-27 03:15:08,209 - Epoch: [243][  150/  518]    Overall Loss 2.878898    Objective Loss 2.878898                                        LR 0.000008    Time 0.207599    
2023-04-27 03:15:18,337 - Epoch: [243][  200/  518]    Overall Loss 2.871688    Objective Loss 2.871688                                        LR 0.000008    Time 0.206327    
2023-04-27 03:15:28,517 - Epoch: [243][  250/  518]    Overall Loss 2.864661    Objective Loss 2.864661                                        LR 0.000008    Time 0.205779    
2023-04-27 03:15:38,698 - Epoch: [243][  300/  518]    Overall Loss 2.856239    Objective Loss 2.856239                                        LR 0.000008    Time 0.205412    
2023-04-27 03:15:48,887 - Epoch: [243][  350/  518]    Overall Loss 2.849897    Objective Loss 2.849897                                        LR 0.000008    Time 0.205174    
2023-04-27 03:15:59,016 - Epoch: [243][  400/  518]    Overall Loss 2.853410    Objective Loss 2.853410                                        LR 0.000008    Time 0.204847    
2023-04-27 03:16:09,115 - Epoch: [243][  450/  518]    Overall Loss 2.845115    Objective Loss 2.845115                                        LR 0.000008    Time 0.204524    
2023-04-27 03:16:19,301 - Epoch: [243][  500/  518]    Overall Loss 2.850060    Objective Loss 2.850060                                        LR 0.000008    Time 0.204440    
2023-04-27 03:16:22,824 - Epoch: [243][  518/  518]    Overall Loss 2.850139    Objective Loss 2.850139                                        LR 0.000008    Time 0.204136    
2023-04-27 03:16:22,900 - --- validate (epoch=243)-----------
2023-04-27 03:16:22,901 - 4952 samples (32 per mini-batch)
2023-04-27 03:16:29,715 - Epoch: [243][   50/  155]    Loss 3.140612    mAP 0.443695    
2023-04-27 03:16:36,122 - Epoch: [243][  100/  155]    Loss 3.136742    mAP 0.454521    
2023-04-27 03:16:42,596 - Epoch: [243][  150/  155]    Loss 3.148346    mAP 0.456518    
2023-04-27 03:16:43,150 - Epoch: [243][  155/  155]    Loss 3.153287    mAP 0.454238    
2023-04-27 03:16:43,217 - ==> mAP: 0.45424    Loss: 3.153

2023-04-27 03:16:43,221 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:16:43,221 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:16:43,258 - 

2023-04-27 03:16:43,258 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:16:54,221 - Epoch: [244][   50/  518]    Overall Loss 2.761588    Objective Loss 2.761588                                        LR 0.000008    Time 0.219211    
2023-04-27 03:17:04,381 - Epoch: [244][  100/  518]    Overall Loss 2.795673    Objective Loss 2.795673                                        LR 0.000008    Time 0.211185    
2023-04-27 03:17:14,520 - Epoch: [244][  150/  518]    Overall Loss 2.804243    Objective Loss 2.804243                                        LR 0.000008    Time 0.208375    
2023-04-27 03:17:24,755 - Epoch: [244][  200/  518]    Overall Loss 2.816166    Objective Loss 2.816166                                        LR 0.000008    Time 0.207446    
2023-04-27 03:17:34,980 - Epoch: [244][  250/  518]    Overall Loss 2.823339    Objective Loss 2.823339                                        LR 0.000008    Time 0.206851    
2023-04-27 03:17:45,131 - Epoch: [244][  300/  518]    Overall Loss 2.831828    Objective Loss 2.831828                                        LR 0.000008    Time 0.206208    
2023-04-27 03:17:55,259 - Epoch: [244][  350/  518]    Overall Loss 2.838586    Objective Loss 2.838586                                        LR 0.000008    Time 0.205682    
2023-04-27 03:18:05,384 - Epoch: [244][  400/  518]    Overall Loss 2.838281    Objective Loss 2.838281                                        LR 0.000008    Time 0.205280    
2023-04-27 03:18:15,587 - Epoch: [244][  450/  518]    Overall Loss 2.838302    Objective Loss 2.838302                                        LR 0.000008    Time 0.205140    
2023-04-27 03:18:25,814 - Epoch: [244][  500/  518]    Overall Loss 2.835812    Objective Loss 2.835812                                        LR 0.000008    Time 0.205078    
2023-04-27 03:18:29,392 - Epoch: [244][  518/  518]    Overall Loss 2.835433    Objective Loss 2.835433                                        LR 0.000008    Time 0.204857    
2023-04-27 03:18:29,469 - --- validate (epoch=244)-----------
2023-04-27 03:18:29,469 - 4952 samples (32 per mini-batch)
2023-04-27 03:18:36,252 - Epoch: [244][   50/  155]    Loss 3.169090    mAP 0.459490    
2023-04-27 03:18:42,663 - Epoch: [244][  100/  155]    Loss 3.148612    mAP 0.462304    
2023-04-27 03:18:49,025 - Epoch: [244][  150/  155]    Loss 3.143157    mAP 0.457734    
2023-04-27 03:18:49,590 - Epoch: [244][  155/  155]    Loss 3.143421    mAP 0.457843    
2023-04-27 03:18:49,671 - ==> mAP: 0.45784    Loss: 3.143

2023-04-27 03:18:49,675 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:18:49,675 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:18:49,712 - 

2023-04-27 03:18:49,712 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:19:00,669 - Epoch: [245][   50/  518]    Overall Loss 2.872949    Objective Loss 2.872949                                        LR 0.000008    Time 0.219091    
2023-04-27 03:19:10,922 - Epoch: [245][  100/  518]    Overall Loss 2.870876    Objective Loss 2.870876                                        LR 0.000008    Time 0.212061    
2023-04-27 03:19:21,034 - Epoch: [245][  150/  518]    Overall Loss 2.869929    Objective Loss 2.869929                                        LR 0.000008    Time 0.208775    
2023-04-27 03:19:31,248 - Epoch: [245][  200/  518]    Overall Loss 2.850621    Objective Loss 2.850621                                        LR 0.000008    Time 0.207642    
2023-04-27 03:19:41,444 - Epoch: [245][  250/  518]    Overall Loss 2.841840    Objective Loss 2.841840                                        LR 0.000008    Time 0.206890    
2023-04-27 03:19:51,637 - Epoch: [245][  300/  518]    Overall Loss 2.828718    Objective Loss 2.828718                                        LR 0.000008    Time 0.206379    
2023-04-27 03:20:01,784 - Epoch: [245][  350/  518]    Overall Loss 2.826111    Objective Loss 2.826111                                        LR 0.000008    Time 0.205883    
2023-04-27 03:20:11,853 - Epoch: [245][  400/  518]    Overall Loss 2.825982    Objective Loss 2.825982                                        LR 0.000008    Time 0.205316    
2023-04-27 03:20:22,049 - Epoch: [245][  450/  518]    Overall Loss 2.826327    Objective Loss 2.826327                                        LR 0.000008    Time 0.205158    
2023-04-27 03:20:32,195 - Epoch: [245][  500/  518]    Overall Loss 2.830322    Objective Loss 2.830322                                        LR 0.000008    Time 0.204932    
2023-04-27 03:20:35,707 - Epoch: [245][  518/  518]    Overall Loss 2.832335    Objective Loss 2.832335                                        LR 0.000008    Time 0.204588    
2023-04-27 03:20:35,784 - --- validate (epoch=245)-----------
2023-04-27 03:20:35,784 - 4952 samples (32 per mini-batch)
2023-04-27 03:20:42,522 - Epoch: [245][   50/  155]    Loss 3.124952    mAP 0.437278    
2023-04-27 03:20:48,914 - Epoch: [245][  100/  155]    Loss 3.127481    mAP 0.445795    
2023-04-27 03:20:55,342 - Epoch: [245][  150/  155]    Loss 3.139831    mAP 0.446873    
2023-04-27 03:20:55,910 - Epoch: [245][  155/  155]    Loss 3.143261    mAP 0.445066    
2023-04-27 03:20:55,994 - ==> mAP: 0.44507    Loss: 3.143

2023-04-27 03:20:55,998 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:20:55,998 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:20:56,034 - 

2023-04-27 03:20:56,035 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:21:07,032 - Epoch: [246][   50/  518]    Overall Loss 2.860270    Objective Loss 2.860270                                        LR 0.000008    Time 0.219885    
2023-04-27 03:21:17,216 - Epoch: [246][  100/  518]    Overall Loss 2.880617    Objective Loss 2.880617                                        LR 0.000008    Time 0.211775    
2023-04-27 03:21:27,348 - Epoch: [246][  150/  518]    Overall Loss 2.855224    Objective Loss 2.855224                                        LR 0.000008    Time 0.208714    
2023-04-27 03:21:37,461 - Epoch: [246][  200/  518]    Overall Loss 2.851640    Objective Loss 2.851640                                        LR 0.000008    Time 0.207094    
2023-04-27 03:21:47,578 - Epoch: [246][  250/  518]    Overall Loss 2.850439    Objective Loss 2.850439                                        LR 0.000008    Time 0.206137    
2023-04-27 03:21:57,735 - Epoch: [246][  300/  518]    Overall Loss 2.849799    Objective Loss 2.849799                                        LR 0.000008    Time 0.205634    
2023-04-27 03:22:07,940 - Epoch: [246][  350/  518]    Overall Loss 2.850857    Objective Loss 2.850857                                        LR 0.000008    Time 0.205407    
2023-04-27 03:22:18,101 - Epoch: [246][  400/  518]    Overall Loss 2.850094    Objective Loss 2.850094                                        LR 0.000008    Time 0.205132    
2023-04-27 03:22:28,226 - Epoch: [246][  450/  518]    Overall Loss 2.841234    Objective Loss 2.841234                                        LR 0.000008    Time 0.204835    
2023-04-27 03:22:38,405 - Epoch: [246][  500/  518]    Overall Loss 2.842936    Objective Loss 2.842936                                        LR 0.000008    Time 0.204707    
2023-04-27 03:22:42,003 - Epoch: [246][  518/  518]    Overall Loss 2.842401    Objective Loss 2.842401                                        LR 0.000008    Time 0.204538    
2023-04-27 03:22:42,082 - --- validate (epoch=246)-----------
2023-04-27 03:22:42,082 - 4952 samples (32 per mini-batch)
2023-04-27 03:22:48,848 - Epoch: [246][   50/  155]    Loss 3.146606    mAP 0.429978    
2023-04-27 03:22:55,253 - Epoch: [246][  100/  155]    Loss 3.145628    mAP 0.444043    
2023-04-27 03:23:01,658 - Epoch: [246][  150/  155]    Loss 3.144306    mAP 0.441878    
2023-04-27 03:23:02,234 - Epoch: [246][  155/  155]    Loss 3.144701    mAP 0.443237    
2023-04-27 03:23:02,307 - ==> mAP: 0.44324    Loss: 3.145

2023-04-27 03:23:02,311 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:23:02,311 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:23:02,347 - 

2023-04-27 03:23:02,347 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:23:13,239 - Epoch: [247][   50/  518]    Overall Loss 2.860594    Objective Loss 2.860594                                        LR 0.000008    Time 0.217794    
2023-04-27 03:23:23,410 - Epoch: [247][  100/  518]    Overall Loss 2.863541    Objective Loss 2.863541                                        LR 0.000008    Time 0.210590    
2023-04-27 03:23:33,528 - Epoch: [247][  150/  518]    Overall Loss 2.871121    Objective Loss 2.871121                                        LR 0.000008    Time 0.207831    
2023-04-27 03:23:43,670 - Epoch: [247][  200/  518]    Overall Loss 2.849465    Objective Loss 2.849465                                        LR 0.000008    Time 0.206576    
2023-04-27 03:23:53,848 - Epoch: [247][  250/  518]    Overall Loss 2.843417    Objective Loss 2.843417                                        LR 0.000008    Time 0.205968    
2023-04-27 03:24:03,926 - Epoch: [247][  300/  518]    Overall Loss 2.846619    Objective Loss 2.846619                                        LR 0.000008    Time 0.205228    
2023-04-27 03:24:14,069 - Epoch: [247][  350/  518]    Overall Loss 2.848366    Objective Loss 2.848366                                        LR 0.000008    Time 0.204885    
2023-04-27 03:24:24,226 - Epoch: [247][  400/  518]    Overall Loss 2.845663    Objective Loss 2.845663                                        LR 0.000008    Time 0.204663    
2023-04-27 03:24:34,396 - Epoch: [247][  450/  518]    Overall Loss 2.841443    Objective Loss 2.841443                                        LR 0.000008    Time 0.204519    
2023-04-27 03:24:44,603 - Epoch: [247][  500/  518]    Overall Loss 2.841172    Objective Loss 2.841172                                        LR 0.000008    Time 0.204477    
2023-04-27 03:24:48,151 - Epoch: [247][  518/  518]    Overall Loss 2.845963    Objective Loss 2.845963                                        LR 0.000008    Time 0.204221    
2023-04-27 03:24:48,227 - --- validate (epoch=247)-----------
2023-04-27 03:24:48,227 - 4952 samples (32 per mini-batch)
2023-04-27 03:24:55,046 - Epoch: [247][   50/  155]    Loss 3.181366    mAP 0.456877    
2023-04-27 03:25:01,455 - Epoch: [247][  100/  155]    Loss 3.152826    mAP 0.455065    
2023-04-27 03:25:07,825 - Epoch: [247][  150/  155]    Loss 3.136389    mAP 0.455786    
2023-04-27 03:25:08,392 - Epoch: [247][  155/  155]    Loss 3.143326    mAP 0.454374    
2023-04-27 03:25:08,471 - ==> mAP: 0.45437    Loss: 3.143

2023-04-27 03:25:08,475 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:25:08,475 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:25:08,511 - 

2023-04-27 03:25:08,512 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:25:19,361 - Epoch: [248][   50/  518]    Overall Loss 2.823946    Objective Loss 2.823946                                        LR 0.000008    Time 0.216933    
2023-04-27 03:25:29,516 - Epoch: [248][  100/  518]    Overall Loss 2.837164    Objective Loss 2.837164                                        LR 0.000008    Time 0.209998    
2023-04-27 03:25:39,641 - Epoch: [248][  150/  518]    Overall Loss 2.829524    Objective Loss 2.829524                                        LR 0.000008    Time 0.207489    
2023-04-27 03:25:49,859 - Epoch: [248][  200/  518]    Overall Loss 2.828369    Objective Loss 2.828369                                        LR 0.000008    Time 0.206698    
2023-04-27 03:26:00,057 - Epoch: [248][  250/  518]    Overall Loss 2.829400    Objective Loss 2.829400                                        LR 0.000008    Time 0.206143    
2023-04-27 03:26:10,196 - Epoch: [248][  300/  518]    Overall Loss 2.837136    Objective Loss 2.837136                                        LR 0.000008    Time 0.205578    
2023-04-27 03:26:20,351 - Epoch: [248][  350/  518]    Overall Loss 2.837948    Objective Loss 2.837948                                        LR 0.000008    Time 0.205220    
2023-04-27 03:26:30,492 - Epoch: [248][  400/  518]    Overall Loss 2.841136    Objective Loss 2.841136                                        LR 0.000008    Time 0.204917    
2023-04-27 03:26:40,661 - Epoch: [248][  450/  518]    Overall Loss 2.843777    Objective Loss 2.843777                                        LR 0.000008    Time 0.204741    
2023-04-27 03:26:50,780 - Epoch: [248][  500/  518]    Overall Loss 2.839210    Objective Loss 2.839210                                        LR 0.000008    Time 0.204503    
2023-04-27 03:26:54,301 - Epoch: [248][  518/  518]    Overall Loss 2.840259    Objective Loss 2.840259                                        LR 0.000008    Time 0.204193    
2023-04-27 03:26:54,375 - --- validate (epoch=248)-----------
2023-04-27 03:26:54,376 - 4952 samples (32 per mini-batch)
2023-04-27 03:27:01,119 - Epoch: [248][   50/  155]    Loss 3.120208    mAP 0.466587    
2023-04-27 03:27:07,502 - Epoch: [248][  100/  155]    Loss 3.121465    mAP 0.457607    
2023-04-27 03:27:13,867 - Epoch: [248][  150/  155]    Loss 3.137175    mAP 0.446078    
2023-04-27 03:27:14,432 - Epoch: [248][  155/  155]    Loss 3.141208    mAP 0.445244    
2023-04-27 03:27:14,503 - ==> mAP: 0.44524    Loss: 3.141

2023-04-27 03:27:14,507 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:27:14,507 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:27:14,545 - 

2023-04-27 03:27:14,545 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:27:25,602 - Epoch: [249][   50/  518]    Overall Loss 2.819794    Objective Loss 2.819794                                        LR 0.000008    Time 0.221070    
2023-04-27 03:27:35,749 - Epoch: [249][  100/  518]    Overall Loss 2.863397    Objective Loss 2.863397                                        LR 0.000008    Time 0.211990    
2023-04-27 03:27:45,922 - Epoch: [249][  150/  518]    Overall Loss 2.858910    Objective Loss 2.858910                                        LR 0.000008    Time 0.209135    
2023-04-27 03:27:56,067 - Epoch: [249][  200/  518]    Overall Loss 2.861012    Objective Loss 2.861012                                        LR 0.000008    Time 0.207570    
2023-04-27 03:28:06,198 - Epoch: [249][  250/  518]    Overall Loss 2.862865    Objective Loss 2.862865                                        LR 0.000008    Time 0.206575    
2023-04-27 03:28:16,412 - Epoch: [249][  300/  518]    Overall Loss 2.852235    Objective Loss 2.852235                                        LR 0.000008    Time 0.206184    
2023-04-27 03:28:26,540 - Epoch: [249][  350/  518]    Overall Loss 2.853227    Objective Loss 2.853227                                        LR 0.000008    Time 0.205664    
2023-04-27 03:28:36,780 - Epoch: [249][  400/  518]    Overall Loss 2.844112    Objective Loss 2.844112                                        LR 0.000008    Time 0.205551    
2023-04-27 03:28:46,927 - Epoch: [249][  450/  518]    Overall Loss 2.844496    Objective Loss 2.844496                                        LR 0.000008    Time 0.205258    
2023-04-27 03:28:57,065 - Epoch: [249][  500/  518]    Overall Loss 2.846503    Objective Loss 2.846503                                        LR 0.000008    Time 0.205004    
2023-04-27 03:29:00,606 - Epoch: [249][  518/  518]    Overall Loss 2.848741    Objective Loss 2.848741                                        LR 0.000008    Time 0.204716    
2023-04-27 03:29:00,682 - --- validate (epoch=249)-----------
2023-04-27 03:29:00,682 - 4952 samples (32 per mini-batch)
2023-04-27 03:29:07,521 - Epoch: [249][   50/  155]    Loss 3.127368    mAP 0.466355    
2023-04-27 03:29:13,927 - Epoch: [249][  100/  155]    Loss 3.144789    mAP 0.460856    
2023-04-27 03:29:20,306 - Epoch: [249][  150/  155]    Loss 3.147786    mAP 0.457912    
2023-04-27 03:29:20,876 - Epoch: [249][  155/  155]    Loss 3.144298    mAP 0.457769    
2023-04-27 03:29:20,950 - ==> mAP: 0.45777    Loss: 3.144

2023-04-27 03:29:20,954 - ==> Best [mAP: 0.462889   vloss: 3.144180   Sparsity:0.00   Params: 2177087 on epoch: 201]
2023-04-27 03:29:20,954 - Saving checkpoint to: logs/2023.04.26-184348/checkpoint.pth.tar
2023-04-27 03:29:21,036 - 

2023-04-27 03:29:21,036 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:29:32,619 - Epoch: [250][   50/  518]    Overall Loss 4.548745    Objective Loss 4.548745                                        LR 0.000008    Time 0.231603    
2023-04-27 03:29:43,410 - Epoch: [250][  100/  518]    Overall Loss 4.060120    Objective Loss 4.060120                                        LR 0.000008    Time 0.223702    
2023-04-27 03:29:54,271 - Epoch: [250][  150/  518]    Overall Loss 3.837740    Objective Loss 3.837740                                        LR 0.000008    Time 0.221526    
2023-04-27 03:30:05,026 - Epoch: [250][  200/  518]    Overall Loss 3.698043    Objective Loss 3.698043                                        LR 0.000008    Time 0.219912    
2023-04-27 03:30:15,965 - Epoch: [250][  250/  518]    Overall Loss 3.618128    Objective Loss 3.618128                                        LR 0.000008    Time 0.219682    
2023-04-27 03:30:26,808 - Epoch: [250][  300/  518]    Overall Loss 3.558953    Objective Loss 3.558953                                        LR 0.000008    Time 0.219206    
2023-04-27 03:30:37,615 - Epoch: [250][  350/  518]    Overall Loss 3.511840    Objective Loss 3.511840                                        LR 0.000008    Time 0.218763    
2023-04-27 03:30:48,440 - Epoch: [250][  400/  518]    Overall Loss 3.477347    Objective Loss 3.477347                                        LR 0.000008    Time 0.218476    
2023-04-27 03:30:59,357 - Epoch: [250][  450/  518]    Overall Loss 3.442102    Objective Loss 3.442102                                        LR 0.000008    Time 0.218458    
2023-04-27 03:31:10,175 - Epoch: [250][  500/  518]    Overall Loss 3.420557    Objective Loss 3.420557                                        LR 0.000008    Time 0.218244    
2023-04-27 03:31:13,917 - Epoch: [250][  518/  518]    Overall Loss 3.412381    Objective Loss 3.412381                                        LR 0.000008    Time 0.217884    
2023-04-27 03:31:13,994 - --- validate (epoch=250)-----------
2023-04-27 03:31:13,994 - 4952 samples (32 per mini-batch)
2023-04-27 03:31:22,173 - Epoch: [250][   50/  155]    Loss 3.287830    mAP 0.406113    
2023-04-27 03:31:29,971 - Epoch: [250][  100/  155]    Loss 3.285118    mAP 0.400154    
2023-04-27 03:31:37,770 - Epoch: [250][  150/  155]    Loss 3.276130    mAP 0.401186    
2023-04-27 03:31:38,478 - Epoch: [250][  155/  155]    Loss 3.276710    mAP 0.401332    
2023-04-27 03:31:38,553 - ==> mAP: 0.40133    Loss: 3.277

2023-04-27 03:31:38,557 - ==> Best [mAP: 0.401332   vloss: 3.276710   Sparsity:0.00   Params: 2177087 on epoch: 250]
2023-04-27 03:31:38,557 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:31:38,594 - 

2023-04-27 03:31:38,594 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:31:50,254 - Epoch: [251][   50/  518]    Overall Loss 3.195521    Objective Loss 3.195521                                        LR 0.000008    Time 0.233147    
2023-04-27 03:32:01,091 - Epoch: [251][  100/  518]    Overall Loss 3.191063    Objective Loss 3.191063                                        LR 0.000008    Time 0.224925    
2023-04-27 03:32:11,873 - Epoch: [251][  150/  518]    Overall Loss 3.175939    Objective Loss 3.175939                                        LR 0.000008    Time 0.221820    
2023-04-27 03:32:22,608 - Epoch: [251][  200/  518]    Overall Loss 3.164506    Objective Loss 3.164506                                        LR 0.000008    Time 0.220033    
2023-04-27 03:32:33,446 - Epoch: [251][  250/  518]    Overall Loss 3.167774    Objective Loss 3.167774                                        LR 0.000008    Time 0.219374    
2023-04-27 03:32:44,307 - Epoch: [251][  300/  518]    Overall Loss 3.154498    Objective Loss 3.154498                                        LR 0.000008    Time 0.219008    
2023-04-27 03:32:55,132 - Epoch: [251][  350/  518]    Overall Loss 3.142627    Objective Loss 3.142627                                        LR 0.000008    Time 0.218644    
2023-04-27 03:33:05,986 - Epoch: [251][  400/  518]    Overall Loss 3.138122    Objective Loss 3.138122                                        LR 0.000008    Time 0.218445    
2023-04-27 03:33:16,765 - Epoch: [251][  450/  518]    Overall Loss 3.137090    Objective Loss 3.137090                                        LR 0.000008    Time 0.218125    
2023-04-27 03:33:27,578 - Epoch: [251][  500/  518]    Overall Loss 3.130152    Objective Loss 3.130152                                        LR 0.000008    Time 0.217936    
2023-04-27 03:33:31,344 - Epoch: [251][  518/  518]    Overall Loss 3.130237    Objective Loss 3.130237                                        LR 0.000008    Time 0.217631    
2023-04-27 03:33:31,419 - --- validate (epoch=251)-----------
2023-04-27 03:33:31,420 - 4952 samples (32 per mini-batch)
2023-04-27 03:33:39,637 - Epoch: [251][   50/  155]    Loss 3.194700    mAP 0.423771    
2023-04-27 03:33:47,437 - Epoch: [251][  100/  155]    Loss 3.205864    mAP 0.417054    
2023-04-27 03:33:55,265 - Epoch: [251][  150/  155]    Loss 3.212300    mAP 0.411294    
2023-04-27 03:33:55,969 - Epoch: [251][  155/  155]    Loss 3.205666    mAP 0.410577    
2023-04-27 03:33:56,038 - ==> mAP: 0.41058    Loss: 3.206

2023-04-27 03:33:56,042 - ==> Best [mAP: 0.410577   vloss: 3.205666   Sparsity:0.00   Params: 2177087 on epoch: 251]
2023-04-27 03:33:56,042 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:33:56,092 - 

2023-04-27 03:33:56,092 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:34:07,710 - Epoch: [252][   50/  518]    Overall Loss 3.089833    Objective Loss 3.089833                                        LR 0.000008    Time 0.232303    
2023-04-27 03:34:18,580 - Epoch: [252][  100/  518]    Overall Loss 3.113138    Objective Loss 3.113138                                        LR 0.000008    Time 0.224837    
2023-04-27 03:34:29,331 - Epoch: [252][  150/  518]    Overall Loss 3.099819    Objective Loss 3.099819                                        LR 0.000008    Time 0.221553    
2023-04-27 03:34:40,112 - Epoch: [252][  200/  518]    Overall Loss 3.084473    Objective Loss 3.084473                                        LR 0.000008    Time 0.220061    
2023-04-27 03:34:50,989 - Epoch: [252][  250/  518]    Overall Loss 3.086754    Objective Loss 3.086754                                        LR 0.000008    Time 0.219550    
2023-04-27 03:35:01,827 - Epoch: [252][  300/  518]    Overall Loss 3.083670    Objective Loss 3.083670                                        LR 0.000008    Time 0.219081    
2023-04-27 03:35:12,593 - Epoch: [252][  350/  518]    Overall Loss 3.092436    Objective Loss 3.092436                                        LR 0.000008    Time 0.218540    
2023-04-27 03:35:23,399 - Epoch: [252][  400/  518]    Overall Loss 3.088105    Objective Loss 3.088105                                        LR 0.000008    Time 0.218234    
2023-04-27 03:35:34,187 - Epoch: [252][  450/  518]    Overall Loss 3.087804    Objective Loss 3.087804                                        LR 0.000008    Time 0.217955    
2023-04-27 03:35:45,018 - Epoch: [252][  500/  518]    Overall Loss 3.086814    Objective Loss 3.086814                                        LR 0.000008    Time 0.217817    
2023-04-27 03:35:48,761 - Epoch: [252][  518/  518]    Overall Loss 3.084454    Objective Loss 3.084454                                        LR 0.000008    Time 0.217474    
2023-04-27 03:35:48,838 - --- validate (epoch=252)-----------
2023-04-27 03:35:48,838 - 4952 samples (32 per mini-batch)
2023-04-27 03:35:57,009 - Epoch: [252][   50/  155]    Loss 3.187899    mAP 0.417022    
2023-04-27 03:36:04,824 - Epoch: [252][  100/  155]    Loss 3.193881    mAP 0.408778    
2023-04-27 03:36:12,649 - Epoch: [252][  150/  155]    Loss 3.186190    mAP 0.417699    
2023-04-27 03:36:13,367 - Epoch: [252][  155/  155]    Loss 3.182253    mAP 0.419383    
2023-04-27 03:36:13,442 - ==> mAP: 0.41938    Loss: 3.182

2023-04-27 03:36:13,445 - ==> Best [mAP: 0.419383   vloss: 3.182253   Sparsity:0.00   Params: 2177087 on epoch: 252]
2023-04-27 03:36:13,445 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:36:13,495 - 

2023-04-27 03:36:13,495 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:36:25,223 - Epoch: [253][   50/  518]    Overall Loss 3.079634    Objective Loss 3.079634                                        LR 0.000008    Time 0.234519    
2023-04-27 03:36:36,099 - Epoch: [253][  100/  518]    Overall Loss 3.077322    Objective Loss 3.077322                                        LR 0.000008    Time 0.226003    
2023-04-27 03:36:46,908 - Epoch: [253][  150/  518]    Overall Loss 3.086872    Objective Loss 3.086872                                        LR 0.000008    Time 0.222714    
2023-04-27 03:36:57,736 - Epoch: [253][  200/  518]    Overall Loss 3.065894    Objective Loss 3.065894                                        LR 0.000008    Time 0.221168    
2023-04-27 03:37:08,517 - Epoch: [253][  250/  518]    Overall Loss 3.065806    Objective Loss 3.065806                                        LR 0.000008    Time 0.220053    
2023-04-27 03:37:19,295 - Epoch: [253][  300/  518]    Overall Loss 3.066572    Objective Loss 3.066572                                        LR 0.000008    Time 0.219298    
2023-04-27 03:37:30,092 - Epoch: [253][  350/  518]    Overall Loss 3.063381    Objective Loss 3.063381                                        LR 0.000008    Time 0.218814    
2023-04-27 03:37:40,898 - Epoch: [253][  400/  518]    Overall Loss 3.066760    Objective Loss 3.066760                                        LR 0.000008    Time 0.218473    
2023-04-27 03:37:51,711 - Epoch: [253][  450/  518]    Overall Loss 3.068889    Objective Loss 3.068889                                        LR 0.000008    Time 0.218224    
2023-04-27 03:38:02,551 - Epoch: [253][  500/  518]    Overall Loss 3.064633    Objective Loss 3.064633                                        LR 0.000008    Time 0.218078    
2023-04-27 03:38:06,336 - Epoch: [253][  518/  518]    Overall Loss 3.065516    Objective Loss 3.065516                                        LR 0.000008    Time 0.217807    
2023-04-27 03:38:06,414 - --- validate (epoch=253)-----------
2023-04-27 03:38:06,414 - 4952 samples (32 per mini-batch)
2023-04-27 03:38:14,656 - Epoch: [253][   50/  155]    Loss 3.181040    mAP 0.425296    
2023-04-27 03:38:22,510 - Epoch: [253][  100/  155]    Loss 3.159753    mAP 0.429916    
2023-04-27 03:38:30,291 - Epoch: [253][  150/  155]    Loss 3.160320    mAP 0.417846    
2023-04-27 03:38:31,004 - Epoch: [253][  155/  155]    Loss 3.158065    mAP 0.419727    
2023-04-27 03:38:31,088 - ==> mAP: 0.41973    Loss: 3.158

2023-04-27 03:38:31,093 - ==> Best [mAP: 0.419727   vloss: 3.158065   Sparsity:0.00   Params: 2177087 on epoch: 253]
2023-04-27 03:38:31,093 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:38:31,143 - 

2023-04-27 03:38:31,143 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:38:42,761 - Epoch: [254][   50/  518]    Overall Loss 3.042650    Objective Loss 3.042650                                        LR 0.000008    Time 0.232300    
2023-04-27 03:38:53,548 - Epoch: [254][  100/  518]    Overall Loss 3.045320    Objective Loss 3.045320                                        LR 0.000008    Time 0.224004    
2023-04-27 03:39:04,320 - Epoch: [254][  150/  518]    Overall Loss 3.034513    Objective Loss 3.034513                                        LR 0.000008    Time 0.221141    
2023-04-27 03:39:15,190 - Epoch: [254][  200/  518]    Overall Loss 3.026439    Objective Loss 3.026439                                        LR 0.000008    Time 0.220198    
2023-04-27 03:39:26,077 - Epoch: [254][  250/  518]    Overall Loss 3.040811    Objective Loss 3.040811                                        LR 0.000008    Time 0.219700    
2023-04-27 03:39:36,955 - Epoch: [254][  300/  518]    Overall Loss 3.041100    Objective Loss 3.041100                                        LR 0.000008    Time 0.219338    
2023-04-27 03:39:47,930 - Epoch: [254][  350/  518]    Overall Loss 3.045341    Objective Loss 3.045341                                        LR 0.000008    Time 0.219358    
2023-04-27 03:39:58,679 - Epoch: [254][  400/  518]    Overall Loss 3.040291    Objective Loss 3.040291                                        LR 0.000008    Time 0.218805    
2023-04-27 03:40:09,519 - Epoch: [254][  450/  518]    Overall Loss 3.035574    Objective Loss 3.035574                                        LR 0.000008    Time 0.218578    
2023-04-27 03:40:20,324 - Epoch: [254][  500/  518]    Overall Loss 3.033338    Objective Loss 3.033338                                        LR 0.000008    Time 0.218328    
2023-04-27 03:40:24,055 - Epoch: [254][  518/  518]    Overall Loss 3.032259    Objective Loss 3.032259                                        LR 0.000008    Time 0.217944    
2023-04-27 03:40:24,132 - --- validate (epoch=254)-----------
2023-04-27 03:40:24,132 - 4952 samples (32 per mini-batch)
2023-04-27 03:40:32,471 - Epoch: [254][   50/  155]    Loss 3.166718    mAP 0.429130    
2023-04-27 03:40:40,333 - Epoch: [254][  100/  155]    Loss 3.171566    mAP 0.432213    
2023-04-27 03:40:48,133 - Epoch: [254][  150/  155]    Loss 3.154675    mAP 0.431558    
2023-04-27 03:40:48,852 - Epoch: [254][  155/  155]    Loss 3.152628    mAP 0.430818    
2023-04-27 03:40:48,929 - ==> mAP: 0.43082    Loss: 3.153

2023-04-27 03:40:48,933 - ==> Best [mAP: 0.430818   vloss: 3.152628   Sparsity:0.00   Params: 2177087 on epoch: 254]
2023-04-27 03:40:48,933 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:40:48,982 - 

2023-04-27 03:40:48,982 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:41:00,532 - Epoch: [255][   50/  518]    Overall Loss 3.033332    Objective Loss 3.033332                                        LR 0.000008    Time 0.230943    
2023-04-27 03:41:11,351 - Epoch: [255][  100/  518]    Overall Loss 3.042704    Objective Loss 3.042704                                        LR 0.000008    Time 0.223650    
2023-04-27 03:41:22,198 - Epoch: [255][  150/  518]    Overall Loss 3.043596    Objective Loss 3.043596                                        LR 0.000008    Time 0.221403    
2023-04-27 03:41:32,949 - Epoch: [255][  200/  518]    Overall Loss 3.039157    Objective Loss 3.039157                                        LR 0.000008    Time 0.219798    
2023-04-27 03:41:43,785 - Epoch: [255][  250/  518]    Overall Loss 3.038485    Objective Loss 3.038485                                        LR 0.000008    Time 0.219176    
2023-04-27 03:41:54,700 - Epoch: [255][  300/  518]    Overall Loss 3.032716    Objective Loss 3.032716                                        LR 0.000008    Time 0.219024    
2023-04-27 03:42:05,543 - Epoch: [255][  350/  518]    Overall Loss 3.043618    Objective Loss 3.043618                                        LR 0.000008    Time 0.218712    
2023-04-27 03:42:16,362 - Epoch: [255][  400/  518]    Overall Loss 3.040685    Objective Loss 3.040685                                        LR 0.000008    Time 0.218416    
2023-04-27 03:42:27,150 - Epoch: [255][  450/  518]    Overall Loss 3.039949    Objective Loss 3.039949                                        LR 0.000008    Time 0.218118    
2023-04-27 03:42:37,996 - Epoch: [255][  500/  518]    Overall Loss 3.034383    Objective Loss 3.034383                                        LR 0.000008    Time 0.217993    
2023-04-27 03:42:41,744 - Epoch: [255][  518/  518]    Overall Loss 3.033733    Objective Loss 3.033733                                        LR 0.000008    Time 0.217654    
2023-04-27 03:42:41,821 - --- validate (epoch=255)-----------
2023-04-27 03:42:41,822 - 4952 samples (32 per mini-batch)
2023-04-27 03:42:50,043 - Epoch: [255][   50/  155]    Loss 3.114162    mAP 0.433121    
2023-04-27 03:42:57,858 - Epoch: [255][  100/  155]    Loss 3.152177    mAP 0.427948    
2023-04-27 03:43:05,675 - Epoch: [255][  150/  155]    Loss 3.143248    mAP 0.428432    
2023-04-27 03:43:06,385 - Epoch: [255][  155/  155]    Loss 3.144234    mAP 0.427871    
2023-04-27 03:43:06,458 - ==> mAP: 0.42787    Loss: 3.144

2023-04-27 03:43:06,462 - ==> Best [mAP: 0.430818   vloss: 3.152628   Sparsity:0.00   Params: 2177087 on epoch: 254]
2023-04-27 03:43:06,462 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:43:06,496 - 

2023-04-27 03:43:06,496 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:43:18,178 - Epoch: [256][   50/  518]    Overall Loss 3.041977    Objective Loss 3.041977                                        LR 0.000008    Time 0.233590    
2023-04-27 03:43:29,096 - Epoch: [256][  100/  518]    Overall Loss 3.059568    Objective Loss 3.059568                                        LR 0.000008    Time 0.225956    
2023-04-27 03:43:39,928 - Epoch: [256][  150/  518]    Overall Loss 3.041158    Objective Loss 3.041158                                        LR 0.000008    Time 0.222840    
2023-04-27 03:43:50,761 - Epoch: [256][  200/  518]    Overall Loss 3.037275    Objective Loss 3.037275                                        LR 0.000008    Time 0.221289    
2023-04-27 03:44:01,598 - Epoch: [256][  250/  518]    Overall Loss 3.034150    Objective Loss 3.034150                                        LR 0.000008    Time 0.220373    
2023-04-27 03:44:12,387 - Epoch: [256][  300/  518]    Overall Loss 3.020145    Objective Loss 3.020145                                        LR 0.000008    Time 0.219602    
2023-04-27 03:44:23,141 - Epoch: [256][  350/  518]    Overall Loss 3.015872    Objective Loss 3.015872                                        LR 0.000008    Time 0.218952    
2023-04-27 03:44:33,888 - Epoch: [256][  400/  518]    Overall Loss 3.015427    Objective Loss 3.015427                                        LR 0.000008    Time 0.218446    
2023-04-27 03:44:44,681 - Epoch: [256][  450/  518]    Overall Loss 3.017475    Objective Loss 3.017475                                        LR 0.000008    Time 0.218154    
2023-04-27 03:44:55,418 - Epoch: [256][  500/  518]    Overall Loss 3.017320    Objective Loss 3.017320                                        LR 0.000008    Time 0.217810    
2023-04-27 03:44:59,144 - Epoch: [256][  518/  518]    Overall Loss 3.016991    Objective Loss 3.016991                                        LR 0.000008    Time 0.217433    
2023-04-27 03:44:59,221 - --- validate (epoch=256)-----------
2023-04-27 03:44:59,221 - 4952 samples (32 per mini-batch)
2023-04-27 03:45:07,539 - Epoch: [256][   50/  155]    Loss 3.125432    mAP 0.436287    
2023-04-27 03:45:15,402 - Epoch: [256][  100/  155]    Loss 3.156298    mAP 0.420897    
2023-04-27 03:45:23,246 - Epoch: [256][  150/  155]    Loss 3.154693    mAP 0.426640    
2023-04-27 03:45:23,973 - Epoch: [256][  155/  155]    Loss 3.152663    mAP 0.429709    
2023-04-27 03:45:24,046 - ==> mAP: 0.42971    Loss: 3.153

2023-04-27 03:45:24,050 - ==> Best [mAP: 0.430818   vloss: 3.152628   Sparsity:0.00   Params: 2177087 on epoch: 254]
2023-04-27 03:45:24,050 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:45:24,084 - 

2023-04-27 03:45:24,084 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:45:35,675 - Epoch: [257][   50/  518]    Overall Loss 3.033524    Objective Loss 3.033524                                        LR 0.000008    Time 0.231771    
2023-04-27 03:45:46,484 - Epoch: [257][  100/  518]    Overall Loss 2.991298    Objective Loss 2.991298                                        LR 0.000008    Time 0.223957    
2023-04-27 03:45:57,292 - Epoch: [257][  150/  518]    Overall Loss 2.998900    Objective Loss 2.998900                                        LR 0.000008    Time 0.221348    
2023-04-27 03:46:08,127 - Epoch: [257][  200/  518]    Overall Loss 2.992074    Objective Loss 2.992074                                        LR 0.000008    Time 0.220180    
2023-04-27 03:46:18,971 - Epoch: [257][  250/  518]    Overall Loss 2.998997    Objective Loss 2.998997                                        LR 0.000008    Time 0.219511    
2023-04-27 03:46:29,761 - Epoch: [257][  300/  518]    Overall Loss 3.005716    Objective Loss 3.005716                                        LR 0.000008    Time 0.218888    
2023-04-27 03:46:40,538 - Epoch: [257][  350/  518]    Overall Loss 3.001889    Objective Loss 3.001889                                        LR 0.000008    Time 0.218405    
2023-04-27 03:46:51,357 - Epoch: [257][  400/  518]    Overall Loss 3.002834    Objective Loss 3.002834                                        LR 0.000008    Time 0.218149    
2023-04-27 03:47:02,223 - Epoch: [257][  450/  518]    Overall Loss 3.001299    Objective Loss 3.001299                                        LR 0.000008    Time 0.218053    
2023-04-27 03:47:13,148 - Epoch: [257][  500/  518]    Overall Loss 3.003319    Objective Loss 3.003319                                        LR 0.000008    Time 0.218094    
2023-04-27 03:47:16,898 - Epoch: [257][  518/  518]    Overall Loss 3.000654    Objective Loss 3.000654                                        LR 0.000008    Time 0.217755    
2023-04-27 03:47:16,975 - --- validate (epoch=257)-----------
2023-04-27 03:47:16,975 - 4952 samples (32 per mini-batch)
2023-04-27 03:47:25,144 - Epoch: [257][   50/  155]    Loss 3.161425    mAP 0.423738    
2023-04-27 03:47:32,991 - Epoch: [257][  100/  155]    Loss 3.155525    mAP 0.421179    
2023-04-27 03:47:40,845 - Epoch: [257][  150/  155]    Loss 3.137262    mAP 0.423640    
2023-04-27 03:47:41,559 - Epoch: [257][  155/  155]    Loss 3.138539    mAP 0.422382    
2023-04-27 03:47:41,633 - ==> mAP: 0.42238    Loss: 3.139

2023-04-27 03:47:41,636 - ==> Best [mAP: 0.430818   vloss: 3.152628   Sparsity:0.00   Params: 2177087 on epoch: 254]
2023-04-27 03:47:41,637 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:47:41,671 - 

2023-04-27 03:47:41,671 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:47:53,174 - Epoch: [258][   50/  518]    Overall Loss 3.017400    Objective Loss 3.017400                                        LR 0.000008    Time 0.230004    
2023-04-27 03:48:04,099 - Epoch: [258][  100/  518]    Overall Loss 2.990669    Objective Loss 2.990669                                        LR 0.000008    Time 0.224237    
2023-04-27 03:48:14,967 - Epoch: [258][  150/  518]    Overall Loss 3.000493    Objective Loss 3.000493                                        LR 0.000008    Time 0.221933    
2023-04-27 03:48:25,795 - Epoch: [258][  200/  518]    Overall Loss 3.005089    Objective Loss 3.005089                                        LR 0.000008    Time 0.220581    
2023-04-27 03:48:36,656 - Epoch: [258][  250/  518]    Overall Loss 3.011870    Objective Loss 3.011870                                        LR 0.000008    Time 0.219903    
2023-04-27 03:48:47,500 - Epoch: [258][  300/  518]    Overall Loss 3.015900    Objective Loss 3.015900                                        LR 0.000008    Time 0.219395    
2023-04-27 03:48:58,412 - Epoch: [258][  350/  518]    Overall Loss 3.012027    Objective Loss 3.012027                                        LR 0.000008    Time 0.219226    
2023-04-27 03:49:09,165 - Epoch: [258][  400/  518]    Overall Loss 3.009724    Objective Loss 3.009724                                        LR 0.000008    Time 0.218701    
2023-04-27 03:49:19,952 - Epoch: [258][  450/  518]    Overall Loss 3.005817    Objective Loss 3.005817                                        LR 0.000008    Time 0.218369    
2023-04-27 03:49:30,796 - Epoch: [258][  500/  518]    Overall Loss 3.008661    Objective Loss 3.008661                                        LR 0.000008    Time 0.218217    
2023-04-27 03:49:34,616 - Epoch: [258][  518/  518]    Overall Loss 3.009099    Objective Loss 3.009099                                        LR 0.000008    Time 0.218008    
2023-04-27 03:49:34,691 - --- validate (epoch=258)-----------
2023-04-27 03:49:34,692 - 4952 samples (32 per mini-batch)
2023-04-27 03:49:42,905 - Epoch: [258][   50/  155]    Loss 3.108758    mAP 0.438205    
2023-04-27 03:49:50,765 - Epoch: [258][  100/  155]    Loss 3.120084    mAP 0.434161    
2023-04-27 03:49:58,617 - Epoch: [258][  150/  155]    Loss 3.127042    mAP 0.433657    
2023-04-27 03:49:59,328 - Epoch: [258][  155/  155]    Loss 3.123749    mAP 0.433398    
2023-04-27 03:49:59,404 - ==> mAP: 0.43340    Loss: 3.124

2023-04-27 03:49:59,408 - ==> Best [mAP: 0.433398   vloss: 3.123749   Sparsity:0.00   Params: 2177087 on epoch: 258]
2023-04-27 03:49:59,408 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:49:59,457 - 

2023-04-27 03:49:59,457 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:50:10,919 - Epoch: [259][   50/  518]    Overall Loss 2.977145    Objective Loss 2.977145                                        LR 0.000008    Time 0.229187    
2023-04-27 03:50:21,743 - Epoch: [259][  100/  518]    Overall Loss 3.006082    Objective Loss 3.006082                                        LR 0.000008    Time 0.222818    
2023-04-27 03:50:32,541 - Epoch: [259][  150/  518]    Overall Loss 3.012120    Objective Loss 3.012120                                        LR 0.000008    Time 0.220517    
2023-04-27 03:50:43,311 - Epoch: [259][  200/  518]    Overall Loss 3.010245    Objective Loss 3.010245                                        LR 0.000008    Time 0.219229    
2023-04-27 03:50:54,216 - Epoch: [259][  250/  518]    Overall Loss 3.007414    Objective Loss 3.007414                                        LR 0.000008    Time 0.218997    
2023-04-27 03:51:04,987 - Epoch: [259][  300/  518]    Overall Loss 3.005342    Objective Loss 3.005342                                        LR 0.000008    Time 0.218399    
2023-04-27 03:51:15,755 - Epoch: [259][  350/  518]    Overall Loss 2.998101    Objective Loss 2.998101                                        LR 0.000008    Time 0.217960    
2023-04-27 03:51:26,558 - Epoch: [259][  400/  518]    Overall Loss 2.999981    Objective Loss 2.999981                                        LR 0.000008    Time 0.217718    
2023-04-27 03:51:37,317 - Epoch: [259][  450/  518]    Overall Loss 2.996935    Objective Loss 2.996935                                        LR 0.000008    Time 0.217433    
2023-04-27 03:51:48,147 - Epoch: [259][  500/  518]    Overall Loss 2.992858    Objective Loss 2.992858                                        LR 0.000008    Time 0.217345    
2023-04-27 03:51:51,880 - Epoch: [259][  518/  518]    Overall Loss 2.993708    Objective Loss 2.993708                                        LR 0.000008    Time 0.216998    
2023-04-27 03:51:51,955 - --- validate (epoch=259)-----------
2023-04-27 03:51:51,956 - 4952 samples (32 per mini-batch)
2023-04-27 03:52:00,233 - Epoch: [259][   50/  155]    Loss 3.110187    mAP 0.432729    
2023-04-27 03:52:08,138 - Epoch: [259][  100/  155]    Loss 3.118631    mAP 0.425356    
2023-04-27 03:52:15,997 - Epoch: [259][  150/  155]    Loss 3.123641    mAP 0.426056    
2023-04-27 03:52:16,713 - Epoch: [259][  155/  155]    Loss 3.126384    mAP 0.423183    
2023-04-27 03:52:16,797 - ==> mAP: 0.42318    Loss: 3.126

2023-04-27 03:52:16,801 - ==> Best [mAP: 0.433398   vloss: 3.123749   Sparsity:0.00   Params: 2177087 on epoch: 258]
2023-04-27 03:52:16,801 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:52:16,837 - 

2023-04-27 03:52:16,837 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:52:28,384 - Epoch: [260][   50/  518]    Overall Loss 3.036504    Objective Loss 3.036504                                        LR 0.000008    Time 0.230896    
2023-04-27 03:52:39,154 - Epoch: [260][  100/  518]    Overall Loss 3.029900    Objective Loss 3.029900                                        LR 0.000008    Time 0.223127    
2023-04-27 03:52:50,047 - Epoch: [260][  150/  518]    Overall Loss 3.021124    Objective Loss 3.021124                                        LR 0.000008    Time 0.221360    
2023-04-27 03:53:00,846 - Epoch: [260][  200/  518]    Overall Loss 3.024080    Objective Loss 3.024080                                        LR 0.000008    Time 0.220008    
2023-04-27 03:53:11,737 - Epoch: [260][  250/  518]    Overall Loss 3.014920    Objective Loss 3.014920                                        LR 0.000008    Time 0.219566    
2023-04-27 03:53:22,549 - Epoch: [260][  300/  518]    Overall Loss 3.001418    Objective Loss 3.001418                                        LR 0.000008    Time 0.219006    
2023-04-27 03:53:33,327 - Epoch: [260][  350/  518]    Overall Loss 2.997989    Objective Loss 2.997989                                        LR 0.000008    Time 0.218508    
2023-04-27 03:53:44,144 - Epoch: [260][  400/  518]    Overall Loss 2.996089    Objective Loss 2.996089                                        LR 0.000008    Time 0.218235    
2023-04-27 03:53:54,960 - Epoch: [260][  450/  518]    Overall Loss 2.994810    Objective Loss 2.994810                                        LR 0.000008    Time 0.218019    
2023-04-27 03:54:05,797 - Epoch: [260][  500/  518]    Overall Loss 2.995519    Objective Loss 2.995519                                        LR 0.000008    Time 0.217887    
2023-04-27 03:54:09,573 - Epoch: [260][  518/  518]    Overall Loss 2.992879    Objective Loss 2.992879                                        LR 0.000008    Time 0.217604    
2023-04-27 03:54:09,649 - --- validate (epoch=260)-----------
2023-04-27 03:54:09,650 - 4952 samples (32 per mini-batch)
2023-04-27 03:54:17,914 - Epoch: [260][   50/  155]    Loss 3.131004    mAP 0.445847    
2023-04-27 03:54:25,810 - Epoch: [260][  100/  155]    Loss 3.113933    mAP 0.443389    
2023-04-27 03:54:33,717 - Epoch: [260][  150/  155]    Loss 3.111556    mAP 0.437782    
2023-04-27 03:54:34,438 - Epoch: [260][  155/  155]    Loss 3.108645    mAP 0.437520    
2023-04-27 03:54:34,511 - ==> mAP: 0.43752    Loss: 3.109

2023-04-27 03:54:34,515 - ==> Best [mAP: 0.437520   vloss: 3.108645   Sparsity:0.00   Params: 2177087 on epoch: 260]
2023-04-27 03:54:34,515 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:54:34,564 - 

2023-04-27 03:54:34,564 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:54:46,131 - Epoch: [261][   50/  518]    Overall Loss 2.976004    Objective Loss 2.976004                                        LR 0.000008    Time 0.231286    
2023-04-27 03:54:56,960 - Epoch: [261][  100/  518]    Overall Loss 2.989624    Objective Loss 2.989624                                        LR 0.000008    Time 0.223919    
2023-04-27 03:55:07,785 - Epoch: [261][  150/  518]    Overall Loss 2.987740    Objective Loss 2.987740                                        LR 0.000008    Time 0.221436    
2023-04-27 03:55:18,593 - Epoch: [261][  200/  518]    Overall Loss 2.986831    Objective Loss 2.986831                                        LR 0.000008    Time 0.220108    
2023-04-27 03:55:29,448 - Epoch: [261][  250/  518]    Overall Loss 3.002772    Objective Loss 3.002772                                        LR 0.000008    Time 0.219502    
2023-04-27 03:55:40,204 - Epoch: [261][  300/  518]    Overall Loss 2.995075    Objective Loss 2.995075                                        LR 0.000008    Time 0.218765    
2023-04-27 03:55:51,018 - Epoch: [261][  350/  518]    Overall Loss 2.993761    Objective Loss 2.993761                                        LR 0.000008    Time 0.218406    
2023-04-27 03:56:01,983 - Epoch: [261][  400/  518]    Overall Loss 2.994682    Objective Loss 2.994682                                        LR 0.000008    Time 0.218514    
2023-04-27 03:56:12,773 - Epoch: [261][  450/  518]    Overall Loss 2.991048    Objective Loss 2.991048                                        LR 0.000008    Time 0.218208    
2023-04-27 03:56:23,538 - Epoch: [261][  500/  518]    Overall Loss 2.994679    Objective Loss 2.994679                                        LR 0.000008    Time 0.217916    
2023-04-27 03:56:27,266 - Epoch: [261][  518/  518]    Overall Loss 2.994769    Objective Loss 2.994769                                        LR 0.000008    Time 0.217539    
2023-04-27 03:56:27,343 - --- validate (epoch=261)-----------
2023-04-27 03:56:27,343 - 4952 samples (32 per mini-batch)
2023-04-27 03:56:35,615 - Epoch: [261][   50/  155]    Loss 3.079841    mAP 0.439834    
2023-04-27 03:56:43,474 - Epoch: [261][  100/  155]    Loss 3.110404    mAP 0.434605    
2023-04-27 03:56:51,365 - Epoch: [261][  150/  155]    Loss 3.104727    mAP 0.437321    
2023-04-27 03:56:52,082 - Epoch: [261][  155/  155]    Loss 3.104831    mAP 0.437064    
2023-04-27 03:56:52,157 - ==> mAP: 0.43706    Loss: 3.105

2023-04-27 03:56:52,161 - ==> Best [mAP: 0.437520   vloss: 3.108645   Sparsity:0.00   Params: 2177087 on epoch: 260]
2023-04-27 03:56:52,161 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:56:52,195 - 

2023-04-27 03:56:52,195 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:57:03,874 - Epoch: [262][   50/  518]    Overall Loss 2.966476    Objective Loss 2.966476                                        LR 0.000008    Time 0.233516    
2023-04-27 03:57:14,697 - Epoch: [262][  100/  518]    Overall Loss 2.994615    Objective Loss 2.994615                                        LR 0.000008    Time 0.224977    
2023-04-27 03:57:25,450 - Epoch: [262][  150/  518]    Overall Loss 3.000324    Objective Loss 3.000324                                        LR 0.000008    Time 0.221659    
2023-04-27 03:57:36,243 - Epoch: [262][  200/  518]    Overall Loss 2.988159    Objective Loss 2.988159                                        LR 0.000008    Time 0.220202    
2023-04-27 03:57:47,037 - Epoch: [262][  250/  518]    Overall Loss 2.981325    Objective Loss 2.981325                                        LR 0.000008    Time 0.219329    
2023-04-27 03:57:57,951 - Epoch: [262][  300/  518]    Overall Loss 2.984138    Objective Loss 2.984138                                        LR 0.000008    Time 0.219151    
2023-04-27 03:58:08,710 - Epoch: [262][  350/  518]    Overall Loss 2.983599    Objective Loss 2.983599                                        LR 0.000008    Time 0.218580    
2023-04-27 03:58:19,497 - Epoch: [262][  400/  518]    Overall Loss 2.985411    Objective Loss 2.985411                                        LR 0.000008    Time 0.218221    
2023-04-27 03:58:30,299 - Epoch: [262][  450/  518]    Overall Loss 2.979877    Objective Loss 2.979877                                        LR 0.000008    Time 0.217974    
2023-04-27 03:58:41,095 - Epoch: [262][  500/  518]    Overall Loss 2.984228    Objective Loss 2.984228                                        LR 0.000008    Time 0.217765    
2023-04-27 03:58:44,843 - Epoch: [262][  518/  518]    Overall Loss 2.982605    Objective Loss 2.982605                                        LR 0.000008    Time 0.217433    
2023-04-27 03:58:44,921 - --- validate (epoch=262)-----------
2023-04-27 03:58:44,921 - 4952 samples (32 per mini-batch)
2023-04-27 03:58:53,163 - Epoch: [262][   50/  155]    Loss 3.123451    mAP 0.412307    
2023-04-27 03:59:01,029 - Epoch: [262][  100/  155]    Loss 3.141107    mAP 0.420080    
2023-04-27 03:59:08,900 - Epoch: [262][  150/  155]    Loss 3.137512    mAP 0.426609    
2023-04-27 03:59:09,618 - Epoch: [262][  155/  155]    Loss 3.136288    mAP 0.427992    
2023-04-27 03:59:09,683 - ==> mAP: 0.42799    Loss: 3.136

2023-04-27 03:59:09,687 - ==> Best [mAP: 0.437520   vloss: 3.108645   Sparsity:0.00   Params: 2177087 on epoch: 260]
2023-04-27 03:59:09,687 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 03:59:09,721 - 

2023-04-27 03:59:09,721 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 03:59:21,388 - Epoch: [263][   50/  518]    Overall Loss 2.962949    Objective Loss 2.962949                                        LR 0.000008    Time 0.233279    
2023-04-27 03:59:32,111 - Epoch: [263][  100/  518]    Overall Loss 2.992859    Objective Loss 2.992859                                        LR 0.000008    Time 0.223856    
2023-04-27 03:59:42,976 - Epoch: [263][  150/  518]    Overall Loss 2.993453    Objective Loss 2.993453                                        LR 0.000008    Time 0.221660    
2023-04-27 03:59:53,785 - Epoch: [263][  200/  518]    Overall Loss 2.996130    Objective Loss 2.996130                                        LR 0.000008    Time 0.220285    
2023-04-27 04:00:04,600 - Epoch: [263][  250/  518]    Overall Loss 2.997093    Objective Loss 2.997093                                        LR 0.000008    Time 0.219479    
2023-04-27 04:00:15,418 - Epoch: [263][  300/  518]    Overall Loss 2.993174    Objective Loss 2.993174                                        LR 0.000008    Time 0.218954    
2023-04-27 04:00:26,273 - Epoch: [263][  350/  518]    Overall Loss 2.990055    Objective Loss 2.990055                                        LR 0.000008    Time 0.218684    
2023-04-27 04:00:37,180 - Epoch: [263][  400/  518]    Overall Loss 2.992574    Objective Loss 2.992574                                        LR 0.000008    Time 0.218614    
2023-04-27 04:00:47,998 - Epoch: [263][  450/  518]    Overall Loss 2.989300    Objective Loss 2.989300                                        LR 0.000008    Time 0.218360    
2023-04-27 04:00:58,846 - Epoch: [263][  500/  518]    Overall Loss 2.989268    Objective Loss 2.989268                                        LR 0.000008    Time 0.218217    
2023-04-27 04:01:02,565 - Epoch: [263][  518/  518]    Overall Loss 2.987842    Objective Loss 2.987842                                        LR 0.000008    Time 0.217813    
2023-04-27 04:01:02,642 - --- validate (epoch=263)-----------
2023-04-27 04:01:02,642 - 4952 samples (32 per mini-batch)
2023-04-27 04:01:10,854 - Epoch: [263][   50/  155]    Loss 3.111518    mAP 0.436154    
2023-04-27 04:01:18,727 - Epoch: [263][  100/  155]    Loss 3.099971    mAP 0.439544    
2023-04-27 04:01:26,553 - Epoch: [263][  150/  155]    Loss 3.103498    mAP 0.432834    
2023-04-27 04:01:27,267 - Epoch: [263][  155/  155]    Loss 3.103355    mAP 0.433379    
2023-04-27 04:01:27,342 - ==> mAP: 0.43338    Loss: 3.103

2023-04-27 04:01:27,346 - ==> Best [mAP: 0.437520   vloss: 3.108645   Sparsity:0.00   Params: 2177087 on epoch: 260]
2023-04-27 04:01:27,346 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:01:27,380 - 

2023-04-27 04:01:27,380 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:01:39,160 - Epoch: [264][   50/  518]    Overall Loss 2.986884    Objective Loss 2.986884                                        LR 0.000008    Time 0.235539    
2023-04-27 04:01:49,991 - Epoch: [264][  100/  518]    Overall Loss 2.981842    Objective Loss 2.981842                                        LR 0.000008    Time 0.226068    
2023-04-27 04:02:00,934 - Epoch: [264][  150/  518]    Overall Loss 2.961959    Objective Loss 2.961959                                        LR 0.000008    Time 0.223654    
2023-04-27 04:02:11,800 - Epoch: [264][  200/  518]    Overall Loss 2.967916    Objective Loss 2.967916                                        LR 0.000008    Time 0.222063    
2023-04-27 04:02:22,605 - Epoch: [264][  250/  518]    Overall Loss 2.968542    Objective Loss 2.968542                                        LR 0.000008    Time 0.220863    
2023-04-27 04:02:33,426 - Epoch: [264][  300/  518]    Overall Loss 2.964595    Objective Loss 2.964595                                        LR 0.000008    Time 0.220119    
2023-04-27 04:02:44,182 - Epoch: [264][  350/  518]    Overall Loss 2.963838    Objective Loss 2.963838                                        LR 0.000008    Time 0.219398    
2023-04-27 04:02:55,013 - Epoch: [264][  400/  518]    Overall Loss 2.974209    Objective Loss 2.974209                                        LR 0.000008    Time 0.219048    
2023-04-27 04:03:05,749 - Epoch: [264][  450/  518]    Overall Loss 2.972455    Objective Loss 2.972455                                        LR 0.000008    Time 0.218564    
2023-04-27 04:03:16,527 - Epoch: [264][  500/  518]    Overall Loss 2.972489    Objective Loss 2.972489                                        LR 0.000008    Time 0.218261    
2023-04-27 04:03:20,260 - Epoch: [264][  518/  518]    Overall Loss 2.970721    Objective Loss 2.970721                                        LR 0.000008    Time 0.217881    
2023-04-27 04:03:20,336 - --- validate (epoch=264)-----------
2023-04-27 04:03:20,336 - 4952 samples (32 per mini-batch)
2023-04-27 04:03:28,575 - Epoch: [264][   50/  155]    Loss 3.101590    mAP 0.437617    
2023-04-27 04:03:36,433 - Epoch: [264][  100/  155]    Loss 3.099237    mAP 0.441297    
2023-04-27 04:03:44,277 - Epoch: [264][  150/  155]    Loss 3.095793    mAP 0.441372    
2023-04-27 04:03:44,988 - Epoch: [264][  155/  155]    Loss 3.099365    mAP 0.441580    
2023-04-27 04:03:45,069 - ==> mAP: 0.44158    Loss: 3.099

2023-04-27 04:03:45,073 - ==> Best [mAP: 0.441580   vloss: 3.099365   Sparsity:0.00   Params: 2177087 on epoch: 264]
2023-04-27 04:03:45,073 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:03:45,122 - 

2023-04-27 04:03:45,122 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:03:56,877 - Epoch: [265][   50/  518]    Overall Loss 2.936734    Objective Loss 2.936734                                        LR 0.000008    Time 0.235046    
2023-04-27 04:04:07,667 - Epoch: [265][  100/  518]    Overall Loss 2.953271    Objective Loss 2.953271                                        LR 0.000008    Time 0.225401    
2023-04-27 04:04:18,477 - Epoch: [265][  150/  518]    Overall Loss 2.961389    Objective Loss 2.961389                                        LR 0.000008    Time 0.222329    
2023-04-27 04:04:29,259 - Epoch: [265][  200/  518]    Overall Loss 2.949948    Objective Loss 2.949948                                        LR 0.000008    Time 0.220646    
2023-04-27 04:04:40,050 - Epoch: [265][  250/  518]    Overall Loss 2.963297    Objective Loss 2.963297                                        LR 0.000008    Time 0.219677    
2023-04-27 04:04:50,931 - Epoch: [265][  300/  518]    Overall Loss 2.965835    Objective Loss 2.965835                                        LR 0.000008    Time 0.219326    
2023-04-27 04:05:01,815 - Epoch: [265][  350/  518]    Overall Loss 2.965457    Objective Loss 2.965457                                        LR 0.000008    Time 0.219087    
2023-04-27 04:05:12,597 - Epoch: [265][  400/  518]    Overall Loss 2.964274    Objective Loss 2.964274                                        LR 0.000008    Time 0.218653    
2023-04-27 04:05:23,365 - Epoch: [265][  450/  518]    Overall Loss 2.965862    Objective Loss 2.965862                                        LR 0.000008    Time 0.218283    
2023-04-27 04:05:34,162 - Epoch: [265][  500/  518]    Overall Loss 2.970218    Objective Loss 2.970218                                        LR 0.000008    Time 0.218046    
2023-04-27 04:05:37,927 - Epoch: [265][  518/  518]    Overall Loss 2.969797    Objective Loss 2.969797                                        LR 0.000008    Time 0.217736    
2023-04-27 04:05:38,001 - --- validate (epoch=265)-----------
2023-04-27 04:05:38,001 - 4952 samples (32 per mini-batch)
2023-04-27 04:05:46,261 - Epoch: [265][   50/  155]    Loss 3.137069    mAP 0.418654    
2023-04-27 04:05:54,158 - Epoch: [265][  100/  155]    Loss 3.098488    mAP 0.425617    
2023-04-27 04:06:02,027 - Epoch: [265][  150/  155]    Loss 3.105071    mAP 0.426756    
2023-04-27 04:06:02,755 - Epoch: [265][  155/  155]    Loss 3.105330    mAP 0.428440    
2023-04-27 04:06:02,829 - ==> mAP: 0.42844    Loss: 3.105

2023-04-27 04:06:02,833 - ==> Best [mAP: 0.441580   vloss: 3.099365   Sparsity:0.00   Params: 2177087 on epoch: 264]
2023-04-27 04:06:02,833 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:06:02,867 - 

2023-04-27 04:06:02,867 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:06:14,420 - Epoch: [266][   50/  518]    Overall Loss 2.992824    Objective Loss 2.992824                                        LR 0.000008    Time 0.231006    
2023-04-27 04:06:25,224 - Epoch: [266][  100/  518]    Overall Loss 2.953759    Objective Loss 2.953759                                        LR 0.000008    Time 0.223532    
2023-04-27 04:06:36,058 - Epoch: [266][  150/  518]    Overall Loss 2.964682    Objective Loss 2.964682                                        LR 0.000008    Time 0.221237    
2023-04-27 04:06:46,853 - Epoch: [266][  200/  518]    Overall Loss 2.956539    Objective Loss 2.956539                                        LR 0.000008    Time 0.219896    
2023-04-27 04:06:57,680 - Epoch: [266][  250/  518]    Overall Loss 2.967604    Objective Loss 2.967604                                        LR 0.000008    Time 0.219217    
2023-04-27 04:07:08,473 - Epoch: [266][  300/  518]    Overall Loss 2.972245    Objective Loss 2.972245                                        LR 0.000008    Time 0.218651    
2023-04-27 04:07:19,324 - Epoch: [266][  350/  518]    Overall Loss 2.970165    Objective Loss 2.970165                                        LR 0.000008    Time 0.218414    
2023-04-27 04:07:30,139 - Epoch: [266][  400/  518]    Overall Loss 2.971205    Objective Loss 2.971205                                        LR 0.000008    Time 0.218146    
2023-04-27 04:07:40,879 - Epoch: [266][  450/  518]    Overall Loss 2.968785    Objective Loss 2.968785                                        LR 0.000008    Time 0.217771    
2023-04-27 04:07:51,679 - Epoch: [266][  500/  518]    Overall Loss 2.965673    Objective Loss 2.965673                                        LR 0.000008    Time 0.217590    
2023-04-27 04:07:55,385 - Epoch: [266][  518/  518]    Overall Loss 2.967023    Objective Loss 2.967023                                        LR 0.000008    Time 0.217184    
2023-04-27 04:07:55,459 - --- validate (epoch=266)-----------
2023-04-27 04:07:55,460 - 4952 samples (32 per mini-batch)
2023-04-27 04:08:03,663 - Epoch: [266][   50/  155]    Loss 3.095660    mAP 0.447301    
2023-04-27 04:08:11,508 - Epoch: [266][  100/  155]    Loss 3.114401    mAP 0.428971    
2023-04-27 04:08:19,301 - Epoch: [266][  150/  155]    Loss 3.114974    mAP 0.424620    
2023-04-27 04:08:20,013 - Epoch: [266][  155/  155]    Loss 3.117396    mAP 0.425426    
2023-04-27 04:08:20,086 - ==> mAP: 0.42543    Loss: 3.117

2023-04-27 04:08:20,089 - ==> Best [mAP: 0.441580   vloss: 3.099365   Sparsity:0.00   Params: 2177087 on epoch: 264]
2023-04-27 04:08:20,089 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:08:20,124 - 

2023-04-27 04:08:20,124 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:08:31,700 - Epoch: [267][   50/  518]    Overall Loss 2.955357    Objective Loss 2.955357                                        LR 0.000008    Time 0.231475    
2023-04-27 04:08:42,488 - Epoch: [267][  100/  518]    Overall Loss 2.962126    Objective Loss 2.962126                                        LR 0.000008    Time 0.223593    
2023-04-27 04:08:53,233 - Epoch: [267][  150/  518]    Overall Loss 2.966127    Objective Loss 2.966127                                        LR 0.000008    Time 0.220691    
2023-04-27 04:09:04,070 - Epoch: [267][  200/  518]    Overall Loss 2.972083    Objective Loss 2.972083                                        LR 0.000008    Time 0.219692    
2023-04-27 04:09:14,873 - Epoch: [267][  250/  518]    Overall Loss 2.971427    Objective Loss 2.971427                                        LR 0.000008    Time 0.218959    
2023-04-27 04:09:25,728 - Epoch: [267][  300/  518]    Overall Loss 2.973632    Objective Loss 2.973632                                        LR 0.000008    Time 0.218645    
2023-04-27 04:09:36,518 - Epoch: [267][  350/  518]    Overall Loss 2.974892    Objective Loss 2.974892                                        LR 0.000008    Time 0.218234    
2023-04-27 04:09:47,414 - Epoch: [267][  400/  518]    Overall Loss 2.971805    Objective Loss 2.971805                                        LR 0.000008    Time 0.218192    
2023-04-27 04:09:58,179 - Epoch: [267][  450/  518]    Overall Loss 2.968771    Objective Loss 2.968771                                        LR 0.000008    Time 0.217866    
2023-04-27 04:10:08,967 - Epoch: [267][  500/  518]    Overall Loss 2.970430    Objective Loss 2.970430                                        LR 0.000008    Time 0.217652    
2023-04-27 04:10:12,708 - Epoch: [267][  518/  518]    Overall Loss 2.972870    Objective Loss 2.972870                                        LR 0.000008    Time 0.217311    
2023-04-27 04:10:12,787 - --- validate (epoch=267)-----------
2023-04-27 04:10:12,788 - 4952 samples (32 per mini-batch)
2023-04-27 04:10:21,050 - Epoch: [267][   50/  155]    Loss 3.100581    mAP 0.433832    
2023-04-27 04:10:28,921 - Epoch: [267][  100/  155]    Loss 3.125120    mAP 0.431062    
2023-04-27 04:10:36,788 - Epoch: [267][  150/  155]    Loss 3.117895    mAP 0.429705    
2023-04-27 04:10:37,497 - Epoch: [267][  155/  155]    Loss 3.119131    mAP 0.428177    
2023-04-27 04:10:37,571 - ==> mAP: 0.42818    Loss: 3.119

2023-04-27 04:10:37,575 - ==> Best [mAP: 0.441580   vloss: 3.099365   Sparsity:0.00   Params: 2177087 on epoch: 264]
2023-04-27 04:10:37,575 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:10:37,609 - 

2023-04-27 04:10:37,609 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:10:49,254 - Epoch: [268][   50/  518]    Overall Loss 2.969801    Objective Loss 2.969801                                        LR 0.000008    Time 0.232838    
2023-04-27 04:11:00,056 - Epoch: [268][  100/  518]    Overall Loss 2.979739    Objective Loss 2.979739                                        LR 0.000008    Time 0.224426    
2023-04-27 04:11:10,798 - Epoch: [268][  150/  518]    Overall Loss 2.971685    Objective Loss 2.971685                                        LR 0.000008    Time 0.221219    
2023-04-27 04:11:21,583 - Epoch: [268][  200/  518]    Overall Loss 2.964974    Objective Loss 2.964974                                        LR 0.000008    Time 0.219830    
2023-04-27 04:11:32,358 - Epoch: [268][  250/  518]    Overall Loss 2.975782    Objective Loss 2.975782                                        LR 0.000008    Time 0.218960    
2023-04-27 04:11:43,174 - Epoch: [268][  300/  518]    Overall Loss 2.974181    Objective Loss 2.974181                                        LR 0.000008    Time 0.218514    
2023-04-27 04:11:54,087 - Epoch: [268][  350/  518]    Overall Loss 2.975762    Objective Loss 2.975762                                        LR 0.000008    Time 0.218473    
2023-04-27 04:12:04,939 - Epoch: [268][  400/  518]    Overall Loss 2.979975    Objective Loss 2.979975                                        LR 0.000008    Time 0.218289    
2023-04-27 04:12:15,736 - Epoch: [268][  450/  518]    Overall Loss 2.978045    Objective Loss 2.978045                                        LR 0.000008    Time 0.218024    
2023-04-27 04:12:26,582 - Epoch: [268][  500/  518]    Overall Loss 2.971995    Objective Loss 2.971995                                        LR 0.000008    Time 0.217912    
2023-04-27 04:12:30,337 - Epoch: [268][  518/  518]    Overall Loss 2.969809    Objective Loss 2.969809                                        LR 0.000008    Time 0.217587    
2023-04-27 04:12:30,414 - --- validate (epoch=268)-----------
2023-04-27 04:12:30,414 - 4952 samples (32 per mini-batch)
2023-04-27 04:12:38,674 - Epoch: [268][   50/  155]    Loss 3.104807    mAP 0.440002    
2023-04-27 04:12:46,579 - Epoch: [268][  100/  155]    Loss 3.107998    mAP 0.445402    
2023-04-27 04:12:54,421 - Epoch: [268][  150/  155]    Loss 3.110720    mAP 0.434012    
2023-04-27 04:12:55,139 - Epoch: [268][  155/  155]    Loss 3.105723    mAP 0.434941    
2023-04-27 04:12:55,215 - ==> mAP: 0.43494    Loss: 3.106

2023-04-27 04:12:55,219 - ==> Best [mAP: 0.441580   vloss: 3.099365   Sparsity:0.00   Params: 2177087 on epoch: 264]
2023-04-27 04:12:55,219 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:12:55,253 - 

2023-04-27 04:12:55,253 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:13:06,850 - Epoch: [269][   50/  518]    Overall Loss 2.961357    Objective Loss 2.961357                                        LR 0.000008    Time 0.231887    
2023-04-27 04:13:17,661 - Epoch: [269][  100/  518]    Overall Loss 2.963585    Objective Loss 2.963585                                        LR 0.000008    Time 0.224029    
2023-04-27 04:13:28,484 - Epoch: [269][  150/  518]    Overall Loss 2.965968    Objective Loss 2.965968                                        LR 0.000008    Time 0.221499    
2023-04-27 04:13:39,263 - Epoch: [269][  200/  518]    Overall Loss 2.966466    Objective Loss 2.966466                                        LR 0.000008    Time 0.220012    
2023-04-27 04:13:50,046 - Epoch: [269][  250/  518]    Overall Loss 2.962672    Objective Loss 2.962672                                        LR 0.000008    Time 0.219134    
2023-04-27 04:14:00,813 - Epoch: [269][  300/  518]    Overall Loss 2.959192    Objective Loss 2.959192                                        LR 0.000008    Time 0.218496    
2023-04-27 04:14:11,603 - Epoch: [269][  350/  518]    Overall Loss 2.949789    Objective Loss 2.949789                                        LR 0.000008    Time 0.218108    
2023-04-27 04:14:22,436 - Epoch: [269][  400/  518]    Overall Loss 2.951523    Objective Loss 2.951523                                        LR 0.000008    Time 0.217924    
2023-04-27 04:14:33,197 - Epoch: [269][  450/  518]    Overall Loss 2.960219    Objective Loss 2.960219                                        LR 0.000008    Time 0.217619    
2023-04-27 04:14:44,127 - Epoch: [269][  500/  518]    Overall Loss 2.965894    Objective Loss 2.965894                                        LR 0.000008    Time 0.217714    
2023-04-27 04:14:47,898 - Epoch: [269][  518/  518]    Overall Loss 2.962807    Objective Loss 2.962807                                        LR 0.000008    Time 0.217428    
2023-04-27 04:14:47,975 - --- validate (epoch=269)-----------
2023-04-27 04:14:47,975 - 4952 samples (32 per mini-batch)
2023-04-27 04:14:56,261 - Epoch: [269][   50/  155]    Loss 3.101738    mAP 0.439422    
2023-04-27 04:15:04,155 - Epoch: [269][  100/  155]    Loss 3.097216    mAP 0.442862    
2023-04-27 04:15:11,996 - Epoch: [269][  150/  155]    Loss 3.101330    mAP 0.443494    
2023-04-27 04:15:12,720 - Epoch: [269][  155/  155]    Loss 3.098334    mAP 0.444663    
2023-04-27 04:15:12,796 - ==> mAP: 0.44466    Loss: 3.098

2023-04-27 04:15:12,800 - ==> Best [mAP: 0.444663   vloss: 3.098334   Sparsity:0.00   Params: 2177087 on epoch: 269]
2023-04-27 04:15:12,800 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:15:12,847 - 

2023-04-27 04:15:12,847 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:15:24,353 - Epoch: [270][   50/  518]    Overall Loss 2.990140    Objective Loss 2.990140                                        LR 0.000008    Time 0.230063    
2023-04-27 04:15:35,280 - Epoch: [270][  100/  518]    Overall Loss 2.961487    Objective Loss 2.961487                                        LR 0.000008    Time 0.224290    
2023-04-27 04:15:46,149 - Epoch: [270][  150/  518]    Overall Loss 2.965554    Objective Loss 2.965554                                        LR 0.000008    Time 0.221972    
2023-04-27 04:15:57,047 - Epoch: [270][  200/  518]    Overall Loss 2.968105    Objective Loss 2.968105                                        LR 0.000008    Time 0.220964    
2023-04-27 04:16:07,794 - Epoch: [270][  250/  518]    Overall Loss 2.953144    Objective Loss 2.953144                                        LR 0.000008    Time 0.219751    
2023-04-27 04:16:18,589 - Epoch: [270][  300/  518]    Overall Loss 2.955148    Objective Loss 2.955148                                        LR 0.000008    Time 0.219106    
2023-04-27 04:16:29,309 - Epoch: [270][  350/  518]    Overall Loss 2.953630    Objective Loss 2.953630                                        LR 0.000008    Time 0.218428    
2023-04-27 04:16:40,142 - Epoch: [270][  400/  518]    Overall Loss 2.955674    Objective Loss 2.955674                                        LR 0.000008    Time 0.218204    
2023-04-27 04:16:50,992 - Epoch: [270][  450/  518]    Overall Loss 2.952844    Objective Loss 2.952844                                        LR 0.000008    Time 0.218067    
2023-04-27 04:17:01,787 - Epoch: [270][  500/  518]    Overall Loss 2.955289    Objective Loss 2.955289                                        LR 0.000008    Time 0.217846    
2023-04-27 04:17:05,498 - Epoch: [270][  518/  518]    Overall Loss 2.955501    Objective Loss 2.955501                                        LR 0.000008    Time 0.217439    
2023-04-27 04:17:05,573 - --- validate (epoch=270)-----------
2023-04-27 04:17:05,574 - 4952 samples (32 per mini-batch)
2023-04-27 04:17:13,862 - Epoch: [270][   50/  155]    Loss 3.114160    mAP 0.453228    
2023-04-27 04:17:21,783 - Epoch: [270][  100/  155]    Loss 3.083950    mAP 0.443441    
2023-04-27 04:17:29,664 - Epoch: [270][  150/  155]    Loss 3.081920    mAP 0.445769    
2023-04-27 04:17:30,391 - Epoch: [270][  155/  155]    Loss 3.081809    mAP 0.446835    
2023-04-27 04:17:30,465 - ==> mAP: 0.44684    Loss: 3.082

2023-04-27 04:17:30,469 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:17:30,469 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:17:30,520 - 

2023-04-27 04:17:30,520 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:17:42,156 - Epoch: [271][   50/  518]    Overall Loss 2.946502    Objective Loss 2.946502                                        LR 0.000008    Time 0.232658    
2023-04-27 04:17:52,974 - Epoch: [271][  100/  518]    Overall Loss 2.959829    Objective Loss 2.959829                                        LR 0.000008    Time 0.224489    
2023-04-27 04:18:03,747 - Epoch: [271][  150/  518]    Overall Loss 2.966087    Objective Loss 2.966087                                        LR 0.000008    Time 0.221470    
2023-04-27 04:18:14,543 - Epoch: [271][  200/  518]    Overall Loss 2.961211    Objective Loss 2.961211                                        LR 0.000008    Time 0.220073    
2023-04-27 04:18:25,365 - Epoch: [271][  250/  518]    Overall Loss 2.963180    Objective Loss 2.963180                                        LR 0.000008    Time 0.219342    
2023-04-27 04:18:36,205 - Epoch: [271][  300/  518]    Overall Loss 2.963341    Objective Loss 2.963341                                        LR 0.000008    Time 0.218912    
2023-04-27 04:18:47,002 - Epoch: [271][  350/  518]    Overall Loss 2.960858    Objective Loss 2.960858                                        LR 0.000008    Time 0.218485    
2023-04-27 04:18:57,773 - Epoch: [271][  400/  518]    Overall Loss 2.957729    Objective Loss 2.957729                                        LR 0.000008    Time 0.218097    
2023-04-27 04:19:08,547 - Epoch: [271][  450/  518]    Overall Loss 2.963586    Objective Loss 2.963586                                        LR 0.000008    Time 0.217802    
2023-04-27 04:19:19,414 - Epoch: [271][  500/  518]    Overall Loss 2.958697    Objective Loss 2.958697                                        LR 0.000008    Time 0.217753    
2023-04-27 04:19:23,201 - Epoch: [271][  518/  518]    Overall Loss 2.958937    Objective Loss 2.958937                                        LR 0.000008    Time 0.217497    
2023-04-27 04:19:23,276 - --- validate (epoch=271)-----------
2023-04-27 04:19:23,276 - 4952 samples (32 per mini-batch)
2023-04-27 04:19:31,520 - Epoch: [271][   50/  155]    Loss 3.080792    mAP 0.446138    
2023-04-27 04:19:39,411 - Epoch: [271][  100/  155]    Loss 3.076481    mAP 0.443767    
2023-04-27 04:19:47,311 - Epoch: [271][  150/  155]    Loss 3.095284    mAP 0.441196    
2023-04-27 04:19:48,029 - Epoch: [271][  155/  155]    Loss 3.095184    mAP 0.440172    
2023-04-27 04:19:48,103 - ==> mAP: 0.44017    Loss: 3.095

2023-04-27 04:19:48,107 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:19:48,107 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:19:48,161 - 

2023-04-27 04:19:48,161 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:19:59,815 - Epoch: [272][   50/  518]    Overall Loss 2.935930    Objective Loss 2.935930                                        LR 0.000008    Time 0.233014    
2023-04-27 04:20:10,641 - Epoch: [272][  100/  518]    Overall Loss 2.951069    Objective Loss 2.951069                                        LR 0.000008    Time 0.224742    
2023-04-27 04:20:21,452 - Epoch: [272][  150/  518]    Overall Loss 2.938881    Objective Loss 2.938881                                        LR 0.000008    Time 0.221893    
2023-04-27 04:20:32,245 - Epoch: [272][  200/  518]    Overall Loss 2.936373    Objective Loss 2.936373                                        LR 0.000008    Time 0.220380    
2023-04-27 04:20:43,135 - Epoch: [272][  250/  518]    Overall Loss 2.938552    Objective Loss 2.938552                                        LR 0.000008    Time 0.219858    
2023-04-27 04:20:54,007 - Epoch: [272][  300/  518]    Overall Loss 2.942840    Objective Loss 2.942840                                        LR 0.000008    Time 0.219447    
2023-04-27 04:21:04,859 - Epoch: [272][  350/  518]    Overall Loss 2.944756    Objective Loss 2.944756                                        LR 0.000008    Time 0.219101    
2023-04-27 04:21:15,667 - Epoch: [272][  400/  518]    Overall Loss 2.940727    Objective Loss 2.940727                                        LR 0.000008    Time 0.218729    
2023-04-27 04:21:26,497 - Epoch: [272][  450/  518]    Overall Loss 2.941674    Objective Loss 2.941674                                        LR 0.000008    Time 0.218490    
2023-04-27 04:21:37,318 - Epoch: [272][  500/  518]    Overall Loss 2.937368    Objective Loss 2.937368                                        LR 0.000008    Time 0.218278    
2023-04-27 04:21:41,058 - Epoch: [272][  518/  518]    Overall Loss 2.942120    Objective Loss 2.942120                                        LR 0.000008    Time 0.217912    
2023-04-27 04:21:41,131 - --- validate (epoch=272)-----------
2023-04-27 04:21:41,131 - 4952 samples (32 per mini-batch)
2023-04-27 04:21:49,423 - Epoch: [272][   50/  155]    Loss 3.101016    mAP 0.427001    
2023-04-27 04:21:57,322 - Epoch: [272][  100/  155]    Loss 3.093959    mAP 0.432191    
2023-04-27 04:22:05,174 - Epoch: [272][  150/  155]    Loss 3.098715    mAP 0.434778    
2023-04-27 04:22:05,884 - Epoch: [272][  155/  155]    Loss 3.101460    mAP 0.432179    
2023-04-27 04:22:05,961 - ==> mAP: 0.43218    Loss: 3.101

2023-04-27 04:22:05,965 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:22:05,965 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:22:05,999 - 

2023-04-27 04:22:05,999 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:22:17,673 - Epoch: [273][   50/  518]    Overall Loss 2.967865    Objective Loss 2.967865                                        LR 0.000008    Time 0.233419    
2023-04-27 04:22:28,503 - Epoch: [273][  100/  518]    Overall Loss 2.952416    Objective Loss 2.952416                                        LR 0.000008    Time 0.224994    
2023-04-27 04:22:39,381 - Epoch: [273][  150/  518]    Overall Loss 2.955802    Objective Loss 2.955802                                        LR 0.000008    Time 0.222505    
2023-04-27 04:22:50,232 - Epoch: [273][  200/  518]    Overall Loss 2.948194    Objective Loss 2.948194                                        LR 0.000008    Time 0.221126    
2023-04-27 04:23:01,065 - Epoch: [273][  250/  518]    Overall Loss 2.951914    Objective Loss 2.951914                                        LR 0.000008    Time 0.220227    
2023-04-27 04:23:11,945 - Epoch: [273][  300/  518]    Overall Loss 2.947430    Objective Loss 2.947430                                        LR 0.000008    Time 0.219783    
2023-04-27 04:23:22,787 - Epoch: [273][  350/  518]    Overall Loss 2.938222    Objective Loss 2.938222                                        LR 0.000008    Time 0.219359    
2023-04-27 04:23:33,643 - Epoch: [273][  400/  518]    Overall Loss 2.943493    Objective Loss 2.943493                                        LR 0.000008    Time 0.219075    
2023-04-27 04:23:44,433 - Epoch: [273][  450/  518]    Overall Loss 2.940493    Objective Loss 2.940493                                        LR 0.000008    Time 0.218709    
2023-04-27 04:23:55,343 - Epoch: [273][  500/  518]    Overall Loss 2.947603    Objective Loss 2.947603                                        LR 0.000008    Time 0.218655    
2023-04-27 04:23:59,116 - Epoch: [273][  518/  518]    Overall Loss 2.947886    Objective Loss 2.947886                                        LR 0.000008    Time 0.218339    
2023-04-27 04:23:59,192 - --- validate (epoch=273)-----------
2023-04-27 04:23:59,193 - 4952 samples (32 per mini-batch)
2023-04-27 04:24:07,466 - Epoch: [273][   50/  155]    Loss 3.102883    mAP 0.442735    
2023-04-27 04:24:15,356 - Epoch: [273][  100/  155]    Loss 3.085895    mAP 0.443532    
2023-04-27 04:24:23,219 - Epoch: [273][  150/  155]    Loss 3.088370    mAP 0.434602    
2023-04-27 04:24:23,928 - Epoch: [273][  155/  155]    Loss 3.088096    mAP 0.432939    
2023-04-27 04:24:23,997 - ==> mAP: 0.43294    Loss: 3.088

2023-04-27 04:24:24,001 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:24:24,001 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:24:24,036 - 

2023-04-27 04:24:24,036 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:24:35,545 - Epoch: [274][   50/  518]    Overall Loss 2.923915    Objective Loss 2.923915                                        LR 0.000008    Time 0.230126    
2023-04-27 04:24:46,388 - Epoch: [274][  100/  518]    Overall Loss 2.909212    Objective Loss 2.909212                                        LR 0.000008    Time 0.223472    
2023-04-27 04:24:57,230 - Epoch: [274][  150/  518]    Overall Loss 2.925743    Objective Loss 2.925743                                        LR 0.000008    Time 0.221252    
2023-04-27 04:25:08,032 - Epoch: [274][  200/  518]    Overall Loss 2.938922    Objective Loss 2.938922                                        LR 0.000008    Time 0.219939    
2023-04-27 04:25:18,831 - Epoch: [274][  250/  518]    Overall Loss 2.935996    Objective Loss 2.935996                                        LR 0.000008    Time 0.219142    
2023-04-27 04:25:29,475 - Epoch: [274][  300/  518]    Overall Loss 2.940027    Objective Loss 2.940027                                        LR 0.000008    Time 0.218093    
2023-04-27 04:25:40,291 - Epoch: [274][  350/  518]    Overall Loss 2.945195    Objective Loss 2.945195                                        LR 0.000008    Time 0.217835    
2023-04-27 04:25:51,102 - Epoch: [274][  400/  518]    Overall Loss 2.950226    Objective Loss 2.950226                                        LR 0.000008    Time 0.217630    
2023-04-27 04:26:01,887 - Epoch: [274][  450/  518]    Overall Loss 2.949610    Objective Loss 2.949610                                        LR 0.000008    Time 0.217411    
2023-04-27 04:26:12,709 - Epoch: [274][  500/  518]    Overall Loss 2.952144    Objective Loss 2.952144                                        LR 0.000008    Time 0.217311    
2023-04-27 04:26:16,489 - Epoch: [274][  518/  518]    Overall Loss 2.952191    Objective Loss 2.952191                                        LR 0.000008    Time 0.217057    
2023-04-27 04:26:16,566 - --- validate (epoch=274)-----------
2023-04-27 04:26:16,567 - 4952 samples (32 per mini-batch)
2023-04-27 04:26:24,833 - Epoch: [274][   50/  155]    Loss 3.152308    mAP 0.435724    
2023-04-27 04:26:32,761 - Epoch: [274][  100/  155]    Loss 3.114090    mAP 0.443574    
2023-04-27 04:26:40,577 - Epoch: [274][  150/  155]    Loss 3.089632    mAP 0.438103    
2023-04-27 04:26:41,293 - Epoch: [274][  155/  155]    Loss 3.090330    mAP 0.435754    
2023-04-27 04:26:41,374 - ==> mAP: 0.43575    Loss: 3.090

2023-04-27 04:26:41,378 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:26:41,378 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:26:41,412 - 

2023-04-27 04:26:41,412 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:26:53,172 - Epoch: [275][   50/  518]    Overall Loss 2.932323    Objective Loss 2.932323                                        LR 0.000008    Time 0.235141    
2023-04-27 04:27:03,966 - Epoch: [275][  100/  518]    Overall Loss 2.927982    Objective Loss 2.927982                                        LR 0.000008    Time 0.225495    
2023-04-27 04:27:14,710 - Epoch: [275][  150/  518]    Overall Loss 2.935759    Objective Loss 2.935759                                        LR 0.000008    Time 0.221950    
2023-04-27 04:27:25,510 - Epoch: [275][  200/  518]    Overall Loss 2.938367    Objective Loss 2.938367                                        LR 0.000008    Time 0.220453    
2023-04-27 04:27:36,278 - Epoch: [275][  250/  518]    Overall Loss 2.939211    Objective Loss 2.939211                                        LR 0.000008    Time 0.219427    
2023-04-27 04:27:46,991 - Epoch: [275][  300/  518]    Overall Loss 2.942019    Objective Loss 2.942019                                        LR 0.000008    Time 0.218561    
2023-04-27 04:27:57,878 - Epoch: [275][  350/  518]    Overall Loss 2.942978    Objective Loss 2.942978                                        LR 0.000008    Time 0.218439    
2023-04-27 04:28:08,735 - Epoch: [275][  400/  518]    Overall Loss 2.944065    Objective Loss 2.944065                                        LR 0.000008    Time 0.218273    
2023-04-27 04:28:19,642 - Epoch: [275][  450/  518]    Overall Loss 2.946423    Objective Loss 2.946423                                        LR 0.000008    Time 0.218256    
2023-04-27 04:28:30,486 - Epoch: [275][  500/  518]    Overall Loss 2.940299    Objective Loss 2.940299                                        LR 0.000008    Time 0.218115    
2023-04-27 04:28:34,277 - Epoch: [275][  518/  518]    Overall Loss 2.938989    Objective Loss 2.938989                                        LR 0.000008    Time 0.217852    
2023-04-27 04:28:34,353 - --- validate (epoch=275)-----------
2023-04-27 04:28:34,354 - 4952 samples (32 per mini-batch)
2023-04-27 04:28:42,610 - Epoch: [275][   50/  155]    Loss 3.086319    mAP 0.447668    
2023-04-27 04:28:50,512 - Epoch: [275][  100/  155]    Loss 3.098762    mAP 0.444151    
2023-04-27 04:28:58,373 - Epoch: [275][  150/  155]    Loss 3.081419    mAP 0.441319    
2023-04-27 04:28:59,080 - Epoch: [275][  155/  155]    Loss 3.083455    mAP 0.438655    
2023-04-27 04:28:59,153 - ==> mAP: 0.43866    Loss: 3.083

2023-04-27 04:28:59,157 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:28:59,157 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:28:59,191 - 

2023-04-27 04:28:59,191 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:29:10,729 - Epoch: [276][   50/  518]    Overall Loss 2.955948    Objective Loss 2.955948                                        LR 0.000008    Time 0.230700    
2023-04-27 04:29:21,461 - Epoch: [276][  100/  518]    Overall Loss 2.934062    Objective Loss 2.934062                                        LR 0.000008    Time 0.222649    
2023-04-27 04:29:32,260 - Epoch: [276][  150/  518]    Overall Loss 2.936394    Objective Loss 2.936394                                        LR 0.000008    Time 0.220416    
2023-04-27 04:29:43,084 - Epoch: [276][  200/  518]    Overall Loss 2.936130    Objective Loss 2.936130                                        LR 0.000008    Time 0.219426    
2023-04-27 04:29:53,998 - Epoch: [276][  250/  518]    Overall Loss 2.943391    Objective Loss 2.943391                                        LR 0.000008    Time 0.219189    
2023-04-27 04:30:04,725 - Epoch: [276][  300/  518]    Overall Loss 2.932665    Objective Loss 2.932665                                        LR 0.000008    Time 0.218410    
2023-04-27 04:30:15,598 - Epoch: [276][  350/  518]    Overall Loss 2.931324    Objective Loss 2.931324                                        LR 0.000008    Time 0.218269    
2023-04-27 04:30:26,503 - Epoch: [276][  400/  518]    Overall Loss 2.929658    Objective Loss 2.929658                                        LR 0.000008    Time 0.218245    
2023-04-27 04:30:37,360 - Epoch: [276][  450/  518]    Overall Loss 2.930414    Objective Loss 2.930414                                        LR 0.000008    Time 0.218117    
2023-04-27 04:30:48,133 - Epoch: [276][  500/  518]    Overall Loss 2.933673    Objective Loss 2.933673                                        LR 0.000008    Time 0.217849    
2023-04-27 04:30:51,892 - Epoch: [276][  518/  518]    Overall Loss 2.934845    Objective Loss 2.934845                                        LR 0.000008    Time 0.217535    
2023-04-27 04:30:51,967 - --- validate (epoch=276)-----------
2023-04-27 04:30:51,967 - 4952 samples (32 per mini-batch)
2023-04-27 04:31:00,264 - Epoch: [276][   50/  155]    Loss 3.067852    mAP 0.435315    
2023-04-27 04:31:08,178 - Epoch: [276][  100/  155]    Loss 3.099052    mAP 0.441556    
2023-04-27 04:31:16,054 - Epoch: [276][  150/  155]    Loss 3.081428    mAP 0.435440    
2023-04-27 04:31:16,782 - Epoch: [276][  155/  155]    Loss 3.084396    mAP 0.435081    
2023-04-27 04:31:16,855 - ==> mAP: 0.43508    Loss: 3.084

2023-04-27 04:31:16,859 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:31:16,859 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:31:16,893 - 

2023-04-27 04:31:16,894 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:31:28,648 - Epoch: [277][   50/  518]    Overall Loss 2.981578    Objective Loss 2.981578                                        LR 0.000008    Time 0.235037    
2023-04-27 04:31:39,411 - Epoch: [277][  100/  518]    Overall Loss 2.937921    Objective Loss 2.937921                                        LR 0.000008    Time 0.225127    
2023-04-27 04:31:50,361 - Epoch: [277][  150/  518]    Overall Loss 2.953810    Objective Loss 2.953810                                        LR 0.000008    Time 0.223076    
2023-04-27 04:32:01,184 - Epoch: [277][  200/  518]    Overall Loss 2.970160    Objective Loss 2.970160                                        LR 0.000008    Time 0.221417    
2023-04-27 04:32:11,960 - Epoch: [277][  250/  518]    Overall Loss 2.968933    Objective Loss 2.968933                                        LR 0.000008    Time 0.220229    
2023-04-27 04:32:22,766 - Epoch: [277][  300/  518]    Overall Loss 2.962673    Objective Loss 2.962673                                        LR 0.000008    Time 0.219541    
2023-04-27 04:32:33,596 - Epoch: [277][  350/  518]    Overall Loss 2.960302    Objective Loss 2.960302                                        LR 0.000008    Time 0.219115    
2023-04-27 04:32:44,508 - Epoch: [277][  400/  518]    Overall Loss 2.957348    Objective Loss 2.957348                                        LR 0.000008    Time 0.219002    
2023-04-27 04:32:55,313 - Epoch: [277][  450/  518]    Overall Loss 2.959697    Objective Loss 2.959697                                        LR 0.000008    Time 0.218676    
2023-04-27 04:33:06,232 - Epoch: [277][  500/  518]    Overall Loss 2.958548    Objective Loss 2.958548                                        LR 0.000008    Time 0.218643    
2023-04-27 04:33:09,974 - Epoch: [277][  518/  518]    Overall Loss 2.956048    Objective Loss 2.956048                                        LR 0.000008    Time 0.218268    
2023-04-27 04:33:10,051 - --- validate (epoch=277)-----------
2023-04-27 04:33:10,051 - 4952 samples (32 per mini-batch)
2023-04-27 04:33:18,287 - Epoch: [277][   50/  155]    Loss 3.097670    mAP 0.422080    
2023-04-27 04:33:26,164 - Epoch: [277][  100/  155]    Loss 3.098254    mAP 0.426799    
2023-04-27 04:33:34,019 - Epoch: [277][  150/  155]    Loss 3.101232    mAP 0.432692    
2023-04-27 04:33:34,729 - Epoch: [277][  155/  155]    Loss 3.096425    mAP 0.432949    
2023-04-27 04:33:34,803 - ==> mAP: 0.43295    Loss: 3.096

2023-04-27 04:33:34,807 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:33:34,807 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:33:34,841 - 

2023-04-27 04:33:34,841 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:33:46,528 - Epoch: [278][   50/  518]    Overall Loss 2.953580    Objective Loss 2.953580                                        LR 0.000008    Time 0.233685    
2023-04-27 04:33:57,386 - Epoch: [278][  100/  518]    Overall Loss 2.930538    Objective Loss 2.930538                                        LR 0.000008    Time 0.225407    
2023-04-27 04:34:08,259 - Epoch: [278][  150/  518]    Overall Loss 2.928814    Objective Loss 2.928814                                        LR 0.000008    Time 0.222747    
2023-04-27 04:34:19,087 - Epoch: [278][  200/  518]    Overall Loss 2.917202    Objective Loss 2.917202                                        LR 0.000008    Time 0.221192    
2023-04-27 04:34:29,885 - Epoch: [278][  250/  518]    Overall Loss 2.922639    Objective Loss 2.922639                                        LR 0.000008    Time 0.220138    
2023-04-27 04:34:40,619 - Epoch: [278][  300/  518]    Overall Loss 2.923455    Objective Loss 2.923455                                        LR 0.000008    Time 0.219224    
2023-04-27 04:34:51,418 - Epoch: [278][  350/  518]    Overall Loss 2.928992    Objective Loss 2.928992                                        LR 0.000008    Time 0.218755    
2023-04-27 04:35:02,326 - Epoch: [278][  400/  518]    Overall Loss 2.930675    Objective Loss 2.930675                                        LR 0.000008    Time 0.218678    
2023-04-27 04:35:13,121 - Epoch: [278][  450/  518]    Overall Loss 2.936264    Objective Loss 2.936264                                        LR 0.000008    Time 0.218366    
2023-04-27 04:35:23,976 - Epoch: [278][  500/  518]    Overall Loss 2.935388    Objective Loss 2.935388                                        LR 0.000008    Time 0.218236    
2023-04-27 04:35:27,716 - Epoch: [278][  518/  518]    Overall Loss 2.932371    Objective Loss 2.932371                                        LR 0.000008    Time 0.217870    
2023-04-27 04:35:27,792 - --- validate (epoch=278)-----------
2023-04-27 04:35:27,793 - 4952 samples (32 per mini-batch)
2023-04-27 04:35:36,060 - Epoch: [278][   50/  155]    Loss 3.042210    mAP 0.449255    
2023-04-27 04:35:43,941 - Epoch: [278][  100/  155]    Loss 3.092301    mAP 0.437435    
2023-04-27 04:35:51,813 - Epoch: [278][  150/  155]    Loss 3.085030    mAP 0.435662    
2023-04-27 04:35:52,532 - Epoch: [278][  155/  155]    Loss 3.086845    mAP 0.436464    
2023-04-27 04:35:52,605 - ==> mAP: 0.43646    Loss: 3.087

2023-04-27 04:35:52,609 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:35:52,609 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:35:52,643 - 

2023-04-27 04:35:52,643 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:36:04,225 - Epoch: [279][   50/  518]    Overall Loss 2.901108    Objective Loss 2.901108                                        LR 0.000008    Time 0.231584    
2023-04-27 04:36:15,084 - Epoch: [279][  100/  518]    Overall Loss 2.909437    Objective Loss 2.909437                                        LR 0.000008    Time 0.224364    
2023-04-27 04:36:25,840 - Epoch: [279][  150/  518]    Overall Loss 2.926170    Objective Loss 2.926170                                        LR 0.000008    Time 0.221273    
2023-04-27 04:36:36,625 - Epoch: [279][  200/  518]    Overall Loss 2.942182    Objective Loss 2.942182                                        LR 0.000008    Time 0.219874    
2023-04-27 04:36:47,402 - Epoch: [279][  250/  518]    Overall Loss 2.954367    Objective Loss 2.954367                                        LR 0.000008    Time 0.219001    
2023-04-27 04:36:58,191 - Epoch: [279][  300/  518]    Overall Loss 2.948124    Objective Loss 2.948124                                        LR 0.000008    Time 0.218458    
2023-04-27 04:37:09,073 - Epoch: [279][  350/  518]    Overall Loss 2.943151    Objective Loss 2.943151                                        LR 0.000008    Time 0.218336    
2023-04-27 04:37:19,831 - Epoch: [279][  400/  518]    Overall Loss 2.946438    Objective Loss 2.946438                                        LR 0.000008    Time 0.217935    
2023-04-27 04:37:30,632 - Epoch: [279][  450/  518]    Overall Loss 2.948950    Objective Loss 2.948950                                        LR 0.000008    Time 0.217718    
2023-04-27 04:37:41,365 - Epoch: [279][  500/  518]    Overall Loss 2.944790    Objective Loss 2.944790                                        LR 0.000008    Time 0.217409    
2023-04-27 04:37:45,119 - Epoch: [279][  518/  518]    Overall Loss 2.943813    Objective Loss 2.943813                                        LR 0.000008    Time 0.217102    
2023-04-27 04:37:45,195 - --- validate (epoch=279)-----------
2023-04-27 04:37:45,195 - 4952 samples (32 per mini-batch)
2023-04-27 04:37:53,416 - Epoch: [279][   50/  155]    Loss 3.076701    mAP 0.429662    
2023-04-27 04:38:01,269 - Epoch: [279][  100/  155]    Loss 3.102287    mAP 0.424192    
2023-04-27 04:38:09,137 - Epoch: [279][  150/  155]    Loss 3.097395    mAP 0.427430    
2023-04-27 04:38:09,847 - Epoch: [279][  155/  155]    Loss 3.096759    mAP 0.426679    
2023-04-27 04:38:09,923 - ==> mAP: 0.42668    Loss: 3.097

2023-04-27 04:38:09,926 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:38:09,927 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:38:09,961 - 

2023-04-27 04:38:09,961 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:38:21,485 - Epoch: [280][   50/  518]    Overall Loss 2.952488    Objective Loss 2.952488                                        LR 0.000008    Time 0.230423    
2023-04-27 04:38:32,364 - Epoch: [280][  100/  518]    Overall Loss 2.961361    Objective Loss 2.961361                                        LR 0.000008    Time 0.223986    
2023-04-27 04:38:43,258 - Epoch: [280][  150/  518]    Overall Loss 2.950216    Objective Loss 2.950216                                        LR 0.000008    Time 0.221944    
2023-04-27 04:38:53,990 - Epoch: [280][  200/  518]    Overall Loss 2.947070    Objective Loss 2.947070                                        LR 0.000008    Time 0.220108    
2023-04-27 04:39:04,828 - Epoch: [280][  250/  518]    Overall Loss 2.945748    Objective Loss 2.945748                                        LR 0.000008    Time 0.219430    
2023-04-27 04:39:15,603 - Epoch: [280][  300/  518]    Overall Loss 2.945397    Objective Loss 2.945397                                        LR 0.000008    Time 0.218771    
2023-04-27 04:39:26,477 - Epoch: [280][  350/  518]    Overall Loss 2.943687    Objective Loss 2.943687                                        LR 0.000008    Time 0.218581    
2023-04-27 04:39:37,167 - Epoch: [280][  400/  518]    Overall Loss 2.941532    Objective Loss 2.941532                                        LR 0.000008    Time 0.217980    
2023-04-27 04:39:47,923 - Epoch: [280][  450/  518]    Overall Loss 2.937614    Objective Loss 2.937614                                        LR 0.000008    Time 0.217658    
2023-04-27 04:39:58,789 - Epoch: [280][  500/  518]    Overall Loss 2.936059    Objective Loss 2.936059                                        LR 0.000008    Time 0.217622    
2023-04-27 04:40:02,585 - Epoch: [280][  518/  518]    Overall Loss 2.932289    Objective Loss 2.932289                                        LR 0.000008    Time 0.217387    
2023-04-27 04:40:02,662 - --- validate (epoch=280)-----------
2023-04-27 04:40:02,663 - 4952 samples (32 per mini-batch)
2023-04-27 04:40:10,998 - Epoch: [280][   50/  155]    Loss 3.094279    mAP 0.443137    
2023-04-27 04:40:18,859 - Epoch: [280][  100/  155]    Loss 3.100650    mAP 0.430133    
2023-04-27 04:40:26,721 - Epoch: [280][  150/  155]    Loss 3.098188    mAP 0.436077    
2023-04-27 04:40:27,437 - Epoch: [280][  155/  155]    Loss 3.097129    mAP 0.435325    
2023-04-27 04:40:27,510 - ==> mAP: 0.43532    Loss: 3.097

2023-04-27 04:40:27,514 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:40:27,514 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:40:27,550 - 

2023-04-27 04:40:27,550 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:40:39,055 - Epoch: [281][   50/  518]    Overall Loss 2.937514    Objective Loss 2.937514                                        LR 0.000008    Time 0.230054    
2023-04-27 04:40:49,865 - Epoch: [281][  100/  518]    Overall Loss 2.940364    Objective Loss 2.940364                                        LR 0.000008    Time 0.223111    
2023-04-27 04:41:00,670 - Epoch: [281][  150/  518]    Overall Loss 2.937374    Objective Loss 2.937374                                        LR 0.000008    Time 0.220763    
2023-04-27 04:41:11,491 - Epoch: [281][  200/  518]    Overall Loss 2.927056    Objective Loss 2.927056                                        LR 0.000008    Time 0.219669    
2023-04-27 04:41:22,299 - Epoch: [281][  250/  518]    Overall Loss 2.935883    Objective Loss 2.935883                                        LR 0.000008    Time 0.218962    
2023-04-27 04:41:33,282 - Epoch: [281][  300/  518]    Overall Loss 2.937159    Objective Loss 2.937159                                        LR 0.000008    Time 0.219073    
2023-04-27 04:41:44,159 - Epoch: [281][  350/  518]    Overall Loss 2.928402    Objective Loss 2.928402                                        LR 0.000008    Time 0.218849    
2023-04-27 04:41:54,979 - Epoch: [281][  400/  518]    Overall Loss 2.930081    Objective Loss 2.930081                                        LR 0.000008    Time 0.218538    
2023-04-27 04:42:05,769 - Epoch: [281][  450/  518]    Overall Loss 2.935111    Objective Loss 2.935111                                        LR 0.000008    Time 0.218232    
2023-04-27 04:42:16,587 - Epoch: [281][  500/  518]    Overall Loss 2.932980    Objective Loss 2.932980                                        LR 0.000008    Time 0.218042    
2023-04-27 04:42:20,367 - Epoch: [281][  518/  518]    Overall Loss 2.936174    Objective Loss 2.936174                                        LR 0.000008    Time 0.217761    
2023-04-27 04:42:20,442 - --- validate (epoch=281)-----------
2023-04-27 04:42:20,443 - 4952 samples (32 per mini-batch)
2023-04-27 04:42:28,691 - Epoch: [281][   50/  155]    Loss 3.078466    mAP 0.415061    
2023-04-27 04:42:36,607 - Epoch: [281][  100/  155]    Loss 3.094941    mAP 0.425258    
2023-04-27 04:42:44,505 - Epoch: [281][  150/  155]    Loss 3.092210    mAP 0.423823    
2023-04-27 04:42:45,225 - Epoch: [281][  155/  155]    Loss 3.093438    mAP 0.423386    
2023-04-27 04:42:45,302 - ==> mAP: 0.42339    Loss: 3.093

2023-04-27 04:42:45,306 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:42:45,306 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:42:45,340 - 

2023-04-27 04:42:45,340 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:42:57,002 - Epoch: [282][   50/  518]    Overall Loss 3.016117    Objective Loss 3.016117                                        LR 0.000008    Time 0.233191    
2023-04-27 04:43:07,711 - Epoch: [282][  100/  518]    Overall Loss 2.980734    Objective Loss 2.980734                                        LR 0.000008    Time 0.223667    
2023-04-27 04:43:18,501 - Epoch: [282][  150/  518]    Overall Loss 2.972292    Objective Loss 2.972292                                        LR 0.000008    Time 0.221036    
2023-04-27 04:43:29,313 - Epoch: [282][  200/  518]    Overall Loss 2.946373    Objective Loss 2.946373                                        LR 0.000008    Time 0.219826    
2023-04-27 04:43:40,103 - Epoch: [282][  250/  518]    Overall Loss 2.963075    Objective Loss 2.963075                                        LR 0.000008    Time 0.219017    
2023-04-27 04:43:50,835 - Epoch: [282][  300/  518]    Overall Loss 2.951786    Objective Loss 2.951786                                        LR 0.000008    Time 0.218282    
2023-04-27 04:44:01,652 - Epoch: [282][  350/  518]    Overall Loss 2.948403    Objective Loss 2.948403                                        LR 0.000008    Time 0.217998    
2023-04-27 04:44:12,601 - Epoch: [282][  400/  518]    Overall Loss 2.941562    Objective Loss 2.941562                                        LR 0.000008    Time 0.218117    
2023-04-27 04:44:23,380 - Epoch: [282][  450/  518]    Overall Loss 2.941648    Objective Loss 2.941648                                        LR 0.000008    Time 0.217833    
2023-04-27 04:44:34,214 - Epoch: [282][  500/  518]    Overall Loss 2.940409    Objective Loss 2.940409                                        LR 0.000008    Time 0.217715    
2023-04-27 04:44:37,968 - Epoch: [282][  518/  518]    Overall Loss 2.943657    Objective Loss 2.943657                                        LR 0.000008    Time 0.217394    
2023-04-27 04:44:38,044 - --- validate (epoch=282)-----------
2023-04-27 04:44:38,044 - 4952 samples (32 per mini-batch)
2023-04-27 04:44:46,313 - Epoch: [282][   50/  155]    Loss 3.079115    mAP 0.459365    
2023-04-27 04:44:54,199 - Epoch: [282][  100/  155]    Loss 3.076551    mAP 0.447932    
2023-04-27 04:45:02,041 - Epoch: [282][  150/  155]    Loss 3.083859    mAP 0.438823    
2023-04-27 04:45:02,750 - Epoch: [282][  155/  155]    Loss 3.086026    mAP 0.437888    
2023-04-27 04:45:02,816 - ==> mAP: 0.43789    Loss: 3.086

2023-04-27 04:45:02,819 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:45:02,819 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:45:02,853 - 

2023-04-27 04:45:02,853 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:45:14,516 - Epoch: [283][   50/  518]    Overall Loss 2.912525    Objective Loss 2.912525                                        LR 0.000008    Time 0.233192    
2023-04-27 04:45:25,369 - Epoch: [283][  100/  518]    Overall Loss 2.923019    Objective Loss 2.923019                                        LR 0.000008    Time 0.225117    
2023-04-27 04:45:36,185 - Epoch: [283][  150/  518]    Overall Loss 2.908248    Objective Loss 2.908248                                        LR 0.000008    Time 0.222174    
2023-04-27 04:45:47,008 - Epoch: [283][  200/  518]    Overall Loss 2.921184    Objective Loss 2.921184                                        LR 0.000008    Time 0.220734    
2023-04-27 04:45:57,848 - Epoch: [283][  250/  518]    Overall Loss 2.933621    Objective Loss 2.933621                                        LR 0.000008    Time 0.219943    
2023-04-27 04:46:08,712 - Epoch: [283][  300/  518]    Overall Loss 2.928550    Objective Loss 2.928550                                        LR 0.000008    Time 0.219493    
2023-04-27 04:46:19,599 - Epoch: [283][  350/  518]    Overall Loss 2.929033    Objective Loss 2.929033                                        LR 0.000008    Time 0.219238    
2023-04-27 04:46:30,332 - Epoch: [283][  400/  518]    Overall Loss 2.930128    Objective Loss 2.930128                                        LR 0.000008    Time 0.218663    
2023-04-27 04:46:41,102 - Epoch: [283][  450/  518]    Overall Loss 2.929946    Objective Loss 2.929946                                        LR 0.000008    Time 0.218296    
2023-04-27 04:46:51,852 - Epoch: [283][  500/  518]    Overall Loss 2.925415    Objective Loss 2.925415                                        LR 0.000008    Time 0.217964    
2023-04-27 04:46:55,578 - Epoch: [283][  518/  518]    Overall Loss 2.922500    Objective Loss 2.922500                                        LR 0.000008    Time 0.217582    
2023-04-27 04:46:55,654 - --- validate (epoch=283)-----------
2023-04-27 04:46:55,654 - 4952 samples (32 per mini-batch)
2023-04-27 04:47:03,938 - Epoch: [283][   50/  155]    Loss 3.148921    mAP 0.429614    
2023-04-27 04:47:11,860 - Epoch: [283][  100/  155]    Loss 3.105006    mAP 0.436788    
2023-04-27 04:47:19,775 - Epoch: [283][  150/  155]    Loss 3.093129    mAP 0.437121    
2023-04-27 04:47:20,493 - Epoch: [283][  155/  155]    Loss 3.094233    mAP 0.437217    
2023-04-27 04:47:20,568 - ==> mAP: 0.43722    Loss: 3.094

2023-04-27 04:47:20,571 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:47:20,571 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:47:20,605 - 

2023-04-27 04:47:20,605 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:47:32,180 - Epoch: [284][   50/  518]    Overall Loss 2.936448    Objective Loss 2.936448                                        LR 0.000008    Time 0.231432    
2023-04-27 04:47:42,990 - Epoch: [284][  100/  518]    Overall Loss 2.973280    Objective Loss 2.973280                                        LR 0.000008    Time 0.223799    
2023-04-27 04:47:53,786 - Epoch: [284][  150/  518]    Overall Loss 2.954745    Objective Loss 2.954745                                        LR 0.000008    Time 0.221164    
2023-04-27 04:48:04,611 - Epoch: [284][  200/  518]    Overall Loss 2.951104    Objective Loss 2.951104                                        LR 0.000008    Time 0.219989    
2023-04-27 04:48:15,517 - Epoch: [284][  250/  518]    Overall Loss 2.948218    Objective Loss 2.948218                                        LR 0.000008    Time 0.219610    
2023-04-27 04:48:26,325 - Epoch: [284][  300/  518]    Overall Loss 2.941096    Objective Loss 2.941096                                        LR 0.000008    Time 0.219029    
2023-04-27 04:48:37,108 - Epoch: [284][  350/  518]    Overall Loss 2.946830    Objective Loss 2.946830                                        LR 0.000008    Time 0.218545    
2023-04-27 04:48:47,911 - Epoch: [284][  400/  518]    Overall Loss 2.939171    Objective Loss 2.939171                                        LR 0.000008    Time 0.218229    
2023-04-27 04:48:58,714 - Epoch: [284][  450/  518]    Overall Loss 2.935497    Objective Loss 2.935497                                        LR 0.000008    Time 0.217985    
2023-04-27 04:49:09,467 - Epoch: [284][  500/  518]    Overall Loss 2.933925    Objective Loss 2.933925                                        LR 0.000008    Time 0.217688    
2023-04-27 04:49:13,278 - Epoch: [284][  518/  518]    Overall Loss 2.931564    Objective Loss 2.931564                                        LR 0.000008    Time 0.217481    
2023-04-27 04:49:13,354 - --- validate (epoch=284)-----------
2023-04-27 04:49:13,354 - 4952 samples (32 per mini-batch)
2023-04-27 04:49:21,648 - Epoch: [284][   50/  155]    Loss 3.101132    mAP 0.418248    
2023-04-27 04:49:29,586 - Epoch: [284][  100/  155]    Loss 3.102800    mAP 0.428656    
2023-04-27 04:49:37,475 - Epoch: [284][  150/  155]    Loss 3.094617    mAP 0.440318    
2023-04-27 04:49:38,194 - Epoch: [284][  155/  155]    Loss 3.093642    mAP 0.440682    
2023-04-27 04:49:38,267 - ==> mAP: 0.44068    Loss: 3.094

2023-04-27 04:49:38,271 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:49:38,271 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:49:38,305 - 

2023-04-27 04:49:38,305 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:49:49,916 - Epoch: [285][   50/  518]    Overall Loss 2.917513    Objective Loss 2.917513                                        LR 0.000008    Time 0.232165    
2023-04-27 04:50:00,679 - Epoch: [285][  100/  518]    Overall Loss 2.907937    Objective Loss 2.907937                                        LR 0.000008    Time 0.223702    
2023-04-27 04:50:11,560 - Epoch: [285][  150/  518]    Overall Loss 2.903786    Objective Loss 2.903786                                        LR 0.000008    Time 0.221659    
2023-04-27 04:50:22,427 - Epoch: [285][  200/  518]    Overall Loss 2.908856    Objective Loss 2.908856                                        LR 0.000008    Time 0.220571    
2023-04-27 04:50:33,288 - Epoch: [285][  250/  518]    Overall Loss 2.906793    Objective Loss 2.906793                                        LR 0.000008    Time 0.219895    
2023-04-27 04:50:44,077 - Epoch: [285][  300/  518]    Overall Loss 2.915454    Objective Loss 2.915454                                        LR 0.000008    Time 0.219205    
2023-04-27 04:50:54,905 - Epoch: [285][  350/  518]    Overall Loss 2.914192    Objective Loss 2.914192                                        LR 0.000008    Time 0.218825    
2023-04-27 04:51:05,733 - Epoch: [285][  400/  518]    Overall Loss 2.918480    Objective Loss 2.918480                                        LR 0.000008    Time 0.218535    
2023-04-27 04:51:16,592 - Epoch: [285][  450/  518]    Overall Loss 2.918362    Objective Loss 2.918362                                        LR 0.000008    Time 0.218383    
2023-04-27 04:51:27,448 - Epoch: [285][  500/  518]    Overall Loss 2.918047    Objective Loss 2.918047                                        LR 0.000008    Time 0.218252    
2023-04-27 04:51:31,145 - Epoch: [285][  518/  518]    Overall Loss 2.919790    Objective Loss 2.919790                                        LR 0.000008    Time 0.217805    
2023-04-27 04:51:31,221 - --- validate (epoch=285)-----------
2023-04-27 04:51:31,222 - 4952 samples (32 per mini-batch)
2023-04-27 04:51:39,518 - Epoch: [285][   50/  155]    Loss 3.100294    mAP 0.426286    
2023-04-27 04:51:47,403 - Epoch: [285][  100/  155]    Loss 3.082893    mAP 0.434670    
2023-04-27 04:51:55,262 - Epoch: [285][  150/  155]    Loss 3.091257    mAP 0.434119    
2023-04-27 04:51:55,975 - Epoch: [285][  155/  155]    Loss 3.093361    mAP 0.432579    
2023-04-27 04:51:56,041 - ==> mAP: 0.43258    Loss: 3.093

2023-04-27 04:51:56,045 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:51:56,045 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:51:56,080 - 

2023-04-27 04:51:56,080 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:52:07,746 - Epoch: [286][   50/  518]    Overall Loss 2.966886    Objective Loss 2.966886                                        LR 0.000008    Time 0.233262    
2023-04-27 04:52:18,648 - Epoch: [286][  100/  518]    Overall Loss 2.948885    Objective Loss 2.948885                                        LR 0.000008    Time 0.225633    
2023-04-27 04:52:29,443 - Epoch: [286][  150/  518]    Overall Loss 2.943470    Objective Loss 2.943470                                        LR 0.000008    Time 0.222379    
2023-04-27 04:52:40,169 - Epoch: [286][  200/  518]    Overall Loss 2.953281    Objective Loss 2.953281                                        LR 0.000008    Time 0.220408    
2023-04-27 04:52:50,960 - Epoch: [286][  250/  518]    Overall Loss 2.945837    Objective Loss 2.945837                                        LR 0.000008    Time 0.219484    
2023-04-27 04:53:01,645 - Epoch: [286][  300/  518]    Overall Loss 2.933130    Objective Loss 2.933130                                        LR 0.000008    Time 0.218516    
2023-04-27 04:53:12,474 - Epoch: [286][  350/  518]    Overall Loss 2.935137    Objective Loss 2.935137                                        LR 0.000008    Time 0.218233    
2023-04-27 04:53:23,293 - Epoch: [286][  400/  518]    Overall Loss 2.936116    Objective Loss 2.936116                                        LR 0.000008    Time 0.217997    
2023-04-27 04:53:34,153 - Epoch: [286][  450/  518]    Overall Loss 2.936821    Objective Loss 2.936821                                        LR 0.000008    Time 0.217905    
2023-04-27 04:53:44,961 - Epoch: [286][  500/  518]    Overall Loss 2.935347    Objective Loss 2.935347                                        LR 0.000008    Time 0.217729    
2023-04-27 04:53:48,703 - Epoch: [286][  518/  518]    Overall Loss 2.935225    Objective Loss 2.935225                                        LR 0.000008    Time 0.217385    
2023-04-27 04:53:48,781 - --- validate (epoch=286)-----------
2023-04-27 04:53:48,781 - 4952 samples (32 per mini-batch)
2023-04-27 04:53:57,061 - Epoch: [286][   50/  155]    Loss 3.047871    mAP 0.435610    
2023-04-27 04:54:04,905 - Epoch: [286][  100/  155]    Loss 3.049760    mAP 0.426265    
2023-04-27 04:54:12,767 - Epoch: [286][  150/  155]    Loss 3.068598    mAP 0.424897    
2023-04-27 04:54:13,484 - Epoch: [286][  155/  155]    Loss 3.069925    mAP 0.424460    
2023-04-27 04:54:13,570 - ==> mAP: 0.42446    Loss: 3.070

2023-04-27 04:54:13,574 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:54:13,574 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:54:13,608 - 

2023-04-27 04:54:13,608 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:54:25,330 - Epoch: [287][   50/  518]    Overall Loss 2.891757    Objective Loss 2.891757                                        LR 0.000008    Time 0.234380    
2023-04-27 04:54:36,188 - Epoch: [287][  100/  518]    Overall Loss 2.925907    Objective Loss 2.925907                                        LR 0.000008    Time 0.225753    
2023-04-27 04:54:46,977 - Epoch: [287][  150/  518]    Overall Loss 2.925918    Objective Loss 2.925918                                        LR 0.000008    Time 0.222420    
2023-04-27 04:54:57,784 - Epoch: [287][  200/  518]    Overall Loss 2.927241    Objective Loss 2.927241                                        LR 0.000008    Time 0.220843    
2023-04-27 04:55:08,620 - Epoch: [287][  250/  518]    Overall Loss 2.939288    Objective Loss 2.939288                                        LR 0.000008    Time 0.220012    
2023-04-27 04:55:19,481 - Epoch: [287][  300/  518]    Overall Loss 2.937170    Objective Loss 2.937170                                        LR 0.000008    Time 0.219539    
2023-04-27 04:55:30,281 - Epoch: [287][  350/  518]    Overall Loss 2.935620    Objective Loss 2.935620                                        LR 0.000008    Time 0.219031    
2023-04-27 04:55:40,995 - Epoch: [287][  400/  518]    Overall Loss 2.933362    Objective Loss 2.933362                                        LR 0.000008    Time 0.218432    
2023-04-27 04:55:51,813 - Epoch: [287][  450/  518]    Overall Loss 2.926508    Objective Loss 2.926508                                        LR 0.000008    Time 0.218199    
2023-04-27 04:56:02,661 - Epoch: [287][  500/  518]    Overall Loss 2.929760    Objective Loss 2.929760                                        LR 0.000008    Time 0.218071    
2023-04-27 04:56:06,424 - Epoch: [287][  518/  518]    Overall Loss 2.930230    Objective Loss 2.930230                                        LR 0.000008    Time 0.217756    
2023-04-27 04:56:06,498 - --- validate (epoch=287)-----------
2023-04-27 04:56:06,499 - 4952 samples (32 per mini-batch)
2023-04-27 04:56:14,733 - Epoch: [287][   50/  155]    Loss 3.094244    mAP 0.426316    
2023-04-27 04:56:22,625 - Epoch: [287][  100/  155]    Loss 3.080599    mAP 0.436101    
2023-04-27 04:56:30,494 - Epoch: [287][  150/  155]    Loss 3.091570    mAP 0.438268    
2023-04-27 04:56:31,203 - Epoch: [287][  155/  155]    Loss 3.091305    mAP 0.438559    
2023-04-27 04:56:31,270 - ==> mAP: 0.43856    Loss: 3.091

2023-04-27 04:56:31,274 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:56:31,274 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:56:31,308 - 

2023-04-27 04:56:31,308 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:56:42,849 - Epoch: [288][   50/  518]    Overall Loss 2.936641    Objective Loss 2.936641                                        LR 0.000008    Time 0.230762    
2023-04-27 04:56:53,654 - Epoch: [288][  100/  518]    Overall Loss 2.908985    Objective Loss 2.908985                                        LR 0.000008    Time 0.223412    
2023-04-27 04:57:04,498 - Epoch: [288][  150/  518]    Overall Loss 2.901962    Objective Loss 2.901962                                        LR 0.000008    Time 0.221229    
2023-04-27 04:57:15,253 - Epoch: [288][  200/  518]    Overall Loss 2.896586    Objective Loss 2.896586                                        LR 0.000008    Time 0.219685    
2023-04-27 04:57:26,161 - Epoch: [288][  250/  518]    Overall Loss 2.910661    Objective Loss 2.910661                                        LR 0.000008    Time 0.219377    
2023-04-27 04:57:37,082 - Epoch: [288][  300/  518]    Overall Loss 2.911461    Objective Loss 2.911461                                        LR 0.000008    Time 0.219211    
2023-04-27 04:57:47,905 - Epoch: [288][  350/  518]    Overall Loss 2.916080    Objective Loss 2.916080                                        LR 0.000008    Time 0.218814    
2023-04-27 04:57:58,719 - Epoch: [288][  400/  518]    Overall Loss 2.910488    Objective Loss 2.910488                                        LR 0.000008    Time 0.218492    
2023-04-27 04:58:09,578 - Epoch: [288][  450/  518]    Overall Loss 2.913205    Objective Loss 2.913205                                        LR 0.000008    Time 0.218345    
2023-04-27 04:58:20,414 - Epoch: [288][  500/  518]    Overall Loss 2.921768    Objective Loss 2.921768                                        LR 0.000008    Time 0.218178    
2023-04-27 04:58:24,156 - Epoch: [288][  518/  518]    Overall Loss 2.922844    Objective Loss 2.922844                                        LR 0.000008    Time 0.217820    
2023-04-27 04:58:24,231 - --- validate (epoch=288)-----------
2023-04-27 04:58:24,231 - 4952 samples (32 per mini-batch)
2023-04-27 04:58:32,507 - Epoch: [288][   50/  155]    Loss 3.090659    mAP 0.447918    
2023-04-27 04:58:40,418 - Epoch: [288][  100/  155]    Loss 3.108958    mAP 0.438976    
2023-04-27 04:58:48,326 - Epoch: [288][  150/  155]    Loss 3.078560    mAP 0.442699    
2023-04-27 04:58:49,033 - Epoch: [288][  155/  155]    Loss 3.073228    mAP 0.441630    
2023-04-27 04:58:49,114 - ==> mAP: 0.44163    Loss: 3.073

2023-04-27 04:58:49,118 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 04:58:49,118 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 04:58:49,152 - 

2023-04-27 04:58:49,153 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 04:59:00,706 - Epoch: [289][   50/  518]    Overall Loss 2.914016    Objective Loss 2.914016                                        LR 0.000008    Time 0.231008    
2023-04-27 04:59:11,483 - Epoch: [289][  100/  518]    Overall Loss 2.912539    Objective Loss 2.912539                                        LR 0.000008    Time 0.223257    
2023-04-27 04:59:22,322 - Epoch: [289][  150/  518]    Overall Loss 2.924027    Objective Loss 2.924027                                        LR 0.000008    Time 0.221090    
2023-04-27 04:59:33,153 - Epoch: [289][  200/  518]    Overall Loss 2.927276    Objective Loss 2.927276                                        LR 0.000008    Time 0.219967    
2023-04-27 04:59:43,964 - Epoch: [289][  250/  518]    Overall Loss 2.930019    Objective Loss 2.930019                                        LR 0.000008    Time 0.219210    
2023-04-27 04:59:54,737 - Epoch: [289][  300/  518]    Overall Loss 2.937924    Objective Loss 2.937924                                        LR 0.000008    Time 0.218581    
2023-04-27 05:00:05,513 - Epoch: [289][  350/  518]    Overall Loss 2.937023    Objective Loss 2.937023                                        LR 0.000008    Time 0.218139    
2023-04-27 05:00:16,326 - Epoch: [289][  400/  518]    Overall Loss 2.931278    Objective Loss 2.931278                                        LR 0.000008    Time 0.217900    
2023-04-27 05:00:27,176 - Epoch: [289][  450/  518]    Overall Loss 2.927935    Objective Loss 2.927935                                        LR 0.000008    Time 0.217796    
2023-04-27 05:00:38,028 - Epoch: [289][  500/  518]    Overall Loss 2.925402    Objective Loss 2.925402                                        LR 0.000008    Time 0.217718    
2023-04-27 05:00:41,775 - Epoch: [289][  518/  518]    Overall Loss 2.922943    Objective Loss 2.922943                                        LR 0.000008    Time 0.217384    
2023-04-27 05:00:41,850 - --- validate (epoch=289)-----------
2023-04-27 05:00:41,850 - 4952 samples (32 per mini-batch)
2023-04-27 05:00:50,134 - Epoch: [289][   50/  155]    Loss 3.065512    mAP 0.430465    
2023-04-27 05:00:58,048 - Epoch: [289][  100/  155]    Loss 3.079609    mAP 0.439569    
2023-04-27 05:01:05,937 - Epoch: [289][  150/  155]    Loss 3.072478    mAP 0.431406    
2023-04-27 05:01:06,653 - Epoch: [289][  155/  155]    Loss 3.069013    mAP 0.431815    
2023-04-27 05:01:06,725 - ==> mAP: 0.43182    Loss: 3.069

2023-04-27 05:01:06,729 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 05:01:06,729 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:01:06,763 - 

2023-04-27 05:01:06,763 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:01:18,510 - Epoch: [290][   50/  518]    Overall Loss 2.919580    Objective Loss 2.919580                                        LR 0.000008    Time 0.234893    
2023-04-27 05:01:29,383 - Epoch: [290][  100/  518]    Overall Loss 2.920591    Objective Loss 2.920591                                        LR 0.000008    Time 0.226156    
2023-04-27 05:01:40,124 - Epoch: [290][  150/  518]    Overall Loss 2.913312    Objective Loss 2.913312                                        LR 0.000008    Time 0.222364    
2023-04-27 05:01:50,990 - Epoch: [290][  200/  518]    Overall Loss 2.918421    Objective Loss 2.918421                                        LR 0.000008    Time 0.221100    
2023-04-27 05:02:01,833 - Epoch: [290][  250/  518]    Overall Loss 2.929135    Objective Loss 2.929135                                        LR 0.000008    Time 0.220245    
2023-04-27 05:02:12,769 - Epoch: [290][  300/  518]    Overall Loss 2.928417    Objective Loss 2.928417                                        LR 0.000008    Time 0.219986    
2023-04-27 05:02:23,659 - Epoch: [290][  350/  518]    Overall Loss 2.928940    Objective Loss 2.928940                                        LR 0.000008    Time 0.219669    
2023-04-27 05:02:34,572 - Epoch: [290][  400/  518]    Overall Loss 2.932021    Objective Loss 2.932021                                        LR 0.000008    Time 0.219489    
2023-04-27 05:02:45,407 - Epoch: [290][  450/  518]    Overall Loss 2.927776    Objective Loss 2.927776                                        LR 0.000008    Time 0.219176    
2023-04-27 05:02:56,193 - Epoch: [290][  500/  518]    Overall Loss 2.921373    Objective Loss 2.921373                                        LR 0.000008    Time 0.218827    
2023-04-27 05:02:59,937 - Epoch: [290][  518/  518]    Overall Loss 2.925155    Objective Loss 2.925155                                        LR 0.000008    Time 0.218449    
2023-04-27 05:03:00,013 - --- validate (epoch=290)-----------
2023-04-27 05:03:00,014 - 4952 samples (32 per mini-batch)
2023-04-27 05:03:08,321 - Epoch: [290][   50/  155]    Loss 3.077751    mAP 0.430518    
2023-04-27 05:03:16,271 - Epoch: [290][  100/  155]    Loss 3.071047    mAP 0.441891    
2023-04-27 05:03:24,116 - Epoch: [290][  150/  155]    Loss 3.068410    mAP 0.445280    
2023-04-27 05:03:24,842 - Epoch: [290][  155/  155]    Loss 3.070588    mAP 0.444036    
2023-04-27 05:03:24,908 - ==> mAP: 0.44404    Loss: 3.071

2023-04-27 05:03:24,911 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 05:03:24,911 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:03:24,946 - 

2023-04-27 05:03:24,946 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:03:36,513 - Epoch: [291][   50/  518]    Overall Loss 2.908736    Objective Loss 2.908736                                        LR 0.000008    Time 0.231285    
2023-04-27 05:03:47,354 - Epoch: [291][  100/  518]    Overall Loss 2.928966    Objective Loss 2.928966                                        LR 0.000008    Time 0.224038    
2023-04-27 05:03:58,258 - Epoch: [291][  150/  518]    Overall Loss 2.932445    Objective Loss 2.932445                                        LR 0.000008    Time 0.222042    
2023-04-27 05:04:09,090 - Epoch: [291][  200/  518]    Overall Loss 2.925612    Objective Loss 2.925612                                        LR 0.000008    Time 0.220684    
2023-04-27 05:04:19,952 - Epoch: [291][  250/  518]    Overall Loss 2.917948    Objective Loss 2.917948                                        LR 0.000008    Time 0.219988    
2023-04-27 05:04:30,781 - Epoch: [291][  300/  518]    Overall Loss 2.920167    Objective Loss 2.920167                                        LR 0.000008    Time 0.219415    
2023-04-27 05:04:41,584 - Epoch: [291][  350/  518]    Overall Loss 2.923842    Objective Loss 2.923842                                        LR 0.000008    Time 0.218932    
2023-04-27 05:04:52,383 - Epoch: [291][  400/  518]    Overall Loss 2.921154    Objective Loss 2.921154                                        LR 0.000008    Time 0.218559    
2023-04-27 05:05:03,143 - Epoch: [291][  450/  518]    Overall Loss 2.919595    Objective Loss 2.919595                                        LR 0.000008    Time 0.218181    
2023-04-27 05:05:14,035 - Epoch: [291][  500/  518]    Overall Loss 2.915669    Objective Loss 2.915669                                        LR 0.000008    Time 0.218145    
2023-04-27 05:05:17,843 - Epoch: [291][  518/  518]    Overall Loss 2.917876    Objective Loss 2.917876                                        LR 0.000008    Time 0.217915    
2023-04-27 05:05:17,920 - --- validate (epoch=291)-----------
2023-04-27 05:05:17,920 - 4952 samples (32 per mini-batch)
2023-04-27 05:05:26,175 - Epoch: [291][   50/  155]    Loss 3.061823    mAP 0.443451    
2023-04-27 05:05:34,117 - Epoch: [291][  100/  155]    Loss 3.075443    mAP 0.438833    
2023-04-27 05:05:41,975 - Epoch: [291][  150/  155]    Loss 3.069740    mAP 0.437865    
2023-04-27 05:05:42,689 - Epoch: [291][  155/  155]    Loss 3.070671    mAP 0.438013    
2023-04-27 05:05:42,762 - ==> mAP: 0.43801    Loss: 3.071

2023-04-27 05:05:42,766 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 05:05:42,766 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:05:42,801 - 

2023-04-27 05:05:42,802 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:05:54,403 - Epoch: [292][   50/  518]    Overall Loss 2.919714    Objective Loss 2.919714                                        LR 0.000008    Time 0.231981    
2023-04-27 05:06:05,313 - Epoch: [292][  100/  518]    Overall Loss 2.950927    Objective Loss 2.950927                                        LR 0.000008    Time 0.225072    
2023-04-27 05:06:16,156 - Epoch: [292][  150/  518]    Overall Loss 2.929389    Objective Loss 2.929389                                        LR 0.000008    Time 0.222322    
2023-04-27 05:06:26,871 - Epoch: [292][  200/  518]    Overall Loss 2.920661    Objective Loss 2.920661                                        LR 0.000008    Time 0.220312    
2023-04-27 05:06:37,697 - Epoch: [292][  250/  518]    Overall Loss 2.922494    Objective Loss 2.922494                                        LR 0.000008    Time 0.219545    
2023-04-27 05:06:48,490 - Epoch: [292][  300/  518]    Overall Loss 2.924583    Objective Loss 2.924583                                        LR 0.000008    Time 0.218927    
2023-04-27 05:06:59,372 - Epoch: [292][  350/  518]    Overall Loss 2.923850    Objective Loss 2.923850                                        LR 0.000008    Time 0.218737    
2023-04-27 05:07:10,201 - Epoch: [292][  400/  518]    Overall Loss 2.921860    Objective Loss 2.921860                                        LR 0.000008    Time 0.218466    
2023-04-27 05:07:21,044 - Epoch: [292][  450/  518]    Overall Loss 2.915925    Objective Loss 2.915925                                        LR 0.000008    Time 0.218283    
2023-04-27 05:07:31,878 - Epoch: [292][  500/  518]    Overall Loss 2.918442    Objective Loss 2.918442                                        LR 0.000008    Time 0.218120    
2023-04-27 05:07:35,637 - Epoch: [292][  518/  518]    Overall Loss 2.917647    Objective Loss 2.917647                                        LR 0.000008    Time 0.217795    
2023-04-27 05:07:35,712 - --- validate (epoch=292)-----------
2023-04-27 05:07:35,712 - 4952 samples (32 per mini-batch)
2023-04-27 05:07:44,007 - Epoch: [292][   50/  155]    Loss 3.026883    mAP 0.445070    
2023-04-27 05:07:51,945 - Epoch: [292][  100/  155]    Loss 3.055471    mAP 0.438649    
2023-04-27 05:07:59,871 - Epoch: [292][  150/  155]    Loss 3.063287    mAP 0.444224    
2023-04-27 05:08:00,600 - Epoch: [292][  155/  155]    Loss 3.063216    mAP 0.443696    
2023-04-27 05:08:00,673 - ==> mAP: 0.44370    Loss: 3.063

2023-04-27 05:08:00,676 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 05:08:00,677 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:08:00,711 - 

2023-04-27 05:08:00,711 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:08:12,261 - Epoch: [293][   50/  518]    Overall Loss 2.915838    Objective Loss 2.915838                                        LR 0.000008    Time 0.230941    
2023-04-27 05:08:23,142 - Epoch: [293][  100/  518]    Overall Loss 2.877692    Objective Loss 2.877692                                        LR 0.000008    Time 0.224264    
2023-04-27 05:08:33,962 - Epoch: [293][  150/  518]    Overall Loss 2.891919    Objective Loss 2.891919                                        LR 0.000008    Time 0.221634    
2023-04-27 05:08:44,664 - Epoch: [293][  200/  518]    Overall Loss 2.900026    Objective Loss 2.900026                                        LR 0.000008    Time 0.219730    
2023-04-27 05:08:55,539 - Epoch: [293][  250/  518]    Overall Loss 2.904639    Objective Loss 2.904639                                        LR 0.000008    Time 0.219278    
2023-04-27 05:09:06,368 - Epoch: [293][  300/  518]    Overall Loss 2.911720    Objective Loss 2.911720                                        LR 0.000008    Time 0.218820    
2023-04-27 05:09:17,259 - Epoch: [293][  350/  518]    Overall Loss 2.911722    Objective Loss 2.911722                                        LR 0.000008    Time 0.218675    
2023-04-27 05:09:27,999 - Epoch: [293][  400/  518]    Overall Loss 2.920950    Objective Loss 2.920950                                        LR 0.000008    Time 0.218187    
2023-04-27 05:09:38,856 - Epoch: [293][  450/  518]    Overall Loss 2.921030    Objective Loss 2.921030                                        LR 0.000008    Time 0.218065    
2023-04-27 05:09:49,710 - Epoch: [293][  500/  518]    Overall Loss 2.918610    Objective Loss 2.918610                                        LR 0.000008    Time 0.217965    
2023-04-27 05:09:53,452 - Epoch: [293][  518/  518]    Overall Loss 2.918124    Objective Loss 2.918124                                        LR 0.000008    Time 0.217613    
2023-04-27 05:09:53,529 - --- validate (epoch=293)-----------
2023-04-27 05:09:53,529 - 4952 samples (32 per mini-batch)
2023-04-27 05:10:01,861 - Epoch: [293][   50/  155]    Loss 3.066046    mAP 0.452367    
2023-04-27 05:10:09,773 - Epoch: [293][  100/  155]    Loss 3.091214    mAP 0.439415    
2023-04-27 05:10:17,677 - Epoch: [293][  150/  155]    Loss 3.070189    mAP 0.442671    
2023-04-27 05:10:18,392 - Epoch: [293][  155/  155]    Loss 3.072362    mAP 0.440900    
2023-04-27 05:10:18,469 - ==> mAP: 0.44090    Loss: 3.072

2023-04-27 05:10:18,473 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 05:10:18,474 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:10:18,508 - 

2023-04-27 05:10:18,508 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:10:30,070 - Epoch: [294][   50/  518]    Overall Loss 2.924362    Objective Loss 2.924362                                        LR 0.000008    Time 0.231177    
2023-04-27 05:10:40,889 - Epoch: [294][  100/  518]    Overall Loss 2.921170    Objective Loss 2.921170                                        LR 0.000008    Time 0.223763    
2023-04-27 05:10:51,712 - Epoch: [294][  150/  518]    Overall Loss 2.927209    Objective Loss 2.927209                                        LR 0.000008    Time 0.221321    
2023-04-27 05:11:02,587 - Epoch: [294][  200/  518]    Overall Loss 2.929932    Objective Loss 2.929932                                        LR 0.000008    Time 0.220356    
2023-04-27 05:11:13,427 - Epoch: [294][  250/  518]    Overall Loss 2.938957    Objective Loss 2.938957                                        LR 0.000008    Time 0.219641    
2023-04-27 05:11:24,273 - Epoch: [294][  300/  518]    Overall Loss 2.938496    Objective Loss 2.938496                                        LR 0.000008    Time 0.219181    
2023-04-27 05:11:35,031 - Epoch: [294][  350/  518]    Overall Loss 2.935979    Objective Loss 2.935979                                        LR 0.000008    Time 0.218602    
2023-04-27 05:11:45,859 - Epoch: [294][  400/  518]    Overall Loss 2.941382    Objective Loss 2.941382                                        LR 0.000008    Time 0.218342    
2023-04-27 05:11:56,672 - Epoch: [294][  450/  518]    Overall Loss 2.936699    Objective Loss 2.936699                                        LR 0.000008    Time 0.218108    
2023-04-27 05:12:07,528 - Epoch: [294][  500/  518]    Overall Loss 2.932593    Objective Loss 2.932593                                        LR 0.000008    Time 0.218006    
2023-04-27 05:12:11,244 - Epoch: [294][  518/  518]    Overall Loss 2.931456    Objective Loss 2.931456                                        LR 0.000008    Time 0.217604    
2023-04-27 05:12:11,319 - --- validate (epoch=294)-----------
2023-04-27 05:12:11,320 - 4952 samples (32 per mini-batch)
2023-04-27 05:12:19,590 - Epoch: [294][   50/  155]    Loss 3.123250    mAP 0.443126    
2023-04-27 05:12:27,441 - Epoch: [294][  100/  155]    Loss 3.093875    mAP 0.440656    
2023-04-27 05:12:35,307 - Epoch: [294][  150/  155]    Loss 3.073903    mAP 0.442217    
2023-04-27 05:12:36,034 - Epoch: [294][  155/  155]    Loss 3.075480    mAP 0.440835    
2023-04-27 05:12:36,107 - ==> mAP: 0.44084    Loss: 3.075

2023-04-27 05:12:36,110 - ==> Best [mAP: 0.446835   vloss: 3.081809   Sparsity:0.00   Params: 2177087 on epoch: 270]
2023-04-27 05:12:36,111 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:12:36,145 - 

2023-04-27 05:12:36,145 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:12:47,661 - Epoch: [295][   50/  518]    Overall Loss 2.909150    Objective Loss 2.909150                                        LR 0.000008    Time 0.230276    
2023-04-27 05:12:58,469 - Epoch: [295][  100/  518]    Overall Loss 2.893798    Objective Loss 2.893798                                        LR 0.000008    Time 0.223201    
2023-04-27 05:13:09,293 - Epoch: [295][  150/  518]    Overall Loss 2.905301    Objective Loss 2.905301                                        LR 0.000008    Time 0.220944    
2023-04-27 05:13:20,078 - Epoch: [295][  200/  518]    Overall Loss 2.901378    Objective Loss 2.901378                                        LR 0.000008    Time 0.219630    
2023-04-27 05:13:30,860 - Epoch: [295][  250/  518]    Overall Loss 2.907015    Objective Loss 2.907015                                        LR 0.000008    Time 0.218825    
2023-04-27 05:13:41,679 - Epoch: [295][  300/  518]    Overall Loss 2.906953    Objective Loss 2.906953                                        LR 0.000008    Time 0.218413    
2023-04-27 05:13:52,465 - Epoch: [295][  350/  518]    Overall Loss 2.911744    Objective Loss 2.911744                                        LR 0.000008    Time 0.218023    
2023-04-27 05:14:03,296 - Epoch: [295][  400/  518]    Overall Loss 2.912571    Objective Loss 2.912571                                        LR 0.000008    Time 0.217843    
2023-04-27 05:14:14,080 - Epoch: [295][  450/  518]    Overall Loss 2.910491    Objective Loss 2.910491                                        LR 0.000008    Time 0.217599    
2023-04-27 05:14:24,883 - Epoch: [295][  500/  518]    Overall Loss 2.910395    Objective Loss 2.910395                                        LR 0.000008    Time 0.217442    
2023-04-27 05:14:28,583 - Epoch: [295][  518/  518]    Overall Loss 2.913088    Objective Loss 2.913088                                        LR 0.000008    Time 0.217028    
2023-04-27 05:14:28,658 - --- validate (epoch=295)-----------
2023-04-27 05:14:28,659 - 4952 samples (32 per mini-batch)
2023-04-27 05:14:36,938 - Epoch: [295][   50/  155]    Loss 3.052971    mAP 0.465437    
2023-04-27 05:14:44,849 - Epoch: [295][  100/  155]    Loss 3.062688    mAP 0.442845    
2023-04-27 05:14:52,792 - Epoch: [295][  150/  155]    Loss 3.055143    mAP 0.448548    
2023-04-27 05:14:53,509 - Epoch: [295][  155/  155]    Loss 3.058122    mAP 0.447032    
2023-04-27 05:14:53,578 - ==> mAP: 0.44703    Loss: 3.058

2023-04-27 05:14:53,581 - ==> Best [mAP: 0.447032   vloss: 3.058122   Sparsity:0.00   Params: 2177087 on epoch: 295]
2023-04-27 05:14:53,582 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:14:53,631 - 

2023-04-27 05:14:53,631 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:15:05,264 - Epoch: [296][   50/  518]    Overall Loss 2.911000    Objective Loss 2.911000                                        LR 0.000008    Time 0.232604    
2023-04-27 05:15:16,008 - Epoch: [296][  100/  518]    Overall Loss 2.912129    Objective Loss 2.912129                                        LR 0.000008    Time 0.223720    
2023-04-27 05:15:26,854 - Epoch: [296][  150/  518]    Overall Loss 2.913533    Objective Loss 2.913533                                        LR 0.000008    Time 0.221448    
2023-04-27 05:15:37,769 - Epoch: [296][  200/  518]    Overall Loss 2.912528    Objective Loss 2.912528                                        LR 0.000008    Time 0.220651    
2023-04-27 05:15:48,605 - Epoch: [296][  250/  518]    Overall Loss 2.922077    Objective Loss 2.922077                                        LR 0.000008    Time 0.219857    
2023-04-27 05:15:59,476 - Epoch: [296][  300/  518]    Overall Loss 2.924272    Objective Loss 2.924272                                        LR 0.000008    Time 0.219446    
2023-04-27 05:16:10,320 - Epoch: [296][  350/  518]    Overall Loss 2.916394    Objective Loss 2.916394                                        LR 0.000008    Time 0.219075    
2023-04-27 05:16:21,149 - Epoch: [296][  400/  518]    Overall Loss 2.917968    Objective Loss 2.917968                                        LR 0.000008    Time 0.218760    
2023-04-27 05:16:31,981 - Epoch: [296][  450/  518]    Overall Loss 2.916689    Objective Loss 2.916689                                        LR 0.000008    Time 0.218520    
2023-04-27 05:16:42,757 - Epoch: [296][  500/  518]    Overall Loss 2.918798    Objective Loss 2.918798                                        LR 0.000008    Time 0.218217    
2023-04-27 05:16:46,514 - Epoch: [296][  518/  518]    Overall Loss 2.920246    Objective Loss 2.920246                                        LR 0.000008    Time 0.217887    
2023-04-27 05:16:46,589 - --- validate (epoch=296)-----------
2023-04-27 05:16:46,589 - 4952 samples (32 per mini-batch)
2023-04-27 05:16:54,882 - Epoch: [296][   50/  155]    Loss 3.028394    mAP 0.462881    
2023-04-27 05:17:02,800 - Epoch: [296][  100/  155]    Loss 3.036356    mAP 0.449288    
2023-04-27 05:17:10,667 - Epoch: [296][  150/  155]    Loss 3.055166    mAP 0.443091    
2023-04-27 05:17:11,391 - Epoch: [296][  155/  155]    Loss 3.057581    mAP 0.443178    
2023-04-27 05:17:11,462 - ==> mAP: 0.44318    Loss: 3.058

2023-04-27 05:17:11,466 - ==> Best [mAP: 0.447032   vloss: 3.058122   Sparsity:0.00   Params: 2177087 on epoch: 295]
2023-04-27 05:17:11,466 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:17:11,500 - 

2023-04-27 05:17:11,500 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:17:23,145 - Epoch: [297][   50/  518]    Overall Loss 2.885653    Objective Loss 2.885653                                        LR 0.000008    Time 0.232835    
2023-04-27 05:17:33,863 - Epoch: [297][  100/  518]    Overall Loss 2.904046    Objective Loss 2.904046                                        LR 0.000008    Time 0.223587    
2023-04-27 05:17:44,665 - Epoch: [297][  150/  518]    Overall Loss 2.912024    Objective Loss 2.912024                                        LR 0.000008    Time 0.221060    
2023-04-27 05:17:55,549 - Epoch: [297][  200/  518]    Overall Loss 2.912725    Objective Loss 2.912725                                        LR 0.000008    Time 0.220208    
2023-04-27 05:18:06,320 - Epoch: [297][  250/  518]    Overall Loss 2.913028    Objective Loss 2.913028                                        LR 0.000008    Time 0.219245    
2023-04-27 05:18:17,119 - Epoch: [297][  300/  518]    Overall Loss 2.917759    Objective Loss 2.917759                                        LR 0.000008    Time 0.218694    
2023-04-27 05:18:27,999 - Epoch: [297][  350/  518]    Overall Loss 2.907387    Objective Loss 2.907387                                        LR 0.000008    Time 0.218535    
2023-04-27 05:18:38,864 - Epoch: [297][  400/  518]    Overall Loss 2.906146    Objective Loss 2.906146                                        LR 0.000008    Time 0.218376    
2023-04-27 05:18:49,603 - Epoch: [297][  450/  518]    Overall Loss 2.908022    Objective Loss 2.908022                                        LR 0.000008    Time 0.217972    
2023-04-27 05:19:00,409 - Epoch: [297][  500/  518]    Overall Loss 2.909624    Objective Loss 2.909624                                        LR 0.000008    Time 0.217784    
2023-04-27 05:19:04,134 - Epoch: [297][  518/  518]    Overall Loss 2.910147    Objective Loss 2.910147                                        LR 0.000008    Time 0.217406    
2023-04-27 05:19:04,212 - --- validate (epoch=297)-----------
2023-04-27 05:19:04,212 - 4952 samples (32 per mini-batch)
2023-04-27 05:19:12,548 - Epoch: [297][   50/  155]    Loss 3.104408    mAP 0.433900    
2023-04-27 05:19:20,498 - Epoch: [297][  100/  155]    Loss 3.092896    mAP 0.442911    
2023-04-27 05:19:28,455 - Epoch: [297][  150/  155]    Loss 3.070721    mAP 0.453656    
2023-04-27 05:19:29,171 - Epoch: [297][  155/  155]    Loss 3.073783    mAP 0.451723    
2023-04-27 05:19:29,247 - ==> mAP: 0.45172    Loss: 3.074

2023-04-27 05:19:29,251 - ==> Best [mAP: 0.451723   vloss: 3.073783   Sparsity:0.00   Params: 2177087 on epoch: 297]
2023-04-27 05:19:29,251 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:19:29,300 - 

2023-04-27 05:19:29,300 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:19:40,861 - Epoch: [298][   50/  518]    Overall Loss 2.877476    Objective Loss 2.877476                                        LR 0.000008    Time 0.231174    
2023-04-27 05:19:51,667 - Epoch: [298][  100/  518]    Overall Loss 2.892009    Objective Loss 2.892009                                        LR 0.000008    Time 0.223627    
2023-04-27 05:20:02,353 - Epoch: [298][  150/  518]    Overall Loss 2.878752    Objective Loss 2.878752                                        LR 0.000008    Time 0.220318    
2023-04-27 05:20:13,172 - Epoch: [298][  200/  518]    Overall Loss 2.893607    Objective Loss 2.893607                                        LR 0.000008    Time 0.219323    
2023-04-27 05:20:23,933 - Epoch: [298][  250/  518]    Overall Loss 2.904146    Objective Loss 2.904146                                        LR 0.000008    Time 0.218495    
2023-04-27 05:20:34,707 - Epoch: [298][  300/  518]    Overall Loss 2.906283    Objective Loss 2.906283                                        LR 0.000008    Time 0.217989    
2023-04-27 05:20:45,512 - Epoch: [298][  350/  518]    Overall Loss 2.901674    Objective Loss 2.901674                                        LR 0.000008    Time 0.217713    
2023-04-27 05:20:56,283 - Epoch: [298][  400/  518]    Overall Loss 2.905595    Objective Loss 2.905595                                        LR 0.000008    Time 0.217423    
2023-04-27 05:21:07,115 - Epoch: [298][  450/  518]    Overall Loss 2.908722    Objective Loss 2.908722                                        LR 0.000008    Time 0.217333    
2023-04-27 05:21:17,998 - Epoch: [298][  500/  518]    Overall Loss 2.909473    Objective Loss 2.909473                                        LR 0.000008    Time 0.217362    
2023-04-27 05:21:21,692 - Epoch: [298][  518/  518]    Overall Loss 2.910258    Objective Loss 2.910258                                        LR 0.000008    Time 0.216941    
2023-04-27 05:21:21,767 - --- validate (epoch=298)-----------
2023-04-27 05:21:21,768 - 4952 samples (32 per mini-batch)
2023-04-27 05:21:30,044 - Epoch: [298][   50/  155]    Loss 3.078304    mAP 0.445496    
2023-04-27 05:21:37,950 - Epoch: [298][  100/  155]    Loss 3.068417    mAP 0.445819    
2023-04-27 05:21:45,843 - Epoch: [298][  150/  155]    Loss 3.051445    mAP 0.448288    
2023-04-27 05:21:46,568 - Epoch: [298][  155/  155]    Loss 3.058153    mAP 0.447612    
2023-04-27 05:21:46,648 - ==> mAP: 0.44761    Loss: 3.058

2023-04-27 05:21:46,652 - ==> Best [mAP: 0.451723   vloss: 3.073783   Sparsity:0.00   Params: 2177087 on epoch: 297]
2023-04-27 05:21:46,652 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:21:46,686 - 

2023-04-27 05:21:46,686 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:21:58,227 - Epoch: [299][   50/  518]    Overall Loss 2.936718    Objective Loss 2.936718                                        LR 0.000008    Time 0.230767    
2023-04-27 05:22:09,043 - Epoch: [299][  100/  518]    Overall Loss 2.937289    Objective Loss 2.937289                                        LR 0.000008    Time 0.223527    
2023-04-27 05:22:19,922 - Epoch: [299][  150/  518]    Overall Loss 2.939359    Objective Loss 2.939359                                        LR 0.000008    Time 0.221536    
2023-04-27 05:22:30,851 - Epoch: [299][  200/  518]    Overall Loss 2.942282    Objective Loss 2.942282                                        LR 0.000008    Time 0.220787    
2023-04-27 05:22:41,619 - Epoch: [299][  250/  518]    Overall Loss 2.936919    Objective Loss 2.936919                                        LR 0.000008    Time 0.219694    
2023-04-27 05:22:52,478 - Epoch: [299][  300/  518]    Overall Loss 2.925446    Objective Loss 2.925446                                        LR 0.000008    Time 0.219272    
2023-04-27 05:23:03,270 - Epoch: [299][  350/  518]    Overall Loss 2.920917    Objective Loss 2.920917                                        LR 0.000008    Time 0.218776    
2023-04-27 05:23:14,106 - Epoch: [299][  400/  518]    Overall Loss 2.916930    Objective Loss 2.916930                                        LR 0.000008    Time 0.218516    
2023-04-27 05:23:24,899 - Epoch: [299][  450/  518]    Overall Loss 2.923722    Objective Loss 2.923722                                        LR 0.000008    Time 0.218217    
2023-04-27 05:23:35,765 - Epoch: [299][  500/  518]    Overall Loss 2.920645    Objective Loss 2.920645                                        LR 0.000008    Time 0.218125    
2023-04-27 05:23:39,539 - Epoch: [299][  518/  518]    Overall Loss 2.921241    Objective Loss 2.921241                                        LR 0.000008    Time 0.217830    
2023-04-27 05:23:39,613 - --- validate (epoch=299)-----------
2023-04-27 05:23:39,613 - 4952 samples (32 per mini-batch)
2023-04-27 05:23:47,867 - Epoch: [299][   50/  155]    Loss 3.016052    mAP 0.438493    
2023-04-27 05:23:55,759 - Epoch: [299][  100/  155]    Loss 3.050409    mAP 0.435008    
2023-04-27 05:24:03,640 - Epoch: [299][  150/  155]    Loss 3.064417    mAP 0.436216    
2023-04-27 05:24:04,354 - Epoch: [299][  155/  155]    Loss 3.066608    mAP 0.437309    
2023-04-27 05:24:04,427 - ==> mAP: 0.43731    Loss: 3.067

2023-04-27 05:24:04,431 - ==> Best [mAP: 0.451723   vloss: 3.073783   Sparsity:0.00   Params: 2177087 on epoch: 297]
2023-04-27 05:24:04,431 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:24:04,466 - 

2023-04-27 05:24:04,466 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:24:16,034 - Epoch: [300][   50/  518]    Overall Loss 2.896384    Objective Loss 2.896384                                        LR 0.000008    Time 0.231303    
2023-04-27 05:24:26,807 - Epoch: [300][  100/  518]    Overall Loss 2.883464    Objective Loss 2.883464                                        LR 0.000008    Time 0.223366    
2023-04-27 05:24:37,737 - Epoch: [300][  150/  518]    Overall Loss 2.877581    Objective Loss 2.877581                                        LR 0.000008    Time 0.221768    
2023-04-27 05:24:48,593 - Epoch: [300][  200/  518]    Overall Loss 2.890315    Objective Loss 2.890315                                        LR 0.000008    Time 0.220598    
2023-04-27 05:24:59,403 - Epoch: [300][  250/  518]    Overall Loss 2.890854    Objective Loss 2.890854                                        LR 0.000008    Time 0.219709    
2023-04-27 05:25:10,196 - Epoch: [300][  300/  518]    Overall Loss 2.890381    Objective Loss 2.890381                                        LR 0.000008    Time 0.219066    
2023-04-27 05:25:21,024 - Epoch: [300][  350/  518]    Overall Loss 2.891592    Objective Loss 2.891592                                        LR 0.000008    Time 0.218701    
2023-04-27 05:25:31,776 - Epoch: [300][  400/  518]    Overall Loss 2.902399    Objective Loss 2.902399                                        LR 0.000008    Time 0.218239    
2023-04-27 05:25:42,564 - Epoch: [300][  450/  518]    Overall Loss 2.907935    Objective Loss 2.907935                                        LR 0.000008    Time 0.217960    
2023-04-27 05:25:53,439 - Epoch: [300][  500/  518]    Overall Loss 2.913492    Objective Loss 2.913492                                        LR 0.000008    Time 0.217911    
2023-04-27 05:25:57,240 - Epoch: [300][  518/  518]    Overall Loss 2.916183    Objective Loss 2.916183                                        LR 0.000008    Time 0.217676    
2023-04-27 05:25:57,318 - --- validate (epoch=300)-----------
2023-04-27 05:25:57,319 - 4952 samples (32 per mini-batch)
2023-04-27 05:26:05,644 - Epoch: [300][   50/  155]    Loss 3.062009    mAP 0.442371    
2023-04-27 05:26:13,541 - Epoch: [300][  100/  155]    Loss 3.071778    mAP 0.438962    
2023-04-27 05:26:21,441 - Epoch: [300][  150/  155]    Loss 3.084255    mAP 0.441421    
2023-04-27 05:26:22,167 - Epoch: [300][  155/  155]    Loss 3.079451    mAP 0.443098    
2023-04-27 05:26:22,243 - ==> mAP: 0.44310    Loss: 3.079

2023-04-27 05:26:22,247 - ==> Best [mAP: 0.451723   vloss: 3.073783   Sparsity:0.00   Params: 2177087 on epoch: 297]
2023-04-27 05:26:22,247 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:26:22,281 - 

2023-04-27 05:26:22,281 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:26:33,780 - Epoch: [301][   50/  518]    Overall Loss 2.922221    Objective Loss 2.922221                                        LR 0.000008    Time 0.229929    
2023-04-27 05:26:44,566 - Epoch: [301][  100/  518]    Overall Loss 2.892802    Objective Loss 2.892802                                        LR 0.000008    Time 0.222810    
2023-04-27 05:26:55,398 - Epoch: [301][  150/  518]    Overall Loss 2.899877    Objective Loss 2.899877                                        LR 0.000008    Time 0.220740    
2023-04-27 05:27:06,363 - Epoch: [301][  200/  518]    Overall Loss 2.907066    Objective Loss 2.907066                                        LR 0.000008    Time 0.220375    
2023-04-27 05:27:17,115 - Epoch: [301][  250/  518]    Overall Loss 2.905802    Objective Loss 2.905802                                        LR 0.000008    Time 0.219302    
2023-04-27 05:27:27,922 - Epoch: [301][  300/  518]    Overall Loss 2.905023    Objective Loss 2.905023                                        LR 0.000008    Time 0.218768    
2023-04-27 05:27:38,655 - Epoch: [301][  350/  518]    Overall Loss 2.898447    Objective Loss 2.898447                                        LR 0.000008    Time 0.218177    
2023-04-27 05:27:49,507 - Epoch: [301][  400/  518]    Overall Loss 2.895623    Objective Loss 2.895623                                        LR 0.000008    Time 0.218030    
2023-04-27 05:28:00,302 - Epoch: [301][  450/  518]    Overall Loss 2.896194    Objective Loss 2.896194                                        LR 0.000008    Time 0.217790    
2023-04-27 05:28:11,130 - Epoch: [301][  500/  518]    Overall Loss 2.894379    Objective Loss 2.894379                                        LR 0.000008    Time 0.217664    
2023-04-27 05:28:14,892 - Epoch: [301][  518/  518]    Overall Loss 2.894908    Objective Loss 2.894908                                        LR 0.000008    Time 0.217362    
2023-04-27 05:28:14,969 - --- validate (epoch=301)-----------
2023-04-27 05:28:14,969 - 4952 samples (32 per mini-batch)
2023-04-27 05:28:23,272 - Epoch: [301][   50/  155]    Loss 3.057773    mAP 0.427640    
2023-04-27 05:28:31,217 - Epoch: [301][  100/  155]    Loss 3.064718    mAP 0.430749    
2023-04-27 05:28:39,176 - Epoch: [301][  150/  155]    Loss 3.065453    mAP 0.434767    
2023-04-27 05:28:39,899 - Epoch: [301][  155/  155]    Loss 3.071042    mAP 0.434975    
2023-04-27 05:28:39,963 - ==> mAP: 0.43497    Loss: 3.071

2023-04-27 05:28:39,967 - ==> Best [mAP: 0.451723   vloss: 3.073783   Sparsity:0.00   Params: 2177087 on epoch: 297]
2023-04-27 05:28:39,967 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:28:40,000 - 

2023-04-27 05:28:40,000 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:28:51,690 - Epoch: [302][   50/  518]    Overall Loss 2.931648    Objective Loss 2.931648                                        LR 0.000008    Time 0.233739    
2023-04-27 05:29:02,523 - Epoch: [302][  100/  518]    Overall Loss 2.939891    Objective Loss 2.939891                                        LR 0.000008    Time 0.225182    
2023-04-27 05:29:13,305 - Epoch: [302][  150/  518]    Overall Loss 2.922225    Objective Loss 2.922225                                        LR 0.000008    Time 0.221988    
2023-04-27 05:29:24,177 - Epoch: [302][  200/  518]    Overall Loss 2.920268    Objective Loss 2.920268                                        LR 0.000008    Time 0.220843    
2023-04-27 05:29:35,096 - Epoch: [302][  250/  518]    Overall Loss 2.906661    Objective Loss 2.906661                                        LR 0.000008    Time 0.220345    
2023-04-27 05:29:45,844 - Epoch: [302][  300/  518]    Overall Loss 2.908289    Objective Loss 2.908289                                        LR 0.000008    Time 0.219444    
2023-04-27 05:29:56,582 - Epoch: [302][  350/  518]    Overall Loss 2.909442    Objective Loss 2.909442                                        LR 0.000008    Time 0.218769    
2023-04-27 05:30:07,403 - Epoch: [302][  400/  518]    Overall Loss 2.910627    Objective Loss 2.910627                                        LR 0.000008    Time 0.218473    
2023-04-27 05:30:18,254 - Epoch: [302][  450/  518]    Overall Loss 2.908017    Objective Loss 2.908017                                        LR 0.000008    Time 0.218308    
2023-04-27 05:30:29,081 - Epoch: [302][  500/  518]    Overall Loss 2.909381    Objective Loss 2.909381                                        LR 0.000008    Time 0.218126    
2023-04-27 05:30:32,824 - Epoch: [302][  518/  518]    Overall Loss 2.907117    Objective Loss 2.907117                                        LR 0.000008    Time 0.217773    
2023-04-27 05:30:32,901 - --- validate (epoch=302)-----------
2023-04-27 05:30:32,901 - 4952 samples (32 per mini-batch)
2023-04-27 05:30:41,189 - Epoch: [302][   50/  155]    Loss 3.067212    mAP 0.446631    
2023-04-27 05:30:49,106 - Epoch: [302][  100/  155]    Loss 3.048969    mAP 0.446873    
2023-04-27 05:30:57,004 - Epoch: [302][  150/  155]    Loss 3.045356    mAP 0.452013    
2023-04-27 05:30:57,727 - Epoch: [302][  155/  155]    Loss 3.047499    mAP 0.452178    
2023-04-27 05:30:57,806 - ==> mAP: 0.45218    Loss: 3.047

2023-04-27 05:30:57,810 - ==> Best [mAP: 0.452178   vloss: 3.047499   Sparsity:0.00   Params: 2177087 on epoch: 302]
2023-04-27 05:30:57,810 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:30:57,891 - 

2023-04-27 05:30:57,891 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:31:09,506 - Epoch: [303][   50/  518]    Overall Loss 2.907420    Objective Loss 2.907420                                        LR 0.000008    Time 0.232246    
2023-04-27 05:31:20,289 - Epoch: [303][  100/  518]    Overall Loss 2.923934    Objective Loss 2.923934                                        LR 0.000008    Time 0.223935    
2023-04-27 05:31:31,040 - Epoch: [303][  150/  518]    Overall Loss 2.905343    Objective Loss 2.905343                                        LR 0.000008    Time 0.220955    
2023-04-27 05:31:41,856 - Epoch: [303][  200/  518]    Overall Loss 2.894368    Objective Loss 2.894368                                        LR 0.000008    Time 0.219789    
2023-04-27 05:31:52,601 - Epoch: [303][  250/  518]    Overall Loss 2.900185    Objective Loss 2.900185                                        LR 0.000008    Time 0.218807    
2023-04-27 05:32:03,373 - Epoch: [303][  300/  518]    Overall Loss 2.909748    Objective Loss 2.909748                                        LR 0.000008    Time 0.218239    
2023-04-27 05:32:14,168 - Epoch: [303][  350/  518]    Overall Loss 2.911017    Objective Loss 2.911017                                        LR 0.000008    Time 0.217901    
2023-04-27 05:32:24,968 - Epoch: [303][  400/  518]    Overall Loss 2.914704    Objective Loss 2.914704                                        LR 0.000008    Time 0.217660    
2023-04-27 05:32:35,782 - Epoch: [303][  450/  518]    Overall Loss 2.911229    Objective Loss 2.911229                                        LR 0.000008    Time 0.217502    
2023-04-27 05:32:46,611 - Epoch: [303][  500/  518]    Overall Loss 2.914993    Objective Loss 2.914993                                        LR 0.000008    Time 0.217406    
2023-04-27 05:32:50,390 - Epoch: [303][  518/  518]    Overall Loss 2.915034    Objective Loss 2.915034                                        LR 0.000008    Time 0.217146    
2023-04-27 05:32:50,465 - --- validate (epoch=303)-----------
2023-04-27 05:32:50,465 - 4952 samples (32 per mini-batch)
2023-04-27 05:32:58,752 - Epoch: [303][   50/  155]    Loss 3.083050    mAP 0.445000    
2023-04-27 05:33:06,647 - Epoch: [303][  100/  155]    Loss 3.071810    mAP 0.440054    
2023-04-27 05:33:14,529 - Epoch: [303][  150/  155]    Loss 3.061679    mAP 0.445450    
2023-04-27 05:33:15,251 - Epoch: [303][  155/  155]    Loss 3.059380    mAP 0.447288    
2023-04-27 05:33:15,325 - ==> mAP: 0.44729    Loss: 3.059

2023-04-27 05:33:15,329 - ==> Best [mAP: 0.452178   vloss: 3.047499   Sparsity:0.00   Params: 2177087 on epoch: 302]
2023-04-27 05:33:15,330 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:33:15,365 - 

2023-04-27 05:33:15,365 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:33:27,040 - Epoch: [304][   50/  518]    Overall Loss 2.879444    Objective Loss 2.879444                                        LR 0.000008    Time 0.233453    
2023-04-27 05:33:37,873 - Epoch: [304][  100/  518]    Overall Loss 2.887042    Objective Loss 2.887042                                        LR 0.000008    Time 0.225043    
2023-04-27 05:33:48,725 - Epoch: [304][  150/  518]    Overall Loss 2.879815    Objective Loss 2.879815                                        LR 0.000008    Time 0.222360    
2023-04-27 05:33:59,545 - Epoch: [304][  200/  518]    Overall Loss 2.874711    Objective Loss 2.874711                                        LR 0.000008    Time 0.220863    
2023-04-27 05:34:10,268 - Epoch: [304][  250/  518]    Overall Loss 2.887234    Objective Loss 2.887234                                        LR 0.000008    Time 0.219578    
2023-04-27 05:34:21,109 - Epoch: [304][  300/  518]    Overall Loss 2.885824    Objective Loss 2.885824                                        LR 0.000008    Time 0.219113    
2023-04-27 05:34:31,953 - Epoch: [304][  350/  518]    Overall Loss 2.887334    Objective Loss 2.887334                                        LR 0.000008    Time 0.218787    
2023-04-27 05:34:42,775 - Epoch: [304][  400/  518]    Overall Loss 2.889546    Objective Loss 2.889546                                        LR 0.000008    Time 0.218490    
2023-04-27 05:34:53,682 - Epoch: [304][  450/  518]    Overall Loss 2.895151    Objective Loss 2.895151                                        LR 0.000008    Time 0.218449    
2023-04-27 05:35:04,437 - Epoch: [304][  500/  518]    Overall Loss 2.902143    Objective Loss 2.902143                                        LR 0.000008    Time 0.218112    
2023-04-27 05:35:08,162 - Epoch: [304][  518/  518]    Overall Loss 2.900563    Objective Loss 2.900563                                        LR 0.000008    Time 0.217721    
2023-04-27 05:35:08,238 - --- validate (epoch=304)-----------
2023-04-27 05:35:08,238 - 4952 samples (32 per mini-batch)
2023-04-27 05:35:16,559 - Epoch: [304][   50/  155]    Loss 3.106924    mAP 0.421302    
2023-04-27 05:35:24,481 - Epoch: [304][  100/  155]    Loss 3.066500    mAP 0.444959    
2023-04-27 05:35:32,366 - Epoch: [304][  150/  155]    Loss 3.070094    mAP 0.445770    
2023-04-27 05:35:33,091 - Epoch: [304][  155/  155]    Loss 3.075796    mAP 0.444039    
2023-04-27 05:35:33,164 - ==> mAP: 0.44404    Loss: 3.076

2023-04-27 05:35:33,168 - ==> Best [mAP: 0.452178   vloss: 3.047499   Sparsity:0.00   Params: 2177087 on epoch: 302]
2023-04-27 05:35:33,168 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:35:33,203 - 

2023-04-27 05:35:33,203 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:35:44,840 - Epoch: [305][   50/  518]    Overall Loss 2.850876    Objective Loss 2.850876                                        LR 0.000008    Time 0.232698    
2023-04-27 05:35:55,643 - Epoch: [305][  100/  518]    Overall Loss 2.880279    Objective Loss 2.880279                                        LR 0.000008    Time 0.224355    
2023-04-27 05:36:06,482 - Epoch: [305][  150/  518]    Overall Loss 2.896883    Objective Loss 2.896883                                        LR 0.000008    Time 0.221825    
2023-04-27 05:36:17,285 - Epoch: [305][  200/  518]    Overall Loss 2.905490    Objective Loss 2.905490                                        LR 0.000008    Time 0.220376    
2023-04-27 05:36:28,120 - Epoch: [305][  250/  518]    Overall Loss 2.911508    Objective Loss 2.911508                                        LR 0.000008    Time 0.219631    
2023-04-27 05:36:39,015 - Epoch: [305][  300/  518]    Overall Loss 2.912235    Objective Loss 2.912235                                        LR 0.000008    Time 0.219338    
2023-04-27 05:36:49,866 - Epoch: [305][  350/  518]    Overall Loss 2.912565    Objective Loss 2.912565                                        LR 0.000008    Time 0.219004    
2023-04-27 05:37:00,696 - Epoch: [305][  400/  518]    Overall Loss 2.905274    Objective Loss 2.905274                                        LR 0.000008    Time 0.218700    
2023-04-27 05:37:11,515 - Epoch: [305][  450/  518]    Overall Loss 2.902083    Objective Loss 2.902083                                        LR 0.000008    Time 0.218438    
2023-04-27 05:37:22,363 - Epoch: [305][  500/  518]    Overall Loss 2.907966    Objective Loss 2.907966                                        LR 0.000008    Time 0.218287    
2023-04-27 05:37:26,131 - Epoch: [305][  518/  518]    Overall Loss 2.910261    Objective Loss 2.910261                                        LR 0.000008    Time 0.217975    
2023-04-27 05:37:26,208 - --- validate (epoch=305)-----------
2023-04-27 05:37:26,209 - 4952 samples (32 per mini-batch)
2023-04-27 05:37:34,491 - Epoch: [305][   50/  155]    Loss 3.096755    mAP 0.438945    
2023-04-27 05:37:42,465 - Epoch: [305][  100/  155]    Loss 3.075440    mAP 0.447436    
2023-04-27 05:37:50,338 - Epoch: [305][  150/  155]    Loss 3.071261    mAP 0.444458    
2023-04-27 05:37:51,058 - Epoch: [305][  155/  155]    Loss 3.073961    mAP 0.443614    
2023-04-27 05:37:51,126 - ==> mAP: 0.44361    Loss: 3.074

2023-04-27 05:37:51,130 - ==> Best [mAP: 0.452178   vloss: 3.047499   Sparsity:0.00   Params: 2177087 on epoch: 302]
2023-04-27 05:37:51,130 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:37:51,164 - 

2023-04-27 05:37:51,164 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:38:02,769 - Epoch: [306][   50/  518]    Overall Loss 2.907435    Objective Loss 2.907435                                        LR 0.000008    Time 0.232047    
2023-04-27 05:38:13,480 - Epoch: [306][  100/  518]    Overall Loss 2.904561    Objective Loss 2.904561                                        LR 0.000008    Time 0.223114    
2023-04-27 05:38:24,316 - Epoch: [306][  150/  518]    Overall Loss 2.913193    Objective Loss 2.913193                                        LR 0.000008    Time 0.220976    
2023-04-27 05:38:35,140 - Epoch: [306][  200/  518]    Overall Loss 2.918202    Objective Loss 2.918202                                        LR 0.000008    Time 0.219841    
2023-04-27 05:38:45,896 - Epoch: [306][  250/  518]    Overall Loss 2.920171    Objective Loss 2.920171                                        LR 0.000008    Time 0.218892    
2023-04-27 05:38:56,752 - Epoch: [306][  300/  518]    Overall Loss 2.919023    Objective Loss 2.919023                                        LR 0.000008    Time 0.218593    
2023-04-27 05:39:07,600 - Epoch: [306][  350/  518]    Overall Loss 2.927298    Objective Loss 2.927298                                        LR 0.000008    Time 0.218353    
2023-04-27 05:39:18,457 - Epoch: [306][  400/  518]    Overall Loss 2.925261    Objective Loss 2.925261                                        LR 0.000008    Time 0.218199    
2023-04-27 05:39:29,258 - Epoch: [306][  450/  518]    Overall Loss 2.924377    Objective Loss 2.924377                                        LR 0.000008    Time 0.217952    
2023-04-27 05:39:40,000 - Epoch: [306][  500/  518]    Overall Loss 2.921497    Objective Loss 2.921497                                        LR 0.000008    Time 0.217638    
2023-04-27 05:39:43,718 - Epoch: [306][  518/  518]    Overall Loss 2.921960    Objective Loss 2.921960                                        LR 0.000008    Time 0.217253    
2023-04-27 05:39:43,794 - --- validate (epoch=306)-----------
2023-04-27 05:39:43,795 - 4952 samples (32 per mini-batch)
2023-04-27 05:39:52,143 - Epoch: [306][   50/  155]    Loss 3.052648    mAP 0.456124    
2023-04-27 05:40:00,069 - Epoch: [306][  100/  155]    Loss 3.063056    mAP 0.458237    
2023-04-27 05:40:07,982 - Epoch: [306][  150/  155]    Loss 3.055885    mAP 0.454517    
2023-04-27 05:40:08,694 - Epoch: [306][  155/  155]    Loss 3.054171    mAP 0.452556    
2023-04-27 05:40:08,758 - ==> mAP: 0.45256    Loss: 3.054

2023-04-27 05:40:08,762 - ==> Best [mAP: 0.452556   vloss: 3.054171   Sparsity:0.00   Params: 2177087 on epoch: 306]
2023-04-27 05:40:08,762 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:40:08,811 - 

2023-04-27 05:40:08,811 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:40:20,415 - Epoch: [307][   50/  518]    Overall Loss 2.912392    Objective Loss 2.912392                                        LR 0.000008    Time 0.232021    
2023-04-27 05:40:31,244 - Epoch: [307][  100/  518]    Overall Loss 2.887520    Objective Loss 2.887520                                        LR 0.000008    Time 0.224290    
2023-04-27 05:40:41,976 - Epoch: [307][  150/  518]    Overall Loss 2.882502    Objective Loss 2.882502                                        LR 0.000008    Time 0.221063    
2023-04-27 05:40:52,772 - Epoch: [307][  200/  518]    Overall Loss 2.884478    Objective Loss 2.884478                                        LR 0.000008    Time 0.219769    
2023-04-27 05:41:03,549 - Epoch: [307][  250/  518]    Overall Loss 2.900130    Objective Loss 2.900130                                        LR 0.000008    Time 0.218917    
2023-04-27 05:41:14,314 - Epoch: [307][  300/  518]    Overall Loss 2.900743    Objective Loss 2.900743                                        LR 0.000008    Time 0.218306    
2023-04-27 05:41:25,072 - Epoch: [307][  350/  518]    Overall Loss 2.903699    Objective Loss 2.903699                                        LR 0.000008    Time 0.217854    
2023-04-27 05:41:35,873 - Epoch: [307][  400/  518]    Overall Loss 2.901865    Objective Loss 2.901865                                        LR 0.000008    Time 0.217619    
2023-04-27 05:41:46,628 - Epoch: [307][  450/  518]    Overall Loss 2.901388    Objective Loss 2.901388                                        LR 0.000008    Time 0.217336    
2023-04-27 05:41:57,439 - Epoch: [307][  500/  518]    Overall Loss 2.902333    Objective Loss 2.902333                                        LR 0.000008    Time 0.217223    
2023-04-27 05:42:01,192 - Epoch: [307][  518/  518]    Overall Loss 2.904080    Objective Loss 2.904080                                        LR 0.000008    Time 0.216919    
2023-04-27 05:42:01,271 - --- validate (epoch=307)-----------
2023-04-27 05:42:01,271 - 4952 samples (32 per mini-batch)
2023-04-27 05:42:09,538 - Epoch: [307][   50/  155]    Loss 3.084528    mAP 0.447841    
2023-04-27 05:42:17,501 - Epoch: [307][  100/  155]    Loss 3.082506    mAP 0.448938    
2023-04-27 05:42:25,405 - Epoch: [307][  150/  155]    Loss 3.065253    mAP 0.454253    
2023-04-27 05:42:26,131 - Epoch: [307][  155/  155]    Loss 3.062401    mAP 0.454234    
2023-04-27 05:42:26,203 - ==> mAP: 0.45423    Loss: 3.062

2023-04-27 05:42:26,206 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 05:42:26,206 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:42:26,256 - 

2023-04-27 05:42:26,256 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:42:37,804 - Epoch: [308][   50/  518]    Overall Loss 2.884972    Objective Loss 2.884972                                        LR 0.000008    Time 0.230896    
2023-04-27 05:42:48,656 - Epoch: [308][  100/  518]    Overall Loss 2.905083    Objective Loss 2.905083                                        LR 0.000008    Time 0.223961    
2023-04-27 05:42:59,437 - Epoch: [308][  150/  518]    Overall Loss 2.899229    Objective Loss 2.899229                                        LR 0.000008    Time 0.221170    
2023-04-27 05:43:10,273 - Epoch: [308][  200/  518]    Overall Loss 2.893310    Objective Loss 2.893310                                        LR 0.000008    Time 0.220050    
2023-04-27 05:43:21,071 - Epoch: [308][  250/  518]    Overall Loss 2.898815    Objective Loss 2.898815                                        LR 0.000008    Time 0.219226    
2023-04-27 05:43:31,889 - Epoch: [308][  300/  518]    Overall Loss 2.899628    Objective Loss 2.899628                                        LR 0.000008    Time 0.218743    
2023-04-27 05:43:42,744 - Epoch: [308][  350/  518]    Overall Loss 2.897010    Objective Loss 2.897010                                        LR 0.000008    Time 0.218504    
2023-04-27 05:43:53,632 - Epoch: [308][  400/  518]    Overall Loss 2.896687    Objective Loss 2.896687                                        LR 0.000008    Time 0.218405    
2023-04-27 05:44:04,405 - Epoch: [308][  450/  518]    Overall Loss 2.894929    Objective Loss 2.894929                                        LR 0.000008    Time 0.218075    
2023-04-27 05:44:15,144 - Epoch: [308][  500/  518]    Overall Loss 2.890560    Objective Loss 2.890560                                        LR 0.000008    Time 0.217743    
2023-04-27 05:44:18,888 - Epoch: [308][  518/  518]    Overall Loss 2.890594    Objective Loss 2.890594                                        LR 0.000008    Time 0.217404    
2023-04-27 05:44:18,964 - --- validate (epoch=308)-----------
2023-04-27 05:44:18,964 - 4952 samples (32 per mini-batch)
2023-04-27 05:44:27,297 - Epoch: [308][   50/  155]    Loss 3.076963    mAP 0.436861    
2023-04-27 05:44:35,251 - Epoch: [308][  100/  155]    Loss 3.031208    mAP 0.451594    
2023-04-27 05:44:43,155 - Epoch: [308][  150/  155]    Loss 3.037694    mAP 0.447079    
2023-04-27 05:44:43,874 - Epoch: [308][  155/  155]    Loss 3.041896    mAP 0.446099    
2023-04-27 05:44:43,957 - ==> mAP: 0.44610    Loss: 3.042

2023-04-27 05:44:43,962 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 05:44:43,962 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:44:43,997 - 

2023-04-27 05:44:43,997 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:44:55,747 - Epoch: [309][   50/  518]    Overall Loss 2.965294    Objective Loss 2.965294                                        LR 0.000008    Time 0.234957    
2023-04-27 05:45:06,643 - Epoch: [309][  100/  518]    Overall Loss 2.973806    Objective Loss 2.973806                                        LR 0.000008    Time 0.226419    
2023-04-27 05:45:17,406 - Epoch: [309][  150/  518]    Overall Loss 2.945564    Objective Loss 2.945564                                        LR 0.000008    Time 0.222686    
2023-04-27 05:45:28,195 - Epoch: [309][  200/  518]    Overall Loss 2.937545    Objective Loss 2.937545                                        LR 0.000008    Time 0.220952    
2023-04-27 05:45:39,001 - Epoch: [309][  250/  518]    Overall Loss 2.922190    Objective Loss 2.922190                                        LR 0.000008    Time 0.219979    
2023-04-27 05:45:49,810 - Epoch: [309][  300/  518]    Overall Loss 2.925093    Objective Loss 2.925093                                        LR 0.000008    Time 0.219342    
2023-04-27 05:46:00,554 - Epoch: [309][  350/  518]    Overall Loss 2.914035    Objective Loss 2.914035                                        LR 0.000008    Time 0.218700    
2023-04-27 05:46:11,358 - Epoch: [309][  400/  518]    Overall Loss 2.915409    Objective Loss 2.915409                                        LR 0.000008    Time 0.218369    
2023-04-27 05:46:22,194 - Epoch: [309][  450/  518]    Overall Loss 2.915892    Objective Loss 2.915892                                        LR 0.000008    Time 0.218183    
2023-04-27 05:46:33,048 - Epoch: [309][  500/  518]    Overall Loss 2.915344    Objective Loss 2.915344                                        LR 0.000008    Time 0.218069    
2023-04-27 05:46:36,819 - Epoch: [309][  518/  518]    Overall Loss 2.914107    Objective Loss 2.914107                                        LR 0.000008    Time 0.217770    
2023-04-27 05:46:36,897 - --- validate (epoch=309)-----------
2023-04-27 05:46:36,897 - 4952 samples (32 per mini-batch)
2023-04-27 05:46:45,175 - Epoch: [309][   50/  155]    Loss 3.065429    mAP 0.425488    
2023-04-27 05:46:53,079 - Epoch: [309][  100/  155]    Loss 3.084452    mAP 0.439458    
2023-04-27 05:47:00,941 - Epoch: [309][  150/  155]    Loss 3.062605    mAP 0.442352    
2023-04-27 05:47:01,652 - Epoch: [309][  155/  155]    Loss 3.065904    mAP 0.442887    
2023-04-27 05:47:01,731 - ==> mAP: 0.44289    Loss: 3.066

2023-04-27 05:47:01,734 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 05:47:01,734 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:47:01,768 - 

2023-04-27 05:47:01,769 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:47:13,338 - Epoch: [310][   50/  518]    Overall Loss 2.905827    Objective Loss 2.905827                                        LR 0.000008    Time 0.231329    
2023-04-27 05:47:24,178 - Epoch: [310][  100/  518]    Overall Loss 2.908496    Objective Loss 2.908496                                        LR 0.000008    Time 0.224049    
2023-04-27 05:47:35,075 - Epoch: [310][  150/  518]    Overall Loss 2.883667    Objective Loss 2.883667                                        LR 0.000008    Time 0.222004    
2023-04-27 05:47:45,898 - Epoch: [310][  200/  518]    Overall Loss 2.892712    Objective Loss 2.892712                                        LR 0.000008    Time 0.220607    
2023-04-27 05:47:56,729 - Epoch: [310][  250/  518]    Overall Loss 2.894882    Objective Loss 2.894882                                        LR 0.000008    Time 0.219807    
2023-04-27 05:48:07,556 - Epoch: [310][  300/  518]    Overall Loss 2.891861    Objective Loss 2.891861                                        LR 0.000008    Time 0.219257    
2023-04-27 05:48:18,351 - Epoch: [310][  350/  518]    Overall Loss 2.900937    Objective Loss 2.900937                                        LR 0.000008    Time 0.218772    
2023-04-27 05:48:29,133 - Epoch: [310][  400/  518]    Overall Loss 2.898735    Objective Loss 2.898735                                        LR 0.000008    Time 0.218376    
2023-04-27 05:48:39,911 - Epoch: [310][  450/  518]    Overall Loss 2.900074    Objective Loss 2.900074                                        LR 0.000008    Time 0.218061    
2023-04-27 05:48:50,713 - Epoch: [310][  500/  518]    Overall Loss 2.900069    Objective Loss 2.900069                                        LR 0.000008    Time 0.217856    
2023-04-27 05:48:54,451 - Epoch: [310][  518/  518]    Overall Loss 2.899907    Objective Loss 2.899907                                        LR 0.000008    Time 0.217501    
2023-04-27 05:48:54,526 - --- validate (epoch=310)-----------
2023-04-27 05:48:54,526 - 4952 samples (32 per mini-batch)
2023-04-27 05:49:02,801 - Epoch: [310][   50/  155]    Loss 3.056844    mAP 0.433517    
2023-04-27 05:49:10,719 - Epoch: [310][  100/  155]    Loss 3.057278    mAP 0.434470    
2023-04-27 05:49:18,585 - Epoch: [310][  150/  155]    Loss 3.057944    mAP 0.434180    
2023-04-27 05:49:19,302 - Epoch: [310][  155/  155]    Loss 3.062165    mAP 0.433084    
2023-04-27 05:49:19,369 - ==> mAP: 0.43308    Loss: 3.062

2023-04-27 05:49:19,373 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 05:49:19,373 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:49:19,408 - 

2023-04-27 05:49:19,408 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:49:31,131 - Epoch: [311][   50/  518]    Overall Loss 2.864396    Objective Loss 2.864396                                        LR 0.000008    Time 0.234407    
2023-04-27 05:49:41,947 - Epoch: [311][  100/  518]    Overall Loss 2.880030    Objective Loss 2.880030                                        LR 0.000008    Time 0.225350    
2023-04-27 05:49:52,728 - Epoch: [311][  150/  518]    Overall Loss 2.887256    Objective Loss 2.887256                                        LR 0.000008    Time 0.222094    
2023-04-27 05:50:03,569 - Epoch: [311][  200/  518]    Overall Loss 2.898363    Objective Loss 2.898363                                        LR 0.000008    Time 0.220767    
2023-04-27 05:50:14,354 - Epoch: [311][  250/  518]    Overall Loss 2.907645    Objective Loss 2.907645                                        LR 0.000008    Time 0.219750    
2023-04-27 05:50:25,134 - Epoch: [311][  300/  518]    Overall Loss 2.911398    Objective Loss 2.911398                                        LR 0.000008    Time 0.219053    
2023-04-27 05:50:35,917 - Epoch: [311][  350/  518]    Overall Loss 2.903514    Objective Loss 2.903514                                        LR 0.000008    Time 0.218562    
2023-04-27 05:50:46,774 - Epoch: [311][  400/  518]    Overall Loss 2.904510    Objective Loss 2.904510                                        LR 0.000008    Time 0.218382    
2023-04-27 05:50:57,606 - Epoch: [311][  450/  518]    Overall Loss 2.906296    Objective Loss 2.906296                                        LR 0.000008    Time 0.218185    
2023-04-27 05:51:08,529 - Epoch: [311][  500/  518]    Overall Loss 2.902685    Objective Loss 2.902685                                        LR 0.000008    Time 0.218208    
2023-04-27 05:51:12,286 - Epoch: [311][  518/  518]    Overall Loss 2.901888    Objective Loss 2.901888                                        LR 0.000008    Time 0.217877    
2023-04-27 05:51:12,363 - --- validate (epoch=311)-----------
2023-04-27 05:51:12,363 - 4952 samples (32 per mini-batch)
2023-04-27 05:51:20,742 - Epoch: [311][   50/  155]    Loss 3.072769    mAP 0.438171    
2023-04-27 05:51:28,701 - Epoch: [311][  100/  155]    Loss 3.066971    mAP 0.443615    
2023-04-27 05:51:36,586 - Epoch: [311][  150/  155]    Loss 3.069183    mAP 0.444519    
2023-04-27 05:51:37,304 - Epoch: [311][  155/  155]    Loss 3.064678    mAP 0.443439    
2023-04-27 05:51:37,378 - ==> mAP: 0.44344    Loss: 3.065

2023-04-27 05:51:37,382 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 05:51:37,382 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:51:37,417 - 

2023-04-27 05:51:37,417 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:51:49,114 - Epoch: [312][   50/  518]    Overall Loss 2.938758    Objective Loss 2.938758                                        LR 0.000008    Time 0.233891    
2023-04-27 05:51:59,951 - Epoch: [312][  100/  518]    Overall Loss 2.918911    Objective Loss 2.918911                                        LR 0.000008    Time 0.225299    
2023-04-27 05:52:10,769 - Epoch: [312][  150/  518]    Overall Loss 2.911491    Objective Loss 2.911491                                        LR 0.000008    Time 0.222313    
2023-04-27 05:52:21,597 - Epoch: [312][  200/  518]    Overall Loss 2.910321    Objective Loss 2.910321                                        LR 0.000008    Time 0.220863    
2023-04-27 05:52:32,462 - Epoch: [312][  250/  518]    Overall Loss 2.897864    Objective Loss 2.897864                                        LR 0.000008    Time 0.220145    
2023-04-27 05:52:43,392 - Epoch: [312][  300/  518]    Overall Loss 2.901333    Objective Loss 2.901333                                        LR 0.000008    Time 0.219883    
2023-04-27 05:52:54,217 - Epoch: [312][  350/  518]    Overall Loss 2.904451    Objective Loss 2.904451                                        LR 0.000008    Time 0.219394    
2023-04-27 05:53:05,075 - Epoch: [312][  400/  518]    Overall Loss 2.906437    Objective Loss 2.906437                                        LR 0.000008    Time 0.219111    
2023-04-27 05:53:15,988 - Epoch: [312][  450/  518]    Overall Loss 2.909021    Objective Loss 2.909021                                        LR 0.000008    Time 0.219014    
2023-04-27 05:53:26,870 - Epoch: [312][  500/  518]    Overall Loss 2.908665    Objective Loss 2.908665                                        LR 0.000008    Time 0.218872    
2023-04-27 05:53:30,586 - Epoch: [312][  518/  518]    Overall Loss 2.908173    Objective Loss 2.908173                                        LR 0.000008    Time 0.218440    
2023-04-27 05:53:30,663 - --- validate (epoch=312)-----------
2023-04-27 05:53:30,663 - 4952 samples (32 per mini-batch)
2023-04-27 05:53:39,000 - Epoch: [312][   50/  155]    Loss 3.086608    mAP 0.437746    
2023-04-27 05:53:46,953 - Epoch: [312][  100/  155]    Loss 3.061403    mAP 0.441407    
2023-04-27 05:53:54,850 - Epoch: [312][  150/  155]    Loss 3.065628    mAP 0.443886    
2023-04-27 05:53:55,579 - Epoch: [312][  155/  155]    Loss 3.067960    mAP 0.444896    
2023-04-27 05:53:55,655 - ==> mAP: 0.44490    Loss: 3.068

2023-04-27 05:53:55,659 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 05:53:55,659 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:53:55,693 - 

2023-04-27 05:53:55,693 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:54:07,435 - Epoch: [313][   50/  518]    Overall Loss 2.907078    Objective Loss 2.907078                                        LR 0.000008    Time 0.234793    
2023-04-27 05:54:18,288 - Epoch: [313][  100/  518]    Overall Loss 2.911513    Objective Loss 2.911513                                        LR 0.000008    Time 0.225909    
2023-04-27 05:54:29,108 - Epoch: [313][  150/  518]    Overall Loss 2.924622    Objective Loss 2.924622                                        LR 0.000008    Time 0.222729    
2023-04-27 05:54:39,912 - Epoch: [313][  200/  518]    Overall Loss 2.914248    Objective Loss 2.914248                                        LR 0.000008    Time 0.221056    
2023-04-27 05:54:50,720 - Epoch: [313][  250/  518]    Overall Loss 2.911086    Objective Loss 2.911086                                        LR 0.000008    Time 0.220070    
2023-04-27 05:55:01,522 - Epoch: [313][  300/  518]    Overall Loss 2.907525    Objective Loss 2.907525                                        LR 0.000008    Time 0.219395    
2023-04-27 05:55:12,332 - Epoch: [313][  350/  518]    Overall Loss 2.912121    Objective Loss 2.912121                                        LR 0.000008    Time 0.218934    
2023-04-27 05:55:23,090 - Epoch: [313][  400/  518]    Overall Loss 2.905280    Objective Loss 2.905280                                        LR 0.000008    Time 0.218458    
2023-04-27 05:55:33,900 - Epoch: [313][  450/  518]    Overall Loss 2.896428    Objective Loss 2.896428                                        LR 0.000008    Time 0.218203    
2023-04-27 05:55:44,687 - Epoch: [313][  500/  518]    Overall Loss 2.895912    Objective Loss 2.895912                                        LR 0.000008    Time 0.217954    
2023-04-27 05:55:48,489 - Epoch: [313][  518/  518]    Overall Loss 2.895742    Objective Loss 2.895742                                        LR 0.000008    Time 0.217720    
2023-04-27 05:55:48,564 - --- validate (epoch=313)-----------
2023-04-27 05:55:48,564 - 4952 samples (32 per mini-batch)
2023-04-27 05:55:56,888 - Epoch: [313][   50/  155]    Loss 3.143976    mAP 0.436817    
2023-04-27 05:56:04,816 - Epoch: [313][  100/  155]    Loss 3.106638    mAP 0.438189    
2023-04-27 05:56:12,696 - Epoch: [313][  150/  155]    Loss 3.105042    mAP 0.440790    
2023-04-27 05:56:13,414 - Epoch: [313][  155/  155]    Loss 3.106186    mAP 0.440568    
2023-04-27 05:56:13,492 - ==> mAP: 0.44057    Loss: 3.106

2023-04-27 05:56:13,497 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 05:56:13,497 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:56:13,532 - 

2023-04-27 05:56:13,532 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:56:25,102 - Epoch: [314][   50/  518]    Overall Loss 2.896385    Objective Loss 2.896385                                        LR 0.000008    Time 0.231341    
2023-04-27 05:56:35,887 - Epoch: [314][  100/  518]    Overall Loss 2.900779    Objective Loss 2.900779                                        LR 0.000008    Time 0.223508    
2023-04-27 05:56:46,672 - Epoch: [314][  150/  518]    Overall Loss 2.915138    Objective Loss 2.915138                                        LR 0.000008    Time 0.220896    
2023-04-27 05:56:57,533 - Epoch: [314][  200/  518]    Overall Loss 2.923622    Objective Loss 2.923622                                        LR 0.000008    Time 0.219969    
2023-04-27 05:57:08,319 - Epoch: [314][  250/  518]    Overall Loss 2.904862    Objective Loss 2.904862                                        LR 0.000008    Time 0.219113    
2023-04-27 05:57:19,090 - Epoch: [314][  300/  518]    Overall Loss 2.900474    Objective Loss 2.900474                                        LR 0.000008    Time 0.218491    
2023-04-27 05:57:29,888 - Epoch: [314][  350/  518]    Overall Loss 2.899119    Objective Loss 2.899119                                        LR 0.000008    Time 0.218126    
2023-04-27 05:57:40,673 - Epoch: [314][  400/  518]    Overall Loss 2.902065    Objective Loss 2.902065                                        LR 0.000008    Time 0.217817    
2023-04-27 05:57:51,451 - Epoch: [314][  450/  518]    Overall Loss 2.899959    Objective Loss 2.899959                                        LR 0.000008    Time 0.217563    
2023-04-27 05:58:02,241 - Epoch: [314][  500/  518]    Overall Loss 2.899359    Objective Loss 2.899359                                        LR 0.000008    Time 0.217385    
2023-04-27 05:58:06,008 - Epoch: [314][  518/  518]    Overall Loss 2.897729    Objective Loss 2.897729                                        LR 0.000008    Time 0.217101    
2023-04-27 05:58:06,083 - --- validate (epoch=314)-----------
2023-04-27 05:58:06,084 - 4952 samples (32 per mini-batch)
2023-04-27 05:58:14,372 - Epoch: [314][   50/  155]    Loss 3.076362    mAP 0.436317    
2023-04-27 05:58:22,240 - Epoch: [314][  100/  155]    Loss 3.067671    mAP 0.439035    
2023-04-27 05:58:30,120 - Epoch: [314][  150/  155]    Loss 3.066983    mAP 0.436857    
2023-04-27 05:58:30,837 - Epoch: [314][  155/  155]    Loss 3.062856    mAP 0.438348    
2023-04-27 05:58:30,920 - ==> mAP: 0.43835    Loss: 3.063

2023-04-27 05:58:30,924 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 05:58:30,924 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 05:58:30,960 - 

2023-04-27 05:58:30,960 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 05:58:42,723 - Epoch: [315][   50/  518]    Overall Loss 2.922623    Objective Loss 2.922623                                        LR 0.000008    Time 0.235202    
2023-04-27 05:58:53,595 - Epoch: [315][  100/  518]    Overall Loss 2.904281    Objective Loss 2.904281                                        LR 0.000008    Time 0.226307    
2023-04-27 05:59:04,361 - Epoch: [315][  150/  518]    Overall Loss 2.886336    Objective Loss 2.886336                                        LR 0.000008    Time 0.222637    
2023-04-27 05:59:15,148 - Epoch: [315][  200/  518]    Overall Loss 2.883618    Objective Loss 2.883618                                        LR 0.000008    Time 0.220901    
2023-04-27 05:59:25,998 - Epoch: [315][  250/  518]    Overall Loss 2.887791    Objective Loss 2.887791                                        LR 0.000008    Time 0.220117    
2023-04-27 05:59:36,767 - Epoch: [315][  300/  518]    Overall Loss 2.890666    Objective Loss 2.890666                                        LR 0.000008    Time 0.219322    
2023-04-27 05:59:47,516 - Epoch: [315][  350/  518]    Overall Loss 2.893714    Objective Loss 2.893714                                        LR 0.000008    Time 0.218696    
2023-04-27 05:59:58,311 - Epoch: [315][  400/  518]    Overall Loss 2.894133    Objective Loss 2.894133                                        LR 0.000008    Time 0.218344    
2023-04-27 06:00:09,073 - Epoch: [315][  450/  518]    Overall Loss 2.891237    Objective Loss 2.891237                                        LR 0.000008    Time 0.217995    
2023-04-27 06:00:19,886 - Epoch: [315][  500/  518]    Overall Loss 2.896078    Objective Loss 2.896078                                        LR 0.000008    Time 0.217818    
2023-04-27 06:00:23,680 - Epoch: [315][  518/  518]    Overall Loss 2.897545    Objective Loss 2.897545                                        LR 0.000008    Time 0.217573    
2023-04-27 06:00:23,756 - --- validate (epoch=315)-----------
2023-04-27 06:00:23,756 - 4952 samples (32 per mini-batch)
2023-04-27 06:00:32,091 - Epoch: [315][   50/  155]    Loss 3.036800    mAP 0.469541    
2023-04-27 06:00:40,025 - Epoch: [315][  100/  155]    Loss 3.033217    mAP 0.454582    
2023-04-27 06:00:47,906 - Epoch: [315][  150/  155]    Loss 3.047841    mAP 0.453246    
2023-04-27 06:00:48,629 - Epoch: [315][  155/  155]    Loss 3.051960    mAP 0.453113    
2023-04-27 06:00:48,701 - ==> mAP: 0.45311    Loss: 3.052

2023-04-27 06:00:48,705 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:00:48,705 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:00:48,739 - 

2023-04-27 06:00:48,739 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:01:00,314 - Epoch: [316][   50/  518]    Overall Loss 2.851189    Objective Loss 2.851189                                        LR 0.000008    Time 0.231446    
2023-04-27 06:01:11,131 - Epoch: [316][  100/  518]    Overall Loss 2.842888    Objective Loss 2.842888                                        LR 0.000008    Time 0.223880    
2023-04-27 06:01:21,967 - Epoch: [316][  150/  518]    Overall Loss 2.843306    Objective Loss 2.843306                                        LR 0.000008    Time 0.221482    
2023-04-27 06:01:32,734 - Epoch: [316][  200/  518]    Overall Loss 2.843614    Objective Loss 2.843614                                        LR 0.000008    Time 0.219935    
2023-04-27 06:01:43,537 - Epoch: [316][  250/  518]    Overall Loss 2.851169    Objective Loss 2.851169                                        LR 0.000008    Time 0.219156    
2023-04-27 06:01:54,403 - Epoch: [316][  300/  518]    Overall Loss 2.861848    Objective Loss 2.861848                                        LR 0.000008    Time 0.218843    
2023-04-27 06:02:05,233 - Epoch: [316][  350/  518]    Overall Loss 2.865010    Objective Loss 2.865010                                        LR 0.000008    Time 0.218520    
2023-04-27 06:02:16,040 - Epoch: [316][  400/  518]    Overall Loss 2.867172    Objective Loss 2.867172                                        LR 0.000008    Time 0.218219    
2023-04-27 06:02:26,835 - Epoch: [316][  450/  518]    Overall Loss 2.871870    Objective Loss 2.871870                                        LR 0.000008    Time 0.217957    
2023-04-27 06:02:37,625 - Epoch: [316][  500/  518]    Overall Loss 2.874390    Objective Loss 2.874390                                        LR 0.000008    Time 0.217738    
2023-04-27 06:02:41,356 - Epoch: [316][  518/  518]    Overall Loss 2.874196    Objective Loss 2.874196                                        LR 0.000008    Time 0.217373    
2023-04-27 06:02:41,433 - --- validate (epoch=316)-----------
2023-04-27 06:02:41,433 - 4952 samples (32 per mini-batch)
2023-04-27 06:02:49,687 - Epoch: [316][   50/  155]    Loss 3.034567    mAP 0.446315    
2023-04-27 06:02:57,600 - Epoch: [316][  100/  155]    Loss 3.061110    mAP 0.449510    
2023-04-27 06:03:05,491 - Epoch: [316][  150/  155]    Loss 3.052220    mAP 0.448789    
2023-04-27 06:03:06,214 - Epoch: [316][  155/  155]    Loss 3.049893    mAP 0.450656    
2023-04-27 06:03:06,289 - ==> mAP: 0.45066    Loss: 3.050

2023-04-27 06:03:06,293 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:03:06,293 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:03:06,327 - 

2023-04-27 06:03:06,327 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:03:18,034 - Epoch: [317][   50/  518]    Overall Loss 2.920475    Objective Loss 2.920475                                        LR 0.000008    Time 0.234076    
2023-04-27 06:03:28,811 - Epoch: [317][  100/  518]    Overall Loss 2.918660    Objective Loss 2.918660                                        LR 0.000008    Time 0.224790    
2023-04-27 06:03:39,552 - Epoch: [317][  150/  518]    Overall Loss 2.910671    Objective Loss 2.910671                                        LR 0.000008    Time 0.221462    
2023-04-27 06:03:50,293 - Epoch: [317][  200/  518]    Overall Loss 2.911461    Objective Loss 2.911461                                        LR 0.000008    Time 0.219791    
2023-04-27 06:04:01,103 - Epoch: [317][  250/  518]    Overall Loss 2.911880    Objective Loss 2.911880                                        LR 0.000008    Time 0.219065    
2023-04-27 06:04:11,899 - Epoch: [317][  300/  518]    Overall Loss 2.908811    Objective Loss 2.908811                                        LR 0.000008    Time 0.218538    
2023-04-27 06:04:22,691 - Epoch: [317][  350/  518]    Overall Loss 2.905454    Objective Loss 2.905454                                        LR 0.000008    Time 0.218149    
2023-04-27 06:04:33,519 - Epoch: [317][  400/  518]    Overall Loss 2.906999    Objective Loss 2.906999                                        LR 0.000008    Time 0.217945    
2023-04-27 06:04:44,398 - Epoch: [317][  450/  518]    Overall Loss 2.899917    Objective Loss 2.899917                                        LR 0.000008    Time 0.217902    
2023-04-27 06:04:55,221 - Epoch: [317][  500/  518]    Overall Loss 2.905916    Objective Loss 2.905916                                        LR 0.000008    Time 0.217754    
2023-04-27 06:04:58,978 - Epoch: [317][  518/  518]    Overall Loss 2.904122    Objective Loss 2.904122                                        LR 0.000008    Time 0.217440    
2023-04-27 06:04:59,054 - --- validate (epoch=317)-----------
2023-04-27 06:04:59,055 - 4952 samples (32 per mini-batch)
2023-04-27 06:05:07,390 - Epoch: [317][   50/  155]    Loss 3.117379    mAP 0.441125    
2023-04-27 06:05:15,340 - Epoch: [317][  100/  155]    Loss 3.064856    mAP 0.445234    
2023-04-27 06:05:23,246 - Epoch: [317][  150/  155]    Loss 3.048498    mAP 0.446569    
2023-04-27 06:05:23,972 - Epoch: [317][  155/  155]    Loss 3.048645    mAP 0.447270    
2023-04-27 06:05:24,045 - ==> mAP: 0.44727    Loss: 3.049

2023-04-27 06:05:24,049 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:05:24,049 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:05:24,083 - 

2023-04-27 06:05:24,083 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:05:35,560 - Epoch: [318][   50/  518]    Overall Loss 2.797829    Objective Loss 2.797829                                        LR 0.000008    Time 0.229475    
2023-04-27 06:05:46,356 - Epoch: [318][  100/  518]    Overall Loss 2.812802    Objective Loss 2.812802                                        LR 0.000008    Time 0.222679    
2023-04-27 06:05:57,213 - Epoch: [318][  150/  518]    Overall Loss 2.845383    Objective Loss 2.845383                                        LR 0.000008    Time 0.220826    
2023-04-27 06:06:08,086 - Epoch: [318][  200/  518]    Overall Loss 2.868431    Objective Loss 2.868431                                        LR 0.000008    Time 0.219979    
2023-04-27 06:06:18,885 - Epoch: [318][  250/  518]    Overall Loss 2.875000    Objective Loss 2.875000                                        LR 0.000008    Time 0.219169    
2023-04-27 06:06:29,762 - Epoch: [318][  300/  518]    Overall Loss 2.887547    Objective Loss 2.887547                                        LR 0.000008    Time 0.218894    
2023-04-27 06:06:40,604 - Epoch: [318][  350/  518]    Overall Loss 2.890318    Objective Loss 2.890318                                        LR 0.000008    Time 0.218596    
2023-04-27 06:06:51,479 - Epoch: [318][  400/  518]    Overall Loss 2.898320    Objective Loss 2.898320                                        LR 0.000008    Time 0.218454    
2023-04-27 06:07:02,338 - Epoch: [318][  450/  518]    Overall Loss 2.900876    Objective Loss 2.900876                                        LR 0.000008    Time 0.218311    
2023-04-27 06:07:13,100 - Epoch: [318][  500/  518]    Overall Loss 2.900091    Objective Loss 2.900091                                        LR 0.000008    Time 0.218000    
2023-04-27 06:07:16,828 - Epoch: [318][  518/  518]    Overall Loss 2.900031    Objective Loss 2.900031                                        LR 0.000008    Time 0.217621    
2023-04-27 06:07:16,908 - --- validate (epoch=318)-----------
2023-04-27 06:07:16,908 - 4952 samples (32 per mini-batch)
2023-04-27 06:07:25,235 - Epoch: [318][   50/  155]    Loss 3.069604    mAP 0.446033    
2023-04-27 06:07:33,120 - Epoch: [318][  100/  155]    Loss 3.064371    mAP 0.439774    
2023-04-27 06:07:41,032 - Epoch: [318][  150/  155]    Loss 3.055180    mAP 0.443760    
2023-04-27 06:07:41,747 - Epoch: [318][  155/  155]    Loss 3.054714    mAP 0.441363    
2023-04-27 06:07:41,824 - ==> mAP: 0.44136    Loss: 3.055

2023-04-27 06:07:41,827 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:07:41,827 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:07:41,861 - 

2023-04-27 06:07:41,861 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:07:53,495 - Epoch: [319][   50/  518]    Overall Loss 2.908601    Objective Loss 2.908601                                        LR 0.000008    Time 0.232632    
2023-04-27 06:08:04,234 - Epoch: [319][  100/  518]    Overall Loss 2.925925    Objective Loss 2.925925                                        LR 0.000008    Time 0.223689    
2023-04-27 06:08:15,043 - Epoch: [319][  150/  518]    Overall Loss 2.916265    Objective Loss 2.916265                                        LR 0.000008    Time 0.221175    
2023-04-27 06:08:25,757 - Epoch: [319][  200/  518]    Overall Loss 2.907994    Objective Loss 2.907994                                        LR 0.000008    Time 0.219441    
2023-04-27 06:08:36,515 - Epoch: [319][  250/  518]    Overall Loss 2.907755    Objective Loss 2.907755                                        LR 0.000008    Time 0.218578    
2023-04-27 06:08:47,234 - Epoch: [319][  300/  518]    Overall Loss 2.900710    Objective Loss 2.900710                                        LR 0.000008    Time 0.217873    
2023-04-27 06:08:58,021 - Epoch: [319][  350/  518]    Overall Loss 2.901714    Objective Loss 2.901714                                        LR 0.000008    Time 0.217564    
2023-04-27 06:09:08,834 - Epoch: [319][  400/  518]    Overall Loss 2.901387    Objective Loss 2.901387                                        LR 0.000008    Time 0.217396    
2023-04-27 06:09:19,552 - Epoch: [319][  450/  518]    Overall Loss 2.903243    Objective Loss 2.903243                                        LR 0.000008    Time 0.217056    
2023-04-27 06:09:30,372 - Epoch: [319][  500/  518]    Overall Loss 2.899665    Objective Loss 2.899665                                        LR 0.000008    Time 0.216988    
2023-04-27 06:09:34,089 - Epoch: [319][  518/  518]    Overall Loss 2.900413    Objective Loss 2.900413                                        LR 0.000008    Time 0.216623    
2023-04-27 06:09:34,165 - --- validate (epoch=319)-----------
2023-04-27 06:09:34,166 - 4952 samples (32 per mini-batch)
2023-04-27 06:09:42,479 - Epoch: [319][   50/  155]    Loss 3.047009    mAP 0.435343    
2023-04-27 06:09:50,424 - Epoch: [319][  100/  155]    Loss 3.060467    mAP 0.434605    
2023-04-27 06:09:58,326 - Epoch: [319][  150/  155]    Loss 3.062634    mAP 0.438950    
2023-04-27 06:09:59,041 - Epoch: [319][  155/  155]    Loss 3.064031    mAP 0.437389    
2023-04-27 06:09:59,113 - ==> mAP: 0.43739    Loss: 3.064

2023-04-27 06:09:59,117 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:09:59,117 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:09:59,152 - 

2023-04-27 06:09:59,152 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:10:10,920 - Epoch: [320][   50/  518]    Overall Loss 2.858288    Objective Loss 2.858288                                        LR 0.000008    Time 0.235298    
2023-04-27 06:10:21,673 - Epoch: [320][  100/  518]    Overall Loss 2.864087    Objective Loss 2.864087                                        LR 0.000008    Time 0.225162    
2023-04-27 06:10:32,619 - Epoch: [320][  150/  518]    Overall Loss 2.896284    Objective Loss 2.896284                                        LR 0.000008    Time 0.223072    
2023-04-27 06:10:43,442 - Epoch: [320][  200/  518]    Overall Loss 2.888097    Objective Loss 2.888097                                        LR 0.000008    Time 0.221410    
2023-04-27 06:10:54,265 - Epoch: [320][  250/  518]    Overall Loss 2.887899    Objective Loss 2.887899                                        LR 0.000008    Time 0.220414    
2023-04-27 06:11:05,144 - Epoch: [320][  300/  518]    Overall Loss 2.892971    Objective Loss 2.892971                                        LR 0.000008    Time 0.219936    
2023-04-27 06:11:15,912 - Epoch: [320][  350/  518]    Overall Loss 2.888485    Objective Loss 2.888485                                        LR 0.000008    Time 0.219279    
2023-04-27 06:11:26,726 - Epoch: [320][  400/  518]    Overall Loss 2.893549    Objective Loss 2.893549                                        LR 0.000008    Time 0.218898    
2023-04-27 06:11:37,535 - Epoch: [320][  450/  518]    Overall Loss 2.898373    Objective Loss 2.898373                                        LR 0.000008    Time 0.218595    
2023-04-27 06:11:48,378 - Epoch: [320][  500/  518]    Overall Loss 2.897671    Objective Loss 2.897671                                        LR 0.000008    Time 0.218418    
2023-04-27 06:11:52,176 - Epoch: [320][  518/  518]    Overall Loss 2.899182    Objective Loss 2.899182                                        LR 0.000008    Time 0.218159    
2023-04-27 06:11:52,252 - --- validate (epoch=320)-----------
2023-04-27 06:11:52,252 - 4952 samples (32 per mini-batch)
2023-04-27 06:12:00,528 - Epoch: [320][   50/  155]    Loss 3.092623    mAP 0.438224    
2023-04-27 06:12:08,421 - Epoch: [320][  100/  155]    Loss 3.069668    mAP 0.444822    
2023-04-27 06:12:16,296 - Epoch: [320][  150/  155]    Loss 3.077012    mAP 0.441841    
2023-04-27 06:12:17,009 - Epoch: [320][  155/  155]    Loss 3.077138    mAP 0.440452    
2023-04-27 06:12:17,075 - ==> mAP: 0.44045    Loss: 3.077

2023-04-27 06:12:17,078 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:12:17,079 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:12:17,113 - 

2023-04-27 06:12:17,113 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:12:28,680 - Epoch: [321][   50/  518]    Overall Loss 2.887299    Objective Loss 2.887299                                        LR 0.000008    Time 0.231291    
2023-04-27 06:12:39,404 - Epoch: [321][  100/  518]    Overall Loss 2.906451    Objective Loss 2.906451                                        LR 0.000008    Time 0.222871    
2023-04-27 06:12:50,220 - Epoch: [321][  150/  518]    Overall Loss 2.890821    Objective Loss 2.890821                                        LR 0.000008    Time 0.220677    
2023-04-27 06:13:01,075 - Epoch: [321][  200/  518]    Overall Loss 2.892819    Objective Loss 2.892819                                        LR 0.000008    Time 0.219774    
2023-04-27 06:13:11,858 - Epoch: [321][  250/  518]    Overall Loss 2.889718    Objective Loss 2.889718                                        LR 0.000008    Time 0.218945    
2023-04-27 06:13:22,637 - Epoch: [321][  300/  518]    Overall Loss 2.885065    Objective Loss 2.885065                                        LR 0.000008    Time 0.218378    
2023-04-27 06:13:33,503 - Epoch: [321][  350/  518]    Overall Loss 2.880246    Objective Loss 2.880246                                        LR 0.000008    Time 0.218224    
2023-04-27 06:13:44,342 - Epoch: [321][  400/  518]    Overall Loss 2.877831    Objective Loss 2.877831                                        LR 0.000008    Time 0.218039    
2023-04-27 06:13:55,164 - Epoch: [321][  450/  518]    Overall Loss 2.886921    Objective Loss 2.886921                                        LR 0.000008    Time 0.217858    
2023-04-27 06:14:06,023 - Epoch: [321][  500/  518]    Overall Loss 2.888799    Objective Loss 2.888799                                        LR 0.000008    Time 0.217787    
2023-04-27 06:14:09,752 - Epoch: [321][  518/  518]    Overall Loss 2.888622    Objective Loss 2.888622                                        LR 0.000008    Time 0.217416    
2023-04-27 06:14:09,830 - --- validate (epoch=321)-----------
2023-04-27 06:14:09,830 - 4952 samples (32 per mini-batch)
2023-04-27 06:14:18,119 - Epoch: [321][   50/  155]    Loss 3.046041    mAP 0.446910    
2023-04-27 06:14:26,072 - Epoch: [321][  100/  155]    Loss 3.050211    mAP 0.444533    
2023-04-27 06:14:33,980 - Epoch: [321][  150/  155]    Loss 3.041197    mAP 0.446277    
2023-04-27 06:14:34,712 - Epoch: [321][  155/  155]    Loss 3.040495    mAP 0.447139    
2023-04-27 06:14:34,785 - ==> mAP: 0.44714    Loss: 3.040

2023-04-27 06:14:34,789 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:14:34,789 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:14:34,823 - 

2023-04-27 06:14:34,824 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:14:46,516 - Epoch: [322][   50/  518]    Overall Loss 2.934841    Objective Loss 2.934841                                        LR 0.000008    Time 0.233795    
2023-04-27 06:14:57,303 - Epoch: [322][  100/  518]    Overall Loss 2.897563    Objective Loss 2.897563                                        LR 0.000008    Time 0.224749    
2023-04-27 06:15:08,170 - Epoch: [322][  150/  518]    Overall Loss 2.874655    Objective Loss 2.874655                                        LR 0.000008    Time 0.222271    
2023-04-27 06:15:19,059 - Epoch: [322][  200/  518]    Overall Loss 2.871823    Objective Loss 2.871823                                        LR 0.000008    Time 0.221140    
2023-04-27 06:15:29,954 - Epoch: [322][  250/  518]    Overall Loss 2.878381    Objective Loss 2.878381                                        LR 0.000008    Time 0.220487    
2023-04-27 06:15:40,799 - Epoch: [322][  300/  518]    Overall Loss 2.878026    Objective Loss 2.878026                                        LR 0.000008    Time 0.219884    
2023-04-27 06:15:51,628 - Epoch: [322][  350/  518]    Overall Loss 2.876753    Objective Loss 2.876753                                        LR 0.000008    Time 0.219407    
2023-04-27 06:16:02,425 - Epoch: [322][  400/  518]    Overall Loss 2.876608    Objective Loss 2.876608                                        LR 0.000008    Time 0.218970    
2023-04-27 06:16:13,289 - Epoch: [322][  450/  518]    Overall Loss 2.880017    Objective Loss 2.880017                                        LR 0.000008    Time 0.218778    
2023-04-27 06:16:24,111 - Epoch: [322][  500/  518]    Overall Loss 2.880202    Objective Loss 2.880202                                        LR 0.000008    Time 0.218540    
2023-04-27 06:16:27,813 - Epoch: [322][  518/  518]    Overall Loss 2.878380    Objective Loss 2.878380                                        LR 0.000008    Time 0.218092    
2023-04-27 06:16:27,890 - --- validate (epoch=322)-----------
2023-04-27 06:16:27,890 - 4952 samples (32 per mini-batch)
2023-04-27 06:16:36,182 - Epoch: [322][   50/  155]    Loss 3.040937    mAP 0.450597    
2023-04-27 06:16:44,072 - Epoch: [322][  100/  155]    Loss 3.053674    mAP 0.443531    
2023-04-27 06:16:51,968 - Epoch: [322][  150/  155]    Loss 3.054861    mAP 0.442060    
2023-04-27 06:16:52,680 - Epoch: [322][  155/  155]    Loss 3.054744    mAP 0.441421    
2023-04-27 06:16:52,755 - ==> mAP: 0.44142    Loss: 3.055

2023-04-27 06:16:52,759 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:16:52,759 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:16:52,793 - 

2023-04-27 06:16:52,793 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:17:04,376 - Epoch: [323][   50/  518]    Overall Loss 2.936197    Objective Loss 2.936197                                        LR 0.000008    Time 0.231617    
2023-04-27 06:17:15,272 - Epoch: [323][  100/  518]    Overall Loss 2.923195    Objective Loss 2.923195                                        LR 0.000008    Time 0.224753    
2023-04-27 06:17:26,006 - Epoch: [323][  150/  518]    Overall Loss 2.897659    Objective Loss 2.897659                                        LR 0.000008    Time 0.221383    
2023-04-27 06:17:36,762 - Epoch: [323][  200/  518]    Overall Loss 2.893783    Objective Loss 2.893783                                        LR 0.000008    Time 0.219808    
2023-04-27 06:17:47,542 - Epoch: [323][  250/  518]    Overall Loss 2.895339    Objective Loss 2.895339                                        LR 0.000008    Time 0.218959    
2023-04-27 06:17:58,290 - Epoch: [323][  300/  518]    Overall Loss 2.900201    Objective Loss 2.900201                                        LR 0.000008    Time 0.218289    
2023-04-27 06:18:09,091 - Epoch: [323][  350/  518]    Overall Loss 2.900814    Objective Loss 2.900814                                        LR 0.000008    Time 0.217962    
2023-04-27 06:18:19,867 - Epoch: [323][  400/  518]    Overall Loss 2.903522    Objective Loss 2.903522                                        LR 0.000008    Time 0.217650    
2023-04-27 06:18:30,688 - Epoch: [323][  450/  518]    Overall Loss 2.903875    Objective Loss 2.903875                                        LR 0.000008    Time 0.217511    
2023-04-27 06:18:41,542 - Epoch: [323][  500/  518]    Overall Loss 2.906333    Objective Loss 2.906333                                        LR 0.000008    Time 0.217464    
2023-04-27 06:18:45,294 - Epoch: [323][  518/  518]    Overall Loss 2.907537    Objective Loss 2.907537                                        LR 0.000008    Time 0.217150    
2023-04-27 06:18:45,370 - --- validate (epoch=323)-----------
2023-04-27 06:18:45,371 - 4952 samples (32 per mini-batch)
2023-04-27 06:18:53,655 - Epoch: [323][   50/  155]    Loss 3.060260    mAP 0.449633    
2023-04-27 06:19:01,537 - Epoch: [323][  100/  155]    Loss 3.061981    mAP 0.439486    
2023-04-27 06:19:09,409 - Epoch: [323][  150/  155]    Loss 3.059260    mAP 0.436930    
2023-04-27 06:19:10,129 - Epoch: [323][  155/  155]    Loss 3.056501    mAP 0.438413    
2023-04-27 06:19:10,204 - ==> mAP: 0.43841    Loss: 3.057

2023-04-27 06:19:10,207 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:19:10,207 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:19:10,241 - 

2023-04-27 06:19:10,242 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:19:21,798 - Epoch: [324][   50/  518]    Overall Loss 2.932219    Objective Loss 2.932219                                        LR 0.000008    Time 0.231077    
2023-04-27 06:19:32,703 - Epoch: [324][  100/  518]    Overall Loss 2.911842    Objective Loss 2.911842                                        LR 0.000008    Time 0.224576    
2023-04-27 06:19:43,534 - Epoch: [324][  150/  518]    Overall Loss 2.913623    Objective Loss 2.913623                                        LR 0.000008    Time 0.221914    
2023-04-27 06:19:54,400 - Epoch: [324][  200/  518]    Overall Loss 2.893222    Objective Loss 2.893222                                        LR 0.000008    Time 0.220758    
2023-04-27 06:20:05,207 - Epoch: [324][  250/  518]    Overall Loss 2.899088    Objective Loss 2.899088                                        LR 0.000008    Time 0.219826    
2023-04-27 06:20:16,096 - Epoch: [324][  300/  518]    Overall Loss 2.896315    Objective Loss 2.896315                                        LR 0.000008    Time 0.219482    
2023-04-27 06:20:26,879 - Epoch: [324][  350/  518]    Overall Loss 2.888630    Objective Loss 2.888630                                        LR 0.000008    Time 0.218930    
2023-04-27 06:20:37,714 - Epoch: [324][  400/  518]    Overall Loss 2.889126    Objective Loss 2.889126                                        LR 0.000008    Time 0.218647    
2023-04-27 06:20:48,498 - Epoch: [324][  450/  518]    Overall Loss 2.892778    Objective Loss 2.892778                                        LR 0.000008    Time 0.218314    
2023-04-27 06:20:59,240 - Epoch: [324][  500/  518]    Overall Loss 2.892709    Objective Loss 2.892709                                        LR 0.000008    Time 0.217964    
2023-04-27 06:21:03,027 - Epoch: [324][  518/  518]    Overall Loss 2.890051    Objective Loss 2.890051                                        LR 0.000008    Time 0.217700    
2023-04-27 06:21:03,104 - --- validate (epoch=324)-----------
2023-04-27 06:21:03,104 - 4952 samples (32 per mini-batch)
2023-04-27 06:21:11,408 - Epoch: [324][   50/  155]    Loss 3.094703    mAP 0.455757    
2023-04-27 06:21:19,288 - Epoch: [324][  100/  155]    Loss 3.077866    mAP 0.451941    
2023-04-27 06:21:27,149 - Epoch: [324][  150/  155]    Loss 3.063720    mAP 0.446753    
2023-04-27 06:21:27,871 - Epoch: [324][  155/  155]    Loss 3.061556    mAP 0.444977    
2023-04-27 06:21:27,944 - ==> mAP: 0.44498    Loss: 3.062

2023-04-27 06:21:27,949 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:21:27,949 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:21:27,983 - 

2023-04-27 06:21:27,983 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:21:39,547 - Epoch: [325][   50/  518]    Overall Loss 2.911008    Objective Loss 2.911008                                        LR 0.000008    Time 0.231212    
2023-04-27 06:21:50,332 - Epoch: [325][  100/  518]    Overall Loss 2.901441    Objective Loss 2.901441                                        LR 0.000008    Time 0.223447    
2023-04-27 06:22:01,142 - Epoch: [325][  150/  518]    Overall Loss 2.874001    Objective Loss 2.874001                                        LR 0.000008    Time 0.221017    
2023-04-27 06:22:12,005 - Epoch: [325][  200/  518]    Overall Loss 2.874964    Objective Loss 2.874964                                        LR 0.000008    Time 0.220072    
2023-04-27 06:22:22,809 - Epoch: [325][  250/  518]    Overall Loss 2.881794    Objective Loss 2.881794                                        LR 0.000008    Time 0.219267    
2023-04-27 06:22:33,586 - Epoch: [325][  300/  518]    Overall Loss 2.875110    Objective Loss 2.875110                                        LR 0.000008    Time 0.218642    
2023-04-27 06:22:44,506 - Epoch: [325][  350/  518]    Overall Loss 2.877564    Objective Loss 2.877564                                        LR 0.000008    Time 0.218601    
2023-04-27 06:22:55,280 - Epoch: [325][  400/  518]    Overall Loss 2.879941    Objective Loss 2.879941                                        LR 0.000008    Time 0.218207    
2023-04-27 06:23:06,156 - Epoch: [325][  450/  518]    Overall Loss 2.878470    Objective Loss 2.878470                                        LR 0.000008    Time 0.218128    
2023-04-27 06:23:16,919 - Epoch: [325][  500/  518]    Overall Loss 2.879633    Objective Loss 2.879633                                        LR 0.000008    Time 0.217837    
2023-04-27 06:23:20,711 - Epoch: [325][  518/  518]    Overall Loss 2.878834    Objective Loss 2.878834                                        LR 0.000008    Time 0.217587    
2023-04-27 06:23:20,787 - --- validate (epoch=325)-----------
2023-04-27 06:23:20,788 - 4952 samples (32 per mini-batch)
2023-04-27 06:23:29,061 - Epoch: [325][   50/  155]    Loss 3.074802    mAP 0.436184    
2023-04-27 06:23:36,980 - Epoch: [325][  100/  155]    Loss 3.030940    mAP 0.452566    
2023-04-27 06:23:44,882 - Epoch: [325][  150/  155]    Loss 3.055082    mAP 0.442528    
2023-04-27 06:23:45,596 - Epoch: [325][  155/  155]    Loss 3.051174    mAP 0.444043    
2023-04-27 06:23:45,669 - ==> mAP: 0.44404    Loss: 3.051

2023-04-27 06:23:45,672 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:23:45,672 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:23:45,707 - 

2023-04-27 06:23:45,707 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:23:57,303 - Epoch: [326][   50/  518]    Overall Loss 2.908570    Objective Loss 2.908570                                        LR 0.000008    Time 0.231863    
2023-04-27 06:24:08,159 - Epoch: [326][  100/  518]    Overall Loss 2.898901    Objective Loss 2.898901                                        LR 0.000008    Time 0.224483    
2023-04-27 06:24:18,995 - Epoch: [326][  150/  518]    Overall Loss 2.880191    Objective Loss 2.880191                                        LR 0.000008    Time 0.221885    
2023-04-27 06:24:29,764 - Epoch: [326][  200/  518]    Overall Loss 2.874177    Objective Loss 2.874177                                        LR 0.000008    Time 0.220248    
2023-04-27 06:24:40,617 - Epoch: [326][  250/  518]    Overall Loss 2.879562    Objective Loss 2.879562                                        LR 0.000008    Time 0.219603    
2023-04-27 06:24:51,386 - Epoch: [326][  300/  518]    Overall Loss 2.886982    Objective Loss 2.886982                                        LR 0.000008    Time 0.218895    
2023-04-27 06:25:02,217 - Epoch: [326][  350/  518]    Overall Loss 2.889449    Objective Loss 2.889449                                        LR 0.000008    Time 0.218566    
2023-04-27 06:25:13,092 - Epoch: [326][  400/  518]    Overall Loss 2.895499    Objective Loss 2.895499                                        LR 0.000008    Time 0.218430    
2023-04-27 06:25:23,956 - Epoch: [326][  450/  518]    Overall Loss 2.888790    Objective Loss 2.888790                                        LR 0.000008    Time 0.218298    
2023-04-27 06:25:34,803 - Epoch: [326][  500/  518]    Overall Loss 2.885354    Objective Loss 2.885354                                        LR 0.000008    Time 0.218159    
2023-04-27 06:25:38,557 - Epoch: [326][  518/  518]    Overall Loss 2.881311    Objective Loss 2.881311                                        LR 0.000008    Time 0.217825    
2023-04-27 06:25:38,634 - --- validate (epoch=326)-----------
2023-04-27 06:25:38,634 - 4952 samples (32 per mini-batch)
2023-04-27 06:25:46,929 - Epoch: [326][   50/  155]    Loss 3.056035    mAP 0.437483    
2023-04-27 06:25:54,848 - Epoch: [326][  100/  155]    Loss 3.063077    mAP 0.443356    
2023-04-27 06:26:02,821 - Epoch: [326][  150/  155]    Loss 3.068978    mAP 0.445289    
2023-04-27 06:26:03,540 - Epoch: [326][  155/  155]    Loss 3.067191    mAP 0.444444    
2023-04-27 06:26:03,610 - ==> mAP: 0.44444    Loss: 3.067

2023-04-27 06:26:03,614 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:26:03,614 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:26:03,648 - 

2023-04-27 06:26:03,648 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:26:15,169 - Epoch: [327][   50/  518]    Overall Loss 2.898067    Objective Loss 2.898067                                        LR 0.000008    Time 0.230360    
2023-04-27 06:26:25,888 - Epoch: [327][  100/  518]    Overall Loss 2.870731    Objective Loss 2.870731                                        LR 0.000008    Time 0.222351    
2023-04-27 06:26:36,755 - Epoch: [327][  150/  518]    Overall Loss 2.894087    Objective Loss 2.894087                                        LR 0.000008    Time 0.220670    
2023-04-27 06:26:47,556 - Epoch: [327][  200/  518]    Overall Loss 2.891628    Objective Loss 2.891628                                        LR 0.000008    Time 0.219498    
2023-04-27 06:26:58,379 - Epoch: [327][  250/  518]    Overall Loss 2.884486    Objective Loss 2.884486                                        LR 0.000008    Time 0.218885    
2023-04-27 06:27:09,151 - Epoch: [327][  300/  518]    Overall Loss 2.888028    Objective Loss 2.888028                                        LR 0.000008    Time 0.218307    
2023-04-27 06:27:19,980 - Epoch: [327][  350/  518]    Overall Loss 2.883897    Objective Loss 2.883897                                        LR 0.000008    Time 0.218055    
2023-04-27 06:27:30,763 - Epoch: [327][  400/  518]    Overall Loss 2.884500    Objective Loss 2.884500                                        LR 0.000008    Time 0.217752    
2023-04-27 06:27:41,598 - Epoch: [327][  450/  518]    Overall Loss 2.883573    Objective Loss 2.883573                                        LR 0.000008    Time 0.217632    
2023-04-27 06:27:52,368 - Epoch: [327][  500/  518]    Overall Loss 2.887208    Objective Loss 2.887208                                        LR 0.000008    Time 0.217405    
2023-04-27 06:27:56,086 - Epoch: [327][  518/  518]    Overall Loss 2.891060    Objective Loss 2.891060                                        LR 0.000008    Time 0.217028    
2023-04-27 06:27:56,162 - --- validate (epoch=327)-----------
2023-04-27 06:27:56,162 - 4952 samples (32 per mini-batch)
2023-04-27 06:28:04,447 - Epoch: [327][   50/  155]    Loss 3.056293    mAP 0.450105    
2023-04-27 06:28:12,355 - Epoch: [327][  100/  155]    Loss 3.066155    mAP 0.438426    
2023-04-27 06:28:20,227 - Epoch: [327][  150/  155]    Loss 3.070656    mAP 0.435238    
2023-04-27 06:28:20,942 - Epoch: [327][  155/  155]    Loss 3.072287    mAP 0.436123    
2023-04-27 06:28:21,012 - ==> mAP: 0.43612    Loss: 3.072

2023-04-27 06:28:21,017 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:28:21,017 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:28:21,052 - 

2023-04-27 06:28:21,052 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:28:32,583 - Epoch: [328][   50/  518]    Overall Loss 2.900690    Objective Loss 2.900690                                        LR 0.000008    Time 0.230551    
2023-04-27 06:28:43,372 - Epoch: [328][  100/  518]    Overall Loss 2.869431    Objective Loss 2.869431                                        LR 0.000008    Time 0.223148    
2023-04-27 06:28:54,201 - Epoch: [328][  150/  518]    Overall Loss 2.879019    Objective Loss 2.879019                                        LR 0.000008    Time 0.220950    
2023-04-27 06:29:05,040 - Epoch: [328][  200/  518]    Overall Loss 2.870048    Objective Loss 2.870048                                        LR 0.000008    Time 0.219903    
2023-04-27 06:29:15,806 - Epoch: [328][  250/  518]    Overall Loss 2.879479    Objective Loss 2.879479                                        LR 0.000008    Time 0.218978    
2023-04-27 06:29:26,609 - Epoch: [328][  300/  518]    Overall Loss 2.880988    Objective Loss 2.880988                                        LR 0.000008    Time 0.218486    
2023-04-27 06:29:37,465 - Epoch: [328][  350/  518]    Overall Loss 2.882757    Objective Loss 2.882757                                        LR 0.000008    Time 0.218287    
2023-04-27 06:29:48,351 - Epoch: [328][  400/  518]    Overall Loss 2.889510    Objective Loss 2.889510                                        LR 0.000008    Time 0.218211    
2023-04-27 06:29:59,166 - Epoch: [328][  450/  518]    Overall Loss 2.887727    Objective Loss 2.887727                                        LR 0.000008    Time 0.217995    
2023-04-27 06:30:09,963 - Epoch: [328][  500/  518]    Overall Loss 2.885643    Objective Loss 2.885643                                        LR 0.000008    Time 0.217788    
2023-04-27 06:30:13,652 - Epoch: [328][  518/  518]    Overall Loss 2.885454    Objective Loss 2.885454                                        LR 0.000008    Time 0.217340    
2023-04-27 06:30:13,728 - --- validate (epoch=328)-----------
2023-04-27 06:30:13,728 - 4952 samples (32 per mini-batch)
2023-04-27 06:30:22,051 - Epoch: [328][   50/  155]    Loss 3.044973    mAP 0.452938    
2023-04-27 06:30:29,938 - Epoch: [328][  100/  155]    Loss 3.073371    mAP 0.445014    
2023-04-27 06:30:37,866 - Epoch: [328][  150/  155]    Loss 3.049382    mAP 0.446826    
2023-04-27 06:30:38,592 - Epoch: [328][  155/  155]    Loss 3.047892    mAP 0.447708    
2023-04-27 06:30:38,674 - ==> mAP: 0.44771    Loss: 3.048

2023-04-27 06:30:38,678 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:30:38,679 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:30:38,714 - 

2023-04-27 06:30:38,714 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:30:50,378 - Epoch: [329][   50/  518]    Overall Loss 2.834687    Objective Loss 2.834687                                        LR 0.000008    Time 0.233223    
2023-04-27 06:31:01,193 - Epoch: [329][  100/  518]    Overall Loss 2.859768    Objective Loss 2.859768                                        LR 0.000008    Time 0.224749    
2023-04-27 06:31:11,979 - Epoch: [329][  150/  518]    Overall Loss 2.881079    Objective Loss 2.881079                                        LR 0.000008    Time 0.221726    
2023-04-27 06:31:22,724 - Epoch: [329][  200/  518]    Overall Loss 2.883617    Objective Loss 2.883617                                        LR 0.000008    Time 0.220014    
2023-04-27 06:31:33,575 - Epoch: [329][  250/  518]    Overall Loss 2.889886    Objective Loss 2.889886                                        LR 0.000008    Time 0.219408    
2023-04-27 06:31:44,391 - Epoch: [329][  300/  518]    Overall Loss 2.886845    Objective Loss 2.886845                                        LR 0.000008    Time 0.218887    
2023-04-27 06:31:55,275 - Epoch: [329][  350/  518]    Overall Loss 2.885857    Objective Loss 2.885857                                        LR 0.000008    Time 0.218710    
2023-04-27 06:32:06,130 - Epoch: [329][  400/  518]    Overall Loss 2.886947    Objective Loss 2.886947                                        LR 0.000008    Time 0.218505    
2023-04-27 06:32:16,987 - Epoch: [329][  450/  518]    Overall Loss 2.888617    Objective Loss 2.888617                                        LR 0.000008    Time 0.218351    
2023-04-27 06:32:27,730 - Epoch: [329][  500/  518]    Overall Loss 2.884868    Objective Loss 2.884868                                        LR 0.000008    Time 0.217998    
2023-04-27 06:32:31,498 - Epoch: [329][  518/  518]    Overall Loss 2.885200    Objective Loss 2.885200                                        LR 0.000008    Time 0.217697    
2023-04-27 06:32:31,577 - --- validate (epoch=329)-----------
2023-04-27 06:32:31,577 - 4952 samples (32 per mini-batch)
2023-04-27 06:32:39,910 - Epoch: [329][   50/  155]    Loss 3.069027    mAP 0.450778    
2023-04-27 06:32:47,812 - Epoch: [329][  100/  155]    Loss 3.081711    mAP 0.438957    
2023-04-27 06:32:55,732 - Epoch: [329][  150/  155]    Loss 3.078926    mAP 0.437345    
2023-04-27 06:32:56,449 - Epoch: [329][  155/  155]    Loss 3.075851    mAP 0.437486    
2023-04-27 06:32:56,521 - ==> mAP: 0.43749    Loss: 3.076

2023-04-27 06:32:56,525 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:32:56,525 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:32:56,560 - 

2023-04-27 06:32:56,560 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:33:08,192 - Epoch: [330][   50/  518]    Overall Loss 2.931801    Objective Loss 2.931801                                        LR 0.000008    Time 0.232576    
2023-04-27 06:33:18,966 - Epoch: [330][  100/  518]    Overall Loss 2.925898    Objective Loss 2.925898                                        LR 0.000008    Time 0.224018    
2023-04-27 06:33:29,801 - Epoch: [330][  150/  518]    Overall Loss 2.920256    Objective Loss 2.920256                                        LR 0.000008    Time 0.221567    
2023-04-27 06:33:40,653 - Epoch: [330][  200/  518]    Overall Loss 2.918358    Objective Loss 2.918358                                        LR 0.000008    Time 0.220427    
2023-04-27 06:33:51,403 - Epoch: [330][  250/  518]    Overall Loss 2.907304    Objective Loss 2.907304                                        LR 0.000008    Time 0.219336    
2023-04-27 06:34:02,229 - Epoch: [330][  300/  518]    Overall Loss 2.899963    Objective Loss 2.899963                                        LR 0.000008    Time 0.218859    
2023-04-27 06:34:13,066 - Epoch: [330][  350/  518]    Overall Loss 2.903187    Objective Loss 2.903187                                        LR 0.000008    Time 0.218552    
2023-04-27 06:34:23,931 - Epoch: [330][  400/  518]    Overall Loss 2.899241    Objective Loss 2.899241                                        LR 0.000008    Time 0.218392    
2023-04-27 06:34:34,742 - Epoch: [330][  450/  518]    Overall Loss 2.892030    Objective Loss 2.892030                                        LR 0.000008    Time 0.218147    
2023-04-27 06:34:45,585 - Epoch: [330][  500/  518]    Overall Loss 2.889948    Objective Loss 2.889948                                        LR 0.000008    Time 0.218016    
2023-04-27 06:34:49,384 - Epoch: [330][  518/  518]    Overall Loss 2.892552    Objective Loss 2.892552                                        LR 0.000008    Time 0.217773    
2023-04-27 06:34:49,459 - --- validate (epoch=330)-----------
2023-04-27 06:34:49,459 - 4952 samples (32 per mini-batch)
2023-04-27 06:34:57,766 - Epoch: [330][   50/  155]    Loss 3.082450    mAP 0.427523    
2023-04-27 06:35:05,669 - Epoch: [330][  100/  155]    Loss 3.069876    mAP 0.430367    
2023-04-27 06:35:13,528 - Epoch: [330][  150/  155]    Loss 3.045054    mAP 0.436674    
2023-04-27 06:35:14,257 - Epoch: [330][  155/  155]    Loss 3.044736    mAP 0.439067    
2023-04-27 06:35:14,337 - ==> mAP: 0.43907    Loss: 3.045

2023-04-27 06:35:14,340 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:35:14,340 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:35:14,444 - 

2023-04-27 06:35:14,444 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:35:26,037 - Epoch: [331][   50/  518]    Overall Loss 2.936068    Objective Loss 2.936068                                        LR 0.000008    Time 0.231801    
2023-04-27 06:35:36,777 - Epoch: [331][  100/  518]    Overall Loss 2.906689    Objective Loss 2.906689                                        LR 0.000008    Time 0.223293    
2023-04-27 06:35:47,564 - Epoch: [331][  150/  518]    Overall Loss 2.886034    Objective Loss 2.886034                                        LR 0.000008    Time 0.220762    
2023-04-27 06:35:58,373 - Epoch: [331][  200/  518]    Overall Loss 2.898304    Objective Loss 2.898304                                        LR 0.000008    Time 0.219610    
2023-04-27 06:36:09,223 - Epoch: [331][  250/  518]    Overall Loss 2.891306    Objective Loss 2.891306                                        LR 0.000008    Time 0.219079    
2023-04-27 06:36:20,082 - Epoch: [331][  300/  518]    Overall Loss 2.877816    Objective Loss 2.877816                                        LR 0.000008    Time 0.218760    
2023-04-27 06:36:30,886 - Epoch: [331][  350/  518]    Overall Loss 2.873017    Objective Loss 2.873017                                        LR 0.000008    Time 0.218372    
2023-04-27 06:36:41,751 - Epoch: [331][  400/  518]    Overall Loss 2.874977    Objective Loss 2.874977                                        LR 0.000008    Time 0.218233    
2023-04-27 06:36:52,525 - Epoch: [331][  450/  518]    Overall Loss 2.872947    Objective Loss 2.872947                                        LR 0.000008    Time 0.217924    
2023-04-27 06:37:03,251 - Epoch: [331][  500/  518]    Overall Loss 2.874404    Objective Loss 2.874404                                        LR 0.000008    Time 0.217582    
2023-04-27 06:37:06,989 - Epoch: [331][  518/  518]    Overall Loss 2.873884    Objective Loss 2.873884                                        LR 0.000008    Time 0.217235    
2023-04-27 06:37:07,064 - --- validate (epoch=331)-----------
2023-04-27 06:37:07,064 - 4952 samples (32 per mini-batch)
2023-04-27 06:37:15,321 - Epoch: [331][   50/  155]    Loss 3.044048    mAP 0.443784    
2023-04-27 06:37:23,207 - Epoch: [331][  100/  155]    Loss 3.038157    mAP 0.444719    
2023-04-27 06:37:31,150 - Epoch: [331][  150/  155]    Loss 3.043248    mAP 0.448525    
2023-04-27 06:37:31,871 - Epoch: [331][  155/  155]    Loss 3.041405    mAP 0.448534    
2023-04-27 06:37:31,947 - ==> mAP: 0.44853    Loss: 3.041

2023-04-27 06:37:31,951 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:37:31,951 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:37:31,985 - 

2023-04-27 06:37:31,985 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:37:43,431 - Epoch: [332][   50/  518]    Overall Loss 2.950423    Objective Loss 2.950423                                        LR 0.000008    Time 0.228867    
2023-04-27 06:37:54,249 - Epoch: [332][  100/  518]    Overall Loss 2.909618    Objective Loss 2.909618                                        LR 0.000008    Time 0.222598    
2023-04-27 06:38:05,054 - Epoch: [332][  150/  518]    Overall Loss 2.907474    Objective Loss 2.907474                                        LR 0.000008    Time 0.220427    
2023-04-27 06:38:15,829 - Epoch: [332][  200/  518]    Overall Loss 2.898411    Objective Loss 2.898411                                        LR 0.000008    Time 0.219182    
2023-04-27 06:38:26,597 - Epoch: [332][  250/  518]    Overall Loss 2.890587    Objective Loss 2.890587                                        LR 0.000008    Time 0.218414    
2023-04-27 06:38:37,527 - Epoch: [332][  300/  518]    Overall Loss 2.898944    Objective Loss 2.898944                                        LR 0.000008    Time 0.218439    
2023-04-27 06:38:48,337 - Epoch: [332][  350/  518]    Overall Loss 2.898592    Objective Loss 2.898592                                        LR 0.000008    Time 0.218115    
2023-04-27 06:38:59,137 - Epoch: [332][  400/  518]    Overall Loss 2.896275    Objective Loss 2.896275                                        LR 0.000008    Time 0.217847    
2023-04-27 06:39:09,983 - Epoch: [332][  450/  518]    Overall Loss 2.890017    Objective Loss 2.890017                                        LR 0.000008    Time 0.217741    
2023-04-27 06:39:20,825 - Epoch: [332][  500/  518]    Overall Loss 2.885572    Objective Loss 2.885572                                        LR 0.000008    Time 0.217647    
2023-04-27 06:39:24,572 - Epoch: [332][  518/  518]    Overall Loss 2.884428    Objective Loss 2.884428                                        LR 0.000008    Time 0.217316    
2023-04-27 06:39:24,648 - --- validate (epoch=332)-----------
2023-04-27 06:39:24,649 - 4952 samples (32 per mini-batch)
2023-04-27 06:39:32,967 - Epoch: [332][   50/  155]    Loss 3.066585    mAP 0.446004    
2023-04-27 06:39:40,874 - Epoch: [332][  100/  155]    Loss 3.056042    mAP 0.449794    
2023-04-27 06:39:48,782 - Epoch: [332][  150/  155]    Loss 3.066761    mAP 0.448393    
2023-04-27 06:39:49,499 - Epoch: [332][  155/  155]    Loss 3.066857    mAP 0.446726    
2023-04-27 06:39:49,572 - ==> mAP: 0.44673    Loss: 3.067

2023-04-27 06:39:49,576 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:39:49,576 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:39:49,625 - 

2023-04-27 06:39:49,625 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:40:01,400 - Epoch: [333][   50/  518]    Overall Loss 2.936023    Objective Loss 2.936023                                        LR 0.000008    Time 0.235430    
2023-04-27 06:40:12,166 - Epoch: [333][  100/  518]    Overall Loss 2.869060    Objective Loss 2.869060                                        LR 0.000008    Time 0.225354    
2023-04-27 06:40:22,960 - Epoch: [333][  150/  518]    Overall Loss 2.873143    Objective Loss 2.873143                                        LR 0.000008    Time 0.222187    
2023-04-27 06:40:33,807 - Epoch: [333][  200/  518]    Overall Loss 2.864825    Objective Loss 2.864825                                        LR 0.000008    Time 0.220864    
2023-04-27 06:40:44,588 - Epoch: [333][  250/  518]    Overall Loss 2.873664    Objective Loss 2.873664                                        LR 0.000008    Time 0.219812    
2023-04-27 06:40:55,486 - Epoch: [333][  300/  518]    Overall Loss 2.874126    Objective Loss 2.874126                                        LR 0.000008    Time 0.219498    
2023-04-27 06:41:06,305 - Epoch: [333][  350/  518]    Overall Loss 2.877582    Objective Loss 2.877582                                        LR 0.000008    Time 0.219048    
2023-04-27 06:41:17,152 - Epoch: [333][  400/  518]    Overall Loss 2.881041    Objective Loss 2.881041                                        LR 0.000008    Time 0.218779    
2023-04-27 06:41:28,066 - Epoch: [333][  450/  518]    Overall Loss 2.885089    Objective Loss 2.885089                                        LR 0.000008    Time 0.218721    
2023-04-27 06:41:38,884 - Epoch: [333][  500/  518]    Overall Loss 2.888064    Objective Loss 2.888064                                        LR 0.000008    Time 0.218482    
2023-04-27 06:41:42,626 - Epoch: [333][  518/  518]    Overall Loss 2.887068    Objective Loss 2.887068                                        LR 0.000008    Time 0.218112    
2023-04-27 06:41:42,702 - --- validate (epoch=333)-----------
2023-04-27 06:41:42,702 - 4952 samples (32 per mini-batch)
2023-04-27 06:41:51,056 - Epoch: [333][   50/  155]    Loss 3.037465    mAP 0.455866    
2023-04-27 06:41:59,018 - Epoch: [333][  100/  155]    Loss 3.063801    mAP 0.446767    
2023-04-27 06:42:06,952 - Epoch: [333][  150/  155]    Loss 3.062277    mAP 0.449134    
2023-04-27 06:42:07,663 - Epoch: [333][  155/  155]    Loss 3.063741    mAP 0.447446    
2023-04-27 06:42:07,730 - ==> mAP: 0.44745    Loss: 3.064

2023-04-27 06:42:07,734 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:42:07,734 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:42:07,768 - 

2023-04-27 06:42:07,768 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:42:19,420 - Epoch: [334][   50/  518]    Overall Loss 2.922745    Objective Loss 2.922745                                        LR 0.000008    Time 0.232982    
2023-04-27 06:42:30,258 - Epoch: [334][  100/  518]    Overall Loss 2.905347    Objective Loss 2.905347                                        LR 0.000008    Time 0.224859    
2023-04-27 06:42:41,035 - Epoch: [334][  150/  518]    Overall Loss 2.906397    Objective Loss 2.906397                                        LR 0.000008    Time 0.221741    
2023-04-27 06:42:51,817 - Epoch: [334][  200/  518]    Overall Loss 2.884563    Objective Loss 2.884563                                        LR 0.000008    Time 0.220206    
2023-04-27 06:43:02,686 - Epoch: [334][  250/  518]    Overall Loss 2.873199    Objective Loss 2.873199                                        LR 0.000008    Time 0.219636    
2023-04-27 06:43:13,498 - Epoch: [334][  300/  518]    Overall Loss 2.879659    Objective Loss 2.879659                                        LR 0.000008    Time 0.219066    
2023-04-27 06:43:24,350 - Epoch: [334][  350/  518]    Overall Loss 2.884138    Objective Loss 2.884138                                        LR 0.000008    Time 0.218770    
2023-04-27 06:43:35,138 - Epoch: [334][  400/  518]    Overall Loss 2.886528    Objective Loss 2.886528                                        LR 0.000008    Time 0.218390    
2023-04-27 06:43:45,986 - Epoch: [334][  450/  518]    Overall Loss 2.888450    Objective Loss 2.888450                                        LR 0.000008    Time 0.218228    
2023-04-27 06:43:56,908 - Epoch: [334][  500/  518]    Overall Loss 2.884173    Objective Loss 2.884173                                        LR 0.000008    Time 0.218246    
2023-04-27 06:44:00,668 - Epoch: [334][  518/  518]    Overall Loss 2.882601    Objective Loss 2.882601                                        LR 0.000008    Time 0.217920    
2023-04-27 06:44:00,745 - --- validate (epoch=334)-----------
2023-04-27 06:44:00,745 - 4952 samples (32 per mini-batch)
2023-04-27 06:44:09,072 - Epoch: [334][   50/  155]    Loss 3.009885    mAP 0.460090    
2023-04-27 06:44:17,015 - Epoch: [334][  100/  155]    Loss 3.013375    mAP 0.454209    
2023-04-27 06:44:24,899 - Epoch: [334][  150/  155]    Loss 3.043151    mAP 0.449772    
2023-04-27 06:44:25,615 - Epoch: [334][  155/  155]    Loss 3.044924    mAP 0.448501    
2023-04-27 06:44:25,691 - ==> mAP: 0.44850    Loss: 3.045

2023-04-27 06:44:25,695 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:44:25,695 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:44:25,730 - 

2023-04-27 06:44:25,730 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:44:37,289 - Epoch: [335][   50/  518]    Overall Loss 2.873582    Objective Loss 2.873582                                        LR 0.000008    Time 0.231128    
2023-04-27 06:44:48,081 - Epoch: [335][  100/  518]    Overall Loss 2.873824    Objective Loss 2.873824                                        LR 0.000008    Time 0.223465    
2023-04-27 06:44:58,894 - Epoch: [335][  150/  518]    Overall Loss 2.893780    Objective Loss 2.893780                                        LR 0.000008    Time 0.221054    
2023-04-27 06:45:09,728 - Epoch: [335][  200/  518]    Overall Loss 2.895770    Objective Loss 2.895770                                        LR 0.000008    Time 0.219953    
2023-04-27 06:45:20,483 - Epoch: [335][  250/  518]    Overall Loss 2.893931    Objective Loss 2.893931                                        LR 0.000008    Time 0.218976    
2023-04-27 06:45:31,328 - Epoch: [335][  300/  518]    Overall Loss 2.882284    Objective Loss 2.882284                                        LR 0.000008    Time 0.218625    
2023-04-27 06:45:42,121 - Epoch: [335][  350/  518]    Overall Loss 2.881195    Objective Loss 2.881195                                        LR 0.000008    Time 0.218227    
2023-04-27 06:45:52,868 - Epoch: [335][  400/  518]    Overall Loss 2.875284    Objective Loss 2.875284                                        LR 0.000008    Time 0.217811    
2023-04-27 06:46:03,680 - Epoch: [335][  450/  518]    Overall Loss 2.875264    Objective Loss 2.875264                                        LR 0.000008    Time 0.217632    
2023-04-27 06:46:14,490 - Epoch: [335][  500/  518]    Overall Loss 2.876649    Objective Loss 2.876649                                        LR 0.000008    Time 0.217486    
2023-04-27 06:46:18,253 - Epoch: [335][  518/  518]    Overall Loss 2.878970    Objective Loss 2.878970                                        LR 0.000008    Time 0.217193    
2023-04-27 06:46:18,331 - --- validate (epoch=335)-----------
2023-04-27 06:46:18,331 - 4952 samples (32 per mini-batch)
2023-04-27 06:46:26,628 - Epoch: [335][   50/  155]    Loss 3.027470    mAP 0.437844    
2023-04-27 06:46:34,546 - Epoch: [335][  100/  155]    Loss 3.036690    mAP 0.441274    
2023-04-27 06:46:42,467 - Epoch: [335][  150/  155]    Loss 3.052467    mAP 0.446885    
2023-04-27 06:46:43,188 - Epoch: [335][  155/  155]    Loss 3.050040    mAP 0.448861    
2023-04-27 06:46:43,260 - ==> mAP: 0.44886    Loss: 3.050

2023-04-27 06:46:43,264 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:46:43,265 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:46:43,300 - 

2023-04-27 06:46:43,300 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:46:54,782 - Epoch: [336][   50/  518]    Overall Loss 2.857091    Objective Loss 2.857091                                        LR 0.000008    Time 0.229583    
2023-04-27 06:47:05,626 - Epoch: [336][  100/  518]    Overall Loss 2.874416    Objective Loss 2.874416                                        LR 0.000008    Time 0.223215    
2023-04-27 06:47:16,521 - Epoch: [336][  150/  518]    Overall Loss 2.871755    Objective Loss 2.871755                                        LR 0.000008    Time 0.221437    
2023-04-27 06:47:27,348 - Epoch: [336][  200/  518]    Overall Loss 2.878941    Objective Loss 2.878941                                        LR 0.000008    Time 0.220203    
2023-04-27 06:47:38,122 - Epoch: [336][  250/  518]    Overall Loss 2.883217    Objective Loss 2.883217                                        LR 0.000008    Time 0.219251    
2023-04-27 06:47:48,890 - Epoch: [336][  300/  518]    Overall Loss 2.879619    Objective Loss 2.879619                                        LR 0.000008    Time 0.218597    
2023-04-27 06:47:59,674 - Epoch: [336][  350/  518]    Overall Loss 2.882386    Objective Loss 2.882386                                        LR 0.000008    Time 0.218177    
2023-04-27 06:48:10,482 - Epoch: [336][  400/  518]    Overall Loss 2.883788    Objective Loss 2.883788                                        LR 0.000008    Time 0.217921    
2023-04-27 06:48:21,204 - Epoch: [336][  450/  518]    Overall Loss 2.883968    Objective Loss 2.883968                                        LR 0.000008    Time 0.217530    
2023-04-27 06:48:31,994 - Epoch: [336][  500/  518]    Overall Loss 2.887979    Objective Loss 2.887979                                        LR 0.000008    Time 0.217355    
2023-04-27 06:48:35,748 - Epoch: [336][  518/  518]    Overall Loss 2.890151    Objective Loss 2.890151                                        LR 0.000008    Time 0.217047    
2023-04-27 06:48:35,824 - --- validate (epoch=336)-----------
2023-04-27 06:48:35,824 - 4952 samples (32 per mini-batch)
2023-04-27 06:48:44,088 - Epoch: [336][   50/  155]    Loss 3.025618    mAP 0.463452    
2023-04-27 06:48:52,026 - Epoch: [336][  100/  155]    Loss 3.045393    mAP 0.453762    
2023-04-27 06:48:59,883 - Epoch: [336][  150/  155]    Loss 3.040149    mAP 0.449073    
2023-04-27 06:49:00,608 - Epoch: [336][  155/  155]    Loss 3.039450    mAP 0.448359    
2023-04-27 06:49:00,687 - ==> mAP: 0.44836    Loss: 3.039

2023-04-27 06:49:00,690 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:49:00,690 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:49:00,725 - 

2023-04-27 06:49:00,725 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:49:12,271 - Epoch: [337][   50/  518]    Overall Loss 2.874777    Objective Loss 2.874777                                        LR 0.000008    Time 0.230862    
2023-04-27 06:49:23,063 - Epoch: [337][  100/  518]    Overall Loss 2.871591    Objective Loss 2.871591                                        LR 0.000008    Time 0.223332    
2023-04-27 06:49:33,840 - Epoch: [337][  150/  518]    Overall Loss 2.886036    Objective Loss 2.886036                                        LR 0.000008    Time 0.220728    
2023-04-27 06:49:44,657 - Epoch: [337][  200/  518]    Overall Loss 2.877313    Objective Loss 2.877313                                        LR 0.000008    Time 0.219621    
2023-04-27 06:49:55,479 - Epoch: [337][  250/  518]    Overall Loss 2.887858    Objective Loss 2.887858                                        LR 0.000008    Time 0.218981    
2023-04-27 06:50:06,299 - Epoch: [337][  300/  518]    Overall Loss 2.887338    Objective Loss 2.887338                                        LR 0.000008    Time 0.218545    
2023-04-27 06:50:17,162 - Epoch: [337][  350/  518]    Overall Loss 2.881819    Objective Loss 2.881819                                        LR 0.000008    Time 0.218358    
2023-04-27 06:50:27,912 - Epoch: [337][  400/  518]    Overall Loss 2.883407    Objective Loss 2.883407                                        LR 0.000008    Time 0.217933    
2023-04-27 06:50:38,684 - Epoch: [337][  450/  518]    Overall Loss 2.887523    Objective Loss 2.887523                                        LR 0.000008    Time 0.217653    
2023-04-27 06:50:49,427 - Epoch: [337][  500/  518]    Overall Loss 2.883038    Objective Loss 2.883038                                        LR 0.000008    Time 0.217370    
2023-04-27 06:50:53,189 - Epoch: [337][  518/  518]    Overall Loss 2.883113    Objective Loss 2.883113                                        LR 0.000008    Time 0.217078    
2023-04-27 06:50:53,266 - --- validate (epoch=337)-----------
2023-04-27 06:50:53,266 - 4952 samples (32 per mini-batch)
2023-04-27 06:51:01,490 - Epoch: [337][   50/  155]    Loss 3.050352    mAP 0.436861    
2023-04-27 06:51:09,406 - Epoch: [337][  100/  155]    Loss 3.073283    mAP 0.439461    
2023-04-27 06:51:17,242 - Epoch: [337][  150/  155]    Loss 3.078938    mAP 0.436939    
2023-04-27 06:51:17,960 - Epoch: [337][  155/  155]    Loss 3.077194    mAP 0.436935    
2023-04-27 06:51:18,039 - ==> mAP: 0.43694    Loss: 3.077

2023-04-27 06:51:18,043 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:51:18,043 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:51:18,077 - 

2023-04-27 06:51:18,077 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:51:29,720 - Epoch: [338][   50/  518]    Overall Loss 2.860741    Objective Loss 2.860741                                        LR 0.000008    Time 0.232811    
2023-04-27 06:51:40,514 - Epoch: [338][  100/  518]    Overall Loss 2.873591    Objective Loss 2.873591                                        LR 0.000008    Time 0.224331    
2023-04-27 06:51:51,330 - Epoch: [338][  150/  518]    Overall Loss 2.887936    Objective Loss 2.887936                                        LR 0.000008    Time 0.221645    
2023-04-27 06:52:02,106 - Epoch: [338][  200/  518]    Overall Loss 2.891978    Objective Loss 2.891978                                        LR 0.000008    Time 0.220108    
2023-04-27 06:52:12,883 - Epoch: [338][  250/  518]    Overall Loss 2.898248    Objective Loss 2.898248                                        LR 0.000008    Time 0.219188    
2023-04-27 06:52:23,805 - Epoch: [338][  300/  518]    Overall Loss 2.887280    Objective Loss 2.887280                                        LR 0.000008    Time 0.219057    
2023-04-27 06:52:34,621 - Epoch: [338][  350/  518]    Overall Loss 2.887538    Objective Loss 2.887538                                        LR 0.000008    Time 0.218662    
2023-04-27 06:52:45,466 - Epoch: [338][  400/  518]    Overall Loss 2.886502    Objective Loss 2.886502                                        LR 0.000008    Time 0.218439    
2023-04-27 06:52:56,267 - Epoch: [338][  450/  518]    Overall Loss 2.882063    Objective Loss 2.882063                                        LR 0.000008    Time 0.218165    
2023-04-27 06:53:07,075 - Epoch: [338][  500/  518]    Overall Loss 2.874043    Objective Loss 2.874043                                        LR 0.000008    Time 0.217962    
2023-04-27 06:53:10,791 - Epoch: [338][  518/  518]    Overall Loss 2.873502    Objective Loss 2.873502                                        LR 0.000008    Time 0.217562    
2023-04-27 06:53:10,870 - --- validate (epoch=338)-----------
2023-04-27 06:53:10,871 - 4952 samples (32 per mini-batch)
2023-04-27 06:53:19,205 - Epoch: [338][   50/  155]    Loss 3.048899    mAP 0.463645    
2023-04-27 06:53:27,155 - Epoch: [338][  100/  155]    Loss 3.056503    mAP 0.453047    
2023-04-27 06:53:35,044 - Epoch: [338][  150/  155]    Loss 3.074269    mAP 0.440264    
2023-04-27 06:53:35,755 - Epoch: [338][  155/  155]    Loss 3.073122    mAP 0.440723    
2023-04-27 06:53:35,828 - ==> mAP: 0.44072    Loss: 3.073

2023-04-27 06:53:35,832 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:53:35,832 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:53:35,866 - 

2023-04-27 06:53:35,866 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:53:47,386 - Epoch: [339][   50/  518]    Overall Loss 2.900375    Objective Loss 2.900375                                        LR 0.000008    Time 0.230339    
2023-04-27 06:53:58,164 - Epoch: [339][  100/  518]    Overall Loss 2.882674    Objective Loss 2.882674                                        LR 0.000008    Time 0.222933    
2023-04-27 06:54:09,014 - Epoch: [339][  150/  518]    Overall Loss 2.867812    Objective Loss 2.867812                                        LR 0.000008    Time 0.220946    
2023-04-27 06:54:19,863 - Epoch: [339][  200/  518]    Overall Loss 2.873546    Objective Loss 2.873546                                        LR 0.000008    Time 0.219947    
2023-04-27 06:54:30,674 - Epoch: [339][  250/  518]    Overall Loss 2.862341    Objective Loss 2.862341                                        LR 0.000008    Time 0.219193    
2023-04-27 06:54:41,553 - Epoch: [339][  300/  518]    Overall Loss 2.869350    Objective Loss 2.869350                                        LR 0.000008    Time 0.218919    
2023-04-27 06:54:52,425 - Epoch: [339][  350/  518]    Overall Loss 2.872786    Objective Loss 2.872786                                        LR 0.000008    Time 0.218705    
2023-04-27 06:55:03,228 - Epoch: [339][  400/  518]    Overall Loss 2.877231    Objective Loss 2.877231                                        LR 0.000008    Time 0.218369    
2023-04-27 06:55:13,996 - Epoch: [339][  450/  518]    Overall Loss 2.876158    Objective Loss 2.876158                                        LR 0.000008    Time 0.218031    
2023-04-27 06:55:24,793 - Epoch: [339][  500/  518]    Overall Loss 2.876865    Objective Loss 2.876865                                        LR 0.000008    Time 0.217819    
2023-04-27 06:55:28,519 - Epoch: [339][  518/  518]    Overall Loss 2.874464    Objective Loss 2.874464                                        LR 0.000008    Time 0.217442    
2023-04-27 06:55:28,596 - --- validate (epoch=339)-----------
2023-04-27 06:55:28,596 - 4952 samples (32 per mini-batch)
2023-04-27 06:55:36,851 - Epoch: [339][   50/  155]    Loss 3.066096    mAP 0.446432    
2023-04-27 06:55:44,758 - Epoch: [339][  100/  155]    Loss 3.068812    mAP 0.449686    
2023-04-27 06:55:52,644 - Epoch: [339][  150/  155]    Loss 3.060674    mAP 0.446864    
2023-04-27 06:55:53,370 - Epoch: [339][  155/  155]    Loss 3.060034    mAP 0.445968    
2023-04-27 06:55:53,445 - ==> mAP: 0.44597    Loss: 3.060

2023-04-27 06:55:53,449 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:55:53,449 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:55:53,484 - 

2023-04-27 06:55:53,484 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:56:05,115 - Epoch: [340][   50/  518]    Overall Loss 2.897422    Objective Loss 2.897422                                        LR 0.000008    Time 0.232563    
2023-04-27 06:56:15,919 - Epoch: [340][  100/  518]    Overall Loss 2.858873    Objective Loss 2.858873                                        LR 0.000008    Time 0.224304    
2023-04-27 06:56:26,752 - Epoch: [340][  150/  518]    Overall Loss 2.873354    Objective Loss 2.873354                                        LR 0.000008    Time 0.221745    
2023-04-27 06:56:37,543 - Epoch: [340][  200/  518]    Overall Loss 2.865587    Objective Loss 2.865587                                        LR 0.000008    Time 0.220256    
2023-04-27 06:56:48,336 - Epoch: [340][  250/  518]    Overall Loss 2.868376    Objective Loss 2.868376                                        LR 0.000008    Time 0.219370    
2023-04-27 06:56:59,117 - Epoch: [340][  300/  518]    Overall Loss 2.872872    Objective Loss 2.872872                                        LR 0.000008    Time 0.218740    
2023-04-27 06:57:09,942 - Epoch: [340][  350/  518]    Overall Loss 2.873179    Objective Loss 2.873179                                        LR 0.000008    Time 0.218415    
2023-04-27 06:57:20,808 - Epoch: [340][  400/  518]    Overall Loss 2.871900    Objective Loss 2.871900                                        LR 0.000008    Time 0.218276    
2023-04-27 06:57:31,566 - Epoch: [340][  450/  518]    Overall Loss 2.870087    Objective Loss 2.870087                                        LR 0.000008    Time 0.217926    
2023-04-27 06:57:42,469 - Epoch: [340][  500/  518]    Overall Loss 2.874363    Objective Loss 2.874363                                        LR 0.000008    Time 0.217936    
2023-04-27 06:57:46,174 - Epoch: [340][  518/  518]    Overall Loss 2.874930    Objective Loss 2.874930                                        LR 0.000008    Time 0.217515    
2023-04-27 06:57:46,249 - --- validate (epoch=340)-----------
2023-04-27 06:57:46,250 - 4952 samples (32 per mini-batch)
2023-04-27 06:57:54,485 - Epoch: [340][   50/  155]    Loss 3.017373    mAP 0.444699    
2023-04-27 06:58:02,367 - Epoch: [340][  100/  155]    Loss 3.028053    mAP 0.444389    
2023-04-27 06:58:10,217 - Epoch: [340][  150/  155]    Loss 3.040823    mAP 0.438844    
2023-04-27 06:58:10,941 - Epoch: [340][  155/  155]    Loss 3.036915    mAP 0.438743    
2023-04-27 06:58:11,010 - ==> mAP: 0.43874    Loss: 3.037

2023-04-27 06:58:11,014 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 06:58:11,014 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 06:58:11,049 - 

2023-04-27 06:58:11,049 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 06:58:22,733 - Epoch: [341][   50/  518]    Overall Loss 2.904711    Objective Loss 2.904711                                        LR 0.000008    Time 0.233623    
2023-04-27 06:58:33,490 - Epoch: [341][  100/  518]    Overall Loss 2.864845    Objective Loss 2.864845                                        LR 0.000008    Time 0.224362    
2023-04-27 06:58:44,294 - Epoch: [341][  150/  518]    Overall Loss 2.877123    Objective Loss 2.877123                                        LR 0.000008    Time 0.221588    
2023-04-27 06:58:55,115 - Epoch: [341][  200/  518]    Overall Loss 2.875604    Objective Loss 2.875604                                        LR 0.000008    Time 0.220292    
2023-04-27 06:59:06,007 - Epoch: [341][  250/  518]    Overall Loss 2.870365    Objective Loss 2.870365                                        LR 0.000008    Time 0.219794    
2023-04-27 06:59:16,678 - Epoch: [341][  300/  518]    Overall Loss 2.869766    Objective Loss 2.869766                                        LR 0.000008    Time 0.218727    
2023-04-27 06:59:27,493 - Epoch: [341][  350/  518]    Overall Loss 2.874940    Objective Loss 2.874940                                        LR 0.000008    Time 0.218375    
2023-04-27 06:59:38,234 - Epoch: [341][  400/  518]    Overall Loss 2.878467    Objective Loss 2.878467                                        LR 0.000008    Time 0.217927    
2023-04-27 06:59:49,063 - Epoch: [341][  450/  518]    Overall Loss 2.876464    Objective Loss 2.876464                                        LR 0.000008    Time 0.217774    
2023-04-27 06:59:59,875 - Epoch: [341][  500/  518]    Overall Loss 2.882241    Objective Loss 2.882241                                        LR 0.000008    Time 0.217618    
2023-04-27 07:00:03,619 - Epoch: [341][  518/  518]    Overall Loss 2.879654    Objective Loss 2.879654                                        LR 0.000008    Time 0.217282    
2023-04-27 07:00:03,695 - --- validate (epoch=341)-----------
2023-04-27 07:00:03,696 - 4952 samples (32 per mini-batch)
2023-04-27 07:00:11,994 - Epoch: [341][   50/  155]    Loss 3.097212    mAP 0.422983    
2023-04-27 07:00:19,891 - Epoch: [341][  100/  155]    Loss 3.063150    mAP 0.437400    
2023-04-27 07:00:27,826 - Epoch: [341][  150/  155]    Loss 3.049876    mAP 0.447277    
2023-04-27 07:00:28,552 - Epoch: [341][  155/  155]    Loss 3.049946    mAP 0.447914    
2023-04-27 07:00:28,626 - ==> mAP: 0.44791    Loss: 3.050

2023-04-27 07:00:28,630 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:00:28,630 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:00:28,664 - 

2023-04-27 07:00:28,664 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:00:40,130 - Epoch: [342][   50/  518]    Overall Loss 2.904572    Objective Loss 2.904572                                        LR 0.000008    Time 0.229267    
2023-04-27 07:00:50,909 - Epoch: [342][  100/  518]    Overall Loss 2.896784    Objective Loss 2.896784                                        LR 0.000008    Time 0.222400    
2023-04-27 07:01:01,710 - Epoch: [342][  150/  518]    Overall Loss 2.890759    Objective Loss 2.890759                                        LR 0.000008    Time 0.220267    
2023-04-27 07:01:12,529 - Epoch: [342][  200/  518]    Overall Loss 2.881507    Objective Loss 2.881507                                        LR 0.000008    Time 0.219288    
2023-04-27 07:01:23,373 - Epoch: [342][  250/  518]    Overall Loss 2.877651    Objective Loss 2.877651                                        LR 0.000008    Time 0.218799    
2023-04-27 07:01:34,179 - Epoch: [342][  300/  518]    Overall Loss 2.876120    Objective Loss 2.876120                                        LR 0.000008    Time 0.218346    
2023-04-27 07:01:45,034 - Epoch: [342][  350/  518]    Overall Loss 2.879352    Objective Loss 2.879352                                        LR 0.000008    Time 0.218165    
2023-04-27 07:01:55,835 - Epoch: [342][  400/  518]    Overall Loss 2.886389    Objective Loss 2.886389                                        LR 0.000008    Time 0.217893    
2023-04-27 07:02:06,664 - Epoch: [342][  450/  518]    Overall Loss 2.888313    Objective Loss 2.888313                                        LR 0.000008    Time 0.217743    
2023-04-27 07:02:17,539 - Epoch: [342][  500/  518]    Overall Loss 2.883380    Objective Loss 2.883380                                        LR 0.000008    Time 0.217715    
2023-04-27 07:02:21,315 - Epoch: [342][  518/  518]    Overall Loss 2.886003    Objective Loss 2.886003                                        LR 0.000008    Time 0.217438    
2023-04-27 07:02:21,391 - --- validate (epoch=342)-----------
2023-04-27 07:02:21,391 - 4952 samples (32 per mini-batch)
2023-04-27 07:02:29,671 - Epoch: [342][   50/  155]    Loss 3.074111    mAP 0.447663    
2023-04-27 07:02:37,592 - Epoch: [342][  100/  155]    Loss 3.059137    mAP 0.442576    
2023-04-27 07:02:45,529 - Epoch: [342][  150/  155]    Loss 3.045459    mAP 0.444354    
2023-04-27 07:02:46,243 - Epoch: [342][  155/  155]    Loss 3.044636    mAP 0.443570    
2023-04-27 07:02:46,318 - ==> mAP: 0.44357    Loss: 3.045

2023-04-27 07:02:46,322 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:02:46,322 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:02:46,357 - 

2023-04-27 07:02:46,357 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:02:57,906 - Epoch: [343][   50/  518]    Overall Loss 2.889369    Objective Loss 2.889369                                        LR 0.000008    Time 0.230926    
2023-04-27 07:03:08,637 - Epoch: [343][  100/  518]    Overall Loss 2.885267    Objective Loss 2.885267                                        LR 0.000008    Time 0.222759    
2023-04-27 07:03:19,485 - Epoch: [343][  150/  518]    Overall Loss 2.880531    Objective Loss 2.880531                                        LR 0.000008    Time 0.220817    
2023-04-27 07:03:30,401 - Epoch: [343][  200/  518]    Overall Loss 2.884717    Objective Loss 2.884717                                        LR 0.000008    Time 0.220186    
2023-04-27 07:03:41,251 - Epoch: [343][  250/  518]    Overall Loss 2.878600    Objective Loss 2.878600                                        LR 0.000008    Time 0.219541    
2023-04-27 07:03:52,052 - Epoch: [343][  300/  518]    Overall Loss 2.876696    Objective Loss 2.876696                                        LR 0.000008    Time 0.218948    
2023-04-27 07:04:02,924 - Epoch: [343][  350/  518]    Overall Loss 2.876729    Objective Loss 2.876729                                        LR 0.000008    Time 0.218728    
2023-04-27 07:04:13,695 - Epoch: [343][  400/  518]    Overall Loss 2.875162    Objective Loss 2.875162                                        LR 0.000008    Time 0.218310    
2023-04-27 07:04:24,518 - Epoch: [343][  450/  518]    Overall Loss 2.877057    Objective Loss 2.877057                                        LR 0.000008    Time 0.218102    
2023-04-27 07:04:35,296 - Epoch: [343][  500/  518]    Overall Loss 2.875917    Objective Loss 2.875917                                        LR 0.000008    Time 0.217845    
2023-04-27 07:04:39,080 - Epoch: [343][  518/  518]    Overall Loss 2.877268    Objective Loss 2.877268                                        LR 0.000008    Time 0.217579    
2023-04-27 07:04:39,153 - --- validate (epoch=343)-----------
2023-04-27 07:04:39,153 - 4952 samples (32 per mini-batch)
2023-04-27 07:04:47,404 - Epoch: [343][   50/  155]    Loss 3.064848    mAP 0.427854    
2023-04-27 07:04:55,316 - Epoch: [343][  100/  155]    Loss 3.060547    mAP 0.434964    
2023-04-27 07:05:03,204 - Epoch: [343][  150/  155]    Loss 3.087715    mAP 0.436240    
2023-04-27 07:05:03,929 - Epoch: [343][  155/  155]    Loss 3.088476    mAP 0.435941    
2023-04-27 07:05:04,005 - ==> mAP: 0.43594    Loss: 3.088

2023-04-27 07:05:04,009 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:05:04,009 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:05:04,044 - 

2023-04-27 07:05:04,044 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:05:15,768 - Epoch: [344][   50/  518]    Overall Loss 2.867732    Objective Loss 2.867732                                        LR 0.000008    Time 0.234423    
2023-04-27 07:05:26,626 - Epoch: [344][  100/  518]    Overall Loss 2.875758    Objective Loss 2.875758                                        LR 0.000008    Time 0.225779    
2023-04-27 07:05:37,528 - Epoch: [344][  150/  518]    Overall Loss 2.881706    Objective Loss 2.881706                                        LR 0.000008    Time 0.223187    
2023-04-27 07:05:48,364 - Epoch: [344][  200/  518]    Overall Loss 2.858119    Objective Loss 2.858119                                        LR 0.000008    Time 0.221564    
2023-04-27 07:05:59,223 - Epoch: [344][  250/  518]    Overall Loss 2.871202    Objective Loss 2.871202                                        LR 0.000008    Time 0.220682    
2023-04-27 07:06:10,092 - Epoch: [344][  300/  518]    Overall Loss 2.871163    Objective Loss 2.871163                                        LR 0.000008    Time 0.220125    
2023-04-27 07:06:20,943 - Epoch: [344][  350/  518]    Overall Loss 2.871981    Objective Loss 2.871981                                        LR 0.000008    Time 0.219678    
2023-04-27 07:06:31,691 - Epoch: [344][  400/  518]    Overall Loss 2.869458    Objective Loss 2.869458                                        LR 0.000008    Time 0.219082    
2023-04-27 07:06:42,522 - Epoch: [344][  450/  518]    Overall Loss 2.872439    Objective Loss 2.872439                                        LR 0.000008    Time 0.218807    
2023-04-27 07:06:53,410 - Epoch: [344][  500/  518]    Overall Loss 2.870876    Objective Loss 2.870876                                        LR 0.000008    Time 0.218698    
2023-04-27 07:06:57,137 - Epoch: [344][  518/  518]    Overall Loss 2.871602    Objective Loss 2.871602                                        LR 0.000008    Time 0.218294    
2023-04-27 07:06:57,214 - --- validate (epoch=344)-----------
2023-04-27 07:06:57,214 - 4952 samples (32 per mini-batch)
2023-04-27 07:07:05,485 - Epoch: [344][   50/  155]    Loss 3.051304    mAP 0.449028    
2023-04-27 07:07:13,367 - Epoch: [344][  100/  155]    Loss 3.033700    mAP 0.450079    
2023-04-27 07:07:21,258 - Epoch: [344][  150/  155]    Loss 3.047952    mAP 0.445180    
2023-04-27 07:07:21,977 - Epoch: [344][  155/  155]    Loss 3.045243    mAP 0.446159    
2023-04-27 07:07:22,051 - ==> mAP: 0.44616    Loss: 3.045

2023-04-27 07:07:22,055 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:07:22,055 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:07:22,089 - 

2023-04-27 07:07:22,089 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:07:33,801 - Epoch: [345][   50/  518]    Overall Loss 2.867552    Objective Loss 2.867552                                        LR 0.000008    Time 0.234188    
2023-04-27 07:07:44,529 - Epoch: [345][  100/  518]    Overall Loss 2.911345    Objective Loss 2.911345                                        LR 0.000008    Time 0.224359    
2023-04-27 07:07:55,403 - Epoch: [345][  150/  518]    Overall Loss 2.885362    Objective Loss 2.885362                                        LR 0.000008    Time 0.222051    
2023-04-27 07:08:06,200 - Epoch: [345][  200/  518]    Overall Loss 2.872225    Objective Loss 2.872225                                        LR 0.000008    Time 0.220516    
2023-04-27 07:08:17,036 - Epoch: [345][  250/  518]    Overall Loss 2.863496    Objective Loss 2.863496                                        LR 0.000008    Time 0.219750    
2023-04-27 07:08:27,857 - Epoch: [345][  300/  518]    Overall Loss 2.868553    Objective Loss 2.868553                                        LR 0.000008    Time 0.219190    
2023-04-27 07:08:38,692 - Epoch: [345][  350/  518]    Overall Loss 2.865623    Objective Loss 2.865623                                        LR 0.000008    Time 0.218831    
2023-04-27 07:08:49,486 - Epoch: [345][  400/  518]    Overall Loss 2.863118    Objective Loss 2.863118                                        LR 0.000008    Time 0.218457    
2023-04-27 07:09:00,395 - Epoch: [345][  450/  518]    Overall Loss 2.864808    Objective Loss 2.864808                                        LR 0.000008    Time 0.218423    
2023-04-27 07:09:11,181 - Epoch: [345][  500/  518]    Overall Loss 2.862175    Objective Loss 2.862175                                        LR 0.000008    Time 0.218150    
2023-04-27 07:09:14,968 - Epoch: [345][  518/  518]    Overall Loss 2.860688    Objective Loss 2.860688                                        LR 0.000008    Time 0.217879    
2023-04-27 07:09:15,043 - --- validate (epoch=345)-----------
2023-04-27 07:09:15,044 - 4952 samples (32 per mini-batch)
2023-04-27 07:09:23,367 - Epoch: [345][   50/  155]    Loss 3.066918    mAP 0.459970    
2023-04-27 07:09:31,301 - Epoch: [345][  100/  155]    Loss 3.066694    mAP 0.441291    
2023-04-27 07:09:39,190 - Epoch: [345][  150/  155]    Loss 3.061279    mAP 0.439354    
2023-04-27 07:09:39,918 - Epoch: [345][  155/  155]    Loss 3.064993    mAP 0.439172    
2023-04-27 07:09:39,985 - ==> mAP: 0.43917    Loss: 3.065

2023-04-27 07:09:39,989 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:09:39,989 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:09:40,024 - 

2023-04-27 07:09:40,024 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:09:51,698 - Epoch: [346][   50/  518]    Overall Loss 2.871158    Objective Loss 2.871158                                        LR 0.000008    Time 0.233417    
2023-04-27 07:10:02,484 - Epoch: [346][  100/  518]    Overall Loss 2.863588    Objective Loss 2.863588                                        LR 0.000008    Time 0.224561    
2023-04-27 07:10:13,260 - Epoch: [346][  150/  518]    Overall Loss 2.880691    Objective Loss 2.880691                                        LR 0.000008    Time 0.221532    
2023-04-27 07:10:24,188 - Epoch: [346][  200/  518]    Overall Loss 2.865971    Objective Loss 2.865971                                        LR 0.000008    Time 0.220781    
2023-04-27 07:10:34,953 - Epoch: [346][  250/  518]    Overall Loss 2.880043    Objective Loss 2.880043                                        LR 0.000008    Time 0.219678    
2023-04-27 07:10:45,784 - Epoch: [346][  300/  518]    Overall Loss 2.876956    Objective Loss 2.876956                                        LR 0.000008    Time 0.219165    
2023-04-27 07:10:56,637 - Epoch: [346][  350/  518]    Overall Loss 2.874386    Objective Loss 2.874386                                        LR 0.000008    Time 0.218860    
2023-04-27 07:11:07,418 - Epoch: [346][  400/  518]    Overall Loss 2.875233    Objective Loss 2.875233                                        LR 0.000008    Time 0.218452    
2023-04-27 07:11:18,225 - Epoch: [346][  450/  518]    Overall Loss 2.874625    Objective Loss 2.874625                                        LR 0.000008    Time 0.218191    
2023-04-27 07:11:29,110 - Epoch: [346][  500/  518]    Overall Loss 2.879257    Objective Loss 2.879257                                        LR 0.000008    Time 0.218139    
2023-04-27 07:11:32,869 - Epoch: [346][  518/  518]    Overall Loss 2.881322    Objective Loss 2.881322                                        LR 0.000008    Time 0.217814    
2023-04-27 07:11:32,946 - --- validate (epoch=346)-----------
2023-04-27 07:11:32,947 - 4952 samples (32 per mini-batch)
2023-04-27 07:11:41,238 - Epoch: [346][   50/  155]    Loss 3.016428    mAP 0.448626    
2023-04-27 07:11:49,143 - Epoch: [346][  100/  155]    Loss 3.044954    mAP 0.447872    
2023-04-27 07:11:57,062 - Epoch: [346][  150/  155]    Loss 3.045678    mAP 0.449858    
2023-04-27 07:11:57,787 - Epoch: [346][  155/  155]    Loss 3.046975    mAP 0.450352    
2023-04-27 07:11:57,874 - ==> mAP: 0.45035    Loss: 3.047

2023-04-27 07:11:57,879 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:11:57,879 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:11:57,913 - 

2023-04-27 07:11:57,913 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:12:09,469 - Epoch: [347][   50/  518]    Overall Loss 2.847637    Objective Loss 2.847637                                        LR 0.000008    Time 0.231063    
2023-04-27 07:12:20,250 - Epoch: [347][  100/  518]    Overall Loss 2.882830    Objective Loss 2.882830                                        LR 0.000008    Time 0.223326    
2023-04-27 07:12:31,050 - Epoch: [347][  150/  518]    Overall Loss 2.878398    Objective Loss 2.878398                                        LR 0.000008    Time 0.220877    
2023-04-27 07:12:41,865 - Epoch: [347][  200/  518]    Overall Loss 2.870274    Objective Loss 2.870274                                        LR 0.000008    Time 0.219724    
2023-04-27 07:12:52,728 - Epoch: [347][  250/  518]    Overall Loss 2.876742    Objective Loss 2.876742                                        LR 0.000008    Time 0.219226    
2023-04-27 07:13:03,488 - Epoch: [347][  300/  518]    Overall Loss 2.880631    Objective Loss 2.880631                                        LR 0.000008    Time 0.218549    
2023-04-27 07:13:14,271 - Epoch: [347][  350/  518]    Overall Loss 2.879674    Objective Loss 2.879674                                        LR 0.000008    Time 0.218132    
2023-04-27 07:13:25,180 - Epoch: [347][  400/  518]    Overall Loss 2.880789    Objective Loss 2.880789                                        LR 0.000008    Time 0.218134    
2023-04-27 07:13:35,956 - Epoch: [347][  450/  518]    Overall Loss 2.879857    Objective Loss 2.879857                                        LR 0.000008    Time 0.217838    
2023-04-27 07:13:46,705 - Epoch: [347][  500/  518]    Overall Loss 2.881827    Objective Loss 2.881827                                        LR 0.000008    Time 0.217550    
2023-04-27 07:13:50,455 - Epoch: [347][  518/  518]    Overall Loss 2.882271    Objective Loss 2.882271                                        LR 0.000008    Time 0.217230    
2023-04-27 07:13:50,533 - --- validate (epoch=347)-----------
2023-04-27 07:13:50,534 - 4952 samples (32 per mini-batch)
2023-04-27 07:13:58,849 - Epoch: [347][   50/  155]    Loss 3.047943    mAP 0.453664    
2023-04-27 07:14:06,810 - Epoch: [347][  100/  155]    Loss 3.042837    mAP 0.450900    
2023-04-27 07:14:14,727 - Epoch: [347][  150/  155]    Loss 3.046798    mAP 0.454195    
2023-04-27 07:14:15,437 - Epoch: [347][  155/  155]    Loss 3.050053    mAP 0.453323    
2023-04-27 07:14:15,513 - ==> mAP: 0.45332    Loss: 3.050

2023-04-27 07:14:15,517 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:14:15,517 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:14:15,551 - 

2023-04-27 07:14:15,551 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:14:27,088 - Epoch: [348][   50/  518]    Overall Loss 2.815218    Objective Loss 2.815218                                        LR 0.000008    Time 0.230685    
2023-04-27 07:14:37,947 - Epoch: [348][  100/  518]    Overall Loss 2.829849    Objective Loss 2.829849                                        LR 0.000008    Time 0.223918    
2023-04-27 07:14:48,648 - Epoch: [348][  150/  518]    Overall Loss 2.857381    Objective Loss 2.857381                                        LR 0.000008    Time 0.220607    
2023-04-27 07:14:59,498 - Epoch: [348][  200/  518]    Overall Loss 2.867654    Objective Loss 2.867654                                        LR 0.000008    Time 0.219697    
2023-04-27 07:15:10,254 - Epoch: [348][  250/  518]    Overall Loss 2.870157    Objective Loss 2.870157                                        LR 0.000008    Time 0.218777    
2023-04-27 07:15:20,982 - Epoch: [348][  300/  518]    Overall Loss 2.860486    Objective Loss 2.860486                                        LR 0.000008    Time 0.218066    
2023-04-27 07:15:31,723 - Epoch: [348][  350/  518]    Overall Loss 2.862100    Objective Loss 2.862100                                        LR 0.000008    Time 0.217599    
2023-04-27 07:15:42,503 - Epoch: [348][  400/  518]    Overall Loss 2.863459    Objective Loss 2.863459                                        LR 0.000008    Time 0.217346    
2023-04-27 07:15:53,319 - Epoch: [348][  450/  518]    Overall Loss 2.865505    Objective Loss 2.865505                                        LR 0.000008    Time 0.217228    
2023-04-27 07:16:04,116 - Epoch: [348][  500/  518]    Overall Loss 2.867318    Objective Loss 2.867318                                        LR 0.000008    Time 0.217097    
2023-04-27 07:16:07,875 - Epoch: [348][  518/  518]    Overall Loss 2.870964    Objective Loss 2.870964                                        LR 0.000008    Time 0.216809    
2023-04-27 07:16:07,953 - --- validate (epoch=348)-----------
2023-04-27 07:16:07,953 - 4952 samples (32 per mini-batch)
2023-04-27 07:16:16,251 - Epoch: [348][   50/  155]    Loss 3.025388    mAP 0.429854    
2023-04-27 07:16:24,175 - Epoch: [348][  100/  155]    Loss 2.994480    mAP 0.444592    
2023-04-27 07:16:32,054 - Epoch: [348][  150/  155]    Loss 3.026665    mAP 0.440033    
2023-04-27 07:16:32,777 - Epoch: [348][  155/  155]    Loss 3.031569    mAP 0.440664    
2023-04-27 07:16:32,851 - ==> mAP: 0.44066    Loss: 3.032

2023-04-27 07:16:32,855 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:16:32,855 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:16:32,889 - 

2023-04-27 07:16:32,889 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:16:44,452 - Epoch: [349][   50/  518]    Overall Loss 2.864333    Objective Loss 2.864333                                        LR 0.000008    Time 0.231215    
2023-04-27 07:16:55,239 - Epoch: [349][  100/  518]    Overall Loss 2.892486    Objective Loss 2.892486                                        LR 0.000008    Time 0.223457    
2023-04-27 07:17:06,032 - Epoch: [349][  150/  518]    Overall Loss 2.881909    Objective Loss 2.881909                                        LR 0.000008    Time 0.220912    
2023-04-27 07:17:16,945 - Epoch: [349][  200/  518]    Overall Loss 2.891037    Objective Loss 2.891037                                        LR 0.000008    Time 0.220244    
2023-04-27 07:17:27,812 - Epoch: [349][  250/  518]    Overall Loss 2.893314    Objective Loss 2.893314                                        LR 0.000008    Time 0.219657    
2023-04-27 07:17:38,705 - Epoch: [349][  300/  518]    Overall Loss 2.886468    Objective Loss 2.886468                                        LR 0.000008    Time 0.219351    
2023-04-27 07:17:49,484 - Epoch: [349][  350/  518]    Overall Loss 2.888508    Objective Loss 2.888508                                        LR 0.000008    Time 0.218809    
2023-04-27 07:18:00,267 - Epoch: [349][  400/  518]    Overall Loss 2.885002    Objective Loss 2.885002                                        LR 0.000008    Time 0.218410    
2023-04-27 07:18:11,040 - Epoch: [349][  450/  518]    Overall Loss 2.885557    Objective Loss 2.885557                                        LR 0.000008    Time 0.218080    
2023-04-27 07:18:21,935 - Epoch: [349][  500/  518]    Overall Loss 2.883538    Objective Loss 2.883538                                        LR 0.000008    Time 0.218058    
2023-04-27 07:18:25,715 - Epoch: [349][  518/  518]    Overall Loss 2.884990    Objective Loss 2.884990                                        LR 0.000008    Time 0.217778    
2023-04-27 07:18:25,792 - --- validate (epoch=349)-----------
2023-04-27 07:18:25,792 - 4952 samples (32 per mini-batch)
2023-04-27 07:18:34,053 - Epoch: [349][   50/  155]    Loss 3.057458    mAP 0.440886    
2023-04-27 07:18:41,971 - Epoch: [349][  100/  155]    Loss 3.049870    mAP 0.448305    
2023-04-27 07:18:49,896 - Epoch: [349][  150/  155]    Loss 3.057298    mAP 0.442635    
2023-04-27 07:18:50,613 - Epoch: [349][  155/  155]    Loss 3.058305    mAP 0.443109    
2023-04-27 07:18:50,686 - ==> mAP: 0.44311    Loss: 3.058

2023-04-27 07:18:50,690 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:18:50,690 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:18:50,725 - 

2023-04-27 07:18:50,725 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:19:02,253 - Epoch: [350][   50/  518]    Overall Loss 2.835191    Objective Loss 2.835191                                        LR 0.000008    Time 0.230510    
2023-04-27 07:19:13,119 - Epoch: [350][  100/  518]    Overall Loss 2.835441    Objective Loss 2.835441                                        LR 0.000008    Time 0.223893    
2023-04-27 07:19:24,037 - Epoch: [350][  150/  518]    Overall Loss 2.853099    Objective Loss 2.853099                                        LR 0.000008    Time 0.222037    
2023-04-27 07:19:34,884 - Epoch: [350][  200/  518]    Overall Loss 2.870616    Objective Loss 2.870616                                        LR 0.000008    Time 0.220755    
2023-04-27 07:19:45,670 - Epoch: [350][  250/  518]    Overall Loss 2.875299    Objective Loss 2.875299                                        LR 0.000008    Time 0.219744    
2023-04-27 07:19:56,484 - Epoch: [350][  300/  518]    Overall Loss 2.879387    Objective Loss 2.879387                                        LR 0.000008    Time 0.219160    
2023-04-27 07:20:07,330 - Epoch: [350][  350/  518]    Overall Loss 2.880851    Objective Loss 2.880851                                        LR 0.000008    Time 0.218835    
2023-04-27 07:20:18,058 - Epoch: [350][  400/  518]    Overall Loss 2.880776    Objective Loss 2.880776                                        LR 0.000008    Time 0.218299    
2023-04-27 07:20:28,965 - Epoch: [350][  450/  518]    Overall Loss 2.884960    Objective Loss 2.884960                                        LR 0.000008    Time 0.218276    
2023-04-27 07:20:39,751 - Epoch: [350][  500/  518]    Overall Loss 2.884202    Objective Loss 2.884202                                        LR 0.000008    Time 0.218018    
2023-04-27 07:20:43,531 - Epoch: [350][  518/  518]    Overall Loss 2.886432    Objective Loss 2.886432                                        LR 0.000008    Time 0.217737    
2023-04-27 07:20:43,607 - --- validate (epoch=350)-----------
2023-04-27 07:20:43,607 - 4952 samples (32 per mini-batch)
2023-04-27 07:20:51,933 - Epoch: [350][   50/  155]    Loss 3.050104    mAP 0.457325    
2023-04-27 07:20:59,861 - Epoch: [350][  100/  155]    Loss 3.086197    mAP 0.445514    
2023-04-27 07:21:07,757 - Epoch: [350][  150/  155]    Loss 3.072384    mAP 0.444124    
2023-04-27 07:21:08,468 - Epoch: [350][  155/  155]    Loss 3.070628    mAP 0.443363    
2023-04-27 07:21:08,539 - ==> mAP: 0.44336    Loss: 3.071

2023-04-27 07:21:08,543 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:21:08,543 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:21:08,577 - 

2023-04-27 07:21:08,577 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:21:20,088 - Epoch: [351][   50/  518]    Overall Loss 2.876071    Objective Loss 2.876071                                        LR 0.000008    Time 0.230169    
2023-04-27 07:21:30,994 - Epoch: [351][  100/  518]    Overall Loss 2.867492    Objective Loss 2.867492                                        LR 0.000008    Time 0.224131    
2023-04-27 07:21:41,821 - Epoch: [351][  150/  518]    Overall Loss 2.872653    Objective Loss 2.872653                                        LR 0.000008    Time 0.221591    
2023-04-27 07:21:52,582 - Epoch: [351][  200/  518]    Overall Loss 2.864846    Objective Loss 2.864846                                        LR 0.000008    Time 0.219990    
2023-04-27 07:22:03,425 - Epoch: [351][  250/  518]    Overall Loss 2.880226    Objective Loss 2.880226                                        LR 0.000008    Time 0.219355    
2023-04-27 07:22:14,245 - Epoch: [351][  300/  518]    Overall Loss 2.882585    Objective Loss 2.882585                                        LR 0.000008    Time 0.218858    
2023-04-27 07:22:25,015 - Epoch: [351][  350/  518]    Overall Loss 2.877009    Objective Loss 2.877009                                        LR 0.000008    Time 0.218360    
2023-04-27 07:22:35,771 - Epoch: [351][  400/  518]    Overall Loss 2.870629    Objective Loss 2.870629                                        LR 0.000008    Time 0.217952    
2023-04-27 07:22:46,539 - Epoch: [351][  450/  518]    Overall Loss 2.875464    Objective Loss 2.875464                                        LR 0.000008    Time 0.217660    
2023-04-27 07:22:57,414 - Epoch: [351][  500/  518]    Overall Loss 2.875971    Objective Loss 2.875971                                        LR 0.000008    Time 0.217641    
2023-04-27 07:23:01,130 - Epoch: [351][  518/  518]    Overall Loss 2.876088    Objective Loss 2.876088                                        LR 0.000008    Time 0.217251    
2023-04-27 07:23:01,206 - --- validate (epoch=351)-----------
2023-04-27 07:23:01,207 - 4952 samples (32 per mini-batch)
2023-04-27 07:23:09,512 - Epoch: [351][   50/  155]    Loss 3.077772    mAP 0.449345    
2023-04-27 07:23:17,444 - Epoch: [351][  100/  155]    Loss 3.063352    mAP 0.445561    
2023-04-27 07:23:25,359 - Epoch: [351][  150/  155]    Loss 3.059749    mAP 0.445674    
2023-04-27 07:23:26,085 - Epoch: [351][  155/  155]    Loss 3.056420    mAP 0.447450    
2023-04-27 07:23:26,159 - ==> mAP: 0.44745    Loss: 3.056

2023-04-27 07:23:26,163 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:23:26,163 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:23:26,197 - 

2023-04-27 07:23:26,197 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:23:37,640 - Epoch: [352][   50/  518]    Overall Loss 2.848664    Objective Loss 2.848664                                        LR 0.000008    Time 0.228799    
2023-04-27 07:23:48,404 - Epoch: [352][  100/  518]    Overall Loss 2.867807    Objective Loss 2.867807                                        LR 0.000008    Time 0.222025    
2023-04-27 07:23:59,258 - Epoch: [352][  150/  518]    Overall Loss 2.866106    Objective Loss 2.866106                                        LR 0.000008    Time 0.220369    
2023-04-27 07:24:10,075 - Epoch: [352][  200/  518]    Overall Loss 2.857677    Objective Loss 2.857677                                        LR 0.000008    Time 0.219352    
2023-04-27 07:24:20,889 - Epoch: [352][  250/  518]    Overall Loss 2.861891    Objective Loss 2.861891                                        LR 0.000008    Time 0.218731    
2023-04-27 07:24:31,738 - Epoch: [352][  300/  518]    Overall Loss 2.868159    Objective Loss 2.868159                                        LR 0.000008    Time 0.218434    
2023-04-27 07:24:42,570 - Epoch: [352][  350/  518]    Overall Loss 2.874491    Objective Loss 2.874491                                        LR 0.000008    Time 0.218174    
2023-04-27 07:24:53,364 - Epoch: [352][  400/  518]    Overall Loss 2.869848    Objective Loss 2.869848                                        LR 0.000008    Time 0.217883    
2023-04-27 07:25:04,163 - Epoch: [352][  450/  518]    Overall Loss 2.869536    Objective Loss 2.869536                                        LR 0.000008    Time 0.217667    
2023-04-27 07:25:14,985 - Epoch: [352][  500/  518]    Overall Loss 2.874912    Objective Loss 2.874912                                        LR 0.000008    Time 0.217541    
2023-04-27 07:25:18,712 - Epoch: [352][  518/  518]    Overall Loss 2.873294    Objective Loss 2.873294                                        LR 0.000008    Time 0.217176    
2023-04-27 07:25:18,789 - --- validate (epoch=352)-----------
2023-04-27 07:25:18,790 - 4952 samples (32 per mini-batch)
2023-04-27 07:25:27,079 - Epoch: [352][   50/  155]    Loss 3.047522    mAP 0.455830    
2023-04-27 07:25:34,973 - Epoch: [352][  100/  155]    Loss 3.073195    mAP 0.451507    
2023-04-27 07:25:42,836 - Epoch: [352][  150/  155]    Loss 3.047048    mAP 0.450894    
2023-04-27 07:25:43,556 - Epoch: [352][  155/  155]    Loss 3.042547    mAP 0.452577    
2023-04-27 07:25:43,630 - ==> mAP: 0.45258    Loss: 3.043

2023-04-27 07:25:43,634 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:25:43,634 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:25:43,669 - 

2023-04-27 07:25:43,669 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:25:55,487 - Epoch: [353][   50/  518]    Overall Loss 2.873402    Objective Loss 2.873402                                        LR 0.000008    Time 0.236310    
2023-04-27 07:26:06,311 - Epoch: [353][  100/  518]    Overall Loss 2.864401    Objective Loss 2.864401                                        LR 0.000008    Time 0.226377    
2023-04-27 07:26:17,083 - Epoch: [353][  150/  518]    Overall Loss 2.865162    Objective Loss 2.865162                                        LR 0.000008    Time 0.222723    
2023-04-27 07:26:27,838 - Epoch: [353][  200/  518]    Overall Loss 2.856608    Objective Loss 2.856608                                        LR 0.000008    Time 0.220811    
2023-04-27 07:26:38,589 - Epoch: [353][  250/  518]    Overall Loss 2.863410    Objective Loss 2.863410                                        LR 0.000008    Time 0.219646    
2023-04-27 07:26:49,397 - Epoch: [353][  300/  518]    Overall Loss 2.866467    Objective Loss 2.866467                                        LR 0.000008    Time 0.219058    
2023-04-27 07:27:00,252 - Epoch: [353][  350/  518]    Overall Loss 2.863632    Objective Loss 2.863632                                        LR 0.000008    Time 0.218775    
2023-04-27 07:27:11,078 - Epoch: [353][  400/  518]    Overall Loss 2.862027    Objective Loss 2.862027                                        LR 0.000008    Time 0.218489    
2023-04-27 07:27:21,954 - Epoch: [353][  450/  518]    Overall Loss 2.867089    Objective Loss 2.867089                                        LR 0.000008    Time 0.218379    
2023-04-27 07:27:32,799 - Epoch: [353][  500/  518]    Overall Loss 2.865671    Objective Loss 2.865671                                        LR 0.000008    Time 0.218227    
2023-04-27 07:27:36,553 - Epoch: [353][  518/  518]    Overall Loss 2.867142    Objective Loss 2.867142                                        LR 0.000008    Time 0.217891    
2023-04-27 07:27:36,631 - --- validate (epoch=353)-----------
2023-04-27 07:27:36,632 - 4952 samples (32 per mini-batch)
2023-04-27 07:27:44,932 - Epoch: [353][   50/  155]    Loss 3.032321    mAP 0.461192    
2023-04-27 07:27:52,856 - Epoch: [353][  100/  155]    Loss 3.030413    mAP 0.448500    
2023-04-27 07:28:00,745 - Epoch: [353][  150/  155]    Loss 3.038340    mAP 0.454131    
2023-04-27 07:28:01,468 - Epoch: [353][  155/  155]    Loss 3.034919    mAP 0.451147    
2023-04-27 07:28:01,535 - ==> mAP: 0.45115    Loss: 3.035

2023-04-27 07:28:01,539 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:28:01,539 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:28:01,574 - 

2023-04-27 07:28:01,574 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:28:13,215 - Epoch: [354][   50/  518]    Overall Loss 2.838772    Objective Loss 2.838772                                        LR 0.000008    Time 0.232755    
2023-04-27 07:28:24,001 - Epoch: [354][  100/  518]    Overall Loss 2.857679    Objective Loss 2.857679                                        LR 0.000008    Time 0.224219    
2023-04-27 07:28:34,803 - Epoch: [354][  150/  518]    Overall Loss 2.840003    Objective Loss 2.840003                                        LR 0.000008    Time 0.221485    
2023-04-27 07:28:45,632 - Epoch: [354][  200/  518]    Overall Loss 2.858749    Objective Loss 2.858749                                        LR 0.000008    Time 0.220253    
2023-04-27 07:28:56,398 - Epoch: [354][  250/  518]    Overall Loss 2.852633    Objective Loss 2.852633                                        LR 0.000008    Time 0.219257    
2023-04-27 07:29:07,357 - Epoch: [354][  300/  518]    Overall Loss 2.855336    Objective Loss 2.855336                                        LR 0.000008    Time 0.219239    
2023-04-27 07:29:18,235 - Epoch: [354][  350/  518]    Overall Loss 2.857849    Objective Loss 2.857849                                        LR 0.000008    Time 0.218996    
2023-04-27 07:29:29,057 - Epoch: [354][  400/  518]    Overall Loss 2.862726    Objective Loss 2.862726                                        LR 0.000008    Time 0.218672    
2023-04-27 07:29:39,850 - Epoch: [354][  450/  518]    Overall Loss 2.856046    Objective Loss 2.856046                                        LR 0.000008    Time 0.218357    
2023-04-27 07:29:50,662 - Epoch: [354][  500/  518]    Overall Loss 2.866139    Objective Loss 2.866139                                        LR 0.000008    Time 0.218142    
2023-04-27 07:29:54,446 - Epoch: [354][  518/  518]    Overall Loss 2.868409    Objective Loss 2.868409                                        LR 0.000008    Time 0.217866    
2023-04-27 07:29:54,523 - --- validate (epoch=354)-----------
2023-04-27 07:29:54,524 - 4952 samples (32 per mini-batch)
2023-04-27 07:30:02,805 - Epoch: [354][   50/  155]    Loss 3.046067    mAP 0.450547    
2023-04-27 07:30:10,745 - Epoch: [354][  100/  155]    Loss 3.029114    mAP 0.457531    
2023-04-27 07:30:18,649 - Epoch: [354][  150/  155]    Loss 3.041274    mAP 0.451567    
2023-04-27 07:30:19,366 - Epoch: [354][  155/  155]    Loss 3.046839    mAP 0.449515    
2023-04-27 07:30:19,436 - ==> mAP: 0.44952    Loss: 3.047

2023-04-27 07:30:19,440 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:30:19,440 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:30:19,475 - 

2023-04-27 07:30:19,475 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:30:31,074 - Epoch: [355][   50/  518]    Overall Loss 2.891342    Objective Loss 2.891342                                        LR 0.000008    Time 0.231917    
2023-04-27 07:30:41,907 - Epoch: [355][  100/  518]    Overall Loss 2.892797    Objective Loss 2.892797                                        LR 0.000008    Time 0.224272    
2023-04-27 07:30:52,739 - Epoch: [355][  150/  518]    Overall Loss 2.911606    Objective Loss 2.911606                                        LR 0.000008    Time 0.221723    
2023-04-27 07:31:03,494 - Epoch: [355][  200/  518]    Overall Loss 2.889074    Objective Loss 2.889074                                        LR 0.000008    Time 0.220058    
2023-04-27 07:31:14,303 - Epoch: [355][  250/  518]    Overall Loss 2.889300    Objective Loss 2.889300                                        LR 0.000008    Time 0.219277    
2023-04-27 07:31:25,094 - Epoch: [355][  300/  518]    Overall Loss 2.885582    Objective Loss 2.885582                                        LR 0.000008    Time 0.218694    
2023-04-27 07:31:35,894 - Epoch: [355][  350/  518]    Overall Loss 2.888794    Objective Loss 2.888794                                        LR 0.000008    Time 0.218306    
2023-04-27 07:31:46,632 - Epoch: [355][  400/  518]    Overall Loss 2.888444    Objective Loss 2.888444                                        LR 0.000008    Time 0.217857    
2023-04-27 07:31:57,402 - Epoch: [355][  450/  518]    Overall Loss 2.887773    Objective Loss 2.887773                                        LR 0.000008    Time 0.217581    
2023-04-27 07:32:08,231 - Epoch: [355][  500/  518]    Overall Loss 2.886995    Objective Loss 2.886995                                        LR 0.000008    Time 0.217478    
2023-04-27 07:32:11,988 - Epoch: [355][  518/  518]    Overall Loss 2.886553    Objective Loss 2.886553                                        LR 0.000008    Time 0.217173    
2023-04-27 07:32:12,064 - --- validate (epoch=355)-----------
2023-04-27 07:32:12,064 - 4952 samples (32 per mini-batch)
2023-04-27 07:32:20,365 - Epoch: [355][   50/  155]    Loss 3.053714    mAP 0.446714    
2023-04-27 07:32:28,272 - Epoch: [355][  100/  155]    Loss 3.065095    mAP 0.445573    
2023-04-27 07:32:36,106 - Epoch: [355][  150/  155]    Loss 3.054408    mAP 0.449589    
2023-04-27 07:32:36,824 - Epoch: [355][  155/  155]    Loss 3.051858    mAP 0.448444    
2023-04-27 07:32:36,899 - ==> mAP: 0.44844    Loss: 3.052

2023-04-27 07:32:36,903 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:32:36,903 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:32:36,936 - 

2023-04-27 07:32:36,937 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:32:48,644 - Epoch: [356][   50/  518]    Overall Loss 2.921563    Objective Loss 2.921563                                        LR 0.000008    Time 0.234092    
2023-04-27 07:32:59,466 - Epoch: [356][  100/  518]    Overall Loss 2.883686    Objective Loss 2.883686                                        LR 0.000008    Time 0.225252    
2023-04-27 07:33:10,239 - Epoch: [356][  150/  518]    Overall Loss 2.882355    Objective Loss 2.882355                                        LR 0.000008    Time 0.221974    
2023-04-27 07:33:21,056 - Epoch: [356][  200/  518]    Overall Loss 2.871842    Objective Loss 2.871842                                        LR 0.000008    Time 0.220561    
2023-04-27 07:33:31,842 - Epoch: [356][  250/  518]    Overall Loss 2.870132    Objective Loss 2.870132                                        LR 0.000008    Time 0.219584    
2023-04-27 07:33:42,596 - Epoch: [356][  300/  518]    Overall Loss 2.867799    Objective Loss 2.867799                                        LR 0.000008    Time 0.218829    
2023-04-27 07:33:53,420 - Epoch: [356][  350/  518]    Overall Loss 2.862716    Objective Loss 2.862716                                        LR 0.000008    Time 0.218490    
2023-04-27 07:34:04,234 - Epoch: [356][  400/  518]    Overall Loss 2.869990    Objective Loss 2.869990                                        LR 0.000008    Time 0.218209    
2023-04-27 07:34:15,042 - Epoch: [356][  450/  518]    Overall Loss 2.868876    Objective Loss 2.868876                                        LR 0.000008    Time 0.217977    
2023-04-27 07:34:25,789 - Epoch: [356][  500/  518]    Overall Loss 2.867582    Objective Loss 2.867582                                        LR 0.000008    Time 0.217671    
2023-04-27 07:34:29,563 - Epoch: [356][  518/  518]    Overall Loss 2.866574    Objective Loss 2.866574                                        LR 0.000008    Time 0.217392    
2023-04-27 07:34:29,640 - --- validate (epoch=356)-----------
2023-04-27 07:34:29,641 - 4952 samples (32 per mini-batch)
2023-04-27 07:34:37,912 - Epoch: [356][   50/  155]    Loss 3.096265    mAP 0.440022    
2023-04-27 07:34:45,798 - Epoch: [356][  100/  155]    Loss 3.081795    mAP 0.439278    
2023-04-27 07:34:53,687 - Epoch: [356][  150/  155]    Loss 3.073272    mAP 0.442976    
2023-04-27 07:34:54,407 - Epoch: [356][  155/  155]    Loss 3.073087    mAP 0.442790    
2023-04-27 07:34:54,481 - ==> mAP: 0.44279    Loss: 3.073

2023-04-27 07:34:54,485 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:34:54,486 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:34:54,520 - 

2023-04-27 07:34:54,520 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:35:06,121 - Epoch: [357][   50/  518]    Overall Loss 2.909468    Objective Loss 2.909468                                        LR 0.000008    Time 0.231954    
2023-04-27 07:35:17,073 - Epoch: [357][  100/  518]    Overall Loss 2.885037    Objective Loss 2.885037                                        LR 0.000008    Time 0.225489    
2023-04-27 07:35:27,841 - Epoch: [357][  150/  518]    Overall Loss 2.873085    Objective Loss 2.873085                                        LR 0.000008    Time 0.222099    
2023-04-27 07:35:38,680 - Epoch: [357][  200/  518]    Overall Loss 2.873158    Objective Loss 2.873158                                        LR 0.000008    Time 0.220762    
2023-04-27 07:35:49,497 - Epoch: [357][  250/  518]    Overall Loss 2.877445    Objective Loss 2.877445                                        LR 0.000008    Time 0.219871    
2023-04-27 07:36:00,266 - Epoch: [357][  300/  518]    Overall Loss 2.876632    Objective Loss 2.876632                                        LR 0.000008    Time 0.219119    
2023-04-27 07:36:11,056 - Epoch: [357][  350/  518]    Overall Loss 2.869187    Objective Loss 2.869187                                        LR 0.000008    Time 0.218638    
2023-04-27 07:36:21,781 - Epoch: [357][  400/  518]    Overall Loss 2.866136    Objective Loss 2.866136                                        LR 0.000008    Time 0.218119    
2023-04-27 07:36:32,600 - Epoch: [357][  450/  518]    Overall Loss 2.868380    Objective Loss 2.868380                                        LR 0.000008    Time 0.217920    
2023-04-27 07:36:43,451 - Epoch: [357][  500/  518]    Overall Loss 2.866762    Objective Loss 2.866762                                        LR 0.000008    Time 0.217828    
2023-04-27 07:36:47,284 - Epoch: [357][  518/  518]    Overall Loss 2.867535    Objective Loss 2.867535                                        LR 0.000008    Time 0.217657    
2023-04-27 07:36:47,360 - --- validate (epoch=357)-----------
2023-04-27 07:36:47,361 - 4952 samples (32 per mini-batch)
2023-04-27 07:36:55,605 - Epoch: [357][   50/  155]    Loss 3.036389    mAP 0.443501    
2023-04-27 07:37:03,522 - Epoch: [357][  100/  155]    Loss 3.047261    mAP 0.448576    
2023-04-27 07:37:11,377 - Epoch: [357][  150/  155]    Loss 3.043453    mAP 0.445354    
2023-04-27 07:37:12,095 - Epoch: [357][  155/  155]    Loss 3.043023    mAP 0.445454    
2023-04-27 07:37:12,169 - ==> mAP: 0.44545    Loss: 3.043

2023-04-27 07:37:12,173 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:37:12,173 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:37:12,207 - 

2023-04-27 07:37:12,208 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:37:23,792 - Epoch: [358][   50/  518]    Overall Loss 2.924230    Objective Loss 2.924230                                        LR 0.000008    Time 0.231629    
2023-04-27 07:37:34,521 - Epoch: [358][  100/  518]    Overall Loss 2.909454    Objective Loss 2.909454                                        LR 0.000008    Time 0.223094    
2023-04-27 07:37:45,326 - Epoch: [358][  150/  518]    Overall Loss 2.886820    Objective Loss 2.886820                                        LR 0.000008    Time 0.220748    
2023-04-27 07:37:56,158 - Epoch: [358][  200/  518]    Overall Loss 2.871516    Objective Loss 2.871516                                        LR 0.000008    Time 0.219713    
2023-04-27 07:38:06,879 - Epoch: [358][  250/  518]    Overall Loss 2.869687    Objective Loss 2.869687                                        LR 0.000008    Time 0.218648    
2023-04-27 07:38:17,647 - Epoch: [358][  300/  518]    Overall Loss 2.856580    Objective Loss 2.856580                                        LR 0.000008    Time 0.218096    
2023-04-27 07:38:28,432 - Epoch: [358][  350/  518]    Overall Loss 2.857348    Objective Loss 2.857348                                        LR 0.000008    Time 0.217750    
2023-04-27 07:38:39,276 - Epoch: [358][  400/  518]    Overall Loss 2.855574    Objective Loss 2.855574                                        LR 0.000008    Time 0.217637    
2023-04-27 07:38:50,113 - Epoch: [358][  450/  518]    Overall Loss 2.859818    Objective Loss 2.859818                                        LR 0.000008    Time 0.217533    
2023-04-27 07:39:00,907 - Epoch: [358][  500/  518]    Overall Loss 2.856839    Objective Loss 2.856839                                        LR 0.000008    Time 0.217364    
2023-04-27 07:39:04,643 - Epoch: [358][  518/  518]    Overall Loss 2.854998    Objective Loss 2.854998                                        LR 0.000008    Time 0.217023    
2023-04-27 07:39:04,718 - --- validate (epoch=358)-----------
2023-04-27 07:39:04,718 - 4952 samples (32 per mini-batch)
2023-04-27 07:39:13,007 - Epoch: [358][   50/  155]    Loss 3.050135    mAP 0.457006    
2023-04-27 07:39:20,952 - Epoch: [358][  100/  155]    Loss 3.043688    mAP 0.453332    
2023-04-27 07:39:28,868 - Epoch: [358][  150/  155]    Loss 3.043982    mAP 0.453813    
2023-04-27 07:39:29,595 - Epoch: [358][  155/  155]    Loss 3.046887    mAP 0.454120    
2023-04-27 07:39:29,677 - ==> mAP: 0.45412    Loss: 3.047

2023-04-27 07:39:29,681 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:39:29,681 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:39:29,716 - 

2023-04-27 07:39:29,716 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:39:41,395 - Epoch: [359][   50/  518]    Overall Loss 2.888346    Objective Loss 2.888346                                        LR 0.000008    Time 0.233524    
2023-04-27 07:39:52,167 - Epoch: [359][  100/  518]    Overall Loss 2.907492    Objective Loss 2.907492                                        LR 0.000008    Time 0.224462    
2023-04-27 07:40:02,936 - Epoch: [359][  150/  518]    Overall Loss 2.894209    Objective Loss 2.894209                                        LR 0.000008    Time 0.221425    
2023-04-27 07:40:13,692 - Epoch: [359][  200/  518]    Overall Loss 2.888851    Objective Loss 2.888851                                        LR 0.000008    Time 0.219841    
2023-04-27 07:40:24,603 - Epoch: [359][  250/  518]    Overall Loss 2.877645    Objective Loss 2.877645                                        LR 0.000008    Time 0.219509    
2023-04-27 07:40:35,364 - Epoch: [359][  300/  518]    Overall Loss 2.867877    Objective Loss 2.867877                                        LR 0.000008    Time 0.218790    
2023-04-27 07:40:46,138 - Epoch: [359][  350/  518]    Overall Loss 2.868874    Objective Loss 2.868874                                        LR 0.000008    Time 0.218313    
2023-04-27 07:40:56,966 - Epoch: [359][  400/  518]    Overall Loss 2.875049    Objective Loss 2.875049                                        LR 0.000008    Time 0.218091    
2023-04-27 07:41:07,873 - Epoch: [359][  450/  518]    Overall Loss 2.877105    Objective Loss 2.877105                                        LR 0.000008    Time 0.218092    
2023-04-27 07:41:18,643 - Epoch: [359][  500/  518]    Overall Loss 2.878914    Objective Loss 2.878914                                        LR 0.000008    Time 0.217821    
2023-04-27 07:41:22,368 - Epoch: [359][  518/  518]    Overall Loss 2.879952    Objective Loss 2.879952                                        LR 0.000008    Time 0.217441    
2023-04-27 07:41:22,446 - --- validate (epoch=359)-----------
2023-04-27 07:41:22,446 - 4952 samples (32 per mini-batch)
2023-04-27 07:41:30,723 - Epoch: [359][   50/  155]    Loss 3.014148    mAP 0.437963    
2023-04-27 07:41:38,652 - Epoch: [359][  100/  155]    Loss 3.025238    mAP 0.444137    
2023-04-27 07:41:46,566 - Epoch: [359][  150/  155]    Loss 3.036414    mAP 0.445018    
2023-04-27 07:41:47,284 - Epoch: [359][  155/  155]    Loss 3.039960    mAP 0.444522    
2023-04-27 07:41:47,356 - ==> mAP: 0.44452    Loss: 3.040

2023-04-27 07:41:47,360 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:41:47,361 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:41:47,395 - 

2023-04-27 07:41:47,395 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:41:58,929 - Epoch: [360][   50/  518]    Overall Loss 2.882190    Objective Loss 2.882190                                        LR 0.000008    Time 0.230624    
2023-04-27 07:42:09,734 - Epoch: [360][  100/  518]    Overall Loss 2.904937    Objective Loss 2.904937                                        LR 0.000008    Time 0.223340    
2023-04-27 07:42:20,562 - Epoch: [360][  150/  518]    Overall Loss 2.887813    Objective Loss 2.887813                                        LR 0.000008    Time 0.221074    
2023-04-27 07:42:31,441 - Epoch: [360][  200/  518]    Overall Loss 2.881513    Objective Loss 2.881513                                        LR 0.000008    Time 0.220191    
2023-04-27 07:42:42,236 - Epoch: [360][  250/  518]    Overall Loss 2.885918    Objective Loss 2.885918                                        LR 0.000008    Time 0.219327    
2023-04-27 07:42:53,034 - Epoch: [360][  300/  518]    Overall Loss 2.882595    Objective Loss 2.882595                                        LR 0.000008    Time 0.218761    
2023-04-27 07:43:03,918 - Epoch: [360][  350/  518]    Overall Loss 2.874089    Objective Loss 2.874089                                        LR 0.000008    Time 0.218603    
2023-04-27 07:43:14,733 - Epoch: [360][  400/  518]    Overall Loss 2.866949    Objective Loss 2.866949                                        LR 0.000008    Time 0.218309    
2023-04-27 07:43:25,488 - Epoch: [360][  450/  518]    Overall Loss 2.863040    Objective Loss 2.863040                                        LR 0.000008    Time 0.217950    
2023-04-27 07:43:36,322 - Epoch: [360][  500/  518]    Overall Loss 2.863137    Objective Loss 2.863137                                        LR 0.000008    Time 0.217820    
2023-04-27 07:43:40,041 - Epoch: [360][  518/  518]    Overall Loss 2.865807    Objective Loss 2.865807                                        LR 0.000008    Time 0.217430    
2023-04-27 07:43:40,116 - --- validate (epoch=360)-----------
2023-04-27 07:43:40,116 - 4952 samples (32 per mini-batch)
2023-04-27 07:43:48,430 - Epoch: [360][   50/  155]    Loss 3.038988    mAP 0.435284    
2023-04-27 07:43:56,343 - Epoch: [360][  100/  155]    Loss 3.036872    mAP 0.441390    
2023-04-27 07:44:04,240 - Epoch: [360][  150/  155]    Loss 3.039063    mAP 0.436976    
2023-04-27 07:44:04,948 - Epoch: [360][  155/  155]    Loss 3.043096    mAP 0.433940    
2023-04-27 07:44:05,022 - ==> mAP: 0.43394    Loss: 3.043

2023-04-27 07:44:05,026 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:44:05,026 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:44:05,060 - 

2023-04-27 07:44:05,060 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:44:16,728 - Epoch: [361][   50/  518]    Overall Loss 2.885562    Objective Loss 2.885562                                        LR 0.000008    Time 0.233300    
2023-04-27 07:44:27,523 - Epoch: [361][  100/  518]    Overall Loss 2.850843    Objective Loss 2.850843                                        LR 0.000008    Time 0.224578    
2023-04-27 07:44:38,424 - Epoch: [361][  150/  518]    Overall Loss 2.872980    Objective Loss 2.872980                                        LR 0.000008    Time 0.222382    
2023-04-27 07:44:49,245 - Epoch: [361][  200/  518]    Overall Loss 2.873719    Objective Loss 2.873719                                        LR 0.000008    Time 0.220887    
2023-04-27 07:44:59,934 - Epoch: [361][  250/  518]    Overall Loss 2.861974    Objective Loss 2.861974                                        LR 0.000008    Time 0.219460    
2023-04-27 07:45:10,714 - Epoch: [361][  300/  518]    Overall Loss 2.871653    Objective Loss 2.871653                                        LR 0.000008    Time 0.218810    
2023-04-27 07:45:21,517 - Epoch: [361][  350/  518]    Overall Loss 2.862063    Objective Loss 2.862063                                        LR 0.000008    Time 0.218412    
2023-04-27 07:45:32,267 - Epoch: [361][  400/  518]    Overall Loss 2.857878    Objective Loss 2.857878                                        LR 0.000008    Time 0.217983    
2023-04-27 07:45:43,102 - Epoch: [361][  450/  518]    Overall Loss 2.860287    Objective Loss 2.860287                                        LR 0.000008    Time 0.217838    
2023-04-27 07:45:53,940 - Epoch: [361][  500/  518]    Overall Loss 2.863406    Objective Loss 2.863406                                        LR 0.000008    Time 0.217726    
2023-04-27 07:45:57,672 - Epoch: [361][  518/  518]    Overall Loss 2.860667    Objective Loss 2.860667                                        LR 0.000008    Time 0.217364    
2023-04-27 07:45:57,748 - --- validate (epoch=361)-----------
2023-04-27 07:45:57,748 - 4952 samples (32 per mini-batch)
2023-04-27 07:46:06,041 - Epoch: [361][   50/  155]    Loss 3.052515    mAP 0.441011    
2023-04-27 07:46:13,968 - Epoch: [361][  100/  155]    Loss 3.037367    mAP 0.452613    
2023-04-27 07:46:21,912 - Epoch: [361][  150/  155]    Loss 3.052406    mAP 0.443899    
2023-04-27 07:46:22,634 - Epoch: [361][  155/  155]    Loss 3.057212    mAP 0.440872    
2023-04-27 07:46:22,703 - ==> mAP: 0.44087    Loss: 3.057

2023-04-27 07:46:22,707 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:46:22,707 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:46:22,741 - 

2023-04-27 07:46:22,741 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:46:34,240 - Epoch: [362][   50/  518]    Overall Loss 2.854148    Objective Loss 2.854148                                        LR 0.000008    Time 0.229924    
2023-04-27 07:46:45,054 - Epoch: [362][  100/  518]    Overall Loss 2.851800    Objective Loss 2.851800                                        LR 0.000008    Time 0.223088    
2023-04-27 07:46:55,801 - Epoch: [362][  150/  518]    Overall Loss 2.854388    Objective Loss 2.854388                                        LR 0.000008    Time 0.220358    
2023-04-27 07:47:06,603 - Epoch: [362][  200/  518]    Overall Loss 2.841833    Objective Loss 2.841833                                        LR 0.000008    Time 0.219269    
2023-04-27 07:47:17,332 - Epoch: [362][  250/  518]    Overall Loss 2.844002    Objective Loss 2.844002                                        LR 0.000008    Time 0.218327    
2023-04-27 07:47:28,163 - Epoch: [362][  300/  518]    Overall Loss 2.847365    Objective Loss 2.847365                                        LR 0.000008    Time 0.218035    
2023-04-27 07:47:38,994 - Epoch: [362][  350/  518]    Overall Loss 2.855511    Objective Loss 2.855511                                        LR 0.000008    Time 0.217830    
2023-04-27 07:47:49,829 - Epoch: [362][  400/  518]    Overall Loss 2.861466    Objective Loss 2.861466                                        LR 0.000008    Time 0.217684    
2023-04-27 07:48:00,735 - Epoch: [362][  450/  518]    Overall Loss 2.868857    Objective Loss 2.868857                                        LR 0.000008    Time 0.217729    
2023-04-27 07:48:11,633 - Epoch: [362][  500/  518]    Overall Loss 2.865861    Objective Loss 2.865861                                        LR 0.000008    Time 0.217750    
2023-04-27 07:48:15,383 - Epoch: [362][  518/  518]    Overall Loss 2.864492    Objective Loss 2.864492                                        LR 0.000008    Time 0.217421    
2023-04-27 07:48:15,456 - --- validate (epoch=362)-----------
2023-04-27 07:48:15,457 - 4952 samples (32 per mini-batch)
2023-04-27 07:48:23,781 - Epoch: [362][   50/  155]    Loss 3.081503    mAP 0.442692    
2023-04-27 07:48:31,689 - Epoch: [362][  100/  155]    Loss 3.042356    mAP 0.446073    
2023-04-27 07:48:39,603 - Epoch: [362][  150/  155]    Loss 3.045703    mAP 0.451255    
2023-04-27 07:48:40,321 - Epoch: [362][  155/  155]    Loss 3.043720    mAP 0.452512    
2023-04-27 07:48:40,387 - ==> mAP: 0.45251    Loss: 3.044

2023-04-27 07:48:40,391 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:48:40,391 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:48:40,425 - 

2023-04-27 07:48:40,425 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:48:52,120 - Epoch: [363][   50/  518]    Overall Loss 2.864332    Objective Loss 2.864332                                        LR 0.000008    Time 0.233830    
2023-04-27 07:49:02,998 - Epoch: [363][  100/  518]    Overall Loss 2.867456    Objective Loss 2.867456                                        LR 0.000008    Time 0.225682    
2023-04-27 07:49:13,774 - Epoch: [363][  150/  518]    Overall Loss 2.871798    Objective Loss 2.871798                                        LR 0.000008    Time 0.222283    
2023-04-27 07:49:24,589 - Epoch: [363][  200/  518]    Overall Loss 2.867149    Objective Loss 2.867149                                        LR 0.000008    Time 0.220780    
2023-04-27 07:49:35,420 - Epoch: [363][  250/  518]    Overall Loss 2.866912    Objective Loss 2.866912                                        LR 0.000008    Time 0.219943    
2023-04-27 07:49:46,174 - Epoch: [363][  300/  518]    Overall Loss 2.860939    Objective Loss 2.860939                                        LR 0.000008    Time 0.219128    
2023-04-27 07:49:57,015 - Epoch: [363][  350/  518]    Overall Loss 2.860400    Objective Loss 2.860400                                        LR 0.000008    Time 0.218793    
2023-04-27 07:50:07,856 - Epoch: [363][  400/  518]    Overall Loss 2.854304    Objective Loss 2.854304                                        LR 0.000008    Time 0.218543    
2023-04-27 07:50:18,613 - Epoch: [363][  450/  518]    Overall Loss 2.852139    Objective Loss 2.852139                                        LR 0.000008    Time 0.218160    
2023-04-27 07:50:29,427 - Epoch: [363][  500/  518]    Overall Loss 2.857841    Objective Loss 2.857841                                        LR 0.000008    Time 0.217970    
2023-04-27 07:50:33,194 - Epoch: [363][  518/  518]    Overall Loss 2.857082    Objective Loss 2.857082                                        LR 0.000008    Time 0.217666    
2023-04-27 07:50:33,271 - --- validate (epoch=363)-----------
2023-04-27 07:50:33,271 - 4952 samples (32 per mini-batch)
2023-04-27 07:50:41,529 - Epoch: [363][   50/  155]    Loss 3.069273    mAP 0.432568    
2023-04-27 07:50:49,435 - Epoch: [363][  100/  155]    Loss 3.086864    mAP 0.424311    
2023-04-27 07:50:57,340 - Epoch: [363][  150/  155]    Loss 3.059684    mAP 0.441130    
2023-04-27 07:50:58,064 - Epoch: [363][  155/  155]    Loss 3.056121    mAP 0.441215    
2023-04-27 07:50:58,141 - ==> mAP: 0.44122    Loss: 3.056

2023-04-27 07:50:58,145 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:50:58,146 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:50:58,181 - 

2023-04-27 07:50:58,181 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:51:09,810 - Epoch: [364][   50/  518]    Overall Loss 2.810275    Objective Loss 2.810275                                        LR 0.000008    Time 0.232530    
2023-04-27 07:51:20,593 - Epoch: [364][  100/  518]    Overall Loss 2.828994    Objective Loss 2.828994                                        LR 0.000008    Time 0.224079    
2023-04-27 07:51:31,430 - Epoch: [364][  150/  518]    Overall Loss 2.831079    Objective Loss 2.831079                                        LR 0.000008    Time 0.221621    
2023-04-27 07:51:42,310 - Epoch: [364][  200/  518]    Overall Loss 2.846604    Objective Loss 2.846604                                        LR 0.000008    Time 0.220609    
2023-04-27 07:51:53,103 - Epoch: [364][  250/  518]    Overall Loss 2.850290    Objective Loss 2.850290                                        LR 0.000008    Time 0.219654    
2023-04-27 07:52:03,913 - Epoch: [364][  300/  518]    Overall Loss 2.856504    Objective Loss 2.856504                                        LR 0.000008    Time 0.219071    
2023-04-27 07:52:14,681 - Epoch: [364][  350/  518]    Overall Loss 2.856975    Objective Loss 2.856975                                        LR 0.000008    Time 0.218537    
2023-04-27 07:52:25,536 - Epoch: [364][  400/  518]    Overall Loss 2.865476    Objective Loss 2.865476                                        LR 0.000008    Time 0.218354    
2023-04-27 07:52:36,288 - Epoch: [364][  450/  518]    Overall Loss 2.868669    Objective Loss 2.868669                                        LR 0.000008    Time 0.217984    
2023-04-27 07:52:47,096 - Epoch: [364][  500/  518]    Overall Loss 2.871048    Objective Loss 2.871048                                        LR 0.000008    Time 0.217797    
2023-04-27 07:52:50,825 - Epoch: [364][  518/  518]    Overall Loss 2.868494    Objective Loss 2.868494                                        LR 0.000008    Time 0.217427    
2023-04-27 07:52:50,901 - --- validate (epoch=364)-----------
2023-04-27 07:52:50,902 - 4952 samples (32 per mini-batch)
2023-04-27 07:52:59,219 - Epoch: [364][   50/  155]    Loss 3.007589    mAP 0.466977    
2023-04-27 07:53:07,167 - Epoch: [364][  100/  155]    Loss 3.043014    mAP 0.454582    
2023-04-27 07:53:15,092 - Epoch: [364][  150/  155]    Loss 3.038746    mAP 0.453186    
2023-04-27 07:53:15,804 - Epoch: [364][  155/  155]    Loss 3.039212    mAP 0.452225    
2023-04-27 07:53:15,878 - ==> mAP: 0.45223    Loss: 3.039

2023-04-27 07:53:15,882 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:53:15,882 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:53:15,917 - 

2023-04-27 07:53:15,917 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:53:27,491 - Epoch: [365][   50/  518]    Overall Loss 2.924481    Objective Loss 2.924481                                        LR 0.000008    Time 0.231434    
2023-04-27 07:53:38,360 - Epoch: [365][  100/  518]    Overall Loss 2.905822    Objective Loss 2.905822                                        LR 0.000008    Time 0.224391    
2023-04-27 07:53:49,280 - Epoch: [365][  150/  518]    Overall Loss 2.875816    Objective Loss 2.875816                                        LR 0.000008    Time 0.222382    
2023-04-27 07:54:00,084 - Epoch: [365][  200/  518]    Overall Loss 2.871380    Objective Loss 2.871380                                        LR 0.000008    Time 0.220799    
2023-04-27 07:54:10,844 - Epoch: [365][  250/  518]    Overall Loss 2.870580    Objective Loss 2.870580                                        LR 0.000008    Time 0.219674    
2023-04-27 07:54:21,673 - Epoch: [365][  300/  518]    Overall Loss 2.868904    Objective Loss 2.868904                                        LR 0.000008    Time 0.219153    
2023-04-27 07:54:32,391 - Epoch: [365][  350/  518]    Overall Loss 2.867579    Objective Loss 2.867579                                        LR 0.000008    Time 0.218464    
2023-04-27 07:54:43,306 - Epoch: [365][  400/  518]    Overall Loss 2.871074    Objective Loss 2.871074                                        LR 0.000008    Time 0.218439    
2023-04-27 07:54:54,144 - Epoch: [365][  450/  518]    Overall Loss 2.868886    Objective Loss 2.868886                                        LR 0.000008    Time 0.218249    
2023-04-27 07:55:04,933 - Epoch: [365][  500/  518]    Overall Loss 2.867646    Objective Loss 2.867646                                        LR 0.000008    Time 0.218000    
2023-04-27 07:55:08,630 - Epoch: [365][  518/  518]    Overall Loss 2.869330    Objective Loss 2.869330                                        LR 0.000008    Time 0.217559    
2023-04-27 07:55:08,706 - --- validate (epoch=365)-----------
2023-04-27 07:55:08,707 - 4952 samples (32 per mini-batch)
2023-04-27 07:55:16,966 - Epoch: [365][   50/  155]    Loss 3.140777    mAP 0.441244    
2023-04-27 07:55:24,878 - Epoch: [365][  100/  155]    Loss 3.094540    mAP 0.448591    
2023-04-27 07:55:32,783 - Epoch: [365][  150/  155]    Loss 3.083510    mAP 0.447867    
2023-04-27 07:55:33,509 - Epoch: [365][  155/  155]    Loss 3.084567    mAP 0.447994    
2023-04-27 07:55:33,587 - ==> mAP: 0.44799    Loss: 3.085

2023-04-27 07:55:33,591 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:55:33,591 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:55:33,625 - 

2023-04-27 07:55:33,625 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:55:45,235 - Epoch: [366][   50/  518]    Overall Loss 2.934736    Objective Loss 2.934736                                        LR 0.000008    Time 0.232137    
2023-04-27 07:55:55,993 - Epoch: [366][  100/  518]    Overall Loss 2.896028    Objective Loss 2.896028                                        LR 0.000008    Time 0.223631    
2023-04-27 07:56:06,824 - Epoch: [366][  150/  518]    Overall Loss 2.883364    Objective Loss 2.883364                                        LR 0.000008    Time 0.221287    
2023-04-27 07:56:17,665 - Epoch: [366][  200/  518]    Overall Loss 2.874910    Objective Loss 2.874910                                        LR 0.000008    Time 0.220163    
2023-04-27 07:56:28,424 - Epoch: [366][  250/  518]    Overall Loss 2.871224    Objective Loss 2.871224                                        LR 0.000008    Time 0.219160    
2023-04-27 07:56:39,248 - Epoch: [366][  300/  518]    Overall Loss 2.881342    Objective Loss 2.881342                                        LR 0.000008    Time 0.218708    
2023-04-27 07:56:50,029 - Epoch: [366][  350/  518]    Overall Loss 2.883573    Objective Loss 2.883573                                        LR 0.000008    Time 0.218262    
2023-04-27 07:57:00,847 - Epoch: [366][  400/  518]    Overall Loss 2.876901    Objective Loss 2.876901                                        LR 0.000008    Time 0.218021    
2023-04-27 07:57:11,684 - Epoch: [366][  450/  518]    Overall Loss 2.873009    Objective Loss 2.873009                                        LR 0.000008    Time 0.217876    
2023-04-27 07:57:22,545 - Epoch: [366][  500/  518]    Overall Loss 2.876213    Objective Loss 2.876213                                        LR 0.000008    Time 0.217807    
2023-04-27 07:57:26,259 - Epoch: [366][  518/  518]    Overall Loss 2.874427    Objective Loss 2.874427                                        LR 0.000008    Time 0.217406    
2023-04-27 07:57:26,335 - --- validate (epoch=366)-----------
2023-04-27 07:57:26,336 - 4952 samples (32 per mini-batch)
2023-04-27 07:57:34,631 - Epoch: [366][   50/  155]    Loss 3.033650    mAP 0.439872    
2023-04-27 07:57:42,545 - Epoch: [366][  100/  155]    Loss 3.048375    mAP 0.444336    
2023-04-27 07:57:50,443 - Epoch: [366][  150/  155]    Loss 3.030183    mAP 0.451137    
2023-04-27 07:57:51,163 - Epoch: [366][  155/  155]    Loss 3.025752    mAP 0.451660    
2023-04-27 07:57:51,236 - ==> mAP: 0.45166    Loss: 3.026

2023-04-27 07:57:51,241 - ==> Best [mAP: 0.454234   vloss: 3.062401   Sparsity:0.00   Params: 2177087 on epoch: 307]
2023-04-27 07:57:51,241 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 07:57:51,277 - 

2023-04-27 07:57:51,277 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 07:58:02,761 - Epoch: [367][   50/  518]    Overall Loss 2.903397    Objective Loss 2.903397                                        LR 0.000008    Time 0.229620    
2023-04-27 07:58:13,567 - Epoch: [367][  100/  518]    Overall Loss 2.898923    Objective Loss 2.898923                                        LR 0.000008    Time 0.222854    
2023-04-27 07:58:24,374 - Epoch: [367][  150/  518]    Overall Loss 2.867365    Objective Loss 2.867365                                        LR 0.000008    Time 0.220612    
2023-04-27 07:58:35,126 - Epoch: [367][  200/  518]    Overall Loss 2.872621    Objective Loss 2.872621                                        LR 0.000008    Time 0.219211    
2023-04-27 07:58:45,998 - Epoch: [367][  250/  518]    Overall Loss 2.876251    Objective Loss 2.876251                                        LR 0.000008    Time 0.218848    
2023-04-27 07:58:56,764 - Epoch: [367][  300/  518]    Overall Loss 2.882129    Objective Loss 2.882129                                        LR 0.000008    Time 0.218255    
2023-04-27 07:59:07,564 - Epoch: [367][  350/  518]    Overall Loss 2.880567    Objective Loss 2.880567                                        LR 0.000008    Time 0.217928    
2023-04-27 07:59:18,391 - Epoch: [367][  400/  518]    Overall Loss 2.874665    Objective Loss 2.874665                                        LR 0.000008    Time 0.217752    
2023-04-27 07:59:29,273 - Epoch: [367][  450/  518]    Overall Loss 2.876258    Objective Loss 2.876258                                        LR 0.000008    Time 0.217736    
2023-04-27 07:59:40,115 - Epoch: [367][  500/  518]    Overall Loss 2.876681    Objective Loss 2.876681                                        LR 0.000008    Time 0.217643    
2023-04-27 07:59:43,851 - Epoch: [367][  518/  518]    Overall Loss 2.877396    Objective Loss 2.877396                                        LR 0.000008    Time 0.217290    
2023-04-27 07:59:43,928 - --- validate (epoch=367)-----------
2023-04-27 07:59:43,928 - 4952 samples (32 per mini-batch)
2023-04-27 07:59:52,270 - Epoch: [367][   50/  155]    Loss 3.042438    mAP 0.468007    
2023-04-27 08:00:00,207 - Epoch: [367][  100/  155]    Loss 3.050080    mAP 0.459082    
2023-04-27 08:00:08,113 - Epoch: [367][  150/  155]    Loss 3.038764    mAP 0.455918    
2023-04-27 08:00:08,845 - Epoch: [367][  155/  155]    Loss 3.032273    mAP 0.458592    
2023-04-27 08:00:08,917 - ==> mAP: 0.45859    Loss: 3.032

2023-04-27 08:00:08,921 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:00:08,921 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:00:08,971 - 

2023-04-27 08:00:08,972 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:00:20,611 - Epoch: [368][   50/  518]    Overall Loss 2.857022    Objective Loss 2.857022                                        LR 0.000008    Time 0.232741    
2023-04-27 08:00:31,426 - Epoch: [368][  100/  518]    Overall Loss 2.850707    Objective Loss 2.850707                                        LR 0.000008    Time 0.224499    
2023-04-27 08:00:42,259 - Epoch: [368][  150/  518]    Overall Loss 2.851337    Objective Loss 2.851337                                        LR 0.000008    Time 0.221878    
2023-04-27 08:00:53,090 - Epoch: [368][  200/  518]    Overall Loss 2.850680    Objective Loss 2.850680                                        LR 0.000008    Time 0.220557    
2023-04-27 08:01:03,860 - Epoch: [368][  250/  518]    Overall Loss 2.855631    Objective Loss 2.855631                                        LR 0.000008    Time 0.219516    
2023-04-27 08:01:14,603 - Epoch: [368][  300/  518]    Overall Loss 2.861280    Objective Loss 2.861280                                        LR 0.000008    Time 0.218737    
2023-04-27 08:01:25,442 - Epoch: [368][  350/  518]    Overall Loss 2.856710    Objective Loss 2.856710                                        LR 0.000008    Time 0.218451    
2023-04-27 08:01:36,232 - Epoch: [368][  400/  518]    Overall Loss 2.862302    Objective Loss 2.862302                                        LR 0.000008    Time 0.218116    
2023-04-27 08:01:47,032 - Epoch: [368][  450/  518]    Overall Loss 2.863540    Objective Loss 2.863540                                        LR 0.000008    Time 0.217879    
2023-04-27 08:01:57,958 - Epoch: [368][  500/  518]    Overall Loss 2.865830    Objective Loss 2.865830                                        LR 0.000008    Time 0.217939    
2023-04-27 08:02:01,710 - Epoch: [368][  518/  518]    Overall Loss 2.863271    Objective Loss 2.863271                                        LR 0.000008    Time 0.217608    
2023-04-27 08:02:01,786 - --- validate (epoch=368)-----------
2023-04-27 08:02:01,786 - 4952 samples (32 per mini-batch)
2023-04-27 08:02:10,081 - Epoch: [368][   50/  155]    Loss 3.048494    mAP 0.449850    
2023-04-27 08:02:18,028 - Epoch: [368][  100/  155]    Loss 3.045954    mAP 0.451383    
2023-04-27 08:02:25,921 - Epoch: [368][  150/  155]    Loss 3.045110    mAP 0.453191    
2023-04-27 08:02:26,634 - Epoch: [368][  155/  155]    Loss 3.047396    mAP 0.451256    
2023-04-27 08:02:26,708 - ==> mAP: 0.45126    Loss: 3.047

2023-04-27 08:02:26,711 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:02:26,711 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:02:26,746 - 

2023-04-27 08:02:26,746 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:02:38,410 - Epoch: [369][   50/  518]    Overall Loss 2.814911    Objective Loss 2.814911                                        LR 0.000008    Time 0.233219    
2023-04-27 08:02:49,231 - Epoch: [369][  100/  518]    Overall Loss 2.818468    Objective Loss 2.818468                                        LR 0.000008    Time 0.224809    
2023-04-27 08:03:00,132 - Epoch: [369][  150/  518]    Overall Loss 2.822437    Objective Loss 2.822437                                        LR 0.000008    Time 0.222535    
2023-04-27 08:03:10,910 - Epoch: [369][  200/  518]    Overall Loss 2.839170    Objective Loss 2.839170                                        LR 0.000008    Time 0.220781    
2023-04-27 08:03:21,755 - Epoch: [369][  250/  518]    Overall Loss 2.849044    Objective Loss 2.849044                                        LR 0.000008    Time 0.219999    
2023-04-27 08:03:32,557 - Epoch: [369][  300/  518]    Overall Loss 2.844597    Objective Loss 2.844597                                        LR 0.000008    Time 0.219336    
2023-04-27 08:03:43,343 - Epoch: [369][  350/  518]    Overall Loss 2.855642    Objective Loss 2.855642                                        LR 0.000008    Time 0.218814    
2023-04-27 08:03:54,177 - Epoch: [369][  400/  518]    Overall Loss 2.856524    Objective Loss 2.856524                                        LR 0.000008    Time 0.218542    
2023-04-27 08:04:04,920 - Epoch: [369][  450/  518]    Overall Loss 2.860280    Objective Loss 2.860280                                        LR 0.000008    Time 0.218130    
2023-04-27 08:04:15,733 - Epoch: [369][  500/  518]    Overall Loss 2.858625    Objective Loss 2.858625                                        LR 0.000008    Time 0.217940    
2023-04-27 08:04:19,490 - Epoch: [369][  518/  518]    Overall Loss 2.861826    Objective Loss 2.861826                                        LR 0.000008    Time 0.217619    
2023-04-27 08:04:19,566 - --- validate (epoch=369)-----------
2023-04-27 08:04:19,566 - 4952 samples (32 per mini-batch)
2023-04-27 08:04:27,882 - Epoch: [369][   50/  155]    Loss 3.024224    mAP 0.467254    
2023-04-27 08:04:35,818 - Epoch: [369][  100/  155]    Loss 3.005604    mAP 0.459859    
2023-04-27 08:04:43,704 - Epoch: [369][  150/  155]    Loss 3.017929    mAP 0.452334    
2023-04-27 08:04:44,418 - Epoch: [369][  155/  155]    Loss 3.012405    mAP 0.453111    
2023-04-27 08:04:44,494 - ==> mAP: 0.45311    Loss: 3.012

2023-04-27 08:04:44,498 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:04:44,498 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:04:44,532 - 

2023-04-27 08:04:44,533 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:04:56,105 - Epoch: [370][   50/  518]    Overall Loss 2.873385    Objective Loss 2.873385                                        LR 0.000008    Time 0.231399    
2023-04-27 08:05:06,937 - Epoch: [370][  100/  518]    Overall Loss 2.867400    Objective Loss 2.867400                                        LR 0.000008    Time 0.224003    
2023-04-27 08:05:17,759 - Epoch: [370][  150/  518]    Overall Loss 2.862311    Objective Loss 2.862311                                        LR 0.000008    Time 0.221470    
2023-04-27 08:05:28,587 - Epoch: [370][  200/  518]    Overall Loss 2.856382    Objective Loss 2.856382                                        LR 0.000008    Time 0.220235    
2023-04-27 08:05:39,397 - Epoch: [370][  250/  518]    Overall Loss 2.864513    Objective Loss 2.864513                                        LR 0.000008    Time 0.219421    
2023-04-27 08:05:50,140 - Epoch: [370][  300/  518]    Overall Loss 2.867024    Objective Loss 2.867024                                        LR 0.000008    Time 0.218655    
2023-04-27 08:06:00,955 - Epoch: [370][  350/  518]    Overall Loss 2.861971    Objective Loss 2.861971                                        LR 0.000008    Time 0.218314    
2023-04-27 08:06:11,782 - Epoch: [370][  400/  518]    Overall Loss 2.862488    Objective Loss 2.862488                                        LR 0.000008    Time 0.218090    
2023-04-27 08:06:22,636 - Epoch: [370][  450/  518]    Overall Loss 2.865446    Objective Loss 2.865446                                        LR 0.000008    Time 0.217973    
2023-04-27 08:06:33,463 - Epoch: [370][  500/  518]    Overall Loss 2.863748    Objective Loss 2.863748                                        LR 0.000008    Time 0.217827    
2023-04-27 08:06:37,188 - Epoch: [370][  518/  518]    Overall Loss 2.863527    Objective Loss 2.863527                                        LR 0.000008    Time 0.217448    
2023-04-27 08:06:37,264 - --- validate (epoch=370)-----------
2023-04-27 08:06:37,264 - 4952 samples (32 per mini-batch)
2023-04-27 08:06:45,601 - Epoch: [370][   50/  155]    Loss 3.066857    mAP 0.441622    
2023-04-27 08:06:53,555 - Epoch: [370][  100/  155]    Loss 3.049439    mAP 0.447764    
2023-04-27 08:07:01,490 - Epoch: [370][  150/  155]    Loss 3.041316    mAP 0.452087    
2023-04-27 08:07:02,206 - Epoch: [370][  155/  155]    Loss 3.040429    mAP 0.452405    
2023-04-27 08:07:02,283 - ==> mAP: 0.45241    Loss: 3.040

2023-04-27 08:07:02,287 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:07:02,287 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:07:02,321 - 

2023-04-27 08:07:02,321 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:07:13,803 - Epoch: [371][   50/  518]    Overall Loss 2.863983    Objective Loss 2.863983                                        LR 0.000008    Time 0.229573    
2023-04-27 08:07:24,694 - Epoch: [371][  100/  518]    Overall Loss 2.852425    Objective Loss 2.852425                                        LR 0.000008    Time 0.223685    
2023-04-27 08:07:35,527 - Epoch: [371][  150/  518]    Overall Loss 2.856879    Objective Loss 2.856879                                        LR 0.000008    Time 0.221329    
2023-04-27 08:07:46,343 - Epoch: [371][  200/  518]    Overall Loss 2.861101    Objective Loss 2.861101                                        LR 0.000008    Time 0.220069    
2023-04-27 08:07:57,243 - Epoch: [371][  250/  518]    Overall Loss 2.855805    Objective Loss 2.855805                                        LR 0.000008    Time 0.219651    
2023-04-27 08:08:08,092 - Epoch: [371][  300/  518]    Overall Loss 2.861710    Objective Loss 2.861710                                        LR 0.000008    Time 0.219200    
2023-04-27 08:08:18,931 - Epoch: [371][  350/  518]    Overall Loss 2.857888    Objective Loss 2.857888                                        LR 0.000008    Time 0.218849    
2023-04-27 08:08:29,871 - Epoch: [371][  400/  518]    Overall Loss 2.864811    Objective Loss 2.864811                                        LR 0.000008    Time 0.218839    
2023-04-27 08:08:40,634 - Epoch: [371][  450/  518]    Overall Loss 2.862521    Objective Loss 2.862521                                        LR 0.000008    Time 0.218439    
2023-04-27 08:08:51,480 - Epoch: [371][  500/  518]    Overall Loss 2.860879    Objective Loss 2.860879                                        LR 0.000008    Time 0.218284    
2023-04-27 08:08:55,190 - Epoch: [371][  518/  518]    Overall Loss 2.854553    Objective Loss 2.854553                                        LR 0.000008    Time 0.217859    
2023-04-27 08:08:55,264 - --- validate (epoch=371)-----------
2023-04-27 08:08:55,265 - 4952 samples (32 per mini-batch)
2023-04-27 08:09:03,589 - Epoch: [371][   50/  155]    Loss 3.036824    mAP 0.455412    
2023-04-27 08:09:11,515 - Epoch: [371][  100/  155]    Loss 3.051070    mAP 0.449773    
2023-04-27 08:09:19,398 - Epoch: [371][  150/  155]    Loss 3.043839    mAP 0.450462    
2023-04-27 08:09:20,124 - Epoch: [371][  155/  155]    Loss 3.042390    mAP 0.451275    
2023-04-27 08:09:20,201 - ==> mAP: 0.45128    Loss: 3.042

2023-04-27 08:09:20,205 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:09:20,206 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:09:20,239 - 

2023-04-27 08:09:20,239 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:09:31,812 - Epoch: [372][   50/  518]    Overall Loss 2.869314    Objective Loss 2.869314                                        LR 0.000008    Time 0.231404    
2023-04-27 08:09:42,650 - Epoch: [372][  100/  518]    Overall Loss 2.874960    Objective Loss 2.874960                                        LR 0.000008    Time 0.224065    
2023-04-27 08:09:53,461 - Epoch: [372][  150/  518]    Overall Loss 2.869102    Objective Loss 2.869102                                        LR 0.000008    Time 0.221438    
2023-04-27 08:10:04,236 - Epoch: [372][  200/  518]    Overall Loss 2.869131    Objective Loss 2.869131                                        LR 0.000008    Time 0.219948    
2023-04-27 08:10:15,069 - Epoch: [372][  250/  518]    Overall Loss 2.870465    Objective Loss 2.870465                                        LR 0.000008    Time 0.219284    
2023-04-27 08:10:25,925 - Epoch: [372][  300/  518]    Overall Loss 2.869332    Objective Loss 2.869332                                        LR 0.000008    Time 0.218916    
2023-04-27 08:10:36,722 - Epoch: [372][  350/  518]    Overall Loss 2.871924    Objective Loss 2.871924                                        LR 0.000008    Time 0.218488    
2023-04-27 08:10:47,547 - Epoch: [372][  400/  518]    Overall Loss 2.868544    Objective Loss 2.868544                                        LR 0.000008    Time 0.218237    
2023-04-27 08:10:58,395 - Epoch: [372][  450/  518]    Overall Loss 2.871948    Objective Loss 2.871948                                        LR 0.000008    Time 0.218089    
2023-04-27 08:11:09,228 - Epoch: [372][  500/  518]    Overall Loss 2.868265    Objective Loss 2.868265                                        LR 0.000008    Time 0.217943    
2023-04-27 08:11:12,968 - Epoch: [372][  518/  518]    Overall Loss 2.866628    Objective Loss 2.866628                                        LR 0.000008    Time 0.217590    
2023-04-27 08:11:13,046 - --- validate (epoch=372)-----------
2023-04-27 08:11:13,046 - 4952 samples (32 per mini-batch)
2023-04-27 08:11:21,407 - Epoch: [372][   50/  155]    Loss 3.072641    mAP 0.442055    
2023-04-27 08:11:29,395 - Epoch: [372][  100/  155]    Loss 3.028341    mAP 0.456699    
2023-04-27 08:11:37,326 - Epoch: [372][  150/  155]    Loss 3.035696    mAP 0.452122    
2023-04-27 08:11:38,050 - Epoch: [372][  155/  155]    Loss 3.040617    mAP 0.452249    
2023-04-27 08:11:38,115 - ==> mAP: 0.45225    Loss: 3.041

2023-04-27 08:11:38,119 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:11:38,119 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:11:38,154 - 

2023-04-27 08:11:38,154 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:11:49,882 - Epoch: [373][   50/  518]    Overall Loss 2.857847    Objective Loss 2.857847                                        LR 0.000008    Time 0.234503    
2023-04-27 08:12:00,691 - Epoch: [373][  100/  518]    Overall Loss 2.823592    Objective Loss 2.823592                                        LR 0.000008    Time 0.225322    
2023-04-27 08:12:11,578 - Epoch: [373][  150/  518]    Overall Loss 2.836571    Objective Loss 2.836571                                        LR 0.000008    Time 0.222787    
2023-04-27 08:12:22,437 - Epoch: [373][  200/  518]    Overall Loss 2.838915    Objective Loss 2.838915                                        LR 0.000008    Time 0.221377    
2023-04-27 08:12:33,304 - Epoch: [373][  250/  518]    Overall Loss 2.842713    Objective Loss 2.842713                                        LR 0.000008    Time 0.220563    
2023-04-27 08:12:44,134 - Epoch: [373][  300/  518]    Overall Loss 2.851865    Objective Loss 2.851865                                        LR 0.000008    Time 0.219897    
2023-04-27 08:12:54,891 - Epoch: [373][  350/  518]    Overall Loss 2.852738    Objective Loss 2.852738                                        LR 0.000008    Time 0.219212    
2023-04-27 08:13:05,762 - Epoch: [373][  400/  518]    Overall Loss 2.854312    Objective Loss 2.854312                                        LR 0.000008    Time 0.218984    
2023-04-27 08:13:16,585 - Epoch: [373][  450/  518]    Overall Loss 2.858607    Objective Loss 2.858607                                        LR 0.000008    Time 0.218702    
2023-04-27 08:13:27,405 - Epoch: [373][  500/  518]    Overall Loss 2.864924    Objective Loss 2.864924                                        LR 0.000008    Time 0.218467    
2023-04-27 08:13:31,136 - Epoch: [373][  518/  518]    Overall Loss 2.864545    Objective Loss 2.864545                                        LR 0.000008    Time 0.218078    
2023-04-27 08:13:31,213 - --- validate (epoch=373)-----------
2023-04-27 08:13:31,214 - 4952 samples (32 per mini-batch)
2023-04-27 08:13:39,475 - Epoch: [373][   50/  155]    Loss 3.061898    mAP 0.446175    
2023-04-27 08:13:47,369 - Epoch: [373][  100/  155]    Loss 3.053523    mAP 0.433636    
2023-04-27 08:13:55,254 - Epoch: [373][  150/  155]    Loss 3.037055    mAP 0.442666    
2023-04-27 08:13:55,968 - Epoch: [373][  155/  155]    Loss 3.035556    mAP 0.444424    
2023-04-27 08:13:56,049 - ==> mAP: 0.44442    Loss: 3.036

2023-04-27 08:13:56,053 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:13:56,053 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:13:56,089 - 

2023-04-27 08:13:56,089 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:14:07,772 - Epoch: [374][   50/  518]    Overall Loss 2.862606    Objective Loss 2.862606                                        LR 0.000008    Time 0.233597    
2023-04-27 08:14:18,534 - Epoch: [374][  100/  518]    Overall Loss 2.871711    Objective Loss 2.871711                                        LR 0.000008    Time 0.224411    
2023-04-27 08:14:29,370 - Epoch: [374][  150/  518]    Overall Loss 2.873492    Objective Loss 2.873492                                        LR 0.000008    Time 0.221831    
2023-04-27 08:14:40,179 - Epoch: [374][  200/  518]    Overall Loss 2.860279    Objective Loss 2.860279                                        LR 0.000008    Time 0.220413    
2023-04-27 08:14:50,903 - Epoch: [374][  250/  518]    Overall Loss 2.854906    Objective Loss 2.854906                                        LR 0.000008    Time 0.219221    
2023-04-27 08:15:01,740 - Epoch: [374][  300/  518]    Overall Loss 2.846307    Objective Loss 2.846307                                        LR 0.000008    Time 0.218802    
2023-04-27 08:15:12,603 - Epoch: [374][  350/  518]    Overall Loss 2.847711    Objective Loss 2.847711                                        LR 0.000008    Time 0.218576    
2023-04-27 08:15:23,396 - Epoch: [374][  400/  518]    Overall Loss 2.851909    Objective Loss 2.851909                                        LR 0.000008    Time 0.218233    
2023-04-27 08:15:34,191 - Epoch: [374][  450/  518]    Overall Loss 2.852942    Objective Loss 2.852942                                        LR 0.000008    Time 0.217971    
2023-04-27 08:15:45,026 - Epoch: [374][  500/  518]    Overall Loss 2.852988    Objective Loss 2.852988                                        LR 0.000008    Time 0.217839    
2023-04-27 08:15:48,753 - Epoch: [374][  518/  518]    Overall Loss 2.851952    Objective Loss 2.851952                                        LR 0.000008    Time 0.217464    
2023-04-27 08:15:48,830 - --- validate (epoch=374)-----------
2023-04-27 08:15:48,830 - 4952 samples (32 per mini-batch)
2023-04-27 08:15:57,158 - Epoch: [374][   50/  155]    Loss 3.056324    mAP 0.452514    
2023-04-27 08:16:05,079 - Epoch: [374][  100/  155]    Loss 3.056189    mAP 0.451890    
2023-04-27 08:16:12,952 - Epoch: [374][  150/  155]    Loss 3.037203    mAP 0.448005    
2023-04-27 08:16:13,666 - Epoch: [374][  155/  155]    Loss 3.037995    mAP 0.447683    
2023-04-27 08:16:13,735 - ==> mAP: 0.44768    Loss: 3.038

2023-04-27 08:16:13,739 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:16:13,739 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:16:13,773 - 

2023-04-27 08:16:13,774 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:16:25,496 - Epoch: [375][   50/  518]    Overall Loss 2.870206    Objective Loss 2.870206                                        LR 0.000008    Time 0.234399    
2023-04-27 08:16:36,319 - Epoch: [375][  100/  518]    Overall Loss 2.837856    Objective Loss 2.837856                                        LR 0.000008    Time 0.225415    
2023-04-27 08:16:47,216 - Epoch: [375][  150/  518]    Overall Loss 2.850794    Objective Loss 2.850794                                        LR 0.000008    Time 0.222911    
2023-04-27 08:16:58,054 - Epoch: [375][  200/  518]    Overall Loss 2.850472    Objective Loss 2.850472                                        LR 0.000008    Time 0.221367    
2023-04-27 08:17:08,835 - Epoch: [375][  250/  518]    Overall Loss 2.850345    Objective Loss 2.850345                                        LR 0.000008    Time 0.220210    
2023-04-27 08:17:19,620 - Epoch: [375][  300/  518]    Overall Loss 2.846423    Objective Loss 2.846423                                        LR 0.000008    Time 0.219453    
2023-04-27 08:17:30,450 - Epoch: [375][  350/  518]    Overall Loss 2.850095    Objective Loss 2.850095                                        LR 0.000008    Time 0.219041    
2023-04-27 08:17:41,283 - Epoch: [375][  400/  518]    Overall Loss 2.851993    Objective Loss 2.851993                                        LR 0.000008    Time 0.218741    
2023-04-27 08:17:52,174 - Epoch: [375][  450/  518]    Overall Loss 2.850109    Objective Loss 2.850109                                        LR 0.000008    Time 0.218634    
2023-04-27 08:18:03,025 - Epoch: [375][  500/  518]    Overall Loss 2.852404    Objective Loss 2.852404                                        LR 0.000008    Time 0.218469    
2023-04-27 08:18:06,769 - Epoch: [375][  518/  518]    Overall Loss 2.852170    Objective Loss 2.852170                                        LR 0.000008    Time 0.218105    
2023-04-27 08:18:06,848 - --- validate (epoch=375)-----------
2023-04-27 08:18:06,848 - 4952 samples (32 per mini-batch)
2023-04-27 08:18:15,217 - Epoch: [375][   50/  155]    Loss 3.030808    mAP 0.459773    
2023-04-27 08:18:23,207 - Epoch: [375][  100/  155]    Loss 3.044668    mAP 0.450688    
2023-04-27 08:18:31,173 - Epoch: [375][  150/  155]    Loss 3.033739    mAP 0.450817    
2023-04-27 08:18:31,883 - Epoch: [375][  155/  155]    Loss 3.033724    mAP 0.449076    
2023-04-27 08:18:31,963 - ==> mAP: 0.44908    Loss: 3.034

2023-04-27 08:18:31,966 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:18:31,967 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:18:32,001 - 

2023-04-27 08:18:32,001 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:18:43,680 - Epoch: [376][   50/  518]    Overall Loss 2.890545    Objective Loss 2.890545                                        LR 0.000008    Time 0.233522    
2023-04-27 08:18:54,528 - Epoch: [376][  100/  518]    Overall Loss 2.879744    Objective Loss 2.879744                                        LR 0.000008    Time 0.225228    
2023-04-27 08:19:05,305 - Epoch: [376][  150/  518]    Overall Loss 2.864941    Objective Loss 2.864941                                        LR 0.000008    Time 0.221985    
2023-04-27 08:19:16,085 - Epoch: [376][  200/  518]    Overall Loss 2.860265    Objective Loss 2.860265                                        LR 0.000008    Time 0.220383    
2023-04-27 08:19:26,810 - Epoch: [376][  250/  518]    Overall Loss 2.855235    Objective Loss 2.855235                                        LR 0.000008    Time 0.219199    
2023-04-27 08:19:37,609 - Epoch: [376][  300/  518]    Overall Loss 2.852829    Objective Loss 2.852829                                        LR 0.000008    Time 0.218657    
2023-04-27 08:19:48,410 - Epoch: [376][  350/  518]    Overall Loss 2.854520    Objective Loss 2.854520                                        LR 0.000008    Time 0.218277    
2023-04-27 08:19:59,258 - Epoch: [376][  400/  518]    Overall Loss 2.854647    Objective Loss 2.854647                                        LR 0.000008    Time 0.218108    
2023-04-27 08:20:09,989 - Epoch: [376][  450/  518]    Overall Loss 2.856969    Objective Loss 2.856969                                        LR 0.000008    Time 0.217717    
2023-04-27 08:20:20,791 - Epoch: [376][  500/  518]    Overall Loss 2.861218    Objective Loss 2.861218                                        LR 0.000008    Time 0.217546    
2023-04-27 08:20:24,488 - Epoch: [376][  518/  518]    Overall Loss 2.862852    Objective Loss 2.862852                                        LR 0.000008    Time 0.217122    
2023-04-27 08:20:24,566 - --- validate (epoch=376)-----------
2023-04-27 08:20:24,566 - 4952 samples (32 per mini-batch)
2023-04-27 08:20:32,875 - Epoch: [376][   50/  155]    Loss 3.076894    mAP 0.455674    
2023-04-27 08:20:40,807 - Epoch: [376][  100/  155]    Loss 3.048409    mAP 0.449770    
2023-04-27 08:20:48,695 - Epoch: [376][  150/  155]    Loss 3.049951    mAP 0.447178    
2023-04-27 08:20:49,420 - Epoch: [376][  155/  155]    Loss 3.047767    mAP 0.448709    
2023-04-27 08:20:49,492 - ==> mAP: 0.44871    Loss: 3.048

2023-04-27 08:20:49,496 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:20:49,497 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:20:49,531 - 

2023-04-27 08:20:49,531 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:21:01,222 - Epoch: [377][   50/  518]    Overall Loss 2.861189    Objective Loss 2.861189                                        LR 0.000008    Time 0.233760    
2023-04-27 08:21:12,046 - Epoch: [377][  100/  518]    Overall Loss 2.861075    Objective Loss 2.861075                                        LR 0.000008    Time 0.225109    
2023-04-27 08:21:22,767 - Epoch: [377][  150/  518]    Overall Loss 2.868728    Objective Loss 2.868728                                        LR 0.000008    Time 0.221533    
2023-04-27 08:21:33,576 - Epoch: [377][  200/  518]    Overall Loss 2.857944    Objective Loss 2.857944                                        LR 0.000008    Time 0.220186    
2023-04-27 08:21:44,373 - Epoch: [377][  250/  518]    Overall Loss 2.864840    Objective Loss 2.864840                                        LR 0.000008    Time 0.219331    
2023-04-27 08:21:55,197 - Epoch: [377][  300/  518]    Overall Loss 2.867250    Objective Loss 2.867250                                        LR 0.000008    Time 0.218850    
2023-04-27 08:22:06,019 - Epoch: [377][  350/  518]    Overall Loss 2.867279    Objective Loss 2.867279                                        LR 0.000008    Time 0.218502    
2023-04-27 08:22:16,797 - Epoch: [377][  400/  518]    Overall Loss 2.869935    Objective Loss 2.869935                                        LR 0.000008    Time 0.218131    
2023-04-27 08:22:27,597 - Epoch: [377][  450/  518]    Overall Loss 2.865551    Objective Loss 2.865551                                        LR 0.000008    Time 0.217891    
2023-04-27 08:22:38,473 - Epoch: [377][  500/  518]    Overall Loss 2.867141    Objective Loss 2.867141                                        LR 0.000008    Time 0.217850    
2023-04-27 08:22:42,214 - Epoch: [377][  518/  518]    Overall Loss 2.866565    Objective Loss 2.866565                                        LR 0.000008    Time 0.217501    
2023-04-27 08:22:42,291 - --- validate (epoch=377)-----------
2023-04-27 08:22:42,291 - 4952 samples (32 per mini-batch)
2023-04-27 08:22:50,571 - Epoch: [377][   50/  155]    Loss 3.055832    mAP 0.448093    
2023-04-27 08:22:58,498 - Epoch: [377][  100/  155]    Loss 3.071528    mAP 0.440057    
2023-04-27 08:23:06,393 - Epoch: [377][  150/  155]    Loss 3.045951    mAP 0.443899    
2023-04-27 08:23:07,113 - Epoch: [377][  155/  155]    Loss 3.046380    mAP 0.444904    
2023-04-27 08:23:07,182 - ==> mAP: 0.44490    Loss: 3.046

2023-04-27 08:23:07,186 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:23:07,186 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:23:07,221 - 

2023-04-27 08:23:07,221 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:23:18,778 - Epoch: [378][   50/  518]    Overall Loss 2.832137    Objective Loss 2.832137                                        LR 0.000008    Time 0.231099    
2023-04-27 08:23:29,620 - Epoch: [378][  100/  518]    Overall Loss 2.832259    Objective Loss 2.832259                                        LR 0.000008    Time 0.223953    
2023-04-27 08:23:40,449 - Epoch: [378][  150/  518]    Overall Loss 2.831868    Objective Loss 2.831868                                        LR 0.000008    Time 0.221481    
2023-04-27 08:23:51,241 - Epoch: [378][  200/  518]    Overall Loss 2.849772    Objective Loss 2.849772                                        LR 0.000008    Time 0.220061    
2023-04-27 08:24:02,009 - Epoch: [378][  250/  518]    Overall Loss 2.850465    Objective Loss 2.850465                                        LR 0.000008    Time 0.219119    
2023-04-27 08:24:12,827 - Epoch: [378][  300/  518]    Overall Loss 2.850694    Objective Loss 2.850694                                        LR 0.000008    Time 0.218651    
2023-04-27 08:24:23,688 - Epoch: [378][  350/  518]    Overall Loss 2.853793    Objective Loss 2.853793                                        LR 0.000008    Time 0.218444    
2023-04-27 08:24:34,533 - Epoch: [378][  400/  518]    Overall Loss 2.850773    Objective Loss 2.850773                                        LR 0.000008    Time 0.218247    
2023-04-27 08:24:45,415 - Epoch: [378][  450/  518]    Overall Loss 2.850322    Objective Loss 2.850322                                        LR 0.000008    Time 0.218177    
2023-04-27 08:24:56,257 - Epoch: [378][  500/  518]    Overall Loss 2.856117    Objective Loss 2.856117                                        LR 0.000008    Time 0.218038    
2023-04-27 08:24:59,993 - Epoch: [378][  518/  518]    Overall Loss 2.861394    Objective Loss 2.861394                                        LR 0.000008    Time 0.217674    
2023-04-27 08:25:00,066 - --- validate (epoch=378)-----------
2023-04-27 08:25:00,066 - 4952 samples (32 per mini-batch)
2023-04-27 08:25:08,377 - Epoch: [378][   50/  155]    Loss 3.066599    mAP 0.442920    
2023-04-27 08:25:16,313 - Epoch: [378][  100/  155]    Loss 3.061739    mAP 0.446090    
2023-04-27 08:25:24,204 - Epoch: [378][  150/  155]    Loss 3.039024    mAP 0.452784    
2023-04-27 08:25:24,927 - Epoch: [378][  155/  155]    Loss 3.038256    mAP 0.452016    
2023-04-27 08:25:25,004 - ==> mAP: 0.45202    Loss: 3.038

2023-04-27 08:25:25,007 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:25:25,007 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:25:25,041 - 

2023-04-27 08:25:25,042 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:25:36,710 - Epoch: [379][   50/  518]    Overall Loss 2.834904    Objective Loss 2.834904                                        LR 0.000008    Time 0.233314    
2023-04-27 08:25:47,520 - Epoch: [379][  100/  518]    Overall Loss 2.848456    Objective Loss 2.848456                                        LR 0.000008    Time 0.224738    
2023-04-27 08:25:58,389 - Epoch: [379][  150/  518]    Overall Loss 2.847865    Objective Loss 2.847865                                        LR 0.000008    Time 0.222279    
2023-04-27 08:26:09,204 - Epoch: [379][  200/  518]    Overall Loss 2.859520    Objective Loss 2.859520                                        LR 0.000008    Time 0.220777    
2023-04-27 08:26:20,012 - Epoch: [379][  250/  518]    Overall Loss 2.850339    Objective Loss 2.850339                                        LR 0.000008    Time 0.219848    
2023-04-27 08:26:30,823 - Epoch: [379][  300/  518]    Overall Loss 2.855197    Objective Loss 2.855197                                        LR 0.000008    Time 0.219235    
2023-04-27 08:26:41,692 - Epoch: [379][  350/  518]    Overall Loss 2.855622    Objective Loss 2.855622                                        LR 0.000008    Time 0.218967    
2023-04-27 08:26:52,448 - Epoch: [379][  400/  518]    Overall Loss 2.855319    Objective Loss 2.855319                                        LR 0.000008    Time 0.218481    
2023-04-27 08:27:03,160 - Epoch: [379][  450/  518]    Overall Loss 2.856193    Objective Loss 2.856193                                        LR 0.000008    Time 0.218008    
2023-04-27 08:27:13,997 - Epoch: [379][  500/  518]    Overall Loss 2.862223    Objective Loss 2.862223                                        LR 0.000008    Time 0.217878    
2023-04-27 08:27:17,766 - Epoch: [379][  518/  518]    Overall Loss 2.862782    Objective Loss 2.862782                                        LR 0.000008    Time 0.217582    
2023-04-27 08:27:17,843 - --- validate (epoch=379)-----------
2023-04-27 08:27:17,843 - 4952 samples (32 per mini-batch)
2023-04-27 08:27:26,193 - Epoch: [379][   50/  155]    Loss 3.073034    mAP 0.467737    
2023-04-27 08:27:34,116 - Epoch: [379][  100/  155]    Loss 3.030493    mAP 0.460526    
2023-04-27 08:27:41,983 - Epoch: [379][  150/  155]    Loss 3.051125    mAP 0.456107    
2023-04-27 08:27:42,690 - Epoch: [379][  155/  155]    Loss 3.052549    mAP 0.456555    
2023-04-27 08:27:42,765 - ==> mAP: 0.45656    Loss: 3.053

2023-04-27 08:27:42,770 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:27:42,770 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:27:42,806 - 

2023-04-27 08:27:42,806 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:27:54,477 - Epoch: [380][   50/  518]    Overall Loss 2.824218    Objective Loss 2.824218                                        LR 0.000008    Time 0.233372    
2023-04-27 08:28:05,293 - Epoch: [380][  100/  518]    Overall Loss 2.814120    Objective Loss 2.814120                                        LR 0.000008    Time 0.224823    
2023-04-27 08:28:15,992 - Epoch: [380][  150/  518]    Overall Loss 2.831629    Objective Loss 2.831629                                        LR 0.000008    Time 0.221203    
2023-04-27 08:28:26,786 - Epoch: [380][  200/  518]    Overall Loss 2.838413    Objective Loss 2.838413                                        LR 0.000008    Time 0.219861    
2023-04-27 08:28:37,592 - Epoch: [380][  250/  518]    Overall Loss 2.831339    Objective Loss 2.831339                                        LR 0.000008    Time 0.219109    
2023-04-27 08:28:48,430 - Epoch: [380][  300/  518]    Overall Loss 2.839796    Objective Loss 2.839796                                        LR 0.000008    Time 0.218711    
2023-04-27 08:28:59,221 - Epoch: [380][  350/  518]    Overall Loss 2.836672    Objective Loss 2.836672                                        LR 0.000008    Time 0.218294    
2023-04-27 08:29:10,091 - Epoch: [380][  400/  518]    Overall Loss 2.844403    Objective Loss 2.844403                                        LR 0.000008    Time 0.218177    
2023-04-27 08:29:20,860 - Epoch: [380][  450/  518]    Overall Loss 2.847865    Objective Loss 2.847865                                        LR 0.000008    Time 0.217864    
2023-04-27 08:29:31,709 - Epoch: [380][  500/  518]    Overall Loss 2.842854    Objective Loss 2.842854                                        LR 0.000008    Time 0.217772    
2023-04-27 08:29:35,497 - Epoch: [380][  518/  518]    Overall Loss 2.845024    Objective Loss 2.845024                                        LR 0.000008    Time 0.217517    
2023-04-27 08:29:35,575 - --- validate (epoch=380)-----------
2023-04-27 08:29:35,576 - 4952 samples (32 per mini-batch)
2023-04-27 08:29:43,884 - Epoch: [380][   50/  155]    Loss 3.113311    mAP 0.459118    
2023-04-27 08:29:51,835 - Epoch: [380][  100/  155]    Loss 3.065300    mAP 0.449593    
2023-04-27 08:29:59,778 - Epoch: [380][  150/  155]    Loss 3.055984    mAP 0.443354    
2023-04-27 08:30:00,499 - Epoch: [380][  155/  155]    Loss 3.050506    mAP 0.443435    
2023-04-27 08:30:00,568 - ==> mAP: 0.44343    Loss: 3.051

2023-04-27 08:30:00,571 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:30:00,571 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:30:00,605 - 

2023-04-27 08:30:00,605 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:30:12,174 - Epoch: [381][   50/  518]    Overall Loss 2.899429    Objective Loss 2.899429                                        LR 0.000008    Time 0.231323    
2023-04-27 08:30:23,082 - Epoch: [381][  100/  518]    Overall Loss 2.870579    Objective Loss 2.870579                                        LR 0.000008    Time 0.224726    
2023-04-27 08:30:33,870 - Epoch: [381][  150/  518]    Overall Loss 2.860263    Objective Loss 2.860263                                        LR 0.000008    Time 0.221722    
2023-04-27 08:30:44,681 - Epoch: [381][  200/  518]    Overall Loss 2.848496    Objective Loss 2.848496                                        LR 0.000008    Time 0.220342    
2023-04-27 08:30:55,527 - Epoch: [381][  250/  518]    Overall Loss 2.843503    Objective Loss 2.843503                                        LR 0.000008    Time 0.219649    
2023-04-27 08:31:06,283 - Epoch: [381][  300/  518]    Overall Loss 2.854643    Objective Loss 2.854643                                        LR 0.000008    Time 0.218892    
2023-04-27 08:31:17,098 - Epoch: [381][  350/  518]    Overall Loss 2.851685    Objective Loss 2.851685                                        LR 0.000008    Time 0.218517    
2023-04-27 08:31:27,878 - Epoch: [381][  400/  518]    Overall Loss 2.845929    Objective Loss 2.845929                                        LR 0.000008    Time 0.218148    
2023-04-27 08:31:38,694 - Epoch: [381][  450/  518]    Overall Loss 2.850191    Objective Loss 2.850191                                        LR 0.000008    Time 0.217941    
2023-04-27 08:31:49,589 - Epoch: [381][  500/  518]    Overall Loss 2.851203    Objective Loss 2.851203                                        LR 0.000008    Time 0.217935    
2023-04-27 08:31:53,333 - Epoch: [381][  518/  518]    Overall Loss 2.850890    Objective Loss 2.850890                                        LR 0.000008    Time 0.217587    
2023-04-27 08:31:53,410 - --- validate (epoch=381)-----------
2023-04-27 08:31:53,410 - 4952 samples (32 per mini-batch)
2023-04-27 08:32:01,743 - Epoch: [381][   50/  155]    Loss 3.023347    mAP 0.465214    
2023-04-27 08:32:09,721 - Epoch: [381][  100/  155]    Loss 3.032367    mAP 0.455093    
2023-04-27 08:32:17,632 - Epoch: [381][  150/  155]    Loss 3.024319    mAP 0.457929    
2023-04-27 08:32:18,353 - Epoch: [381][  155/  155]    Loss 3.024346    mAP 0.457336    
2023-04-27 08:32:18,425 - ==> mAP: 0.45734    Loss: 3.024

2023-04-27 08:32:18,429 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:32:18,430 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:32:18,465 - 

2023-04-27 08:32:18,465 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:32:30,073 - Epoch: [382][   50/  518]    Overall Loss 2.880411    Objective Loss 2.880411                                        LR 0.000008    Time 0.232107    
2023-04-27 08:32:40,915 - Epoch: [382][  100/  518]    Overall Loss 2.891887    Objective Loss 2.891887                                        LR 0.000008    Time 0.224459    
2023-04-27 08:32:51,800 - Epoch: [382][  150/  518]    Overall Loss 2.865306    Objective Loss 2.865306                                        LR 0.000008    Time 0.222199    
2023-04-27 08:33:02,617 - Epoch: [382][  200/  518]    Overall Loss 2.850410    Objective Loss 2.850410                                        LR 0.000008    Time 0.220726    
2023-04-27 08:33:13,527 - Epoch: [382][  250/  518]    Overall Loss 2.843497    Objective Loss 2.843497                                        LR 0.000008    Time 0.220213    
2023-04-27 08:33:24,332 - Epoch: [382][  300/  518]    Overall Loss 2.850586    Objective Loss 2.850586                                        LR 0.000008    Time 0.219524    
2023-04-27 08:33:35,221 - Epoch: [382][  350/  518]    Overall Loss 2.852019    Objective Loss 2.852019                                        LR 0.000008    Time 0.219268    
2023-04-27 08:33:46,016 - Epoch: [382][  400/  518]    Overall Loss 2.851629    Objective Loss 2.851629                                        LR 0.000008    Time 0.218845    
2023-04-27 08:33:56,834 - Epoch: [382][  450/  518]    Overall Loss 2.848664    Objective Loss 2.848664                                        LR 0.000008    Time 0.218564    
2023-04-27 08:34:07,768 - Epoch: [382][  500/  518]    Overall Loss 2.846262    Objective Loss 2.846262                                        LR 0.000008    Time 0.218573    
2023-04-27 08:34:11,514 - Epoch: [382][  518/  518]    Overall Loss 2.846528    Objective Loss 2.846528                                        LR 0.000008    Time 0.218209    
2023-04-27 08:34:11,592 - --- validate (epoch=382)-----------
2023-04-27 08:34:11,592 - 4952 samples (32 per mini-batch)
2023-04-27 08:34:19,919 - Epoch: [382][   50/  155]    Loss 3.023836    mAP 0.477010    
2023-04-27 08:34:27,867 - Epoch: [382][  100/  155]    Loss 3.027355    mAP 0.453395    
2023-04-27 08:34:35,782 - Epoch: [382][  150/  155]    Loss 3.025541    mAP 0.449964    
2023-04-27 08:34:36,497 - Epoch: [382][  155/  155]    Loss 3.023584    mAP 0.450474    
2023-04-27 08:34:36,575 - ==> mAP: 0.45047    Loss: 3.024

2023-04-27 08:34:36,578 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:34:36,579 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:34:36,613 - 

2023-04-27 08:34:36,613 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:34:48,137 - Epoch: [383][   50/  518]    Overall Loss 2.888702    Objective Loss 2.888702                                        LR 0.000008    Time 0.230433    
2023-04-27 08:34:58,924 - Epoch: [383][  100/  518]    Overall Loss 2.836354    Objective Loss 2.836354                                        LR 0.000008    Time 0.223068    
2023-04-27 08:35:09,745 - Epoch: [383][  150/  518]    Overall Loss 2.832917    Objective Loss 2.832917                                        LR 0.000008    Time 0.220842    
2023-04-27 08:35:20,507 - Epoch: [383][  200/  518]    Overall Loss 2.831314    Objective Loss 2.831314                                        LR 0.000008    Time 0.219433    
2023-04-27 08:35:31,301 - Epoch: [383][  250/  518]    Overall Loss 2.844469    Objective Loss 2.844469                                        LR 0.000008    Time 0.218715    
2023-04-27 08:35:42,134 - Epoch: [383][  300/  518]    Overall Loss 2.855438    Objective Loss 2.855438                                        LR 0.000008    Time 0.218368    
2023-04-27 08:35:53,012 - Epoch: [383][  350/  518]    Overall Loss 2.852349    Objective Loss 2.852349                                        LR 0.000008    Time 0.218248    
2023-04-27 08:36:03,850 - Epoch: [383][  400/  518]    Overall Loss 2.858935    Objective Loss 2.858935                                        LR 0.000008    Time 0.218058    
2023-04-27 08:36:14,661 - Epoch: [383][  450/  518]    Overall Loss 2.853074    Objective Loss 2.853074                                        LR 0.000008    Time 0.217851    
2023-04-27 08:36:25,522 - Epoch: [383][  500/  518]    Overall Loss 2.856169    Objective Loss 2.856169                                        LR 0.000008    Time 0.217784    
2023-04-27 08:36:29,243 - Epoch: [383][  518/  518]    Overall Loss 2.854858    Objective Loss 2.854858                                        LR 0.000008    Time 0.217398    
2023-04-27 08:36:29,318 - --- validate (epoch=383)-----------
2023-04-27 08:36:29,319 - 4952 samples (32 per mini-batch)
2023-04-27 08:36:37,615 - Epoch: [383][   50/  155]    Loss 3.022514    mAP 0.465446    
2023-04-27 08:36:45,541 - Epoch: [383][  100/  155]    Loss 3.023125    mAP 0.454769    
2023-04-27 08:36:53,435 - Epoch: [383][  150/  155]    Loss 3.032220    mAP 0.445225    
2023-04-27 08:36:54,163 - Epoch: [383][  155/  155]    Loss 3.029943    mAP 0.447040    
2023-04-27 08:36:54,237 - ==> mAP: 0.44704    Loss: 3.030

2023-04-27 08:36:54,241 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:36:54,241 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:36:54,277 - 

2023-04-27 08:36:54,277 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:37:05,985 - Epoch: [384][   50/  518]    Overall Loss 2.835695    Objective Loss 2.835695                                        LR 0.000008    Time 0.234116    
2023-04-27 08:37:16,849 - Epoch: [384][  100/  518]    Overall Loss 2.830107    Objective Loss 2.830107                                        LR 0.000008    Time 0.225675    
2023-04-27 08:37:27,538 - Epoch: [384][  150/  518]    Overall Loss 2.840334    Objective Loss 2.840334                                        LR 0.000008    Time 0.221701    
2023-04-27 08:37:38,320 - Epoch: [384][  200/  518]    Overall Loss 2.831458    Objective Loss 2.831458                                        LR 0.000008    Time 0.220180    
2023-04-27 08:37:49,186 - Epoch: [384][  250/  518]    Overall Loss 2.836290    Objective Loss 2.836290                                        LR 0.000008    Time 0.219601    
2023-04-27 08:38:00,052 - Epoch: [384][  300/  518]    Overall Loss 2.845097    Objective Loss 2.845097                                        LR 0.000008    Time 0.219214    
2023-04-27 08:38:10,861 - Epoch: [384][  350/  518]    Overall Loss 2.849744    Objective Loss 2.849744                                        LR 0.000008    Time 0.218777    
2023-04-27 08:38:21,727 - Epoch: [384][  400/  518]    Overall Loss 2.848560    Objective Loss 2.848560                                        LR 0.000008    Time 0.218590    
2023-04-27 08:38:32,595 - Epoch: [384][  450/  518]    Overall Loss 2.846828    Objective Loss 2.846828                                        LR 0.000008    Time 0.218450    
2023-04-27 08:38:43,450 - Epoch: [384][  500/  518]    Overall Loss 2.849306    Objective Loss 2.849306                                        LR 0.000008    Time 0.218311    
2023-04-27 08:38:47,204 - Epoch: [384][  518/  518]    Overall Loss 2.849997    Objective Loss 2.849997                                        LR 0.000008    Time 0.217973    
2023-04-27 08:38:47,281 - --- validate (epoch=384)-----------
2023-04-27 08:38:47,281 - 4952 samples (32 per mini-batch)
2023-04-27 08:38:55,627 - Epoch: [384][   50/  155]    Loss 3.088969    mAP 0.445020    
2023-04-27 08:39:03,508 - Epoch: [384][  100/  155]    Loss 3.055703    mAP 0.440921    
2023-04-27 08:39:11,396 - Epoch: [384][  150/  155]    Loss 3.040675    mAP 0.448600    
2023-04-27 08:39:12,113 - Epoch: [384][  155/  155]    Loss 3.036911    mAP 0.449585    
2023-04-27 08:39:12,189 - ==> mAP: 0.44959    Loss: 3.037

2023-04-27 08:39:12,193 - ==> Best [mAP: 0.458592   vloss: 3.032273   Sparsity:0.00   Params: 2177087 on epoch: 367]
2023-04-27 08:39:12,193 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:39:12,227 - 

2023-04-27 08:39:12,227 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:39:23,794 - Epoch: [385][   50/  518]    Overall Loss 2.887228    Objective Loss 2.887228                                        LR 0.000008    Time 0.231285    
2023-04-27 08:39:34,597 - Epoch: [385][  100/  518]    Overall Loss 2.861545    Objective Loss 2.861545                                        LR 0.000008    Time 0.223656    
2023-04-27 08:39:45,428 - Epoch: [385][  150/  518]    Overall Loss 2.851685    Objective Loss 2.851685                                        LR 0.000008    Time 0.221297    
2023-04-27 08:39:56,240 - Epoch: [385][  200/  518]    Overall Loss 2.857823    Objective Loss 2.857823                                        LR 0.000008    Time 0.220024    
2023-04-27 08:40:07,224 - Epoch: [385][  250/  518]    Overall Loss 2.844182    Objective Loss 2.844182                                        LR 0.000008    Time 0.219952    
2023-04-27 08:40:17,941 - Epoch: [385][  300/  518]    Overall Loss 2.853734    Objective Loss 2.853734                                        LR 0.000008    Time 0.219010    
2023-04-27 08:40:28,709 - Epoch: [385][  350/  518]    Overall Loss 2.855496    Objective Loss 2.855496                                        LR 0.000008    Time 0.218484    
2023-04-27 08:40:39,515 - Epoch: [385][  400/  518]    Overall Loss 2.859394    Objective Loss 2.859394                                        LR 0.000008    Time 0.218184    
2023-04-27 08:40:50,372 - Epoch: [385][  450/  518]    Overall Loss 2.857065    Objective Loss 2.857065                                        LR 0.000008    Time 0.218065    
2023-04-27 08:41:01,228 - Epoch: [385][  500/  518]    Overall Loss 2.856774    Objective Loss 2.856774                                        LR 0.000008    Time 0.217968    
2023-04-27 08:41:04,964 - Epoch: [385][  518/  518]    Overall Loss 2.856774    Objective Loss 2.856774                                        LR 0.000008    Time 0.217604    
2023-04-27 08:41:05,041 - --- validate (epoch=385)-----------
2023-04-27 08:41:05,041 - 4952 samples (32 per mini-batch)
2023-04-27 08:41:13,387 - Epoch: [385][   50/  155]    Loss 3.007619    mAP 0.468534    
2023-04-27 08:41:21,389 - Epoch: [385][  100/  155]    Loss 3.030757    mAP 0.465943    
2023-04-27 08:41:29,339 - Epoch: [385][  150/  155]    Loss 3.033971    mAP 0.462239    
2023-04-27 08:41:30,070 - Epoch: [385][  155/  155]    Loss 3.029455    mAP 0.461116    
2023-04-27 08:41:30,145 - ==> mAP: 0.46112    Loss: 3.029

2023-04-27 08:41:30,149 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 08:41:30,149 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:41:30,198 - 

2023-04-27 08:41:30,199 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:41:41,928 - Epoch: [386][   50/  518]    Overall Loss 2.862542    Objective Loss 2.862542                                        LR 0.000008    Time 0.234530    
2023-04-27 08:41:52,724 - Epoch: [386][  100/  518]    Overall Loss 2.838003    Objective Loss 2.838003                                        LR 0.000008    Time 0.225215    
2023-04-27 08:42:03,541 - Epoch: [386][  150/  518]    Overall Loss 2.830419    Objective Loss 2.830419                                        LR 0.000008    Time 0.222244    
2023-04-27 08:42:14,362 - Epoch: [386][  200/  518]    Overall Loss 2.822268    Objective Loss 2.822268                                        LR 0.000008    Time 0.220778    
2023-04-27 08:42:25,107 - Epoch: [386][  250/  518]    Overall Loss 2.837538    Objective Loss 2.837538                                        LR 0.000008    Time 0.219598    
2023-04-27 08:42:35,936 - Epoch: [386][  300/  518]    Overall Loss 2.834996    Objective Loss 2.834996                                        LR 0.000008    Time 0.219088    
2023-04-27 08:42:46,719 - Epoch: [386][  350/  518]    Overall Loss 2.835530    Objective Loss 2.835530                                        LR 0.000008    Time 0.218594    
2023-04-27 08:42:57,579 - Epoch: [386][  400/  518]    Overall Loss 2.831335    Objective Loss 2.831335                                        LR 0.000008    Time 0.218418    
2023-04-27 08:43:08,367 - Epoch: [386][  450/  518]    Overall Loss 2.833142    Objective Loss 2.833142                                        LR 0.000008    Time 0.218118    
2023-04-27 08:43:19,216 - Epoch: [386][  500/  518]    Overall Loss 2.837355    Objective Loss 2.837355                                        LR 0.000008    Time 0.218002    
2023-04-27 08:43:22,942 - Epoch: [386][  518/  518]    Overall Loss 2.836474    Objective Loss 2.836474                                        LR 0.000008    Time 0.217618    
2023-04-27 08:43:23,019 - --- validate (epoch=386)-----------
2023-04-27 08:43:23,019 - 4952 samples (32 per mini-batch)
2023-04-27 08:43:31,317 - Epoch: [386][   50/  155]    Loss 3.023105    mAP 0.467699    
2023-04-27 08:43:39,211 - Epoch: [386][  100/  155]    Loss 3.019413    mAP 0.455058    
2023-04-27 08:43:47,073 - Epoch: [386][  150/  155]    Loss 3.061056    mAP 0.445481    
2023-04-27 08:43:47,789 - Epoch: [386][  155/  155]    Loss 3.062415    mAP 0.444434    
2023-04-27 08:43:47,866 - ==> mAP: 0.44443    Loss: 3.062

2023-04-27 08:43:47,870 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 08:43:47,870 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:43:47,904 - 

2023-04-27 08:43:47,905 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:43:59,456 - Epoch: [387][   50/  518]    Overall Loss 2.768243    Objective Loss 2.768243                                        LR 0.000008    Time 0.230969    
2023-04-27 08:44:10,173 - Epoch: [387][  100/  518]    Overall Loss 2.816206    Objective Loss 2.816206                                        LR 0.000008    Time 0.222646    
2023-04-27 08:44:20,939 - Epoch: [387][  150/  518]    Overall Loss 2.821538    Objective Loss 2.821538                                        LR 0.000008    Time 0.220190    
2023-04-27 08:44:31,702 - Epoch: [387][  200/  518]    Overall Loss 2.841096    Objective Loss 2.841096                                        LR 0.000008    Time 0.218949    
2023-04-27 08:44:42,549 - Epoch: [387][  250/  518]    Overall Loss 2.843651    Objective Loss 2.843651                                        LR 0.000008    Time 0.218541    
2023-04-27 08:44:53,363 - Epoch: [387][  300/  518]    Overall Loss 2.848453    Objective Loss 2.848453                                        LR 0.000008    Time 0.218159    
2023-04-27 08:45:04,125 - Epoch: [387][  350/  518]    Overall Loss 2.848273    Objective Loss 2.848273                                        LR 0.000008    Time 0.217738    
2023-04-27 08:45:14,999 - Epoch: [387][  400/  518]    Overall Loss 2.850458    Objective Loss 2.850458                                        LR 0.000008    Time 0.217703    
2023-04-27 08:45:25,781 - Epoch: [387][  450/  518]    Overall Loss 2.845865    Objective Loss 2.845865                                        LR 0.000008    Time 0.217470    
2023-04-27 08:45:36,657 - Epoch: [387][  500/  518]    Overall Loss 2.849574    Objective Loss 2.849574                                        LR 0.000008    Time 0.217472    
2023-04-27 08:45:40,453 - Epoch: [387][  518/  518]    Overall Loss 2.850538    Objective Loss 2.850538                                        LR 0.000008    Time 0.217242    
2023-04-27 08:45:40,530 - --- validate (epoch=387)-----------
2023-04-27 08:45:40,531 - 4952 samples (32 per mini-batch)
2023-04-27 08:45:48,860 - Epoch: [387][   50/  155]    Loss 3.031534    mAP 0.452711    
2023-04-27 08:45:56,768 - Epoch: [387][  100/  155]    Loss 3.016503    mAP 0.450557    
2023-04-27 08:46:04,680 - Epoch: [387][  150/  155]    Loss 3.009257    mAP 0.454487    
2023-04-27 08:46:05,399 - Epoch: [387][  155/  155]    Loss 3.016417    mAP 0.452711    
2023-04-27 08:46:05,474 - ==> mAP: 0.45271    Loss: 3.016

2023-04-27 08:46:05,478 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 08:46:05,478 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:46:05,512 - 

2023-04-27 08:46:05,512 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:46:17,032 - Epoch: [388][   50/  518]    Overall Loss 2.907274    Objective Loss 2.907274                                        LR 0.000008    Time 0.230357    
2023-04-27 08:46:27,873 - Epoch: [388][  100/  518]    Overall Loss 2.896158    Objective Loss 2.896158                                        LR 0.000008    Time 0.223571    
2023-04-27 08:46:38,754 - Epoch: [388][  150/  518]    Overall Loss 2.878404    Objective Loss 2.878404                                        LR 0.000008    Time 0.221574    
2023-04-27 08:46:49,524 - Epoch: [388][  200/  518]    Overall Loss 2.868649    Objective Loss 2.868649                                        LR 0.000008    Time 0.220023    
2023-04-27 08:47:00,247 - Epoch: [388][  250/  518]    Overall Loss 2.863539    Objective Loss 2.863539                                        LR 0.000008    Time 0.218906    
2023-04-27 08:47:11,111 - Epoch: [388][  300/  518]    Overall Loss 2.852898    Objective Loss 2.852898                                        LR 0.000008    Time 0.218630    
2023-04-27 08:47:21,931 - Epoch: [388][  350/  518]    Overall Loss 2.847851    Objective Loss 2.847851                                        LR 0.000008    Time 0.218305    
2023-04-27 08:47:32,740 - Epoch: [388][  400/  518]    Overall Loss 2.851586    Objective Loss 2.851586                                        LR 0.000008    Time 0.218037    
2023-04-27 08:47:43,586 - Epoch: [388][  450/  518]    Overall Loss 2.850619    Objective Loss 2.850619                                        LR 0.000008    Time 0.217909    
2023-04-27 08:47:54,412 - Epoch: [388][  500/  518]    Overall Loss 2.852990    Objective Loss 2.852990                                        LR 0.000008    Time 0.217767    
2023-04-27 08:47:58,113 - Epoch: [388][  518/  518]    Overall Loss 2.853207    Objective Loss 2.853207                                        LR 0.000008    Time 0.217342    
2023-04-27 08:47:58,189 - --- validate (epoch=388)-----------
2023-04-27 08:47:58,190 - 4952 samples (32 per mini-batch)
2023-04-27 08:48:06,488 - Epoch: [388][   50/  155]    Loss 3.009388    mAP 0.454285    
2023-04-27 08:48:14,474 - Epoch: [388][  100/  155]    Loss 3.020181    mAP 0.460567    
2023-04-27 08:48:22,374 - Epoch: [388][  150/  155]    Loss 3.040772    mAP 0.454443    
2023-04-27 08:48:23,086 - Epoch: [388][  155/  155]    Loss 3.039271    mAP 0.452007    
2023-04-27 08:48:23,182 - ==> mAP: 0.45201    Loss: 3.039

2023-04-27 08:48:23,187 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 08:48:23,187 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:48:23,222 - 

2023-04-27 08:48:23,222 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:48:34,884 - Epoch: [389][   50/  518]    Overall Loss 2.789259    Objective Loss 2.789259                                        LR 0.000008    Time 0.233183    
2023-04-27 08:48:45,752 - Epoch: [389][  100/  518]    Overall Loss 2.795462    Objective Loss 2.795462                                        LR 0.000008    Time 0.225256    
2023-04-27 08:48:56,576 - Epoch: [389][  150/  518]    Overall Loss 2.811716    Objective Loss 2.811716                                        LR 0.000008    Time 0.222323    
2023-04-27 08:49:07,405 - Epoch: [389][  200/  518]    Overall Loss 2.825911    Objective Loss 2.825911                                        LR 0.000008    Time 0.220880    
2023-04-27 08:49:18,205 - Epoch: [389][  250/  518]    Overall Loss 2.837898    Objective Loss 2.837898                                        LR 0.000008    Time 0.219896    
2023-04-27 08:49:29,025 - Epoch: [389][  300/  518]    Overall Loss 2.845855    Objective Loss 2.845855                                        LR 0.000008    Time 0.219309    
2023-04-27 08:49:39,917 - Epoch: [389][  350/  518]    Overall Loss 2.845391    Objective Loss 2.845391                                        LR 0.000008    Time 0.219095    
2023-04-27 08:49:50,777 - Epoch: [389][  400/  518]    Overall Loss 2.848477    Objective Loss 2.848477                                        LR 0.000008    Time 0.218853    
2023-04-27 08:50:01,668 - Epoch: [389][  450/  518]    Overall Loss 2.850352    Objective Loss 2.850352                                        LR 0.000008    Time 0.218735    
2023-04-27 08:50:12,534 - Epoch: [389][  500/  518]    Overall Loss 2.848494    Objective Loss 2.848494                                        LR 0.000008    Time 0.218590    
2023-04-27 08:50:16,274 - Epoch: [389][  518/  518]    Overall Loss 2.848160    Objective Loss 2.848160                                        LR 0.000008    Time 0.218214    
2023-04-27 08:50:16,350 - --- validate (epoch=389)-----------
2023-04-27 08:50:16,350 - 4952 samples (32 per mini-batch)
2023-04-27 08:50:24,670 - Epoch: [389][   50/  155]    Loss 3.019130    mAP 0.442860    
2023-04-27 08:50:32,662 - Epoch: [389][  100/  155]    Loss 3.011736    mAP 0.457784    
2023-04-27 08:50:40,593 - Epoch: [389][  150/  155]    Loss 3.036749    mAP 0.449083    
2023-04-27 08:50:41,314 - Epoch: [389][  155/  155]    Loss 3.038026    mAP 0.449045    
2023-04-27 08:50:41,380 - ==> mAP: 0.44905    Loss: 3.038

2023-04-27 08:50:41,385 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 08:50:41,385 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:50:41,419 - 

2023-04-27 08:50:41,420 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:50:53,061 - Epoch: [390][   50/  518]    Overall Loss 2.867159    Objective Loss 2.867159                                        LR 0.000008    Time 0.232770    
2023-04-27 08:51:03,883 - Epoch: [390][  100/  518]    Overall Loss 2.864087    Objective Loss 2.864087                                        LR 0.000008    Time 0.224587    
2023-04-27 08:51:14,719 - Epoch: [390][  150/  518]    Overall Loss 2.851771    Objective Loss 2.851771                                        LR 0.000008    Time 0.221958    
2023-04-27 08:51:25,509 - Epoch: [390][  200/  518]    Overall Loss 2.843303    Objective Loss 2.843303                                        LR 0.000008    Time 0.220412    
2023-04-27 08:51:36,297 - Epoch: [390][  250/  518]    Overall Loss 2.846618    Objective Loss 2.846618                                        LR 0.000008    Time 0.219476    
2023-04-27 08:51:47,138 - Epoch: [390][  300/  518]    Overall Loss 2.844917    Objective Loss 2.844917                                        LR 0.000008    Time 0.219028    
2023-04-27 08:51:57,921 - Epoch: [390][  350/  518]    Overall Loss 2.840128    Objective Loss 2.840128                                        LR 0.000008    Time 0.218541    
2023-04-27 08:52:08,690 - Epoch: [390][  400/  518]    Overall Loss 2.849814    Objective Loss 2.849814                                        LR 0.000008    Time 0.218142    
2023-04-27 08:52:19,555 - Epoch: [390][  450/  518]    Overall Loss 2.855117    Objective Loss 2.855117                                        LR 0.000008    Time 0.218045    
2023-04-27 08:52:30,297 - Epoch: [390][  500/  518]    Overall Loss 2.854512    Objective Loss 2.854512                                        LR 0.000008    Time 0.217721    
2023-04-27 08:52:34,050 - Epoch: [390][  518/  518]    Overall Loss 2.856792    Objective Loss 2.856792                                        LR 0.000008    Time 0.217400    
2023-04-27 08:52:34,127 - --- validate (epoch=390)-----------
2023-04-27 08:52:34,128 - 4952 samples (32 per mini-batch)
2023-04-27 08:52:42,474 - Epoch: [390][   50/  155]    Loss 3.095078    mAP 0.443146    
2023-04-27 08:52:50,422 - Epoch: [390][  100/  155]    Loss 3.070221    mAP 0.447778    
2023-04-27 08:52:58,351 - Epoch: [390][  150/  155]    Loss 3.032854    mAP 0.454169    
2023-04-27 08:52:59,075 - Epoch: [390][  155/  155]    Loss 3.029321    mAP 0.455607    
2023-04-27 08:52:59,150 - ==> mAP: 0.45561    Loss: 3.029

2023-04-27 08:52:59,154 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 08:52:59,154 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:52:59,188 - 

2023-04-27 08:52:59,188 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:53:10,671 - Epoch: [391][   50/  518]    Overall Loss 2.805705    Objective Loss 2.805705                                        LR 0.000008    Time 0.229594    
2023-04-27 08:53:21,448 - Epoch: [391][  100/  518]    Overall Loss 2.838521    Objective Loss 2.838521                                        LR 0.000008    Time 0.222552    
2023-04-27 08:53:32,294 - Epoch: [391][  150/  518]    Overall Loss 2.840934    Objective Loss 2.840934                                        LR 0.000008    Time 0.220667    
2023-04-27 08:53:43,163 - Epoch: [391][  200/  518]    Overall Loss 2.842952    Objective Loss 2.842952                                        LR 0.000008    Time 0.219835    
2023-04-27 08:53:53,987 - Epoch: [391][  250/  518]    Overall Loss 2.844120    Objective Loss 2.844120                                        LR 0.000008    Time 0.219161    
2023-04-27 08:54:04,861 - Epoch: [391][  300/  518]    Overall Loss 2.856096    Objective Loss 2.856096                                        LR 0.000008    Time 0.218873    
2023-04-27 08:54:15,723 - Epoch: [391][  350/  518]    Overall Loss 2.854114    Objective Loss 2.854114                                        LR 0.000008    Time 0.218635    
2023-04-27 08:54:26,563 - Epoch: [391][  400/  518]    Overall Loss 2.852878    Objective Loss 2.852878                                        LR 0.000008    Time 0.218403    
2023-04-27 08:54:37,374 - Epoch: [391][  450/  518]    Overall Loss 2.857822    Objective Loss 2.857822                                        LR 0.000008    Time 0.218156    
2023-04-27 08:54:48,126 - Epoch: [391][  500/  518]    Overall Loss 2.855251    Objective Loss 2.855251                                        LR 0.000008    Time 0.217841    
2023-04-27 08:54:51,875 - Epoch: [391][  518/  518]    Overall Loss 2.855880    Objective Loss 2.855880                                        LR 0.000008    Time 0.217508    
2023-04-27 08:54:51,952 - --- validate (epoch=391)-----------
2023-04-27 08:54:51,952 - 4952 samples (32 per mini-batch)
2023-04-27 08:55:00,233 - Epoch: [391][   50/  155]    Loss 3.079060    mAP 0.436689    
2023-04-27 08:55:08,115 - Epoch: [391][  100/  155]    Loss 3.032654    mAP 0.455208    
2023-04-27 08:55:15,981 - Epoch: [391][  150/  155]    Loss 3.044892    mAP 0.446128    
2023-04-27 08:55:16,701 - Epoch: [391][  155/  155]    Loss 3.039157    mAP 0.445856    
2023-04-27 08:55:16,778 - ==> mAP: 0.44586    Loss: 3.039

2023-04-27 08:55:16,782 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 08:55:16,782 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:55:16,817 - 

2023-04-27 08:55:16,817 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:55:28,402 - Epoch: [392][   50/  518]    Overall Loss 2.898677    Objective Loss 2.898677                                        LR 0.000008    Time 0.231642    
2023-04-27 08:55:39,252 - Epoch: [392][  100/  518]    Overall Loss 2.889155    Objective Loss 2.889155                                        LR 0.000008    Time 0.224307    
2023-04-27 08:55:50,103 - Epoch: [392][  150/  518]    Overall Loss 2.877968    Objective Loss 2.877968                                        LR 0.000008    Time 0.221865    
2023-04-27 08:56:00,929 - Epoch: [392][  200/  518]    Overall Loss 2.871596    Objective Loss 2.871596                                        LR 0.000008    Time 0.220525    
2023-04-27 08:56:11,680 - Epoch: [392][  250/  518]    Overall Loss 2.861046    Objective Loss 2.861046                                        LR 0.000008    Time 0.219416    
2023-04-27 08:56:22,505 - Epoch: [392][  300/  518]    Overall Loss 2.857039    Objective Loss 2.857039                                        LR 0.000008    Time 0.218926    
2023-04-27 08:56:33,328 - Epoch: [392][  350/  518]    Overall Loss 2.865254    Objective Loss 2.865254                                        LR 0.000008    Time 0.218568    
2023-04-27 08:56:44,184 - Epoch: [392][  400/  518]    Overall Loss 2.854395    Objective Loss 2.854395                                        LR 0.000008    Time 0.218383    
2023-04-27 08:56:55,036 - Epoch: [392][  450/  518]    Overall Loss 2.851711    Objective Loss 2.851711                                        LR 0.000008    Time 0.218230    
2023-04-27 08:57:05,851 - Epoch: [392][  500/  518]    Overall Loss 2.850259    Objective Loss 2.850259                                        LR 0.000008    Time 0.218034    
2023-04-27 08:57:09,570 - Epoch: [392][  518/  518]    Overall Loss 2.848551    Objective Loss 2.848551                                        LR 0.000008    Time 0.217637    
2023-04-27 08:57:09,647 - --- validate (epoch=392)-----------
2023-04-27 08:57:09,647 - 4952 samples (32 per mini-batch)
2023-04-27 08:57:17,915 - Epoch: [392][   50/  155]    Loss 3.083833    mAP 0.447890    
2023-04-27 08:57:25,841 - Epoch: [392][  100/  155]    Loss 3.050502    mAP 0.452508    
2023-04-27 08:57:33,754 - Epoch: [392][  150/  155]    Loss 3.030914    mAP 0.453812    
2023-04-27 08:57:34,465 - Epoch: [392][  155/  155]    Loss 3.030393    mAP 0.449737    
2023-04-27 08:57:34,541 - ==> mAP: 0.44974    Loss: 3.030

2023-04-27 08:57:34,545 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 08:57:34,545 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:57:34,579 - 

2023-04-27 08:57:34,580 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 08:57:46,347 - Epoch: [393][   50/  518]    Overall Loss 2.861631    Objective Loss 2.861631                                        LR 0.000008    Time 0.235291    
2023-04-27 08:57:57,111 - Epoch: [393][  100/  518]    Overall Loss 2.883427    Objective Loss 2.883427                                        LR 0.000008    Time 0.225269    
2023-04-27 08:58:07,931 - Epoch: [393][  150/  518]    Overall Loss 2.864893    Objective Loss 2.864893                                        LR 0.000008    Time 0.222300    
2023-04-27 08:58:18,747 - Epoch: [393][  200/  518]    Overall Loss 2.854621    Objective Loss 2.854621                                        LR 0.000008    Time 0.220799    
2023-04-27 08:58:29,565 - Epoch: [393][  250/  518]    Overall Loss 2.838378    Objective Loss 2.838378                                        LR 0.000008    Time 0.219906    
2023-04-27 08:58:40,395 - Epoch: [393][  300/  518]    Overall Loss 2.842262    Objective Loss 2.842262                                        LR 0.000008    Time 0.219349    
2023-04-27 08:58:51,259 - Epoch: [393][  350/  518]    Overall Loss 2.848010    Objective Loss 2.848010                                        LR 0.000008    Time 0.219050    
2023-04-27 08:59:02,021 - Epoch: [393][  400/  518]    Overall Loss 2.845162    Objective Loss 2.845162                                        LR 0.000008    Time 0.218569    
2023-04-27 08:59:12,806 - Epoch: [393][  450/  518]    Overall Loss 2.851758    Objective Loss 2.851758                                        LR 0.000008    Time 0.218247    
2023-04-27 08:59:23,652 - Epoch: [393][  500/  518]    Overall Loss 2.847052    Objective Loss 2.847052                                        LR 0.000008    Time 0.218111    
2023-04-27 08:59:27,388 - Epoch: [393][  518/  518]    Overall Loss 2.846443    Objective Loss 2.846443                                        LR 0.000008    Time 0.217743    
2023-04-27 08:59:27,464 - --- validate (epoch=393)-----------
2023-04-27 08:59:27,465 - 4952 samples (32 per mini-batch)
2023-04-27 08:59:35,723 - Epoch: [393][   50/  155]    Loss 3.043279    mAP 0.427450    
2023-04-27 08:59:43,630 - Epoch: [393][  100/  155]    Loss 3.045599    mAP 0.435736    
2023-04-27 08:59:51,552 - Epoch: [393][  150/  155]    Loss 3.035047    mAP 0.437729    
2023-04-27 08:59:52,266 - Epoch: [393][  155/  155]    Loss 3.032598    mAP 0.437713    
2023-04-27 08:59:52,342 - ==> mAP: 0.43771    Loss: 3.033

2023-04-27 08:59:52,346 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 08:59:52,346 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 08:59:52,380 - 

2023-04-27 08:59:52,380 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 09:00:04,319 - Epoch: [394][   50/  518]    Overall Loss 2.837725    Objective Loss 2.837725                                        LR 0.000008    Time 0.238728    
2023-04-27 09:00:15,233 - Epoch: [394][  100/  518]    Overall Loss 2.850817    Objective Loss 2.850817                                        LR 0.000008    Time 0.228489    
2023-04-27 09:00:26,011 - Epoch: [394][  150/  518]    Overall Loss 2.843131    Objective Loss 2.843131                                        LR 0.000008    Time 0.224169    
2023-04-27 09:00:36,828 - Epoch: [394][  200/  518]    Overall Loss 2.844387    Objective Loss 2.844387                                        LR 0.000008    Time 0.222204    
2023-04-27 09:00:47,678 - Epoch: [394][  250/  518]    Overall Loss 2.852007    Objective Loss 2.852007                                        LR 0.000008    Time 0.221155    
2023-04-27 09:00:58,450 - Epoch: [394][  300/  518]    Overall Loss 2.854395    Objective Loss 2.854395                                        LR 0.000008    Time 0.220200    
2023-04-27 09:01:09,255 - Epoch: [394][  350/  518]    Overall Loss 2.850606    Objective Loss 2.850606                                        LR 0.000008    Time 0.219609    
2023-04-27 09:01:20,121 - Epoch: [394][  400/  518]    Overall Loss 2.845524    Objective Loss 2.845524                                        LR 0.000008    Time 0.219317    
2023-04-27 09:01:30,956 - Epoch: [394][  450/  518]    Overall Loss 2.846373    Objective Loss 2.846373                                        LR 0.000008    Time 0.219024    
2023-04-27 09:01:41,801 - Epoch: [394][  500/  518]    Overall Loss 2.846538    Objective Loss 2.846538                                        LR 0.000008    Time 0.218808    
2023-04-27 09:01:45,500 - Epoch: [394][  518/  518]    Overall Loss 2.844859    Objective Loss 2.844859                                        LR 0.000008    Time 0.218346    
2023-04-27 09:01:45,577 - --- validate (epoch=394)-----------
2023-04-27 09:01:45,577 - 4952 samples (32 per mini-batch)
2023-04-27 09:01:53,909 - Epoch: [394][   50/  155]    Loss 3.044907    mAP 0.454007    
2023-04-27 09:02:01,917 - Epoch: [394][  100/  155]    Loss 3.036424    mAP 0.456919    
2023-04-27 09:02:09,849 - Epoch: [394][  150/  155]    Loss 3.029036    mAP 0.456215    
2023-04-27 09:02:10,576 - Epoch: [394][  155/  155]    Loss 3.031016    mAP 0.456989    
2023-04-27 09:02:10,647 - ==> mAP: 0.45699    Loss: 3.031

2023-04-27 09:02:10,651 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 09:02:10,651 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 09:02:10,685 - 

2023-04-27 09:02:10,685 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 09:02:22,253 - Epoch: [395][   50/  518]    Overall Loss 2.864311    Objective Loss 2.864311                                        LR 0.000008    Time 0.231291    
2023-04-27 09:02:33,015 - Epoch: [395][  100/  518]    Overall Loss 2.856179    Objective Loss 2.856179                                        LR 0.000008    Time 0.223253    
2023-04-27 09:02:43,799 - Epoch: [395][  150/  518]    Overall Loss 2.848957    Objective Loss 2.848957                                        LR 0.000008    Time 0.220716    
2023-04-27 09:02:54,587 - Epoch: [395][  200/  518]    Overall Loss 2.852150    Objective Loss 2.852150                                        LR 0.000008    Time 0.219471    
2023-04-27 09:03:05,413 - Epoch: [395][  250/  518]    Overall Loss 2.842139    Objective Loss 2.842139                                        LR 0.000008    Time 0.218874    
2023-04-27 09:03:16,321 - Epoch: [395][  300/  518]    Overall Loss 2.844124    Objective Loss 2.844124                                        LR 0.000008    Time 0.218750    
2023-04-27 09:03:27,185 - Epoch: [395][  350/  518]    Overall Loss 2.845452    Objective Loss 2.845452                                        LR 0.000008    Time 0.218534    
2023-04-27 09:03:37,990 - Epoch: [395][  400/  518]    Overall Loss 2.849428    Objective Loss 2.849428                                        LR 0.000008    Time 0.218228    
2023-04-27 09:03:48,770 - Epoch: [395][  450/  518]    Overall Loss 2.850638    Objective Loss 2.850638                                        LR 0.000008    Time 0.217933    
2023-04-27 09:03:59,616 - Epoch: [395][  500/  518]    Overall Loss 2.845845    Objective Loss 2.845845                                        LR 0.000008    Time 0.217828    
2023-04-27 09:04:03,365 - Epoch: [395][  518/  518]    Overall Loss 2.845517    Objective Loss 2.845517                                        LR 0.000008    Time 0.217494    
2023-04-27 09:04:03,442 - --- validate (epoch=395)-----------
2023-04-27 09:04:03,442 - 4952 samples (32 per mini-batch)
2023-04-27 09:04:11,795 - Epoch: [395][   50/  155]    Loss 3.046234    mAP 0.451913    
2023-04-27 09:04:19,803 - Epoch: [395][  100/  155]    Loss 3.039536    mAP 0.457541    
2023-04-27 09:04:27,751 - Epoch: [395][  150/  155]    Loss 3.025629    mAP 0.458328    
2023-04-27 09:04:28,478 - Epoch: [395][  155/  155]    Loss 3.025943    mAP 0.458235    
2023-04-27 09:04:28,545 - ==> mAP: 0.45823    Loss: 3.026

2023-04-27 09:04:28,548 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 09:04:28,548 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 09:04:28,583 - 

2023-04-27 09:04:28,583 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 09:04:40,330 - Epoch: [396][   50/  518]    Overall Loss 2.889794    Objective Loss 2.889794                                        LR 0.000008    Time 0.234897    
2023-04-27 09:04:51,182 - Epoch: [396][  100/  518]    Overall Loss 2.873933    Objective Loss 2.873933                                        LR 0.000008    Time 0.225948    
2023-04-27 09:05:01,943 - Epoch: [396][  150/  518]    Overall Loss 2.870502    Objective Loss 2.870502                                        LR 0.000008    Time 0.222359    
2023-04-27 09:05:12,718 - Epoch: [396][  200/  518]    Overall Loss 2.860234    Objective Loss 2.860234                                        LR 0.000008    Time 0.220635    
2023-04-27 09:05:23,571 - Epoch: [396][  250/  518]    Overall Loss 2.861818    Objective Loss 2.861818                                        LR 0.000008    Time 0.219915    
2023-04-27 09:05:34,402 - Epoch: [396][  300/  518]    Overall Loss 2.862359    Objective Loss 2.862359                                        LR 0.000008    Time 0.219362    
2023-04-27 09:05:45,271 - Epoch: [396][  350/  518]    Overall Loss 2.864253    Objective Loss 2.864253                                        LR 0.000008    Time 0.219073    
2023-04-27 09:05:56,110 - Epoch: [396][  400/  518]    Overall Loss 2.860673    Objective Loss 2.860673                                        LR 0.000008    Time 0.218784    
2023-04-27 09:06:06,900 - Epoch: [396][  450/  518]    Overall Loss 2.853595    Objective Loss 2.853595                                        LR 0.000008    Time 0.218448    
2023-04-27 09:06:17,731 - Epoch: [396][  500/  518]    Overall Loss 2.849766    Objective Loss 2.849766                                        LR 0.000008    Time 0.218261    
2023-04-27 09:06:21,524 - Epoch: [396][  518/  518]    Overall Loss 2.854478    Objective Loss 2.854478                                        LR 0.000008    Time 0.217999    
2023-04-27 09:06:21,601 - --- validate (epoch=396)-----------
2023-04-27 09:06:21,602 - 4952 samples (32 per mini-batch)
2023-04-27 09:06:29,888 - Epoch: [396][   50/  155]    Loss 3.086509    mAP 0.438031    
2023-04-27 09:06:37,834 - Epoch: [396][  100/  155]    Loss 3.046841    mAP 0.441977    
2023-04-27 09:06:45,767 - Epoch: [396][  150/  155]    Loss 3.028003    mAP 0.449807    
2023-04-27 09:06:46,497 - Epoch: [396][  155/  155]    Loss 3.027378    mAP 0.448580    
2023-04-27 09:06:46,581 - ==> mAP: 0.44858    Loss: 3.027

2023-04-27 09:06:46,584 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 09:06:46,584 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 09:06:46,619 - 

2023-04-27 09:06:46,619 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 09:06:58,191 - Epoch: [397][   50/  518]    Overall Loss 2.854081    Objective Loss 2.854081                                        LR 0.000008    Time 0.231391    
2023-04-27 09:07:09,038 - Epoch: [397][  100/  518]    Overall Loss 2.853952    Objective Loss 2.853952                                        LR 0.000008    Time 0.224152    
2023-04-27 09:07:19,795 - Epoch: [397][  150/  518]    Overall Loss 2.863148    Objective Loss 2.863148                                        LR 0.000008    Time 0.221136    
2023-04-27 09:07:30,692 - Epoch: [397][  200/  518]    Overall Loss 2.862215    Objective Loss 2.862215                                        LR 0.000008    Time 0.220328    
2023-04-27 09:07:41,582 - Epoch: [397][  250/  518]    Overall Loss 2.853305    Objective Loss 2.853305                                        LR 0.000008    Time 0.219815    
2023-04-27 09:07:52,407 - Epoch: [397][  300/  518]    Overall Loss 2.847071    Objective Loss 2.847071                                        LR 0.000008    Time 0.219257    
2023-04-27 09:08:03,148 - Epoch: [397][  350/  518]    Overall Loss 2.844636    Objective Loss 2.844636                                        LR 0.000008    Time 0.218621    
2023-04-27 09:08:13,938 - Epoch: [397][  400/  518]    Overall Loss 2.838235    Objective Loss 2.838235                                        LR 0.000008    Time 0.218265    
2023-04-27 09:08:24,688 - Epoch: [397][  450/  518]    Overall Loss 2.838606    Objective Loss 2.838606                                        LR 0.000008    Time 0.217897    
2023-04-27 09:08:35,477 - Epoch: [397][  500/  518]    Overall Loss 2.840534    Objective Loss 2.840534                                        LR 0.000008    Time 0.217684    
2023-04-27 09:08:39,206 - Epoch: [397][  518/  518]    Overall Loss 2.839304    Objective Loss 2.839304                                        LR 0.000008    Time 0.217317    
2023-04-27 09:08:39,282 - --- validate (epoch=397)-----------
2023-04-27 09:08:39,283 - 4952 samples (32 per mini-batch)
2023-04-27 09:08:47,583 - Epoch: [397][   50/  155]    Loss 3.034619    mAP 0.443384    
2023-04-27 09:08:55,564 - Epoch: [397][  100/  155]    Loss 3.036795    mAP 0.439716    
2023-04-27 09:09:03,493 - Epoch: [397][  150/  155]    Loss 3.033041    mAP 0.443013    
2023-04-27 09:09:04,203 - Epoch: [397][  155/  155]    Loss 3.034255    mAP 0.441952    
2023-04-27 09:09:04,277 - ==> mAP: 0.44195    Loss: 3.034

2023-04-27 09:09:04,281 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 09:09:04,281 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 09:09:04,315 - 

2023-04-27 09:09:04,316 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 09:09:15,982 - Epoch: [398][   50/  518]    Overall Loss 2.828162    Objective Loss 2.828162                                        LR 0.000008    Time 0.233270    
2023-04-27 09:09:26,794 - Epoch: [398][  100/  518]    Overall Loss 2.845164    Objective Loss 2.845164                                        LR 0.000008    Time 0.224744    
2023-04-27 09:09:37,643 - Epoch: [398][  150/  518]    Overall Loss 2.836454    Objective Loss 2.836454                                        LR 0.000008    Time 0.222146    
2023-04-27 09:09:48,520 - Epoch: [398][  200/  518]    Overall Loss 2.839886    Objective Loss 2.839886                                        LR 0.000008    Time 0.220988    
2023-04-27 09:09:59,379 - Epoch: [398][  250/  518]    Overall Loss 2.835748    Objective Loss 2.835748                                        LR 0.000008    Time 0.220216    
2023-04-27 09:10:10,169 - Epoch: [398][  300/  518]    Overall Loss 2.843931    Objective Loss 2.843931                                        LR 0.000008    Time 0.219477    
2023-04-27 09:10:20,964 - Epoch: [398][  350/  518]    Overall Loss 2.840271    Objective Loss 2.840271                                        LR 0.000008    Time 0.218960    
2023-04-27 09:10:31,757 - Epoch: [398][  400/  518]    Overall Loss 2.843867    Objective Loss 2.843867                                        LR 0.000008    Time 0.218569    
2023-04-27 09:10:42,495 - Epoch: [398][  450/  518]    Overall Loss 2.843937    Objective Loss 2.843937                                        LR 0.000008    Time 0.218142    
2023-04-27 09:10:53,350 - Epoch: [398][  500/  518]    Overall Loss 2.844779    Objective Loss 2.844779                                        LR 0.000008    Time 0.218035    
2023-04-27 09:10:57,097 - Epoch: [398][  518/  518]    Overall Loss 2.845338    Objective Loss 2.845338                                        LR 0.000008    Time 0.217692    
2023-04-27 09:10:57,175 - --- validate (epoch=398)-----------
2023-04-27 09:10:57,175 - 4952 samples (32 per mini-batch)
2023-04-27 09:11:05,534 - Epoch: [398][   50/  155]    Loss 3.059549    mAP 0.439681    
2023-04-27 09:11:13,478 - Epoch: [398][  100/  155]    Loss 3.042070    mAP 0.448026    
2023-04-27 09:11:21,434 - Epoch: [398][  150/  155]    Loss 3.033927    mAP 0.455180    
2023-04-27 09:11:22,160 - Epoch: [398][  155/  155]    Loss 3.028840    mAP 0.457442    
2023-04-27 09:11:22,234 - ==> mAP: 0.45744    Loss: 3.029

2023-04-27 09:11:22,238 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 09:11:22,238 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 09:11:22,273 - 

2023-04-27 09:11:22,274 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-27 09:11:33,784 - Epoch: [399][   50/  518]    Overall Loss 2.900167    Objective Loss 2.900167                                        LR 0.000008    Time 0.230155    
2023-04-27 09:11:44,576 - Epoch: [399][  100/  518]    Overall Loss 2.892673    Objective Loss 2.892673                                        LR 0.000008    Time 0.222984    
2023-04-27 09:11:55,322 - Epoch: [399][  150/  518]    Overall Loss 2.862588    Objective Loss 2.862588                                        LR 0.000008    Time 0.220285    
2023-04-27 09:12:06,100 - Epoch: [399][  200/  518]    Overall Loss 2.858342    Objective Loss 2.858342                                        LR 0.000008    Time 0.219094    
2023-04-27 09:12:16,891 - Epoch: [399][  250/  518]    Overall Loss 2.860577    Objective Loss 2.860577                                        LR 0.000008    Time 0.218434    
2023-04-27 09:12:27,718 - Epoch: [399][  300/  518]    Overall Loss 2.857732    Objective Loss 2.857732                                        LR 0.000008    Time 0.218113    
2023-04-27 09:12:38,484 - Epoch: [399][  350/  518]    Overall Loss 2.861838    Objective Loss 2.861838                                        LR 0.000008    Time 0.217709    
2023-04-27 09:12:49,273 - Epoch: [399][  400/  518]    Overall Loss 2.859286    Objective Loss 2.859286                                        LR 0.000008    Time 0.217463    
2023-04-27 09:13:00,120 - Epoch: [399][  450/  518]    Overall Loss 2.863566    Objective Loss 2.863566                                        LR 0.000008    Time 0.217402    
2023-04-27 09:13:10,982 - Epoch: [399][  500/  518]    Overall Loss 2.864670    Objective Loss 2.864670                                        LR 0.000008    Time 0.217383    
2023-04-27 09:13:14,740 - Epoch: [399][  518/  518]    Overall Loss 2.860107    Objective Loss 2.860107                                        LR 0.000008    Time 0.217084    
2023-04-27 09:13:14,817 - --- validate (epoch=399)-----------
2023-04-27 09:13:14,817 - 4952 samples (32 per mini-batch)
2023-04-27 09:13:23,096 - Epoch: [399][   50/  155]    Loss 3.032493    mAP 0.453379    
2023-04-27 09:13:31,052 - Epoch: [399][  100/  155]    Loss 3.023493    mAP 0.449258    
2023-04-27 09:13:38,973 - Epoch: [399][  150/  155]    Loss 3.024590    mAP 0.459217    
2023-04-27 09:13:39,693 - Epoch: [399][  155/  155]    Loss 3.023713    mAP 0.458375    
2023-04-27 09:13:39,772 - ==> mAP: 0.45838    Loss: 3.024

2023-04-27 09:13:39,775 - ==> Best [mAP: 0.461116   vloss: 3.029455   Sparsity:0.00   Params: 2177087 on epoch: 385]
2023-04-27 09:13:39,776 - Saving checkpoint to: logs/2023.04.26-184348/qat_checkpoint.pth.tar
2023-04-27 09:13:39,810 - --- test ---------------------
2023-04-27 09:13:39,810 - 4952 samples (32 per mini-batch)
2023-04-27 09:13:48,098 - Test: [   50/  155]    Loss 3.027062    mAP 0.451130    
2023-04-27 09:13:56,022 - Test: [  100/  155]    Loss 3.032714    mAP 0.440267    
2023-04-27 09:14:03,925 - Test: [  150/  155]    Loss 3.031370    mAP 0.441334    
2023-04-27 09:14:04,636 - Test: [  155/  155]    Loss 3.028019    mAP 0.442482    
2023-04-27 09:14:04,710 - ==> mAP: 0.44248    Loss: 3.028

2023-04-27 09:14:04,713 - 
2023-04-27 09:14:04,713 - Log file for this run: /home/seldauyanik/Workspace/ai8x-training/logs/2023.04.26-184348/2023.04.26-184348.log
